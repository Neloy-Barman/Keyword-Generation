abstracts,ieee_keywords,author_keywords
"The global bandwidth shortage facing wireless carriers has motivated the exploration of the underutilized millimeter wave (mm-wave) frequency spectrum for future broadband cellular communication networks. There is, however, little knowledge about cellular mm-wave propagation in densely populated indoor and outdoor environments. Obtaining this information is vital for the design and operation of future fifth generation cellular networks that use the mm-wave spectrum. In this paper, we present the motivation for new mm-wave cellular systems, methodology, and hardware for measurements and offer a variety of measurement results that show 28 and 38 GHz frequencies can be used when employing steerable directional antennas at base stations and mobile devices.",[],[]
"Motivated by the recent explosion of interest around blockchains, we examine whether they make a good fit for the Internet of Things (IoT) sector. Blockchains allow us to have a distributed peer-to-peer network where non-trusting members can interact with each other without a trusted intermediary, in a verifiable manner. We review how this mechanism works and also look into smart contracts-scripts that reside on the blockchain that allow for the automation of multi-step processes. We then move into the IoT domain, and describe how a blockchain-IoT combination: 1) facilitates the sharing of services and resources leading to the creation of a marketplace of services between devices and 2) allows us to automate in a cryptographically verifiable manner several existing, time-consuming workflows. We also point out certain issues that should be considered before the deployment of a blockchain network in an IoT setting: from transactional privacy to the expected value of the digitized assets traded on the network. Wherever applicable, we identify solutions and workarounds. Our conclusion is that the blockchain-IoT combination is powerful and can cause significant transformations across several industries, paving the way for new business models and novel, distributed applications.","['Distributed processing', 'Internet of things', 'Cryptography', 'Privacy', 'Blockchains', 'Automation', 'Peer-to-peer computing']","['blockchain', 'distributed systems', 'Internet of Things']"
"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.","['Conferences', 'Machine learning', 'Market research', 'Prediction algorithms', 'Machine learning algorithms', 'Biological system modeling']","['Explainable artificial intelligence', 'interpretable machine learning', 'black-box models']"
"The Internet of Things (IoT) makes smart objects the ultimate building blocks in the development of cyber-physical smart pervasive frameworks. The IoT has a variety of application domains, including health care. The IoT revolution is redesigning modern health care with promising technological, economic, and social prospects. This paper surveys advances in IoT-based health care technologies and reviews the state-of-the-art network architectures/platforms, applications, and industrial trends in IoT-based health care solutions. In addition, this paper analyzes distinct IoT security and privacy features, including security requirements, threat models, and attack taxonomies from the health care perspective. Further, this paper proposes an intelligent collaborative security model to minimize security risk; discusses how different innovations such as big data, ambient intelligence, and wearables can be leveraged in a health care context; addresses various IoT and eHealth policies and regulations across the world to determine how they can facilitate economies and societies in terms of sustainable development; and provides some avenues for future research on IoT-based health care based on a set of open issues and challenges.","['Internet of things', 'Medical services', 'Network security', 'Network architecture', 'Biological system modeling', 'Market research']","['Internet of Things', 'Health Care', 'Services', 'Applications', 'Networks', 'Architectures', 'Platforms', 'Security', 'Technologies', 'Industries', 'Policies', 'Challenges']"
"In the near future, i.e., beyond 4G, some of the prime objectives or demands that need to be addressed are increased capacity, improved data rate, decreased latency, and better quality of service. To meet these demands, drastic improvements need to be made in cellular network architecture. This paper presents the results of a detailed survey on the fifth generation (5G) cellular network architecture and some of the key emerging technologies that are helpful in improving the architecture and meeting the demands of users. In this detailed survey, the prime focus is on the 5G cellular network architecture, massive multiple input multiple output technology, and device-to-device communication (D2D). Along with this, some of the emerging technologies that are addressed in this paper include interference management, spectrum sharing with cognitive radio, ultra-dense networks, multi-radio access technology association, full duplex radios, millimeter wave solutions for 5G cellular networks, and cloud technologies for 5G radio access networks and software defined networks. In this paper, a general probable 5G cellular network architecture is proposed, which shows that D2D, small cell access points, network cloud, and the Internet of Things can be a part of 5G cellular network architecture. A detailed survey is included regarding current research projects being conducted in different countries by research groups and institutions that are working on 5G technologies.","['5G mobile communication', 'Cloud computing', 'MIMO', 'Radio access networks', 'Cellular networks']","['5G', 'Cloud', 'D2D', 'Massive MIMO', 'mm-wave', 'Relay', 'Small-cel']"
"The future of mobile communications looks exciting with the potential new use cases and challenging requirements of future 6th generation (6G) and beyond wireless networks. Since the beginning of the modern era of wireless communications, the propagation medium has been perceived as a randomly behaving entity between the transmitter and the receiver, which degrades the quality of the received signal due to the uncontrollable interactions of the transmitted radio waves with the surrounding objects. The recent advent of reconfigurable intelligent surfaces in wireless communications enables, on the other hand, network operators to control the scattering, reflection, and refraction characteristics of the radio waves, by overcoming the negative effects of natural wireless propagation. Recent results have revealed that reconfigurable intelligent surfaces can effectively control the wavefront, e.g., the phase, amplitude, frequency, and even polarization, of the impinging signals without the need of complex decoding, encoding, and radio frequency processing operations. Motivated by the potential of this emerging technology, the present article is aimed to provide the readers with a detailed overview and historical perspective on state-of-the-art solutions, and to elaborate on the fundamental differences with other technologies, the most important open research issues to tackle, and the reasons why the use of reconfigurable intelligent surfaces necessitates to rethink the communication-theoretic models currently employed in wireless networks. This article also explores theoretical performance limits of reconfigurable intelligent surface-assisted communication systems using mathematical techniques and elaborates on the potential use cases of intelligent surfaces in 6G and beyond wireless networks.","['Wireless networks', '5G mobile communication', 'Surface waves', 'STEM', '6G mobile communication']","['6G', 'large intelligent surfaces', 'meta-surfaces', 'reconfigurable intelligent surfaces', 'smart reflect-arrays', 'software-defined surfaces', 'wireless communications', 'wireless networks']"
"Frequencies from 100 GHz to 3 THz are promising bands for the next generation of wireless communication systems because of the wide swaths of unused and unexplored spectrum. These frequencies also offer the potential for revolutionary applications that will be made possible by new thinking, and advances in devices, circuits, software, signal processing, and systems. This paper describes many of the technical challenges and opportunities for wireless communication and sensing applications above 100 GHz, and presents a number of promising discoveries, novel approaches, and recent results that will aid in the development and implementation of the sixth generation (6G) of wireless networks, and beyond. This paper shows recent regulatory and standard body rulings that are anticipating wireless products and services above 100 GHz and illustrates the viability of wireless cognition, hyper-accurate position location, sensing, and imaging. This paper also presents approaches and results that show how long distance mobile communications will be supported to above 800 GHz since the antenna gains are able to overcome air-induced attenuation, and present methods that reduce the computational complexity and simplify the signal processing used in adaptive antenna arrays, by exploiting the Special Theory of Relativity to create a cone of silence in over-sampled antenna arrays that improve performance for digital phased array antennas. Also, new results that give insights into power efficient beam steering algorithms, and new propagation and partition loss models above 100 GHz are given, and promising imaging, array processing, and position location results are presented. The implementation of spatial consistency at THz frequencies, an important component of channel modeling that considers minute changes and correlations over space, is also discussed. This paper offers the first in-depth look at the vast applications of THz wireless products and applications and provides approaches for how to reduce power and increase performance across several problem domains, giving early evidence that THz techniques are compelling and available for future wireless communications.","['Wireless communication', 'Wireless sensor networks', 'Antenna arrays', 'Bandwidth', 'Communication system security', 'Cognition', 'Imaging']","['mmWave', 'millimeter wave', '5G', 'D-band', '6G', 'channel sounder', 'propagation measurements', 'Terahertz (THz)', 'array processing', 'imaging', 'scattering theory', 'cone of silence', 'digital phased arrays', 'digital beamformer', 'signal processing for THz', 'position location', 'channel modeling', 'THz applications', 'wireless cognition', 'network offloading']"
"The use of unmanned aerial vehicles (UAVs) is growing rapidly across many civil application domains, including real-time monitoring, providing wireless coverage, remote sensing, search and rescue, delivery of goods, security and surveillance, precision agriculture, and civil infrastructure inspection. Smart UAVs are the next big revolution in the UAV technology promising to provide new opportunities in different applications, especially in civil infrastructure in terms of reduced risks and lower cost. Civil infrastructure is expected to dominate more than $45 Billion market value of UAV usage. In this paper, we present UAV civil applications and their challenges. We also discuss the current research trends and provide future insights for potential UAV uses. Furthermore, we present the key challenges for UAV civil applications, including charging challenges, collision avoidance and swarming challenges, and networking and security-related challenges. Based on our review of the recent literature, we discuss open research challenges and draw high-level insights on how these challenges might be approached.","['Unmanned aerial vehicles', 'Market research', 'Wireless sensor networks', 'Wireless communication', 'Communication system security', 'Security', 'Surveillance']","['Civil infrastructure inspection', 'delivery of goods', 'precision agriculture', 'real-time monitoring', 'remote sensing', 'search and rescue', 'security and surveillance', 'UAVs', 'wireless coverage']"
"Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.","['Machine learning', 'Perturbation methods', 'Computer vision', 'Computational modeling', 'Neural networks', 'Task analysis', 'Predictive models']","['Deep learning', 'adversarial perturbation', 'black-box attack', 'white-box attack', 'adversarial learning', 'perturbation detection']"
"Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.","['Intrusion detection', 'Machine learning', 'Recurrent neural networks', 'Training', 'Computational modeling', 'Testing', 'Support vector machines']","['Recurrent neural networks', 'RNN-IDS', 'intrusion detection', 'deep learning', 'machine learning']"
"Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%, 97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic where disease burden and need for preventive measures are at odds with available resources.","['Diseases', 'Lung', 'Databases', 'X-ray imaging', 'Machine learning', 'Tools', 'COVID-19']","['Artificial intelligence', 'COVID-19 pneumonia', 'machine learning', 'transfer learning', 'viral pneumonia', 'computer-aided diagnostic tool']"
"The Internet of Things (IoT) now permeates our daily lives, providing important measurement and collection tools to inform our every decision. Millions of sensors and devices are continuously producing data and exchanging important messages via complex networks supporting machine-to-machine communications and monitoring and controlling critical smart-world infrastructures. As a strategy to mitigate the escalation in resource congestion, edge computing has emerged as a new paradigm to solve IoT and localized computing needs. Compared with the well-known cloud computing, edge computing will migrate data computation or storage to the network “edge”, near the end users. Thus, a number of computation nodes distributed across the network can offload the computational stress away from the centralized data center, and can significantly reduce the latency in message exchange. In addition, the distributed structure can balance network traffic and avoid the traffic peaks in IoT networks, reducing the transmission latency between edge/cloudlet servers and end users, as well as reducing response times for real-time IoT applications in comparison with traditional cloud services. Furthermore, by transferring computation and communication overhead from nodes with limited battery supply to nodes with significant power resources, the system can extend the lifetime of the individual nodes. In this paper, we conduct a comprehensive survey, analyzing how edge computing improves the performance of IoT networks. We categorize edge computing into different groups based on architecture, and study their performance by comparing network latency, bandwidth occupation, energy consumption, and overhead. In addition, we consider security issues in edge computing, evaluating the availability, integrity, and the confidentiality of security strategies of each group, and propose a framework for security evaluation of IoT networks with edge computing. Finally, we compare the performance of various IoT applications (smart city, smart grid, smart transportation, and so on) in edge computing and traditional cloud computing architectures.","['Edge computing', 'Cloud computing', 'Logic gates', 'Servers', 'Security', 'Intelligent sensors']","['Edge computing', 'Internet of Things', 'survey']"
"Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.","['Deep learning', 'Training', 'Computer architecture', 'Feature extraction', 'Recurrent neural networks', 'Feedforward neural networks']","['Machine learning algorithm', 'optimization', 'artificial intelligence', 'deep neural network architectures', 'convolution neural network', 'backpropagation', 'supervised and unsupervised learning']"
"The Internet of Things (IoT) is a promising technology which tends to revolutionize and connect the global world via heterogeneous smart devices through seamless connectivity. The current demand for machine-type communications (MTC) has resulted in a variety of communication technologies with diverse service requirements to achieve the modern IoT vision. More recent cellular standards like long-term evolution (LTE) have been introduced for mobile devices but are not well suited for low-power and low data rate devices such as the IoT devices. To address this, there is a number of emerging IoT standards. Fifth generation (5G) mobile network, in particular, aims to address the limitations of previous cellular standards and be a potential key enabler for future IoT. In this paper, the state-of-the-art of the IoT application requirements along with their associated communication technologies are surveyed. In addition, the third generation partnership project cellular-based low-power wide area solutions to support and enable the new service requirements for Massive to Critical IoT use cases are discussed in detail, including extended coverage global system for mobile communications for the Internet of Things, enhanced machine-type communications, and narrowband-Internet of Things. Furthermore, 5G new radio enhancements for new service requirements and enabling technologies for the IoT are introduced. This paper presents a comprehensive review related to emerging and enabling technologies with main focus on 5G mobile networks that is envisaged to support the exponential traffic growth for enabling the IoT. The challenges and open research directions pertinent to the deployment of massive to critical IoT applications are also presented in coming up with an efficient context-aware congestion control mechanism.","['5G mobile communication', 'Machine-to-machine communications', 'Mobile computing', 'Internet of Things']","['Internet of Things', 'long-term evolution', 'machine-type communications', '5G new radio']"
"With the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. Intelligence comes from data. Integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. Besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. In this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. On this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. Since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.","['Big Data', 'Data mining', 'Internet', 'Product design', 'Real-time systems']","['Big data', 'digital twin', 'smart manufacturing', 'comprehensive comparison', 'convergence']"
"Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.","['Machine learning', 'Pattern recognition', 'Big data', 'Natural language processing', 'Data processing', 'Information analysis']","['Classifier design and evaluation', 'feature representation', 'machine learning', 'neural nets models', 'parallel processing']"
"The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.","['Image analysis', 'Machine learning algorithms', 'Medical diagnostic imaging', 'Convolution']","['Convolutional neural networks', 'medical image analysis', 'machine learning', 'deep learning']"
"Underwater wireless information transfer is of great interest to the military, industry, and the scientific community, as it plays an important role in tactical surveillance, pollution monitoring, oil control and maintenance, offshore explorations, climate change monitoring, and oceanography research. In order to facilitate all these activities, there is an increase in the number of unmanned vehicles or devices deployed underwater, which require high bandwidth and high capacity for information transfer underwater. Although tremendous progress has been made in the field of acoustic communication underwater, however, it is limited by bandwidth. All this has led to the proliferation of underwater optical wireless communication (UOWC), as it provides higher data rates than the traditional acoustic communication systems with significantly lower power consumption and simpler computational complexities for short-range wireless links. UOWC has many potential applications ranging from deep oceans to coastal waters. However, the biggest challenge for underwater wireless communication originates from the fundamental characteristics of ocean or sea water; addressing these challenges requires a thorough understanding of complex physio-chemical biological systems. In this paper, the main focus is to understand the feasibility and the reliability of high data rate underwater optical links due to various propagation phenomena that impact the performance of the system. This paper provides an exhaustive overview of recent advances in UOWC. Channel characterization, modulation schemes, coding techniques, and various sources of noise which are specific to UOWC are discussed. This paper not only provides exhaustive research in underwater optical communication but also aims to provide the development of new ideas that would help in the growth of future underwater communication. A hybrid approach to an acousto-optic communication system is presented that complements the existing acoustic system, resulting in high data rates, low latency, and an energy-efficient system.","['Wireless communication', 'Optical fiber communication', 'Bandwidth allocation', 'Acoustic communication', 'Oceans', 'Underwater communication', 'Radio frequency', 'Modulation', 'Climate change']","['Underwater optical wireless', 'optical beam propagation', 'visible light', 'radio frequency', 'acoustic communication', 'hybrid optical-acoustic system', 'modulation and coding']"
"Sparse representation has attracted much attention from researchers in fields of signal processing, image processing, computer vision, and pattern recognition. Sparse representation also has a good reputation in both theoretical research and practical applications. Many different algorithms have been proposed for sparse representation. The main purpose of this paper is to provide a comprehensive study and an updated review on sparse representation and to supply guidance for researchers. The taxonomy of sparse representation methods can be studied from various viewpoints. For example, in terms of different norm minimizations used in sparsity constraints, the methods can be roughly categorized into five groups: 1) sparse representation with l 0 -norm minimization; 2) sparse representation with lp-norm (0 <; p <; 1) minimization; 3) sparse representation with l 1 -norm minimization; 4) sparse representation with l 2 ,1-norm minimization; and 5) sparse representation with l2-norm minimization. In this paper, a comprehensive overview of sparse representation is provided. The available sparse representation algorithms can also be empirically categorized into four groups: 1) greedy strategy approximation; 2) constrained optimization; 3) proximity algorithm-based optimization; and 4) homotopy algorithm-based sparse representation. The rationales of different algorithms in each category are analyzed and a wide range of sparse representation applications are summarized, which could sufficiently reveal the potential nature of the sparse representation theory. In particular, an experimentally comparative study of these sparse representation algorithms was presented.","['Sparse matrices', 'Algorithm design and analysis', 'Signal processing algorithms', 'Approximation algorithms', 'Approximation methods', 'Signal processing']","['Sparse representation', 'compressive sensing', 'greedy algorithm', 'constrained optimization', 'proximal algorithm', 'homotopy algorithm', 'dictionary learning']"
"Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01-0.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks.","['Intrusion detection', 'Computer security', 'Deep learning', 'Malware', 'Benchmark testing']","['Cyber security', 'intrusion detection', 'malware', 'big data', 'machine learning', 'deep learning', 'deep neural networks', 'cyberattacks', 'cybercrime']"
"The significant benefits associated with microgrids have led to vast efforts to expand their penetration in electric power systems. Although their deployment is rapidly growing, there are still many challenges to efficiently design, control, and operate microgrids when connected to the grid, and also when in islanded mode, where extensive research activities are underway to tackle these issues. It is necessary to have an across-the-board view of the microgrid integration in power systems. This paper presents a review of issues concerning microgrids and provides an account of research in areas related to microgrids, including distributed generation, microgrid value propositions, applications of power electronics, economic issues, microgrid operation and control, microgrid clusters, and protection and communications issues.",[],[]
"Digital Twin technology is an emerging concept that has become the centre of attention for industry and, in more recent years, academia. The advancements in industry 4.0 concepts have facilitated its growth, particularly in the manufacturing industry. The Digital Twin is defined extensively but is best described as the effortless integration of data between a physical and virtual machine in either direction. The challenges, applications, and enabling technologies for Artificial Intelligence, Internet of Things (IoT) and Digital Twins are presented. A review of publications relating to Digital Twins is performed, producing a categorical review of recent papers. The review has categorised them by research areas: manufacturing, healthcare and smart cities, discussing a range of papers that reflect these areas and the current state of research. The paper provides an assessment of the enabling technologies, challenges and open research for Digital Twins.","['Smart cities', 'Data analysis', 'Manufacturing', 'Data models', 'Internet of Things', 'Computational modeling']","['Digital twins', 'applications', 'enabling technologies', 'industrial Internet of Things (IIoT)', 'Internet of Things (IoT)', 'machine learning', 'deep learning', 'literature review']"
"The Internet of Things (IoT) is the next era of communication. Using the IoT, physical objects can be empowered to create, receive, and exchange data in a seamless manner. Various IoT applications focus on automating different tasks and are trying to empower the inanimate physical objects to act without any human intervention. The existing and upcoming IoT applications are highly promising to increase the level of comfort, efficiency, and automation for the users. To be able to implement such a world in an ever-growing fashion requires high security, privacy, authentication, and recovery from attacks. In this regard, it is imperative to make the required changes in the architecture of the IoT applications for achieving end-to-end secure IoT environments. In this paper, a detailed review of the security-related challenges and sources of threat in the IoT applications is presented. After discussing the security issues, various emerging and existing technologies focused on achieving a high degree of trust in the IoT applications are discussed. Four different technologies, blockchain, fog computing, edge computing, and machine learning, to increase the level of security in IoT are discussed.","['Internet of Things', 'Security', 'Edge computing', 'Computer architecture', 'Privacy', 'Blockchain']","['Internet of Things (IoT)', 'IoT security', 'blockchain', 'fog computing', 'edge computing', 'machine learning', 'IoT applications', 'distributed systems']"
"The dissemination of patients' medical records results in diverse risks to patients' privacy as malicious activities on these records cause severe damage to the reputation, finances, and so on of all parties related directly or indirectly to the data. Current methods to effectively manage and protect medical records have been proved to be insufficient. In this paper, we propose MeDShare, a system that addresses the issue of medical data sharing among medical big data custodians in a trust-less environment. The system is blockchain-based and provides data provenance, auditing, and control for shared medical data in cloud repositories among big data entities. MeDShare monitors entities that access data for malicious use from a data custodian system. In MeDShare, data transitions and sharing from one entity to the other, along with all actions performed on the MeDShare system, are recorded in a tamper-proof manner. The design employs smart contracts and an access control mechanism to effectively track the behavior of the data and revoke access to offending entities on detection of violation of permissions on data. The performance of MeDShare is comparable to current cutting edge solutions to data sharing among cloud service providers. By implementing MeDShare, cloud service providers and other data guardians will be able to achieve data provenance and auditing while sharing medical data with entities such as research and medical institutions with minimal risk to data privacy.","['Cloud computing', 'Contracts', 'Access control', 'Electronic mail', 'Monitoring', 'Public key']","['Access control', 'blockchain', 'cloud computing', 'data sharing', 'electronic medical records', 'privacy']"
"Recent technological advancements have led to a deluge of data from distinctive domains (e.g., health care and scientific sensors, user-generated data, Internet and financial companies, and supply chain systems) over the past two decades. The term big data was coined to capture the meaning of this emerging trend. In addition to its sheer volume, big data also exhibits other unique characteristics as compared with traditional data. For instance, big data is commonly unstructured and require more real-time analysis. This development calls for new system architectures for data acquisition, transmission, storage, and large-scale data processing mechanisms. In this paper, we present a literature survey and system tutorial for big data analytics platforms, aiming to provide an overall picture for nonexpert readers and instill a do-it-yourself spirit for advanced audiences to customize their own big-data solutions. First, we present the definition of big data and discuss big data challenges. Next, we present a systematic framework to decompose big data systems into four sequential modules, namely data generation, data acquisition, data storage, and data analytics. These four modules form a big data value chain. Following that, we present a detailed survey of numerous approaches and mechanisms from research and industry communities. In addition, we present the prevalent Hadoop framework for addressing big data challenges. Finally, we outline several evaluation benchmarks and potential research directions for big data systems.","['Big data', 'Information analysis', 'Scalability', 'Data acquisition', 'Medical services', 'Supply chain management', 'Sensor phenomena and characterization', 'Sensor systems', 'Real-time systems', 'Tutorials']","['Big data analytics', 'cloud computing', 'data acquisition', 'data storage', 'data analytics', 'Hadoop']"
"With the developments and applications of the new information technologies, such as cloud computing, Internet of Things, big data, and artificial intelligence, a smart manufacturing era is coming. At the same time, various national manufacturing development strategies have been put forward, such as Industry 4.0, Industrial Internet, manufacturing based on Cyber-Physical System, and Made in China 2025. However, one of specific challenges to achieve smart manufacturing with these strategies is how to converge the manufacturing physical world and the virtual world, so as to realize a series of smart operations in the manufacturing process, including smart interconnection, smart interaction, smart control and management, etc. In this context, as a basic unit of manufacturing, shop-floor is required to reach the interaction and convergence between physical and virtual spaces, which is not only the imperative demand of smart manufacturing, but also the evolving trend of itself. Accordingly, a novel concept of digital twin shopfloor (DTS) based on digital twin is explored and its four key components are discussed, including physical shop-floor, virtual shop-floor, shop-floor service system, and shop-floor digital twin data. What is more, the operation mechanisms and implementing methods for DTS are studied and key technologies as well as challenges ahead are investigated, respectively.","['Production', 'Manufacturing', 'Convergence', 'Data models', 'Aerospace electronics', 'Optimization', 'Cloud computing']","['Smart manufacturing', 'digital twin shop-floor (DTS)', 'digital twin', 'virtual shop-floor (VS)', 'shop-floor service system (SSS)', 'shop-floor digital twin data (SDTD)', 'convergence', 'cyber-physical system (CPS)']"
"Fully convolutional neural networks (FCNs) have been shown to achieve the state-of-the-art performance on the task of classifying time series sequences. We propose the augmentation of fully convolutional networks with long short term memory recurrent neural network (LSTM RNN) sub-modules for time series classification. Our proposed models significantly enhance the performance of fully convolutional networks with a nominal increase in model size and require minimal preprocessing of the data set. The proposed long short term memory fully convolutional network (LSTM-FCN) achieves the state-of-the-art performance compared with others. We also explore the usage of attention mechanism to improve time series classification with the attention long short term memory fully convolutional network (ALSTM-FCN). The attention mechanism allows one to visualize the decision process of the LSTM cell. Furthermore, we propose refinement as a method to enhance the performance of trained models. An overall analysis of the performance of our model is provided and compared with other techniques.","['Time series analysis', 'Recurrent neural networks', 'Feature extraction', 'Convolution', 'Computer architecture', 'Machine learning', 'Machine learning algorithms']","['Convolutional neural network', 'long short term memory recurrent neural network', 'time series classification']"
"The unprecedented outbreak of the 2019 novel coronavirus, termed as COVID-19 by the World Health Organization (WHO), has placed numerous governments around the world in a precarious position. The impact of the COVID-19 outbreak, earlier witnessed by the citizens of China alone, has now become a matter of grave concern for virtually every country in the world. The scarcity of resources to endure the COVID-19 outbreak combined with the fear of overburdened healthcare systems has forced a majority of these countries into a state of partial or complete lockdown. The number of laboratory-confirmed coronavirus cases has been increasing at an alarming rate throughout the world, with reportedly more than 3 million confirmed cases as of 30 April 2020. Adding to these woes, numerous false reports, misinformation, and unsolicited fears in regards to coronavirus, are being circulated regularly since the outbreak of the COVID-19. In response to such acts, we draw on various reliable sources to present a detailed review of all the major aspects associated with the COVID-19 pandemic. In addition to the direct health implications associated with the outbreak of COVID-19, this study highlights its impact on the global economy. In drawing things to a close, we explore the use of technologies such as the Internet of Things (IoT), Unmanned Aerial Vehicles (UAVs), blockchain, Artificial Intelligence (AI), and 5G, among others, to help mitigate the impact of COVID-19 outbreak.","['COVID-19', 'Viruses (medical)', 'Pandemics', 'Artificial intelligence', 'Blockchain', '5G mobile communication']","['Coronavirus', 'COVID-19', 'pandemic', 'transmission stages', 'global economic impact', 'UAVs for disaster management', 'Blockchain', 'IoMT applications', 'IoT', 'AI', '5G']"
"Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).","['Diseases', 'Heart', 'Data mining', 'Support vector machines', 'Feature extraction', 'Machine learning', 'Predictive models']","['Machine learning', 'heart disease prediction', 'feature selection', 'prediction model', 'classification algorithms', 'cardiovascular disease (CVD)']"
"Object detection is one of the most important and challenging branches of computer vision, which has been widely applied in people’s life, such as monitoring security, autonomous driving and so on, with the purpose of locating instances of semantic objects of a certain class. With the rapid development of deep learning algorithms for detection tasks, the performance of object detectors has been greatly improved. In order to understand the main development status of object detection pipeline thoroughly and deeply, in this survey, we analyze the methods of existing typical detection models and describe the benchmark datasets at first. Afterwards and primarily, we provide a comprehensive overview of a variety of object detection methods in a systematic manner, covering the one-stage and two-stage detectors. Moreover, we list the traditional and new applications. Some representative branches of object detection are analyzed as well. Finally, we discuss the architecture of exploiting these object detection methods to build an effective and efficient system and point out a set of development trends to better follow the state-of-the-art algorithms and further research.","['Deep learning', 'Training data', 'Image classification', 'Transportation', 'Object detection', 'Detectors', 'Computer architecture', 'Computer vision', 'Pipelines']","['Classification', 'deep learning', 'localization', 'object detection', 'typical pipelines']"
"With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013-2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8% with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm.","['Diseases', 'Hospitals', 'Prediction algorithms', 'Machine learning algorithms', 'Big Data', 'Data models']","['Big data analytics', 'machine learning', 'healthcare']"
"As the explosive growth of smart devices and the advent of many new applications, traffic volume has been growing exponentially. The traditional centralized network architecture cannot accommodate such user demands due to heavy burden on the backhaul links and long latency. Therefore, new architectures, which bring network functions and contents to the network edge, are proposed, i.e., mobile edge computing and caching. Mobile edge networks provide cloud computing and caching capabilities at the edge of cellular networks. In this survey, we make an exhaustive review on the state-of-the-art research efforts on mobile edge networks. We first give an overview of mobile edge networks, including definition, architecture, and advantages. Next, a comprehensive survey of issues on computing, caching, and communication techniques at the network edge is presented. The applications and use cases of mobile edge networks are discussed. Subsequently, the key enablers of mobile edge networks, such as cloud technology, SDN/NFV, and smart devices are discussed. Finally, open research challenges and future directions are presented as well.","['Mobile communication', 'Cloud computing', 'Mobile computing', 'Edge computing', 'Computer architecture', 'Network architecture', 'Mobile handsets']","['Mobile edge computing', 'mobile edge caching', 'D2D', 'SDN', 'NFV', 'content delivery', 'computational offloading']"
"Internet of Things (IoT) technology has attracted much attention in recent years for its potential to alleviate the strain on healthcare systems caused by an aging population and a rise in chronic illness. Standardization is a key issue limiting progress in this area, and thus this paper proposes a standard model for application in future IoT healthcare systems. This survey paper then presents the state-of-the-art research relating to each area of the model, evaluating their strengths, weaknesses, and overall suitability for a wearable IoT healthcare system. Challenges that healthcare IoT faces including security, privacy, wearability, and low-power operation are presented, and recommendations are made for future research directions.","['Medical services', 'Monitoring', 'Internet of Things', 'Biomedical monitoring', 'Cloud computing', 'Strain', 'Standards']","['Biomedical engineering', 'body sensor networks', 'intelligent systems', 'Internet of Things (IoT)', 'communications standards', 'security', 'wearable sensors']"
"Due to the current structure of digital factory, it is necessary to build the smart factory to upgrade the manufacturing industry. Smart factory adopts the combination of physical technology and cyber technology and deeply integrates previously independent discrete systems making the involved technologies more complex and precise than they are now. In this paper, a hierarchical architecture of the smart factory was proposed first, and then the key technologies were analyzed from the aspects of the physical resource layer, the network layer, and the data application layer. In addition, we discussed the major issues and potential solutions to key emerging technologies, such as Internet of Things (IoT), big data, and cloud computing, which are embedded in the manufacturing process. Finally, a candy packing line was used to verify the key technologies of smart factory, which showed that the overall equipment effectiveness of the equipment is significantly improved.","['Manufacturing', 'Production facilities', 'Computer architecture', 'Cloud computing', 'Robot kinematics']","['Smart factory', 'big data', 'cloud computing', 'cyber-physical systems', 'industrial Internet of Things']"
"The paradigm of Internet of Things (IoT) is paving the way for a world, where many of our daily objects will be interconnected and will interact with their environment in order to collect information and automate certain tasks. Such a vision requires, among other things, seamless authentication, data privacy, security, robustness against attacks, easy deployment, and self-maintenance. Such features can be brought by blockchain, a technology born with a cryptocurrency called Bitcoin. In this paper, a thorough review on how to adapt blockchain to the specific needs of IoT in order to develop Blockchain-based IoT (BIoT) applications is presented. After describing the basics of blockchain, the most relevant BIoT applications are described with the objective of emphasizing how blockchain can impact traditional cloud-centered IoT applications. Then, the current challenges and possible optimizations are detailed regarding many aspects that affect the design, development, and deployment of a BIoT application. Finally, some recommendations are enumerated with the aim of guiding future BIoT researchers and developers on some of the issues that will have to be tackled before deploying the next generation of BIoT applications.","['Peer-to-peer computing', 'Bitcoin', 'Internet of Things', 'Cloud computing', 'Computer architecture']","['IoT', 'blockchain', 'traceability', 'consensus', 'distributed systems', 'BIoT', 'fog computing', 'edge computing']"
"Digital twin can be defined as a virtual representation of a physical asset enabled through data and simulators for real-time prediction, optimization, monitoring, controlling, and improved decision making. Recent advances in computational pipelines, multiphysics solvers, artificial intelligence, big data cybernetics, data processing and management tools bring the promise of digital twins and their impact on society closer to reality. Digital twinning is now an important and emerging trend in many applications. Also referred to as a computational megamodel, device shadow, mirrored system, avatar or a synchronized virtual prototype, there can be no doubt that a digital twin plays a transformative role not only in how we design and operate cyber-physical intelligent systems, but also in how we advance the modularity of multi-disciplinary systems to tackle fundamental barriers not addressed by the current, evolutionary modeling practices. In this work, we review the recent status of methodologies and techniques related to the construction of digital twins mostly from a modeling perspective. Our aim is to provide a detailed coverage of the current challenges and enabling technologies along with recommendations and reflections for various stakeholders.","['Digital twin', 'Real-time systems', 'Monitoring', 'Solid modeling', 'Biological system modeling', 'Big Data', 'Buildings']","['Digital twin', 'artificial intelligence', 'machine learning', 'big data cybernetics', 'hybrid analysis and modeling']"
"Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise. The full potential of ADSs cannot be realized unless the robustness of state-of-the-art is improved further. This paper discusses unsolved problems and surveys the technical aspect of automated driving. Studies regarding present challenges, high-level system architectures, emerging methodologies and core functions including localization, mapping, perception, planning, and human machine interfaces, were thoroughly reviewed. Furthermore, many state-of-the-art algorithms were implemented and compared on our own platform in a real-world driving setting. The paper concludes with an overview of available datasets and tools for ADS development.","['Automation', 'Task analysis', 'Systems architecture', 'Accidents', 'Planning', 'Vehicle dynamics', 'Robot sensing systems']","['Autonomous vehicles', 'control', 'robotics', 'automation', 'intelligent vehicles', 'intelligent transportation systems']"
"This paper promotes the concept of smart and connected communities SCC, which is evolving from the concept of smart cities. SCC are envisioned to address synergistically the needs of remembering the past (preservation and revitalization), the needs of living in the present (livability), and the needs of planning for the future (attainability). Therefore, the vision of SCC is to improve livability, preservation, revitalization, and attainability of a community. The goal of building SCC for a community is to live in the present, plan for the future, and remember the past. We argue that Internet of Things (IoT) has the potential to provide a ubiquitous network of connected devices and smart sensors for SCC, and big data analytics has the potential to enable the move from IoT to real-time control desired for SCC. We highlight mobile crowdsensing and cyber-physical cloud computing as two most important IoT technologies in promoting SCC. As a case study, we present TreSight, which integrates IoT and big data analytics for smart tourism and sustainable cultural heritage in the city of Trento, Italy.","['Internet of things', 'Smart cities', 'Big data', 'Sensors', 'Cultural differences', 'Economics', 'Urban areas', 'Data analytics', 'Sustainable development']","['Internet of Things', 'Big Data Analytics', 'Smart and Connected Communities', 'Smart Cities', 'Smart Tourism', 'Sustainable Cultural Heritage']"
"With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.","['Machine learning', 'Intrusion detection', 'Feature extraction', 'Machine learning algorithms', 'Computer security']","['Cybersecurity', 'intrusion detection', 'deep learning', 'machine learning']"
"Mobile edge computing (MEC) is a promising paradigm to provide cloud-computing capabilities in close proximity to mobile devices in fifth-generation (5G) networks. In this paper, we study energy-efficient computation offloading (EECO) mechanisms for MEC in 5G heterogeneous networks. We formulate an optimization problem to minimize the energy consumption of the offloading system, where the energy cost of both task computing and file transmission are taken into consideration. Incorporating the multi-access characteristics of the 5G heterogeneous network, we then design an EECO scheme, which jointly optimizes offloading and radio resource allocation to obtain the minimal energy consumption under the latency constraints. Numerical results demonstrate energy efficiency improvement of our proposed EECO scheme.","['Cloud computing', 'Mobile handsets', '5G mobile communication', 'Energy consumption', 'Energy efficiency', 'Heterogeneous networks']","['Energy-efficiency', 'offloading', 'mobile edge computing', '5G']"
"Data mining and analytics have played an important role in knowledge discovery and decision making/supports in the process industry over the past several decades. As a computational engine to data mining and analytics, machine learning serves as basic tools for information extraction, data pattern recognition and predictions. From the perspective of machine learning, this paper provides a review on existing data mining and analytics applications in the process industry over the past several decades. The state-of-the-art of data mining and analytics are reviewed through eight unsupervised learning and ten supervised learning algorithms, as well as the application status of semi-supervised learning algorithms. Several perspectives are highlighted and discussed for future researches on data mining and analytics in the process industry.","['Data mining', 'Industries', 'Data models', 'Machine learning algorithms', 'Analytical models', 'Manufacturing', 'Predictive models']","['Data mining', 'data analytics', 'machine learning', 'process industry']"
"Python has become the programming language of choice for research and industry projects related to data science, machine learning, and deep learning. Since optimization is an inherent part of these research fields, more optimization related frameworks have arisen in the past few years. Only a few of them support optimization of multiple conflicting objectives at a time, but do not provide comprehensive tools for a complete multi-objective optimization task. To address this issue, we have developed pymoo, a multi-objective optimization framework in Python. We provide a guide to getting started with our framework by demonstrating the implementation of an exemplary constrained multi-objective optimization scenario. Moreover, we give a high-level overview of the architecture of pymoo to show its capabilities followed by an explanation of each module and its corresponding sub-modules. The implementations in our framework are customizable and algorithms can be modified/extended by supplying custom operators. Moreover, a variety of single, multi- and many-objective test problems are provided and gradients can be retrieved by automatic differentiation out of the box. Also, pymoo addresses practical needs, such as the parallelization of function evaluations, methods to visualize low and high-dimensional spaces, and tools for multi-criteria decision making. For more information about pymoo, readers are encouraged to visit: https://pymoo.org.","['Optimization', 'Python', 'Tools', 'Task analysis', 'Data visualization', 'Evolutionary computation']","['Customization', 'genetic algorithm', 'multi-objective optimization', 'python']"
"The Internet of Things (IoT)-centric concepts like augmented reality, high-resolution video streaming, self-driven cars, smart environment, e-health care, etc. have a ubiquitous presence now. These applications require higher data-rates, large bandwidth, increased capacity, low latency and high throughput. In light of these emerging concepts, IoT has revolutionized the world by providing seamless connectivity between heterogeneous networks (HetNets). The eventual aim of IoT is to introduce the plug and play technology providing the end-user, ease of operation, remotely access control and configurability. This paper presents the IoT technology from a bird's eye view covering its statistical/architectural trends, use cases, challenges and future prospects. The paper also presents a detailed and extensive overview of the emerging 5G-IoT scenario. Fifth Generation (5G) cellular networks provide key enabling technologies for ubiquitous deployment of the IoT technology. These include carrier aggregation, multiple-input multiple-output (MIMO), massive-MIMO (M-MIMO), coordinated multipoint processing (CoMP), device-to-device (D2D) communications, centralized radio access network (CRAN), software-defined wireless sensor networking (SD-WSN), network function virtualization (NFV) and cognitive radios (CRs). This paper presents an exhaustive review for these key enabling technologies and also discusses the new emerging use cases of 5G-IoT driven by the advances in artificial intelligence, machine and deep learning, ongoing 5G initiatives, quality of service (QoS) requirements in 5G and its standardization issues. Finally, the paper discusses challenges in the implementation of 5G-IoT due to high data-rates requiring both cloud-based platforms and IoT devices based edge computing.","['5G mobile communication', 'Market research', 'Protocols', 'Internet of Things', 'Quality of service', 'Security', 'Next generation networking']","['Internet of Things (IoT)', '5G', 'carrier aggregation', 'CoMP', 'CRAN', 'CRs', 'HetNets', 'MIMO', 'M-MIMO', 'NFV', 'SD-WSN', 'QoS']"
"Hybrid analog/digital multiple-input multiple-output architectures were recently proposed as an alternative for fully digital-precoding in millimeter wave wireless communication systems. This is motivated by the possible reduction in the number of RF chains and analog-to-digital converters. In these architectures, the analog processing network is usually based on variable phase shifters. In this paper, we propose hybrid architectures based on switching networks to reduce the complexity and the power consumption of the structures based on phase shifters. We define a power consumption model and use it to evaluate the energy efficiency of both structures. To estimate the complete MIMO channel, we propose an open-loop compressive channel estimation technique that is independent of the hardware used in the analog processing stage. We analyze the performance of the new estimation algorithm for hybrid architectures based on phase shifters and switches. Using the estimate, we develop two algorithms for the design of the hybrid combiner based on switches and analyze the achieved spectral efficiency. Finally, we study the tradeoffs between power consumption, hardware complexity, and spectral efficiency for hybrid architectures based on phase shifting networks and switching networks. Numerical results show that architectures based on switches obtain equal or better channel estimation performance to that obtained using phase shifters, while reducing hardware complexity and power consumption. For equal power consumption, all the hybrid architectures provide similar spectral efficiencies.","['Channel estimation', 'Radio frequency', 'Power demand', 'Phase shifters', 'MIMO', 'Switches', 'Antenna arrays', 'Millimeter wave communication', 'Hybrid systems']","['Millimeter wave', 'hybrid architecture', 'switches', 'channel estimation', 'precoding']"
"What is index modulation (IM)? This is an interesting question that we have started to hear more and more frequently over the past few years. The aim of this paper is to answer this question in a comprehensive manner by covering not only the basic principles and emerging variants of IM, but also reviewing the most recent as well as promising advances in this field toward the application scenarios foreseen in next-generation wireless networks. More specifically, we investigate three forms of IM: spatial modulation, channel modulation and orthogonal frequency division multiplexing (OFDM) with IM, which consider the transmit antennas of a multiple-input multiple-output system, the radio frequency mirrors (parasitic elements) mounted at a transmit antenna and the subcarriers of an OFDM system for IM techniques, respectively. We present the up-to-date advances in these three promising frontiers and discuss possible future research directions for IM-based schemes toward low-complexity, spectrum- and energy-efficient next-generation wireless networks.","['OFDM', 'Indexes', 'Phase modulation', 'MIMO', 'Optical transmitters', 'Optical modulation']","['5G wireless networks', 'channel modulation', 'cognitive radio networks', 'cooperative networks', 'full-duplex networks', 'index modulation', 'MIMO systems', 'multi-carrier systems', 'multi-user systems', 'OFDM', 'OFDM with index modulation', 'practical implementations', 'reconfigurable antennas', 'spatial modulation', 'vehicular communications', 'visible light communications']"
"Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics.","['Hidden Markov models', 'Speech recognition', 'Neural networks', 'Deep learning', 'Feature extraction', 'Computer architecture', 'Acoustics']","['Speech recognition', 'deep neural network', 'systematic review']"
"The k-means algorithm is generally the most known and used clustering method. There are various extensions of k-means to be proposed in the literature. Although it is an unsupervised learning to clustering in pattern recognition and machine learning, the k-means algorithm and its extensions are always influenced by initializations with a necessary number of clusters a priori. That is, the k-means algorithm is not exactly an unsupervised clustering method. In this paper, we construct an unsupervised learning schema for the k-means algorithm so that it is free of initializations without parameter selection and can also simultaneously find an optimal number of clusters. That is, we propose a novel unsupervised k-means (U-k-means) clustering algorithm with automatically finding an optimal number of clusters without giving any initialization and parameter selection. The computational complexity of the proposed U-k-means clustering algorithm is also analyzed. Comparisons between the proposed U-k-means and other existing methods are made. Experimental results and comparisons actually demonstrate these good aspects of the proposed U-k-means clustering algorithm.","['Clustering algorithms', 'Indexes', 'Linear programming', 'Entropy', 'Clustering methods', 'Unsupervised learning', 'Machine learning algorithms']","['Clustering', 'K-means', 'number of clusters', 'initializations', 'unsupervised learning schema', 'Unsupervised k-means (U-k-means)']"
"The past decade has witnessed the rapid evolution in blockchain technologies, which has attracted tremendous interests from both the research communities and industries. The blockchain network was originated from the Internet financial sector as a decentralized, immutable ledger system for transactional data ordering. Nowadays, it is envisioned as a powerful backbone/framework for decentralized data processing and data-driven self-organization in flat, open-access networks. In particular, the plausible characteristics of decentralization, immutability, and self-organization are primarily owing to the unique decentralized consensus mechanisms introduced by blockchain networks. This survey is motivated by the lack of a comprehensive literature review on the development of decentralized consensus mechanisms in blockchain networks. In this paper, we provide a systematic vision of the organization of blockchain networks. By emphasizing the unique characteristics of decentralized consensus in blockchain networks, our in-depth review of the state-of-the-art consensus protocols is focused on both the perspective of distributed consensus system design and the perspective of incentive mechanism design. From a game-theoretic point of view, we also provide a thorough review of the strategy adopted for self-organization by the individual nodes in the blockchain backbone networks. Consequently, we provide a comprehensive survey of the emerging applications of blockchain networks in a broad area of telecommunication. We highlight our special interest in how the consensus mechanisms impact these applications. Finally, we discuss several open issues in the protocol design for blockchain consensus and the related potential research directions.","['Blockchain', 'Protocols', 'Organizations', 'Bitcoin', 'Scalability', 'Standards organizations']","['Blockchain', 'permissionless consensus', 'Byzantine fault tolerance', 'block mining', 'incentive mechanisms', 'game theory', 'P2P networks']"
"Voluminous amounts of data have been produced, since the past decade as the miniaturization of Internet of things (IoT) devices increases. However, such data are not useful without analytic power. Numerous big data, IoT, and analytics solutions have enabled people to obtain valuable insight into large data generated by IoT devices. However, these solutions are still in their infancy, and the domain lacks a comprehensive survey. This paper investigates the state-of-the-art research efforts directed toward big IoT data analytics. The relationship between big data analytics and IoT is explained. Moreover, this paper adds value by proposing a new architecture for big IoT data analytics. Furthermore, big IoT data analytic types, methods, and technologies for big data mining are discussed. Numerous notable use cases are also presented. Several opportunities brought by data analytics in IoT paradigm are then discussed. Finally, open research challenges, such as privacy, big data mining, visualization, and integration, are presented as future research directions.","['Big Data', 'Data analysis', 'Tools', 'Computer architecture', 'Business', 'Sensors', 'Data mining']","['Big data', 'Internet of Things', 'data analytics', 'distributed computing', 'smart city']"
"The grand objective of 5G wireless technology is to support three generic services with vastly heterogeneous requirements: enhanced mobile broadband (eMBB), massive machine-type communications (mMTCs), and ultra-reliable low-latency communications (URLLCs). Service heterogeneity can be accommodated by network slicing, through which each service is allocated resources to provide performance guarantees and isolation from the other services. Slicing of the radio access network (RAN) is typically done by means of orthogonal resource allocation among the services. This paper studies the potential advantages of allowing for non-orthogonal sharing of RAN resources in uplink communications from a set of eMBB, mMTC, and URLLC devices to a common base station. The approach is referred to as heterogeneous nonorthogonal multiple access (H-NOMA), in contrast to the conventional NOMA techniques that involve users with homogeneous requirements and hence can be investigated through a standard multiple access channel. The study devises a communication-theoretic model that accounts for the heterogeneous requirements and characteristics of the three services. The concept of reliability diversity is introduced as a design principle that leverages the different reliability requirements across the services in order to ensure performance guarantees with non-orthogonal RAN slicing. This paper reveals that H-NOMA can lead, in some regimes, to significant gains in terms of performance tradeoffs among the three generic services as compared to orthogonal slicing.","['NOMA', 'Reliability', 'Wireless communication', 'Resource management', 'Radio spectrum management', 'Time-frequency analysis', '5G mobile communication']","['5G mobile communication', 'machine-to-machine communications', 'multiaccess communication', 'NOMA', 'wireless communication']"
"6G and beyond will fulfill the requirements of a fully connected world and provide ubiquitous wireless connectivity for all. Transformative solutions are expected to drive the surge for accommodating a rapidly growing number of intelligent devices and services. Major technological breakthroughs to achieve connectivity goals within 6G include: (i) a network operating at the THz band with much wider spectrum resources, (ii) intelligent communication environments that enable a wireless propagation environment with active signal transmission and reception, (iii) pervasive artificial intelligence, (iv) large-scale network automation, (v) an all-spectrum reconfigurable front-end for dynamic spectrum access, (vi) ambient backscatter communications for energy savings, (vii) the Internet of Space Things enabled by CubeSats and UAVs, and (viii) cell-free massive MIMO communication networks. In this roadmap paper, use cases for these enabling techniques as well as recent advancements on related topics are highlighted, and open problems with possible solutions are discussed, followed by a development timeline outlining the worldwide efforts in the realization of 6G. Going beyond 6G, promising early-stage technologies such as the Internet of NanoThings, the Internet of BioNanoThings, and quantum communications, which are expected to have a far-reaching impact on wireless communications, have also been discussed at length in this paper.","['6G mobile communication', 'Wireless communication', '5G mobile communication', 'Automation', 'Internet', 'Measurement', 'Communication system security']","['6G', 'wireless communications', 'terahertz band', 'intelligent communication environments', 'pervasive artificial intelligence', 'network automation', 'all-spectrum reconfigurable transceivers', 'ambient backscatter communications', 'cell-free massive MIMO', 'Internet of NanoThings', 'Internet of BioNanoThings', 'quantum communications']"
"Recently, artificial intelligence (AI) and blockchain have become two of the most trending and disruptive technologies. Blockchain technology has the ability to automate payment in cryptocurrency and to provide access to a shared ledger of data, transactions, and logs in a decentralized, secure, and trusted manner. Also with smart contracts, blockchain has the ability to govern interactions among participants with no intermediary or a trusted third party. AI, on the other hand, offers intelligence and decision-making capabilities for machines similar to humans. In this paper, we present a detailed survey on blockchain applications for AI. We review the literature, tabulate, and summarize the emerging blockchain applications, platforms, and protocols specifically targeting AI area. We also identify and discuss open research challenges of utilizing blockchain technologies for AI.","['Blockchain', 'Smart contracts', 'Machine learning', 'Decision making', 'Machine learning algorithms', 'Data mining']","['Artificial intelligence', 'machine learning', 'blockchain', 'cybersecurity', 'smart contracts', 'consensus protocols']"
"A variety of rechargeable batteries are now available in world markets for powering electric vehicles (EVs). The lithium-ion (Li-ion) battery is considered the best among all battery types and cells because of its superior characteristics and performance. The positive environmental impacts and recycling potential of lithium batteries have influenced the development of new research for improving Li-ion battery technologies. However, the cost reduction, safe operation, and mitigation of negative ecological impacts are now a common concern for advancement. This paper provides a comprehensive study on the state of the art of Li-ion batteries including the fundamentals, structures, and overall performance evaluations of different types of lithium batteries. A study on a battery management system for Li-ion battery storage in EV applications is demonstrated, which includes a cell condition monitoring, charge, and discharge control, states estimation, protection and equalization, temperature control and heat management, battery fault diagnosis, and assessment aimed at enhancing the overall performance of the system. It is observed that the Li-ion batteries are becoming very popular in vehicle applications due to price reductions and lightweight with high power density. However, the management of the charging and discharging processes, CO2 and greenhouse gases emissions, health effects, and recycling and refurbishing processes have still not been resolved satisfactorily. Consequently, this review focuses on the many factors, challenges, and problems and provides recommendations for sustainable battery manufacturing for future EVs. This review will hopefully lead to increasing efforts toward the development of an advanced Li-ion battery in terms of economics, longevity, specific power, energy density, safety, and performance in vehicle applications.","['Lithium-ion batteries', 'Lithium', 'Cathodes', 'Ions', 'Anodes', 'Electrolytes']","['Lithium-ion battery', 'state-of-the-art of lithium-ion battery', 'energy management system', 'electric vehicle']"
"Unlike previous studies on the Metaverse based on Second Life, the current Metaverse is based on the social value of Generation Z that online and offline selves are not different. With the technological development of deep learning-based high-precision recognition models and natural generation models, Metaverse is being strengthened with various factors, from mobile-based always-on access to connectivity with reality using virtual currency. The integration of enhanced social activities and neural-net methods requires a new definition of Metaverse suitable for the present, different from the previous Metaverse. This paper divides the concepts and essential techniques necessary for realizing the Metaverse into three components (i.e., hardware, software, and contents) and three approaches (i.e., user interaction, implementation, and application) rather than marketing or hardware approach to conduct a comprehensive analysis. Furthermore, we describe essential methods based on three components and techniques to Metaverse’s representative Ready Player One, Roblox, and Facebook research in the domain of films, games, and studies. Finally, we summarize the limitations and directions for implementing the immersive Metaverse as social influences, constraints, and open challenges.","['Augmented reality', 'Avatars', 'Metaverse', 'Artificial intelligence', 'Solid modeling', 'Games', 'Virtual reality']","['Artificial intelligence', 'metaverse', 'cyber world', 'avatar', 'extended reality']"
"When, in 1956, Artificial Intelligence (AI) was officially declared a research field, no one would have ever predicted the huge influence and impact its description, prediction, and prescription capabilities were going to have on our daily lives. In parallel to continuous advances in AI, the past decade has seen the spread of broadband and ubiquitous connectivity, (embedded) sensors collecting descriptive high dimensional data, and improvements in big data processing techniques and cloud computing. The joint usage of such technologies has led to the creation of digital twins, artificial intelligent virtual replicas of physical systems. Digital Twin (DT) technology is nowadays being developed and commercialized to optimize several manufacturing and aviation processes, while in the healthcare and medicine fields this technology is still at its early development stage. This paper presents the results of a study focused on the analysis of the state-of-the-art definitions of DT, the investigation of the main characteristics that a DT should possess, and the exploration of the domains in which DT applications are currently being developed. The design implications derived from the study are then presented: they focus on socio-technical design aspects and DT lifecycle. Open issues and challenges that require to be addressed in the future are finally discussed.","['Artificial intelligence', 'Data models', 'Atmospheric modeling', 'Military aircraft', 'Big Data', 'Sensors']","['Artificial intelligence', 'digital twin', 'human-computer interaction', 'Internet of Things', 'machine learning', 'sensor systems']"
"Blockchain is the underlying technology of a number of digital cryptocurrencies. Blockchain is a chain of blocks that store information with digital signatures in a decentralized and distributed network. The features of blockchain, including decentralization, immutability, transparency and auditability, make transactions more secure and tamper proof. Apart from cryptocurrency, blockchain technology can be used in financial and social services, risk management, healthcare facilities, and so on. A number of research studies focus on the opportunity that blockchain provides in various application domains. This paper presents a comparative study of the tradeoffs of blockchain and also explains the taxonomy and architecture of blockchain, provides a comparison among different consensus mechanisms and discusses challenges, including scalability, privacy, interoperability, energy consumption and regulatory issues. In addition, this paper also notes the future scope of blockchain technology.","['Blockchain', 'Bitcoin', 'Peer-to-peer computing', 'Digital signatures', 'Computer architecture', 'Government']","['Blockchain', 'distributed ledger', 'consensus procedures', 'cryptocurrency', 'smart contract', 'selfish mining', 'energy consumption']"
"Battery technology is the bottleneck of the electric vehicles (EVs). It is important, both in theory and practical application, to do research on the modeling and state estimation of batteries, which is essential to optimizing energy management, extending the life cycle, reducing cost, and safeguarding the safe application of batteries in EVs. However, the batteries, with strong time-variables and nonlinear characteristics, are further influenced by such random factors such as driving loads, operational conditions, in the application of EVs. The real-time, accurate estimation of their state is challenging. The classification of the estimation methodologies for estimating state-of-charge (SoC) of battery focusing with the estimation method/algorithm, advantages, drawbacks, and estimation error are systematically and separately discussed. Especially for the battery packs existing of the inevitable inconsistency in cell capacity, resistance and voltage, the advanced characterizing monomer selection, and bias correction-based method has been described and discussed. The review also presents the key feedback factors that are indispensable for accurate estimation of battery SoC, it will be helpful for ensuring the SoC estimation accuracy. It will be very helpful for choosing an appropriate method to develop a reliable and safe battery management system and energy management strategy of the EVs. Finally, the paper also highlights a number of key factors and challenges, and presents the possible recommendations for the development of next generation of smart SoC estimation and battery management systems for electric vehicles and battery energy storage system.","['Batteries', 'Estimation', 'Integrated circuit modeling', 'Mathematical model', 'Battery charge measurement', 'State of charge', 'Electric vehicles']","['Batteries', 'data-driven estimation', 'electric vehicles', 'model based estimation', 'multi-scale', 'state of charge']"
"The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data.","['Big Data', 'Machine learning algorithms', 'Data mining', 'Algorithm design and analysis', 'Data analysis', 'Support vector machines', 'Classification algorithms']","['Big Data', 'Big Data Vs', 'data analysis', 'data analytics', 'deep learning', 'distributed computing', 'machine learning', 'neural networks']"
"To meet the fast-growing energy demand and, at the same time, tackle environmental concerns resulting from conventional energy sources, renewable energy sources are getting integrated in power networks to ensure reliable and affordable energy for the public and industrial sectors. However, the integration of renewable energy in the ageing electrical grids can result in new risks/challenges, such as security of supply, base load energy capacity, seasonal effects, and so on. Recent research and development in microgrids have proved that microgrids, which are fueled by renewable energy sources and managed by smart grids (use of smart sensors and smart energy management system), can offer higher reliability and more efficient energy systems in a cost-effective manner. Further improvement in the reliability and efficiency of electrical grids can be achieved by utilizing dc distribution in microgrid systems. DC microgrid is an attractive technology in the modern electrical grid system because of its natural interface with renewable energy sources, electric loads, and energy storage systems. In the recent past, an increase in research work has been observed in the area of dc microgrid, which brings this technology closer to practical implementation. This paper presents the state-of-the-art dc microgrid technology that covers ac interfaces, architectures, possible grounding schemes, power quality issues, and communication systems. The advantages of dc grids can be harvested in many applications to improve their reliability and efficiency. This paper also discusses benefits and challenges of using dc grid systems in several applications. This paper highlights the urgent need of standardizations for dc microgrid technology and presents recent updates in this area.","['Microgrids', 'Power system reliability', 'Reliability', 'Grounding', 'Renewable energy sources', 'Batteries', 'Power quality']","['DC microgrid', 'architectures', 'power quality', 'grounding', 'communication network', 'smart grid and standardization']"
"The 5G System is being developed and enhanced to provide unparalleled connectivity to connect everyone and everything, everywhere. The first version of the 5G System, based on the Release 15 (“Rel-15”) version of the specifications developed by 3GPP, comprising the 5G Core (5GC) and 5G New Radio (NR) with 5G User Equipment (UE), is currently being deployed commercially throughout the world both at sub-6 GHz and at mmWave frequencies. Concurrently, the second phase of 5G is being standardized by 3GPP in the Release 16 (“Rel-16”) version of the specifications which will be completed by March 2020. While the main focus of Rel-15 was on enhanced mobile broadband services, the focus of Rel-16 is on new features for URLLC (Ultra-Reliable Low Latency Communication) and Industrial IoT, including Time Sensitive Communication (TSC), enhanced Location Services, and support for Non-Public Networks (NPNs). In addition, some crucial new features, such as NR on unlicensed bands (NR-U), Integrated Access & Backhaul (IAB) and NR Vehicle-to-X (V2X), are also being introduced as part of Rel-16, as well as enhancements for massive MIMO, wireless and wireline convergence, the Service Based Architecture (SBA) and Network Slicing. Finally, the number of use cases, types of connectivity and users, and applications running on top of 5G networks, are all expected to increase dramatically, thus motivating additional security features to counter security threats which are expected to increase in number, scale and variety. In this paper, we discuss the Rel-16 features and provide an outlook towards Rel-17 and beyond, covering both new features and enhancements of existing features. 5G Evolution will focus on three main areas: enhancements to features introduced in Rel-15 and Rel-16, features that are needed for operational enhancements, and new features to further expand the applicability of the 5G System to new markets and use cases.","['5G mobile communication', 'Computer architecture', '3GPP', 'Data analysis', 'Wireless communication', 'Convergence', 'Security']","['5G new radio', '5G core', '5G system', 'non-public network', 'industrial IoT', 'time sensitive communication', 'ultra-reliable low-latency communications', 'integrated access and backhaul', 'converged edge and core clouds', 'positioning', 'NR-unlicensed', 'non-terrestrial network']"
"This paper presents an in-depth analysis of the majority of the deep neural networks (DNNs) proposed in the state of the art for image recognition. For each DNN, multiple performance indices are observed, such as recognition accuracy, model complexity, computational complexity, memory usage, and inference time. The behavior of such performance indices and some combinations of them are analyzed and discussed. To measure the indices, we experiment the use of DNNs on two different computer architectures, a workstation equipped with a NVIDIA Titan X Pascal, and an embedded system based on a NVIDIA Jetson TX1 board. This experimentation allows a direct comparison between DNNs running on machines with very different computational capacities. This paper is useful for researchers to have a complete view of what solutions have been explored so far and in which research directions are worth exploring in the future, and for practitioners to select the DNN architecture(s) that better fit the resource constraints of practical deployments and applications. To complete this work, all the DNNs, as well as the software used for the analysis, are available online.","['Computational modeling', 'Graphics processing units', 'Computational complexity', 'Memory management', 'Embedded systems']","['Deep neural networks', 'convolutional neural networks', 'image recognition']"
"Motion planning is a fundamental research area in robotics. Sampling-based methods offer an efficient solution for what is otherwise a rather challenging dilemma of path planning. Consequently, these methods have been extended further away from basic robot planning into further difficult scenarios and diverse applications. A comprehensive survey of the growing body of work in sampling-based planning is given here. Simulations are executed to evaluate some of the proposed planners and highlight some of the implementation details that are often left unspecified. An emphasis is placed on contemporary research directions in this field. We address planners that tackle current issues in robotics. For instance, real-life kinodynamic planning, optimal planning, replanning in dynamic environments, and planning under uncertainty are discussed. The aim of this paper is to survey the state of the art in motion planning and to assess selected planners, examine implementation details and above all shed a light on the current challenges in motion planning and the promising approaches that will potentially overcome those problems.","['Planning', 'Measurement', 'Heuristic algorithms', 'Robot sensing systems', 'Path planning', 'Vegetation']","['Planning', 'sampling', 'randomization', 'RRT', 'PRM', 'path', 'motion', 'autonomous robots']"
"Despite the perception people may have regarding the agricultural process, the reality is that today's agriculture industry is data-centered, precise, and smarter than ever. The rapid emergence of the Internet-of-Things (IoT) based technologies redesigned almost every industry including “smart agriculture” which moved the industry from statistical to quantitative approaches. Such revolutionary changes are shaking the existing agriculture methods and creating new opportunities along a range of challenges. This article highlights the potential of wireless sensors and IoT in agriculture, as well as the challenges expected to be faced when integrating this technology with the traditional farming practices. IoT devices and communication techniques associated with wireless sensors encountered in agriculture applications are analyzed in detail. What sensors are available for specific agriculture application, like soil preparation, crop status, irrigation, insect and pest detection are listed. How this technology helping the growers throughout the crop stages, from sowing until harvesting, packing and transportation is explained. Furthermore, the use of unmanned aerial vehicles for crop surveillance and other favorable applications such as optimizing crop yield is considered in this article. State-of-the-art IoT-based architectures and platforms used in agriculture are also highlighted wherever suitable. Finally, based on this thorough review, we identify current and future trends of IoT in agriculture and highlight potential research challenges.","['Agriculture', 'Soil', 'Production', 'Intelligent sensors', 'Sociology']","['Food quality and quantity', 'Internet-of-Things (IoTs)', 'smart agriculture', 'advanced agriculture practices', 'urban farming', 'agriculture robots', 'automation', 'future food expectation']"
"Non-orthogonal multiple access (NOMA) has recently been considered as a key enabling technique for 5G cellular systems. In NOMA, by exploiting the channel gain differences, multiple users are multiplexed into transmission power domain and then non-orthogonally scheduled for transmission on the same spectrum resources. Successive interference cancellation (SIC) is then applied at the receivers to decode the message signals. In this paper, first, we briefly describe the differences in the working principles of uplink and downlink NOMA transmissions in a cellular wireless system. Then, for both uplink and downlink NOMAs, we formulate a sum-throughput maximization problem in a cell such that the user clustering (i.e., grouping users into a single cluster or multiple clusters) and power allocations in NOMA clusters can be optimized under transmission power constraints, minimum rate requirements of the users, and SIC constraints. Due to the combinatorial nature of the formulated mixed integer non-linear programming problem, we solve the problem in two steps, i.e., by first grouping users into clusters and then optimizing their respective power allocations. In particular, we propose a low-complexity sub-optimal user grouping scheme. The proposed scheme exploits the channel gain differences among users in an NOMA cluster and groups them into a single cluster or multiple clusters in order to enhance the sum-throughput of the system. For a given set of NOMA clusters, we then derive the optimal power allocation policy that maximizes the sum-throughput per NOMA cluster and in turn maximizes the overall system throughput. Using Karush-Kuhn-Tucker optimality conditions, closed-form solutions for optimal power allocations are derived for any cluster size, considering both uplink and downlink NOMA systems. Numerical results compare the performances of NOMA and OMA and illustrate the significance of NOMA in various network scenarios.","['NOMA', 'Resource management', 'Uplink', 'Downlink', '5G mobile communication', 'Multiplexing', 'Silicon carbide']","['5G cellular', 'non-orthogonal multiple access (NOMA)', 'orthogonal multiple access (OMA)', 'power allocation', 'throughput maximization', 'user grouping']"
"The recent expansion of the Internet of Things (IoT) and the consequent explosion in the volume of data produced by smart devices have led to the outsourcing of data to designated data centers. However, to manage these huge data stores, centralized data centers, such as cloud storage cannot afford auspicious way. There are many challenges that must be addressed in the traditional network architecture due to the rapid growth in the diversity and number of devices connected to the internet, which is not designed to provide high availability, real-time data delivery, scalability, security, resilience, and low latency. To address these issues, this paper proposes a novel blockchain-based distributed cloud architecture with a software defined networking (SDN) enable controller fog nodes at the edge of the network to meet the required design principles. The proposed model is a distributed cloud architecture based on blockchain technology, which provides low-cost, secure, and on-demand access to the most competitive computing infrastructures in an IoT network. By creating a distributed cloud infrastructure, the proposed model enables cost-effective high-performance computing. Furthermore, to bring computing resources to the edge of the IoT network and allow low latency access to large amounts of data in a secure manner, we provide a secure distributed fog node architecture that uses SDN and blockchain techniques. Fog nodes are distributed fog computing entities that allow the deployment of fog services, and are formed by multiple computing resources at the edge of the IoT network. We evaluated the performance of our proposed architecture and compared it with the existing models using various performance measures. The results of our evaluation show that performance is improved by reducing the induced delay, reducing the response time, increasing throughput, and the ability to detect real-time attacks in the IoT network with low performance overheads.","['Cloud computing', 'Computer architecture', 'Edge computing', 'Performance evaluation', 'Peer-to-peer computing', 'Distributed databases', 'Security']","['Internet of things', 'software defined networking', 'security', 'blockchain', 'cloud computing', 'fog computing', 'edge computing']"
"Recurrent neural network (RNN) and long short-term memory (LSTM) have achieved great success in processing sequential multimedia data and yielded the state-of-the-art results in speech recognition, digital signal processing, video processing, and text data analysis. In this paper, we propose a novel action recognition method by processing the video data using convolutional neural network (CNN) and deep bidirectional LSTM (DB-LSTM) network. First, deep features are extracted from every sixth frame of the videos, which helps reduce the redundancy and complexity. Next, the sequential information among frame features is learnt using DB-LSTM network, where multiple layers are stacked together in both forward pass and backward pass of DB-LSTM to increase its depth. The proposed method is capable of learning long term sequences and can process lengthy videos by analyzing features for a certain time interval. Experimental results show significant improvements in action recognition using the proposed method on three benchmark data sets including UCF-101, YouTube 11 Actions, and HMDB51 compared with the state-of-the-art action recognition methods.","['Feature extraction', 'Computer architecture', 'Streaming media', 'Visualization', 'Microprocessors', 'Logic gates', 'Shape']","['Action recognition', 'deep learning', 'recurrent neural network', 'deep bidirectional long short-term memory', 'convolution neural network']"
"Internet of Things is smartly changing various existing research areas into new themes, including smart health, smart home, smart industry, and smart transport. Relying on the basis of “smart transport,” Internet of Vehicles (IoV) is evolving as a new theme of research and development from vehicular ad hoc networks (VANETs). This paper presents a comprehensive framework of IoV with emphasis on layered architecture, protocol stack, network model, challenges, and future aspects. Specifically, following the background on the evolution of VANETs and motivation on IoV an overview of IoV is presented as the heterogeneous vehicular networks. The IoV includes five types of vehicular communications, namely, vehicle-to-vehicle, vehicle-to-roadside, vehicle-to-infrastructure of cellular networks, vehicle-to-personal devices, and vehicle-to-sensors. A five layered architecture of IoV is proposed considering functionalities and representations of each layer. A protocol stack for the layered architecture is structured considering management, operational, and security planes. A network model of IoV is proposed based on the three network elements, including cloud, connection, and client. The benefits of the design and development of IoV are highlighted by performing a qualitative comparison between IoV and VANETs. Finally, the challenges ahead for realizing IoV are discussed and future aspects of IoV are envisioned.","['Intelligent vehicles', 'Internet of things', 'Vehicular ad hoc networks', 'Cloud computing', 'Computer architecture', 'Heterogeneous networks', 'Reliability']","['Vehicular adhoc networks', 'Internet of Vehicles', 'cloud computing', 'heterogeneous networks']"
"The use of renewable energy resources, such as solar, wind, and biomass will not diminish their availability. Sunlight being a constant source of energy is used to meet the ever-increasing energy need. This review discusses the world's energy needs, renewable energy technologies for domestic use, and highlights public opinions on renewable energy. A systematic review of the literature was conducted from 2009 to 2018. During this process, more than 300 articles were classified and 42 papers were filtered for critical review. The literature analysis showed that despite serious efforts at all levels to reduce reliance on fossil fuels by promoting renewable energy as its alternative, fossil fuels continue to contribute 73.5% to the worldwide electricity production in 2017. Conversely, renewable sources contributed only 26.5%. Furthermore, this study highlights that the lack of public awareness is a major barrier to the acceptance of renewable energy technologies. The results of this study show that worldwide energy crises can be managed by integrating renewable energy sources in the power generation. Moreover, in order to facilitate the development of renewable energy technologies, this systematic review has highlighted the importance of public opinion and performed a real-time analysis of public tweets. This example of tweet analysis is a relatively novel initiative in a review study that will seek to direct the attention of future researchers and policymakers toward public opinion and recommend the implications to both academia and industries.","['Fossil fuels', 'Systematics', 'Information technology', 'Computer science', 'Wind', 'Biomass']","['Energy policies', 'public opinion', 'renewable energy sources (RES)', 'renewable energy technology (RET)', 'solar energy', 'wind energy']"
"Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19. Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85% accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this method will speed up COVID-19 detection and lead to more robust systems of radiology.","['Generative adversarial networks', 'Training', 'Biomedical imaging', 'X-ray imaging', 'Computer architecture', 'Machine learning', 'COVID-19']","['Deep learning', 'convolutional neural networks', 'generative adversarial networks', 'synthetic data augmentation', 'COVID-19 detection']"
"Driven by the emergence of new compute-intensive applications and the vision of the Internet of Things (IoT), it is foreseen that the emerging 5G network will face an unprecedented increase in traffic volume and computation demands. However, end users mostly have limited storage capacities and finite processing capabilities, thus how to run compute-intensive applications on resource-constrained users has recently become a natural concern. Mobile edge computing (MEC), a key technology in the emerging fifth generation (5G) network, can optimize mobile resources by hosting compute-intensive applications, process large data before sending to the cloud, provide the cloud-computing capabilities within the radio access network (RAN) in close proximity to mobile users, and offer context-aware services with the help of RAN information. Therefore, MEC enables a wide variety of applications, where the real-time response is strictly required, e.g., driverless vehicles, augmented reality, robotics, and immerse media. Indeed, the paradigm shift from 4G to 5G could become a reality with the advent of new technological concepts. The successful realization of MEC in the 5G network is still in its infancy and demands for constant efforts from both academic and industry communities. In this survey, we first provide a holistic overview of MEC technology and its potential use cases and applications. Then, we outline up-to-date researches on the integration of MEC with the new technologies that will be deployed in 5G and beyond. We also summarize testbeds and experimental evaluations, and open source activities, for edge computing. We further summarize lessons learned from state-of-the-art research works as well as discuss challenges and potential future directions for MEC research.","['Cloud computing', '5G mobile communication', 'Edge computing', 'Internet of Things', 'Radio access networks', 'NOMA', 'Wireless communication']","['5G and beyond network', 'heterogeneous networks', 'Internet of Things', 'machine learning', 'edge computing', 'non-orthogonal multiple access', 'testbeds', 'unmanned aerial vehicle', 'wireless power transfer and energy harvesting']"
"U-net is an image segmentation technique developed primarily for image segmentation tasks. These traits provide U-net with a high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in nearly all major image modalities, from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. Given that U-net's potential is still increasing, this narrative literature review examines the numerous developments and breakthroughs in the U-net architecture and provides observations on recent trends. We also discuss the many innovations that have advanced in deep learning and discuss how these tools facilitate U-net. In addition, we review the different image modalities and application areas that have been enhanced by U-net.","['Image segmentation', 'Convolution', 'Biomedical imaging', 'Three-dimensional displays', 'Logic gates', 'Deep learning', 'Computer architecture']","['Biomedical imaging', 'deep learning', 'neural network architecture', 'segmentation', 'U-net']"
"In new product development, time to market (TTM) is critical for the success and profitability of next generation products. When these products include sophisticated electronics encased in 3D packaging with complex geometries and intricate detail, TTM can be compromised - resulting in lost opportunity. The use of advanced 3D printing technology enhanced with component placement and electrical interconnect deposition can provide electronic prototypes that now can be rapidly fabricated in comparable time frames as traditional 2D bread-boarded prototypes; however, these 3D prototypes include the advantage of being embedded within more appropriate shapes in order to authentically prototype products earlier in the development cycle. The fabrication freedom offered by 3D printing techniques, such as stereolithography and fused deposition modeling have recently been explored in the context of 3D electronics integration - referred to as 3D structural electronics or 3D printed electronics. Enhanced 3D printing may eventually be employed to manufacture end-use parts and thus offer unit-level customization with local manufacturing; however, until the materials and dimensional accuracies improve (an eventuality), 3D printing technologies can be employed to reduce development times by providing advanced geometrically appropriate electronic prototypes. This paper describes the development process used to design a novelty six-sided gaming die. The die includes a microprocessor and accelerometer, which together detect motion and upon halting, identify the top surface through gravity and illuminate light-emitting diodes for a striking effect. By applying 3D printing of structural electronics to expedite prototyping, the development cycle was reduced from weeks to hours.","['Product development', 'Three dimensional displays', 'Printing', 'Product life cycle management', 'Economics', 'Consumer electronics', 'Time to market', 'Prototypes', 'Packaging']","['3D printed electronics', 'additive manufacturing', 'direct-print', 'electronic gaming die', 'hybrid manufacturing', 'rapid prototyping', 'structural electronics', 'three-dimensional electronics']"
"A network traffic classifier (NTC) is an important part of current network monitoring systems, being its task to infer the network service that is currently used by a communication flow (e.g., HTTP and SIP). The detection is based on a number of features associated with the communication flow, for example, source and destination ports and bytes transmitted per packet. NTC is important, because much information about a current network flow can be learned and anticipated just by knowing its network service (required latency, traffic volume, and possible duration). This is of particular interest for the management and monitoring of Internet of Things (IoT) networks, where NTC will help to segregate traffic and behavior of heterogeneous devices and services. In this paper, we present a new technique for NTC based on a combination of deep learning models that can be used for IoT traffic. We show that a recurrent neural network (RNN) combined with a convolutional neural network (CNN) provides best detection results. The natural domain for a CNN, which is image processing, has been extended to NTC in an easy and natural way. We show that the proposed method provides better detection results than alternative algorithms without requiring any feature engineering, which is usual when applying other models. A complete study is presented on several architectures that integrate a CNN and an RNN, including the impact of the features chosen and the length of the network flows used for training.","['Ports (Computers)', 'Telecommunication traffic', 'Feature extraction', 'Recurrent neural networks', 'Machine learning', 'Payloads', 'Biological neural networks']","['Convolutional neural network', 'deep learning', 'network traffic classification', 'recurrent neural network']"
"Cyber-physical system (CPS) is a new trend in the Internet-of-Things related research works, where physical systems act as the sensors to collect real-world information and communicate them to the computation modules (i.e. cyber layer), which further analyze and notify the findings to the corresponding physical systems through a feedback loop. Contemporary researchers recommend integrating cloud technologies in the CPS cyber layer to ensure the scalability of storage, computation, and cross domain communication capabilities. Though there exist a few descriptive models of the cloud-based CPS architecture, it is important to analytically describe the key CPS properties: computation, control, and communication. In this paper, we present a digital twin architecture reference model for the cloud-based CPS, C2PS, where we analytically describe the key properties of the C2PS. The model helps in identifying various degrees of basic and hybrid computation-interaction modes in this paradigm. We have designed C2PS smart interaction controller using a Bayesian belief network, so that the system dynamically considers current contexts. The composition of fuzzy rule base with the Bayes network further enables the system with reconfiguration capability. We also describe analytically, how C2PS subsystem communications can generate even more complex system-of-systems. Later, we present a telematics-based prototype driving assistance application for the vehicular domain of C2PS, VCPS, to demonstrate the efficacy of the architecture reference model.","['Cloud computing', 'Computer architecture', 'Sensors', 'Social network services', 'Analytical models', 'Urban areas', 'Computational modeling']","['Digital twin', 'cyber-physical systems', 'Internet-of-Things', 'social internet of vehicles', 'sensing-as-a-service', 'analytical model']"
"Ultra-wideband millimeter-wave (mmWave) propagation measurements were conducted in the 28- and 73-GHz frequency bands in a typical indoor office environment in downtown Brooklyn, New York, on the campus of New York University. The measurements provide large-scale path loss and temporal statistics that will be useful for ultra-dense indoor wireless networks for future mmWave bands. This paper presents the details of measurements that employed a 400 Megachips-per-second broadband sliding correlator channel sounder, using rotatable highly directional horn antennas for both co-polarized and cross-polarized antenna configurations. The measurement environment was a closed-plan in-building scenario that included a line-of-sight and non-line-of-sight corridor, a hallway, a cubicle farm, and adjacent-room communication links. Well-known and new single-frequency and multi-frequency directional and omnidirectional large-scale path loss models are presented and evaluated based on more than 14 000 directional power delay profiles acquired from unique transmitter and receiver antenna pointing angle combinations. Omnidirectional path loss models, synthesized from the directional measurements, are provided for the case of arbitrary polarization coupling, as well as for the specific cases of co-polarized and cross-polarized antenna orientations. The results show that novel large-scale path loss models provided here are simpler and more physically based compared to previous 3GPP and ITU indoor propagation models that require more model parameters and offer very little additional accuracy and lack a physical basis. Multipath time dispersion statistics for mmWave systems using directional antennas are presented for co-polarization, crosspolarization, and combined-polarization scenarios, and show that the multipath root mean square delay spread can be reduced when using transmitter and receiver antenna pointing angles that result in the strongest received power. Raw omnidirectional path loss data and closed-form optimization formulas for all path loss models are given in the Appendices.","['Millimeter wave communication', 'Wideband', 'Propagation measurements', 'Ultra wideband communication', '5G mobile communication', 'Loss measurement', 'Path planning', 'Polarization', 'Multipath channels']","['Millimeter-wave', 'mmWave', 'path loss', '5G', 'indoor hotspot', 'RMS delay spread', 'small cell', 'channel sounder', 'propagation', '28 GHz', '73 GHz', 'multipath', 'polarization']"
"The Internet of Things (IoT) is a dynamic global information network consisting of Internet-connected objects, such as radio frequency identifications, sensors, and actuators, as well as other instruments and smart appliances that are becoming an integral component of the Internet. Over the last few years, we have seen a plethora of IoT solutions making their way into the industry marketplace. Context-aware communications and computing have played a critical role throughout the last few years of ubiquitous computing and are expected to play a significant role in the IoT paradigm as well. In this paper, we examine a variety of popular and innovative IoT solutions in terms of context-aware technology perspectives. More importantly, we evaluate these IoT solutions using a framework that we built around well-known context-aware computing theories. This survey is intended to serve as a guideline and a conceptual framework for context-aware product development and research in the IoT paradigm. It also provides a systematic exploration of existing IoT products in the marketplace and highlights a number of potentially significant research directions and trends.","['Context awareness', 'Internet of things', 'Market research', 'Information networks', 'Internet', 'Globalization', 'Interconnections', 'Product development', 'Futures research']","['Internet of things', 'industry solutions', 'contextawareness', 'product review', 'IoT marketplace']"
"Over the past three decades, significant developments have been made in hyperspectral imaging due to which it has emerged as an effective tool in numerous civil, environmental, and military applications. Modern sensor technologies are capable of covering large surfaces of earth with exceptional spatial, spectral, and temporal resolutions. Due to these features, hyperspectral imaging has been effectively used in numerous remote sensing applications requiring estimation of physical parameters of many complex surfaces and identification of visually similar materials having fine spectral signatures. In the recent years, ground based hyperspectral imaging has gained immense interest in the research on electronic imaging for food inspection, forensic science, medical surgery and diagnosis, and military applications. This review focuses on the fundamentals of hyperspectral image analysis and its modern applications such as food quality and safety assessment, medical diagnosis and image guided surgery, forensic document examination, defense and homeland security, remote sensing applications such as precision agriculture and water resource management and material identification and mapping of artworks. Moreover, recent research on the use of hyperspectral imaging for examination of forgery detection in questioned documents, aided by deep learning, is also presented. This review can be a useful baseline for future research in hyperspectral image analysis.","['Hyperspectral imaging', 'Spatial resolution', 'Imaging', 'Safety']","['Agriculture', 'document images', 'food quality and safety', 'hyperspectral imaging', 'medical imaging', 'remote sensing']"
"In this paper, an improved ant colony optimization (ICMPACO) algorithm based on the multi-population strategy, co-evolution mechanism, pheromone updating strategy, and pheromone diffusion mechanism is proposed to balance the convergence speed and solution diversity, and improve the optimization performance in solving the large-scale optimization problem. In the proposed ICMPACO algorithm, the optimization problem is divided into several sub-problems and the ants in the population are divided into elite ants and common ants in order to improve the convergence rate, and avoid to fall into the local optimum value. The pheromone updating strategy is used to improve optimization ability. The pheromone diffusion mechanism is used to make the pheromone released by ants at a certain point, which gradually affects a certain range of adjacent regions. The co-evolution mechanism is used to interchange information among different sub-populations in order to implement information sharing. In order to verify the optimization performance of the ICMPACO algorithm, the traveling salesmen problem (TSP) and the actual gate assignment problem are selected here. The experiment results show that the proposed ICMPACO algorithm can effectively obtain the best optimization value in solving TSP and effectively solve the gate assignment problem, obtain better assignment result, and it takes on better optimization ability and stability.","['Optimization', 'Convergence', 'Scheduling', 'Sociology', 'Statistics', 'Heuristic algorithms', 'Ant colony optimization']","['Co-evolution mechanism', 'ACO', 'pheromone updating strategy', 'pheromone diffusion mechanism', 'hybrid strategy', 'assignment problem']"
"5G is the next cellular generation and is expected to quench the growing thirst for taxing data rates and to enable the Internet of Things. Focused research and standardization work have been addressing the corresponding challenges from the radio perspective while employing advanced features, such as network densification, massive multiple-input-multiple-output antennae, coordinated multi-point processing, inter-cell interference mitigation techniques, carrier aggregation, and new spectrum exploration. Nevertheless, a new bottleneck has emerged: the backhaul. The ultra-dense and heavy traffic cells should be connected to the core network through the backhaul, often with extreme requirements in terms of capacity, latency, availability, energy, and cost efficiency. This pioneering survey explains the 5G backhaul paradigm, presents a critical analysis of legacy, cutting-edge solutions, and new trends in backhauling, and proposes a novel consolidated 5G backhaul framework. A new joint radio access and backhaul perspective is proposed for the evaluation of backhaul technologies which reinforces the belief that no single solution can solve the holistic 5G backhaul problem. This paper also reveals hidden advantages and shortcomings of backhaul solutions, which are not evident when backhaul technologies are inspected as an independent part of the 5G network. This survey is key in identifying essential catalysts that are believed to jointly pave the way to solving the beyond-2020 backhauling challenge. Lessons learned, unsolved challenges, and a new consolidated 5G backhaul vision are thus presented.","['5G mobile communication', 'Cellular networks', 'Backhaul communication', 'Microcells', 'Heterogeneous networks', 'Internet of things', 'MIMO', 'Market research', 'Software defined radio', 'Interference (signal)']","['5G', 'backhaul', 'fronthaul', 'small cells', 'heterogeneous network', 'C-RAN', 'SDN', 'SON', 'backhaul as a service']"
"The recent outbreak of COVID-19 has taken the world by surprise, forcing lockdowns and straining public health care systems. COVID-19 is known to be a highly infectious virus, and infected individuals do not initially exhibit symptoms, while some remain asymptomatic. Thus, a non-negligible fraction of the population can, at any given time, be a hidden source of transmissions. In response, many governments have shown great interest in smartphone contact tracing apps that help automate the difficult task of tracing all recent contacts of newly identified infected individuals. However, tracing apps have generated much discussion around their key attributes, including system architecture, data management, privacy, security, proximity estimation, and attack vulnerability. In this article, we provide the first comprehensive review of these much-discussed tracing app attributes. We also present an overview of many proposed tracing app examples, some of which have been deployed countrywide, and discuss the concerns users have reported regarding their usage. We close by outlining potential research directions for next-generation app design, which would facilitate improved tracing and security performance, as well as wide adoption by the population at large.","['Servers', 'Security', 'Privacy', 'Computer architecture', 'Viruses (medical)', 'Data privacy', 'Bluetooth', 'COVID-19']","['Contact tracing', 'privacy', 'security']"
"Machine learning methods have been remarkably successful for a wide range of application areas in the extraction of essential information from data. An exciting and relatively recent development is the uptake of machine learning in the natural sciences, where the major goal is to obtain novel scientific insights and discoveries from observational or simulated data. A prerequisite for obtaining a scientific outcome is domain knowledge, which is needed to gain explainability, but also to enhance scientific consistency. In this article, we review explainable machine learning in view of applications in the natural sciences and discuss three core elements that we identified as relevant in this context: transparency, interpretability, and explainability. With respect to these core elements, we provide a survey of recent scientific works that incorporate machine learning and the way that explainable machine learning is used in combination with domain knowledge from the application areas.","['Machine learning', 'Data models', 'Mathematical model', 'Kernel', 'Biological system modeling', 'Approximation algorithms', 'Data mining']","['Explainable machine learning', 'informed machine learning', 'interpretability', 'scientific consistency', 'transparency']"
"Deep learning has exploded in the public consciousness, primarily as predictive and analytical products suffuse our world, in the form of numerous human-centered smart-world systems, including targeted advertisements, natural language assistants and interpreters, and prototype self-driving vehicle systems. Yet to most, the underlying mechanisms that enable such human-centered smart products remain obscure. In contrast, researchers across disciplines have been incorporating deep learning into their research to solve problems that could not have been approached before. In this paper, we seek to provide a thorough investigation of deep learning in its applications and mechanisms. Specifically, as a categorical collection of state of the art in deep learning research, we hope to provide a broad reference for those seeking a primer on deep learning and its various implementations, platforms, algorithms, and uses in a variety of smart-world systems. Furthermore, we hope to outline recent key advancements in the technology, and provide insight into areas, in which deep learning can improve investigation, as well as highlight new areas of research that have yet to see the application of deep learning, but could nonetheless benefit immensely. We hope this survey provides a valuable reference for new deep learning practitioners, as well as those seeking to innovate in the application of deep learning.","['Machine learning', 'Neurons', 'Neural networks', 'Task analysis', 'Learning systems', 'Computational modeling', 'Training']","['Human-centered smart systems', 'deep learning', 'platform', 'neural networks', 'emergent applications', 'Internet of Things', 'cyber-physical systems', 'survey', 'networking', 'security']"
"In the past two decades, reversible data hiding (RDH), also referred to as lossless or invertible data hiding, has gradually become a very active research area in the field of data hiding. This has been verified by more and more papers on increasingly wide-spread subjects in the field of RDH research that have been published these days. In this paper, the various RDH algorithms and researches have been classified into the following six categories: 1) RDH into image spatial domain; 2) RDH into image compressed domain (e.g., JPEG); 3) RDH suitable for image semi-fragile authentication; 4) RDH with image contrast enhancement; 5) RDH into encrypted images, which is expected to have wide application in the cloud computation; and 6) RDH into video and into audio. For each of these six categories, the history of technical developments, the current state of the arts, and the possible future researches are presented and discussed. It is expected that the RDH technology and its applications in the real word will continue to move ahead.","['Data hiding', 'Video communication', 'Reversible data hiding', 'Classification algorithms', 'Image coding', 'Transform coding', 'Cryptography', 'Authentication']","['Reversible data hiding', 'lossless data hiding', 'invertible data hiding', 'histogram shifting', 'difference expansion', 'prediction-error', 'sorting', 'robust reversible data hiding', 'video reversible data hiding', 'audio reversible data hiding']"
"The focus of wireless research is increasingly shifting toward 6G as 5G deployments get underway. At this juncture, it is essential to establish a vision of future communications to provide guidance for that research. In this paper, we attempt to paint a broad picture of communication needs and technologies in the timeframe of 6G. The future of connectivity is in the creation of digital twin worlds that are a true representation of the physical and biological worlds at every spatial and time instant, unifying our experience across these physical, biological and digital worlds. New themes are likely to emerge that will shape 6G system requirements and technologies, such as: (i) new man-machine interfaces created by a collection of multiple local devices acting in unison; (ii) ubiquitous universal computing distributed among multiple local devices and the cloud; (iii) multi-sensory data fusion to create multi-verse maps and new mixed-reality experiences; and (iv) precision sensing and actuation to control the physical world. With rapid advances in artificial intelligence, it has the potential to become the foundation for the 6G air interface and network, making data, compute and energy the new resources to be exploited for achieving superior performance. In addition, in this paper we discuss the other major technology transformations that are likely to define 6G: (i) cognitive spectrum sharing methods and new spectrum bands; (ii) the integration of localization and sensing capabilities into the system definition, (iii) the achievement of extreme performance requirements on latency and reliability; (iv) new network architecture paradigms involving sub-networks and RAN-Core convergence; and (v) new security and privacy schemes.","['6G mobile communication', '5G mobile communication', 'Robot sensing systems', 'Biology', 'Digital twin', 'User interfaces']","['6G', 'AI/ML driven air interface', 'network localization and sensing', 'cognitive spectrum sharing', 'sub-terahertz', 'RAN-Core convergence', 'subnetworks', 'security', 'privacy', 'network as a platform']"
"Due to the significant advancement of the Internet of Things (IoT) in the healthcare sector, the security, and the integrity of the medical data became big challenges for healthcare services applications. This paper proposes a hybrid security model for securing the diagnostic text data in medical images. The proposed model is developed through integrating either 2-D discrete wavelet transform 1 level (2D-DWT-1L) or 2-D discrete wavelet transform 2 level (2D-DWT-2L) steganography technique with a proposed hybrid encryption scheme. The proposed hybrid encryption schema is built using a combination of Advanced Encryption Standard, and Rivest, Shamir, and Adleman algorithms. The proposed model starts by encrypting the secret data; then it hides the result in a cover image using 2D-DWT-1L or 2D-DWT-2L. Both color and gray-scale images are used as cover images to conceal different text sizes. The performance of the proposed system was evaluated based on six statistical parameters; the peak signal-to-noise ratio (PSNR), mean square error (MSE), bit error rate (BER), structural similarity (SSIM), structural content (SC), and correlation. The PSNR values were relatively varied from 50.59 to 57.44 in case of color images and from 50.52 to 56.09 with the gray scale images. The MSE values varied from 0.12 to 0.57 for the color images and from 0.14 to 0.57 for the gray scale images. The BER values were zero for both images, while SSIM, SC, and correlation values were ones for both images. Compared with the state-of-the-art methods, the proposed model proved its ability to hide the confidential patient's data into a transmitted cover image with high imperceptibility, capacity, and minimal deterioration in the received stego-image.","['Encryption', 'Medical diagnostic imaging', 'Medical services', 'Data models']","['Cryptography', 'DWT-1level', 'DWT-2level', 'encryption', 'healthcare services', 'Internet of Things', 'medical images', 'steganography']"
"Due to digitization, a huge volume of data is being generated across several sectors such as healthcare, production, sales, IoT devices, Web, organizations. Machine learning algorithms are used to uncover patterns among the attributes of this data. Hence, they can be used to make predictions that can be used by medical practitioners and people at managerial level to make executive decisions. Not all the attributes in the datasets generated are important for training the machine learning algorithms. Some attributes might be irrelevant and some might not affect the outcome of the prediction. Ignoring or removing these irrelevant or less important attributes reduces the burden on machine learning algorithms. In this work two of the prominent dimensionality reduction techniques, Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are investigated on four popular Machine Learning (ML) algorithms, Decision Tree Induction, Support Vector Machine (SVM), Naive Bayes Classifier and Random Forest Classifier using publicly available Cardiotocography (CTG) dataset from University of California and Irvine Machine Learning Repository. The experimentation results prove that PCA outperforms LDA in all the measures. Also, the performance of the classifiers, Decision Tree, Random Forest examined is not affected much by using PCA and LDA.To further analyze the performance of PCA and LDA the eperimentation is carried out on Diabetic Retinopathy (DR) and Intrusion Detection System (IDS) datasets. Experimentation results prove that ML algorithms with PCA produce better results when dimensionality of the datasets is high. When dimensionality of datasets is low it is observed that the ML algorithms without dimensionality reduction yields better results.","['Dimensionality reduction', 'Principal component analysis', 'Machine learning algorithms', 'Support vector machines', 'Medical diagnostic imaging', 'Feature extraction']","['Cardiotocography dataset', 'dimensionality reduction', 'feature engineering', 'linear discriminant analysis', 'machine learning', 'principal component analysis']"
"One of the key enablers of future wireless communications is constituted by massive multiple-input multiple-output (MIMO) systems, which can improve the spectral efficiency by orders of magnitude. In existing massive MIMO systems, however, conventional phased arrays are used for beamforming. This method results in excessive power consumption and high hardware costs. Recently, reconfigurable intelligent surface (RIS) has been considered as one of the revolutionary technologies to enable energy-efficient and smart wireless communications, which is a two-dimensional structure with a large number of passive elements. In this paper, we develop a new type of high-gain yet low-cost RIS that bears 256 elements. The proposed RIS combines the functions of phase shift and radiation together on an electromagnetic surface, where positive intrinsic-negative (PIN) diodes are used to realize 2-bit phase shifting for beamforming. This radical design forms the basis for the world’s first wireless communication prototype using RIS having 256 two-bit elements. The prototype consists of modular hardware and flexible software that encompass the following: the hosts for parameter setting and data exchange, the universal software radio peripherals (USRPs) for baseband and radio frequency (RF) signal processing, as well as the RIS for signal transmission and reception. Our performance evaluation confirms the feasibility and efficiency of RISs in wireless communications. We show that, at 2.3 GHz, the proposed RIS can achieve a 21.7 dBi antenna gain. At the millimeter wave (mmWave) frequency, that is, 28.5 GHz, it attains a 19.1 dBi antenna gain. Furthermore, it has been shown that the RIS-based wireless communication prototype developed is capable of significantly reducing the power consumption.","['Wireless communication', 'Phased arrays', 'Prototypes', 'Radio frequency', 'MIMO communication']","['Massive MIMO', 'prototype', 'reconfigurable intelligent surface (RIS)', 'wireless communication']"
"A microgrid (MG) is a local entity that consists of distributed energy resources (DERs) to achieve local power reliability and sustainable energy utilization. The MG concept or renewable energy technologies integrated with energy storage systems (ESS) have gained increasing interest and popularity because it can store energy at off-peak hours and supply energy at peak hours. However, existing ESS technology faces challenges in storing energy due to various issues, such as charging/discharging, safety, reliability, size, cost, life cycle, and overall management. Thus, an advanced ESS is required with regard to capacity, protection, control interface, energy management, and characteristics to enhance the performance of ESS in MG applications. This paper comprehensively reviews the types of ESS technologies, ESS structures along with their configurations, classifications, features, energy conversion, and evaluation process. Moreover, details on the advantages and disadvantages of ESS in MG applications have been analyzed based on the process of energy formations, material selection, power transfer mechanism, capacity, efficiency, and cycle period. Existing reviews critically demonstrate the current technologies for ESS in MG applications. However, the optimum management of ESSs for efficient MG operation remains a challenge in modern power system networks. This review also highlights the key factors, issues, and challenges with possible recommendations for the further development of ESS in future MG applications. All the highlighted insights of this review significantly contribute to the increasing effort toward the development of a cost-effective and efficient ESS model with a prolonged life cycle for sustainable MG implementation.","['Batteries', 'Power system reliability', 'Reliability', 'Renewable energy sources', 'Lithium', 'Fuel cells']","['Energy storage system', 'microgrid', 'distributed energy resources', 'ESS technologies', 'energy management']"
"Multi-agent systems (MASs) have received tremendous attention from scholars in different disciplines, including computer science and civil engineering, as a means to solve complex problems by subdividing them into smaller tasks. The individual tasks are allocated to autonomous entities, known as agents. Each agent decides on a proper action to solve the task using multiple inputs, e.g., history of actions, interactions with its neighboring agents, and its goal. The MAS has found multiple applications, including modeling complex systems, smart grids, and computer networks. Despite their wide applicability, there are still a number of challenges faced by MAS, including coordination between agents, security, and task allocation. This survey provides a comprehensive discussion of all aspects of MAS, starting from definitions, features, applications, challenges, and communications to evaluation. A classification on MAS applications and challenges is provided along with references for further studies. We expect this paper to serve as an insightful and comprehensive resource on the MAS for researchers and practitioners in the area.","['Task analysis', 'Multi-agent systems', 'Computer science', 'Security', 'Australia', 'Computational modeling', 'Decision making']","['Multi-agent systems', 'survey', 'MAS applications', 'challenges']"
"Internet of things (IoT) is a promising technology which provides efficient and reliable solutions towards the modernization of several domains. IoT based solutions are being developed to automatically maintain and monitor agricultural farms with minimal human involvement. The article presents many aspects of technologies involved in the domain of IoT in agriculture. It explains the major components of IoT based smart farming. A rigorous discussion on network technologies used in IoT based agriculture has been presented, that involves network architecture and layers, network topologies used, and protocols. Furthermore, the connection of IoT based agriculture systems with relevant technologies including cloud computing, big data storage and analytics has also been presented. In addition, security issues in IoT agriculture have been highlighted. A list of smart phone based and sensor based applications developed for different aspects of farm management has also been presented. Lastly, the regulations and policies made by several countries to standardize IoT based agriculture have been presented along with few available success stories. In the end, some open research issues and challenges in IoT agriculture field have been presented.","['Agriculture', 'Monitoring', 'Internet of Things', 'Protocols', 'Temperature sensors', 'Temperature measurement', 'Data acquisition']","['IoT', 'smart farming', 'applications', 'protocols', 'network', 'architecture', 'platforms', 'industries', 'security', 'challenges', 'technologies', 'policies']"
"Fog computing paradigm extends the storage, networking, and computing facilities of the cloud computing toward the edge of the networks while offloading the cloud data centers and reducing service latency to the end users. However, the characteristics of fog computing arise new security and privacy challenges. The existing security and privacy measurements for cloud computing cannot be directly applied to the fog computing due to its features, such as mobility, heterogeneity, and large-scale geo-distribution. This paper provides an overview of existing security and privacy concerns, particularly for the fog computing. Afterward, this survey highlights ongoing research effort, open challenges, and research trends in privacy and security issues for fog computing.","['Edge computing', 'Cloud computing', 'Privacy', 'Computational modeling', 'Authentication', 'Electronic mail']","['Fog', 'fog computing', 'fog networking', 'security', 'privacy', 'IoT', 'privacy threats', 'security threats']"
"In traditional cloud storage systems, attribute-based encryption (ABE) is regarded as an important technology for solving the problem of data privacy and fine-grained access control. However, in all ABE schemes, the private key generator has the ability to decrypt all data stored in the cloud server, which may bring serious problems such as key abuse and privacy data leakage. Meanwhile, the traditional cloud storage model runs in a centralized storage manner, so single point of failure may leads to the collapse of system. With the development of blockchain technology, decentralized storage mode has entered the public view. The decentralized storage approach can solve the problem of single point of failure in traditional cloud storage systems and enjoy a number of advantages over centralized storage, such as low price and high throughput. In this paper, we study the data storage and sharing scheme for decentralized storage systems and propose a framework that combines the decentralized storage system interplanetary file system, the Ethereum blockchain, and ABE technology. In this framework, the data owner has the ability to distribute secret key for data users and encrypt shared data by specifying access policy, and the scheme achieves fine-grained access control over data. At the same time, based on smart contract on the Ethereum blockchain, the keyword search function on the cipher text of the decentralized storage systems is implemented, which solves the problem that the cloud server may not return all of the results searched or return wrong results in the traditional cloud storage systems. Finally, we simulated the scheme in the Linux system and the Ethereum official test network Rinkeby, and the experimental results show that our scheme is feasible.","['Encryption', 'Cloud computing', 'Access control', 'Contracts', 'Data privacy']","['ABE', 'Ethereum blockchain', 'smart contract', 'IPFS', 'access control', 'keyword searchable']"
"For more than a decade now, radio frequency identification (RFID) technology has been quite effective in providing anti-counterfeits measures in the supply chain. However, the genuineness of RFID tags cannot be guaranteed in the post supply chain, since these tags can be rather easily cloned in the public space. In this paper, we propose a novel product ownership management system (POMS) of RFID-attached products for anti-counterfeits that can be used in the post supply chain. For this purpose, we leverage the idea of Bitcoin's blockchain that anyone can check the proof of possession of balance. With the proposed POMS, a customer can reject the purchase of counterfeits even with genuine RFID tag information, if the seller does not possess their ownership. We have implemented a proof-of-concept experimental system employing a blockchain-based decentralized application platform, Ethereum, and evaluated its cost performance. Results have shown that, typically, the cost of managing the ownership of a product with up to six transfers is less than U.S. $1.","['Supply chains', 'Bitcoin', 'RFID tags', 'Protocols', 'Internet']","['Anti-counterfeits technology', 'POMS (products ownership management system)', 'blockchain', 'Ethereum', 'security']"
"With the rising interest in autonomous vehicles, developing radio access technologies (RATs) that enable reliable and low-latency vehicular communications has become of paramount importance. Dedicated short-range communications (DSRCs) and cellular V2X (C-V2X) are two present-day technologies that are capable of supporting day-1 vehicular applications. However, these RATs fall short of supporting communication requirements of many advanced vehicular applications, which are believed to be critical in enabling fully autonomous vehicles. Both the DSRC and C-V2X are undergoing extensive enhancements in order to support advanced vehicular applications that are characterized by high reliability, low latency, and high throughput requirements. These RAT evolutions—the IEEE 802.11bd for the DSRC and NR V2X for C-V2X—can supplement today’s vehicular sensors in enabling autonomous driving. In this paper, we survey the latest developments in the standardization of 802.11bd and NR V2X. We begin with a brief description of the two present-day vehicular RATs. In doing so, we highlight their inability to guarantee the quality of service requirements of many advanced vehicular applications. We then look at the two RAT evolutions, i.e., the IEEE 802.11bd and NR V2X, outline their objectives, describe their salient features, and provide an in-depth description of key mechanisms that enable these features. While both, the IEEE 802.11bd and NR V2X, are in their initial stages of development, we shed light on their preliminary performance projections and compare and contrast the two evolutionary RATs with their respective predecessors.","['Radio access technologies', 'Vehicle-to-everything', '3GPP', 'Communication channels', '5G mobile communication', 'Reliability']","['C-V2X', 'DSRC', 'IEEE 802.11bd', 'NR V2X']"
"Alternaria leaf spot, Brown spot, Mosaic, Grey spot, and Rust are five common types of apple leaf diseases that severely affect apple yield. However, the existing research lacks an accurate and fast detector of apple diseases for ensuring the healthy development of the apple industry. This paper proposes a deep learning approach that is based on improved convolutional neural networks (CNNs) for the real-time detection of apple leaf diseases. In this paper, the apple leaf disease dataset (ALDD), which is composed of laboratory images and complex images under real field conditions, is first constructed via data augmentation and image annotation technologies. Based on this, a new apple leaf disease detection model that uses deep-CNNs is proposed by introducing the GoogLeNet Inception structure and Rainbow concatenation. Finally, under the hold-out testing dataset, using a dataset of 26,377 images of diseased apple leaves, the proposed INAR-SSD (SSD with Inception module and Rainbow concatenation) model is trained to detect these five common apple leaf diseases. The experimental results show that the INAR-SSD model realizes a detection performance of 78.80% mAP on ALDD, with a high-detection speed of 23.13 FPS. The results demonstrate that the novel INAR-SSD model provides a high-performance solution for the early diagnosis of apple leaf diseases that can perform real-time detection of these diseases with higher accuracy and faster detection speed than previous methods.","['Diseases', 'Feature extraction', 'Real-time systems', 'Convolutional neural networks', 'Training', 'Deep learning', 'Agriculture']","['Apple leaf diseases', 'real-time detection', 'deep learning', 'convolutional neural networks', 'feature fusion']"
"The globalized production and the distribution of agriculture production bring a renewed focus on the safety, quality, and the validation of several important criteria in agriculture and food supply chains. The growing number of issues related to food safety and contamination risks has established an immense need for effective traceability solution that acts as an essential quality management tool ensuring adequate safety of products in the agricultural supply chain. Blockchain is a disruptive technology that can provide an innovative solution for product traceability in agriculture and food supply chains. Today's agricultural supply chains are complex ecosystem involving several stakeholders making it cumbersome to validate several important criteria such as country of origin, stages in crop development, conformance to quality standards, and monitor yields. In this paper, we propose an approach that leverages the Ethereum blockchain and smart contracts efficiently perform business transactions for soybean tracking and traceability across the agricultural supply chain. Our proposed solution eliminates the need for a trusted centralized authority, intermediaries and provides transactions records, enhancing efficiency and safety with high integrity, reliability, and security. The proposed solution focuses on the utilization of smart contracts to govern and control all interactions and transactions among all the participants involved within the supply chain ecosystem. All transactions are recorded and stored in the blockchain's immutable ledger with links to a decentralized file system (IPFS) and thus providing to all a high level of transparency and traceability into the supply chain ecosystem in a secure, trusted, reliable, and efficient manner.","['Supply chains', 'Blockchain', 'Smart contracts', 'Agriculture', 'Safety', 'Data mining', 'Contamination']","['Blockchain', 'Ethereum', 'smart contracts', 'traceability', 'Soybean', 'agricultural supply chain', 'food safety']"
"Fog computing-enhanced Internet of Things (IoT) has recently received considerable attention, as the fog devices deployed at the network edge can not only provide low latency, location awareness but also improve real-time and quality of services in IoT application scenarios. Privacy-preserving data aggregation is one of typical fog computing applications in IoT, and many privacy-preserving data aggregation schemes have been proposed in the past years. However, most of them only support data aggregation for homogeneous IoT devices, and cannot aggregate hybrid IoT devices' data into one in some real IoT applications. To address this challenge, in this paper, we present a lightweight privacy-preserving data aggregation scheme, called Lightweight Privacy-preserving Data Aggregation, for fog computing-enhanced IoT. The proposed LPDA is characterized by employing the homomorphic Paillier encryption, Chinese Remainder Theorem, and one-way hash chain techniques to not only aggregate hybrid IoT devices' data into one, but also early filter injected false data at the network edge. Detailed security analysis shows LPDA is really secure and privacy-enhanced with differential privacy techniques. In addition, extensive performance evaluations are conducted, and the results indicate LPDA is really lightweight in fog computing-enhanced IoT.","['Security', 'Data aggregation', 'Edge computing', 'Real-time systems', 'Internet of Things', 'Aggregates', 'Computational modeling']","['Internet of Things', 'fog computing', 'privacy-preserving aggregation', 'lightweight', 'differential privacy']"
"The development of an anomaly-based intrusion detection system (IDS) is a primary research direction in the field of intrusion detection. An IDS learns normal and anomalous behavior by analyzing network traffic and can detect unknown and new attacks. However, the performance of an IDS is highly dependent on feature design, and designing a feature set that can accurately characterize network traffic is still an ongoing research issue. Anomaly-based IDSs also have the problem of a high false alarm rate (FAR), which seriously restricts their practical applications. In this paper, we propose a novel IDS called the hierarchical spatial-temporal features-based intrusion detection system (HAST-IDS), which first learns the low-level spatial features of network traffic using deep convolutional neural networks (CNNs) and then learns high-level temporal features using long short-term memory networks. The entire process of feature learning is completed by the deep neural networks automatically; no feature engineering techniques are required. The automatically learned traffic features effectively reduce the FAR. The standard DARPA1998 and ISCX2012 data sets are used to evaluate the performance of the proposed system. The experimental results show that the HAST-IDS outperforms other published approaches in terms of accuracy, detection rate, and FAR, which successfully demonstrates its effectiveness in both feature learning and FAR reduction.","['Telecommunication traffic', 'Feature extraction', 'Intrusion detection', 'Recurrent neural networks', 'Natural language processing']","['Network intrusion detection', 'deep neural networks', 'representation learning']"
"Blockchain technology enables the creation of a decentralized environment, where transactions and data are not under the control of any third party organization. Any transaction ever completed is recorded in a public ledger in a verifiable and permanent way. Based on the blockchain technology, we propose a global higher education credit platform, named EduCTX. This platform is based on the concept of the European Credit Transfer and Accumulation System (ECTS). It constitutes a globally trusted, decentralized higher education credit, and grading system that can offer a globally unified viewpoint for students and higher education institutions (HEIs), as well as for other potential stakeholders, such as companies, institutions, and organizations. As a proof of concept, we present a prototype implementation of the environment, based on the open-source Ark Blockchain Platform. Based on a globally distributed peer-to-peer network, EduCTX will process, manage, and control ECTX tokens, which represent credits that students gain for completed courses, such as ECTS. HEIs are the peers of the blockchain network. The platform is a first step toward a more transparent and technologically advanced form of higher education systems. The EduCTX platform represents the basis of the EduCTX initiative, which anticipates that various HEIs would join forces in order to create a globally efficient, simplified, and ubiquitous environment in order to avoid language and administrative barriers. Therefore, we invite and encourage HEIs to join the EduCTX initiative and the EduCTX blockchain network.","['Education', 'Prototypes', 'Europe', 'Bitcoin', 'Open source software', 'Organizations']","['Blockchain', 'higher education', 'ECTS', 'tokens']"
"Due to the proliferation of ICT during the last few decades, there is an exponential increase in the usage of various smart applications such as smart farming, smart healthcare, supply-chain & logistics, business, tourism and hospitality, energy management etc. However, for all the aforementioned applications, security and privacy are major concerns keeping in view of the usage of the open channel, i.e., Internet for data transfer. Although many security solutions and standards have been proposed over the years to enhance the security levels of aforementioned smart applications, but the existing solutions are either based upon the centralized architecture (having single point of failure) or having high computation and communication costs. Moreover, most of the existing security solutions have focussed only on few aspects and fail to address scalability, robustness, data storage, network latency, auditability, immutability, and traceability. To handle the aforementioned issues, blockchain technology can be one of the solutions. Motivated from these facts, in this paper, we present a systematic review of various blockchain-based solutions and their applicability in various Industry 4.0-based applications. Our contributions in this paper are in four fold. Firstly, we explored the current state-of-the-art solutions in the blockchain technology for the smart applications. Then, we illustrated the reference architecture used for the blockchain applicability in various Industry 4.0 applications. Then, merits and demerits of the traditional security solutions are also discussed in comparison to their countermeasures. Finally, we provided a comparison of existing blockchain-based security solutions using various parameters to provide deep insights to the readers about its applicability in various applications.","['Industries', 'Medical services', 'Computer architecture', 'Data privacy', 'Internet']","['Blockchain', 'consensus algorithms', 'cyber-physical systems', 'IoT', 'smart grid', 'supply chain management', 'intelligent transportation']"
"In the field of agricultural information, the automatic identification and diagnosis of maize leaf diseases is highly desired. To improve the identification accuracy of maize leaf diseases and reduce the number of network parameters, the improved GoogLeNet and Cifar10 models based on deep learning are proposed for leaf disease recognition in this paper. Two improved models that are used to train and test nine kinds of maize leaf images are obtained by adjusting the parameters, changing the pooling combinations, adding dropout operations and rectified linear unit functions, and reducing the number of classifiers. In addition, the number of parameters of the improved models is significantly smaller than that of the VGG and AlexNet structures. During the recognition of eight kinds of maize leaf diseases, the GoogLeNet model achieves a top - 1 average identification accuracy of 98.9%, and the Cifar10 model achieves an average accuracy of 98.8%. The improved methods are possibly improved the accuracy of maize leaf disease, and reduced the convergence iterations, which can effectively improve the model training and recognition efficiency.","['Diseases', 'Training', 'Machine learning', 'Support vector machines', 'Testing', 'Convolutional neural networks']","['Deep learning', 'deep convolutional neural networks', 'identification', 'image processing', 'leaf diseases']"
"The vision of Industry 4.0, otherwise known as the fourth industrial revolution, is the integration of massively deployed smart computing and network technologies in industrial production and manufacturing settings for the purposes of automation, reliability, and control, implicating the development of an Industrial Internet of Things (I-IoT). Specifically, I-IoT is devoted to adopting the IoT to enable the interconnection of anything, anywhere, and at any time in the manufacturing system context to improve the productivity, efficiency, safety, and intelligence. As an emerging technology, I-IoT has distinct properties and requirements that distinguish it from consumer IoT, including the unique types of smart devices incorporated, network technologies and quality-of-service requirements, and strict needs of command and control. To more clearly understand the complexities of I-IoT and its distinct needs and to present a unified assessment of the technology from a systems’ perspective, in this paper, we comprehensively survey the body of existing research on I-IoT. Particularly, we first present the I-IoT architecture, I-IoT applications (i.e., factory automation and process automation), and their characteristics. We then consider existing research efforts from the three key system aspects of control, networking, and computing. Regarding control, we first categorize industrial control systems and then present recent and relevant research efforts. Next, considering networking, we propose a three-dimensional framework to explore the existing research space and investigate the adoption of some representative networking technologies, including 5G, machine-to-machine communication, and software-defined networking. Similarly, concerning computing, we again propose a second three-dimensional framework that explores the problem space of computing in I-IoT and investigate the cloud, edge, and hybrid cloud and edge computing platforms. Finally, we outline particular challenges and future research needs in control, networking, and computing systems, as well as for the adoption of machine learning in an I-IoT context.","['Manufacturing', 'Automation', 'Machine learning', 'Sensors', 'Production', 'Control systems', 'Cloud computing']","['Industrial Internet of Things', 'industrial cyber physical systems', 'application and service', 'control', 'networking', 'computing', 'machine learning', 'big data analytics', 'survey', 'future research directions']"
"Smart world is envisioned as an era in which objects (e.g., watches, mobile phones, computers, cars, buses, and trains) can automatically and intelligently serve people in a collaborative manner. Paving the way for smart world, Internet of Things (IoT) connects everything in the smart world. Motivated by achieving a sustainable smart world, this paper discusses various technologies and issues regarding green IoT, which further reduces the energy consumption of IoT. Particularly, an overview regarding IoT and green IoT is performed first. Then, the hot green information and communications technologies (ICTs) (e.g., green radio-frequency identification, green wireless sensor network, green cloud computing, green machine to machine, and green data center) enabling green IoT are studied, and general green ICT principles are summarized. Furthermore, the latest developments and future vision about sensor cloud, which is a novel paradigm in green IoT, are reviewed and introduced, respectively. Finally, future research directions and open problems about green IoT are presented. Our work targets to be an enlightening and latest guidance for research with respect to green IoT and smart world.","['Internet of things', 'Radio frequency identification', 'Wireless sensor networks', 'Machine-to-machine communications', 'Cloud computing', 'Data centers']","['Smart world', 'internet of things', 'green', 'radio frequency identification', 'wireless sensor network', 'cloud computing', 'machine to machine', 'data center', 'sensor-cloud']"
"New high-data-rate multimedia services and applications are evolving continuously and exponentially increasing the demand for wireless capacity of fifth-generation (5G) and beyond. The existing radio frequency (RF) communication spectrum is insufficient to meet the demands of future high-datarate 5G services. Optical wireless communication (OWC), which uses an ultra-wide range of unregulated spectrum, has emerged as a promising solution to overcome the RF spectrum crisis. It has attracted growing research interest worldwide in the last decade for indoor and outdoor applications. OWC offloads huge data traffic applications from RF networks. A 100 Gb/s data rate has already been demonstrated through OWC. It offers services indoors as well as outdoors, and communication distances range from several nm to more than 10000 km. This paper provides a technology overview and a review on optical wireless technologies, such as visible light communication, light fidelity, optical camera communication, free space optical communication, and light detection and ranging. We survey the key technologies for understanding OWC and present state-of-the-art criteria in aspects, such as classification, spectrum use, architecture, and applications. The key contribution of this paper is to clarify the differences among different promising optical wireless technologies and between these technologies and their corresponding similar existing RF technologies.","['Wireless communication', '5G mobile communication', 'Radio frequency', 'Optical transmitters', 'Optical fiber communication', 'Optical sensors']","['Free space optical communication', 'infrared', 'light detection and ranging', 'light fidelity', 'optical camera communication', 'optical wireless communication', 'radio frequency', 'ultraviolet', 'visible light', 'visible light communication']"
"COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19's spread in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to 5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning (DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs), Extreme Learning Machine (ELM), and Long/Short Term Memory (LSTM). It delineates an integrated bioinformatics approach in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers. The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of the COVID-19 disease. The most recent related publications and medical reports were investigated with the purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs for each platform, including various forms of the data, such as clinical data and medical imaging which can improve the performance of the introduced approaches toward the best responses in practical applications.","['Artificial intelligence', 'COVID-19', 'Medical diagnostic imaging', 'Databases']","['Artificial intelligence', 'big data', 'bioinformatics', 'biomedical informatics', 'COVID-19', 'deep learning', 'diagnosis', 'machine learning', 'treatment']"
"The growing popularity and development of data mining technologies bring serious threat to the security of individual,'s sensitive information. An emerging research topic in data mining, known as privacy-preserving data mining (PPDM), has been extensively studied in recent years. The basic idea of PPDM is to modify the data in such a way so as to perform data mining algorithms effectively without compromising the security of sensitive information contained in the data. Current studies of PPDM mainly focus on how to reduce the privacy risk brought by data mining operations, while in fact, unwanted disclosure of sensitive information may also happen in the process of data collecting, data publishing, and information (i.e., the data mining results) delivering. In this paper, we view the privacy issues related to data mining from a wider perspective and investigate various approaches that can help to protect sensitive information. In particular, we identify four different types of users involved in data mining applications, namely, data provider, data collector, data miner, and decision maker. For each type of user, we discuss his privacy concerns and the methods that can be adopted to protect sensitive information. We briefly introduce the basics of related research topics, review state-of-the-art approaches, and present some preliminary thoughts on future research directions. Besides exploring the privacy-preserving approaches for each type of user, we also review the game theoretical approaches, which are proposed for analyzing the interactions among different users in a data mining scenario, each of whom has his own valuation on the sensitive information. By differentiating the responsibilities of different users with respect to security of sensitive information, we would like to provide some useful insights into the study of PPDM.","['Privacy', 'Data mining', 'Game theory', 'Tracking', 'Computer security', 'Data privacy', 'Algorithm design and analysis']","['data mining', 'sensitive information', 'privacypreserving data mining', 'anonymization', 'provenance', 'game theory', 'privacy auction', 'anti-tracking']"
"Diverse proprietary network appliances increase both the capital and operational expense of service providers, meanwhile causing problems of network ossification. Network function virtualization (NFV) is proposed to address these issues by implementing network functions as pure software on commodity and general hardware. NFV allows flexible provisioning, deployment, and centralized management of virtual network functions. Integrated with SDN, the software-defined NFV architecture further offers agile traffic steering and joint optimization of network functions and resources. This architecture benefits a wide range of applications (e.g., service chaining) and is becoming the dominant form of NFV. In this survey, we present a thorough investigation of the development of NFV under the software-defined NFV architecture, with an emphasis on service chaining as its application. We first introduce the software-defined NFV architecture as the state of the art of NFV and present relationships between NFV and SDN. Then, we provide a historic view of the involvement from middlebox to NFV. Finally, we introduce significant challenges and relevant solutions of NFV, and discuss its future research directions by different application domains.","['Computer architecture', 'Virtualization', 'Hardware', 'Software', 'Home appliances', 'Control systems', 'Servers']","['Software-defined networks', 'network function virtualization', 'middlebox', 'service chain', 'network virtualization']"
"Emerging technologies such as the Internet of Things (IoT) require latency-aware computation for real-time application processing. In IoT environments, connected things generate a huge amount of data, which are generally referred to as big data. Data generated from IoT devices are generally processed in a cloud infrastructure because of the on-demand services and scalability features of the cloud computing paradigm. However, processing IoT application requests on the cloud exclusively is not an efficient solution for some IoT applications, especially time-sensitive ones. To address this issue, Fog computing, which resides in between cloud and IoT devices, was proposed. In general, in the Fog computing environment, IoT devices are connected to Fog devices. These Fog devices are located in close proximity to users and are responsible for intermediate computation and storage. One of the key challenges in running IoT applications in a Fog computing environment are resource allocation and task scheduling. Fog computing research is still in its infancy, and taxonomy-based investigation into the requirements of Fog infrastructure, platform, and applications mapped to current research is still required. This survey will help the industry and research community synthesize and identify the requirements for Fog computing. This paper starts with an overview of Fog computing in which the definition of Fog computing, research trends, and the technical differences between Fog and cloud are reviewed. Then, we investigate numerous proposed Fog computing architectures and describe the components of these architectures in detail. From this, the role of each component will be defined, which will help in the deployment of Fog computing. Next, a taxonomy of Fog computing is proposed by considering the requirements of the Fog computing paradigm. We also discuss existing research works and gaps in resource allocation and scheduling, fault tolerance, simulation tools, and Fog-based microservices. Finally, by addressing the limitations of current research works, we present some open issues, which will determine the future research direction for the Fog computing paradigm.","['Edge computing', 'Cloud computing', 'Computer architecture', 'Market research', 'Internet of Things', 'Resource management', 'Taxonomy']","['Fog computing', 'Internet of Things (IoT)', 'fog devices', 'fault tolerance', 'IoT application', 'microservices']"
"Intrusion detection is a fundamental part of security tools, such as adaptive security appliances, intrusion detection systems, intrusion prevention systems, and firewalls. Various intrusion detection techniques are used, but their performance is an issue. Intrusion detection performance depends on accuracy, which needs to improve to decrease false alarms and to increase the detection rate. To resolve concerns on performance, multilayer perceptron, support vector machine (SVM), and other techniques have been used in recent work. Such techniques indicate limitations and are not efficient for use in large data sets, such as system and network data. The intrusion detection system is used in analyzing huge traffic data; thus, an efficient classification technique is necessary to overcome the issue. This problem is considered in this paper. Well-known machine learning techniques, namely, SVM, random forest, and extreme learning machine (ELM) are applied. These techniques are well-known because of their capability in classification. The NSL–knowledge discovery and data mining data set is used, which is considered a benchmark in the evaluation of intrusion detection mechanisms. The results indicate that ELM outperforms other approaches.","['Intrusion detection', 'Support vector machines', 'Radio frequency', 'Training', 'Forestry', 'Kernel']","['Detection rate', 'extreme learning machine', 'false alarms', 'NSL–KDD', 'random forest', 'support vector machine']"
"In the past years, traditional pattern recognition methods have made great progress. However, these methods rely heavily on manual feature extraction, which may hinder the generalization model performance. With the increasing popularity and success of deep learning methods, using these techniques to recognize human actions in mobile and wearable computing scenarios has attracted widespread attention. In this paper, a deep neural network that combines convolutional layers with long short-term memory (LSTM) was proposed. This model could extract activity features automatically and classify them with a few model parameters. LSTM is a variant of the recurrent neural network (RNN), which is more suitable for processing temporal sequences. In the proposed architecture, the raw data collected by mobile sensors was fed into a two-layer LSTM followed by convolutional layers. In addition, a global average pooling layer (GAP) was applied to replace the fully connected layer after convolution for reducing model parameters. Moreover, a batch normalization layer (BN) was added after the GAP layer to speed up the convergence, and obvious results were achieved. The model performance was evaluated on three public datasets (UCI, WISDM, and OPPORTUNITY). Finally, the overall accuracy of the model in the UCI-HAR dataset is 95.78%, in the WISDM dataset is 95.85%, and in the OPPORTUNITY dataset is 92.63%. The results show that the proposed model has higher robustness and better activity detection capability than some of the reported results. It can not only adaptively extract activity features, but also has fewer parameters and higher accuracy.","['Feature extraction', 'Activity recognition', 'Acceleration', 'Deep learning', 'Sensor phenomena and characterization', 'Accelerometers']","['Human activity recognition', 'convolution', 'long short-term memory', 'mobile sensors']"
"Brain tumor classification is a crucial task to evaluate the tumors and make a treatment decision according to their classes. There are many imaging techniques used to detect brain tumors. However, MRI is commonly used due to its superior image quality and the fact of relying on no ionizing radiation. Deep learning (DL) is a subfield of machine learning and recently showed a remarkable performance, especially in classification and segmentation problems. In this paper, a DL model based on a convolutional neural network is proposed to classify different brain tumor types using two publicly available datasets. The former one classifies tumors into (meningioma, glioma, and pituitary tumor). The other one differentiates between the three glioma grades (Grade II, Grade III, and Grade IV). The datasets include 233 and 73 patients with a total of 3064 and 516 images on T1-weighted contrast-enhanced images for the first and second datasets, respectively. The proposed network structure achieves a significant performance with the best overall accuracy of 96.13% and 98.7%, respectively, for the two studies. The results indicate the ability of the model for brain tumor multi-classification purposes.","['Tumors', 'Feature extraction', 'Cancer', 'Task analysis', 'Magnetic resonance imaging', 'Convolutional neural networks', 'Training']","['Brain tumor', 'convolutional neural network', 'data augmentation', 'deep learning', 'MRI']"
"Wind energy has seen great development during the past decade. However, wind turbine availability and reliability, especially for offshore sites, still need to be improved, which strongly affect the cost of wind energy. Wind turbine operational cost is closely depending on component failure and repair rate, while fault detection and isolation will be very helpful to improve the availability and reliability factors. In this paper, an efficient machine learning method, random forests (RFs) in combination with extreme gradient boosting (XGBoost), is used to establish the data-driven wind turbine fault detection framework. In the proposed design, RF is used to rank the features by importance, which are either direct sensor signals or constructed variables from prior knowledge. Then, based on the top-ranking features, XGBoost trains the ensemble classifier for each specific fault. In order to verify the effectiveness of the proposed approach, numerical simulations using the state-of-the-art wind turbine simulator FAST are conducted for three different types of wind turbines in both the below and above rated conditions. It is shown that the proposed approach is robust to various wind turbine models including offshore ones in different working conditions. Besides, the proposed ensemble classifier is able to protect against overfitting, and it achieves better wind turbine fault detection results than the support vector machine method when dealing with multidimensional data.","['Wind turbines', 'Generators', 'Actuators', 'Blades', 'Radio frequency', 'Fault detection', 'Support vector machines']","['Wind turbines', 'fault detection', 'data-driven', 'random forests', 'extreme gradient boosting']"
"Generative adversarial network (GANs) is one of the most important research avenues in the field of artificial intelligence, and its outstanding data generation capacity has received wide attention. In this paper, we present the recent progress on GANs. First, the basic theory of GANs and the differences among different generative models in recent years were analyzed and summarized. Then, the derived models of GANs are classified and introduced one by one. Third, the training tricks and evaluation metrics were given. Fourth, the applications of GANs were introduced. Finally, the problem, we need to address, and future directions were discussed.","['Gallium nitride', 'Generators', 'Generative adversarial networks', 'Training', 'Feature extraction', 'Data models', 'Unsupervised learning']","['Deep learning', 'machine learning', 'unsupervised learning', 'generative adversarial networks']"
"Software defined networking (SDN) brings about innovation, simplicity in network management, and configuration in network computing. Traditional networks often lack the flexibility to bring into effect instant changes because of the rigidity of the network and also the over dependence on proprietary services. SDN decouples the control plane from the data plane, thus moving the control logic from the node to a central controller. A wireless sensor network (WSN) is a great platform for low-rate wireless personal area networks with little resources and short communication ranges. However, as the scale of WSN expands, it faces several challenges, such as network management and heterogeneous-node networks. The SDN approach to WSNs seeks to alleviate most of the challenges and ultimately foster efficiency and sustainability in WSNs. The fusion of these two models gives rise to a new paradigm: Software defined wireless sensor networks (SDWSN). The SDWSN model is also envisioned to play a critical role in the looming Internet of Things paradigm. This paper presents a comprehensive review of the SDWSN literature. Moreover, it delves into some of the challenges facing this paradigm, as well as the major SDWSN design requirements that need to be considered to address these challenges.","['Wireless sensor networks', 'Software', 'Protocols', 'Iron', 'Internet of Things', 'Switches']","['Software defined wireless sensor networks', 'software defined networking', 'wireless sensor networks']"
"The recent advances in embedded processing have enabled the vision based systems to detect fire during surveillance using convolutional neural networks (CNNs). However, such methods generally need more computational time and memory, restricting its implementation in surveillance networks. In this research paper, we propose a cost-effective fire detection CNN architecture for surveillance videos. The model is inspired from GoogleNet architecture, considering its reasonable computational complexity and suitability for the intended problem compared to other computationally expensive networks such as AlexNet. To balance the efficiency and accuracy, the model is fine-tuned considering the nature of the target problem and fire data. Experimental results on benchmark fire datasets reveal the effectiveness of the proposed framework and validate its suitability for fire detection in CCTV surveillance systems compared to state-of-the-art methods.","['Fires', 'Surveillance', 'Computer architecture', 'Videos', 'Color', 'Feature extraction', 'Convolution']","['Fire detection', 'image classification', 'real-world applications', 'deep learning', 'CCTV video analysis']"
"With the purpose of identifying cyber threats and possible incidents, intrusion detection systems (IDSs) are widely deployed in various computer networks. In order to enhance the detection capability of a single IDS, collaborative intrusion detection networks (or collaborative IDSs) have been developed, which allow IDS nodes to exchange data with each other. However, data and trust management still remain two challenges for current detection architectures, which may degrade the effectiveness of such detection systems. In recent years, blockchain technology has shown its adaptability in many fields, such as supply chain management, international payment, interbanking, and so on. As blockchain can protect the integrity of data storage and ensure process transparency, it has a potential to be applied to intrusion detection domain. Motivated by this, this paper provides a review regarding the intersection of IDSs and blockchains. In particular, we introduce the background of intrusion detection and blockchain, discuss the applicability of blockchain to intrusion detection, and identify open challenges in this direction.","['Intrusion detection', 'Collaboration', 'Peer-to-peer computing', 'Monitoring', 'Resistance']","['Blockchain technology', 'intrusion detection', 'collaborative network', 'trust management', 'data sharing and management']"
"Internet of Things (IoT) is one of the evolutionary directions of the Internet. This paper focuses on the low earth orbit (LEO) satellite constellation-based IoT services for their irreplaceable functions. In many cases, IoT devices are distributed in remote areas (e.g., desert, ocean, and forest) in some special applications, they are placed in some extreme topography, where are unable to have direct terrestrial network accesses and can only be covered by satellite. Comparing with the traditional geostationary earth orbit (GEO) systems, LEO satellite constellation has the advantages of low propagation delay, small propagation loss and global coverage. Furthermore, revision of existing IoT protocol are necessary to enhance the compatibility of the LEO satellite constellation-based IoT with terrestrial IoT systems. In this paper, we provide an overview of the architecture of the LEO satellite constellation-based IoT including the following topics: LEO satellite constellation structure, efficient spectrum allocation, heterogeneous networks compatibility, and access and routing protocols.","['Low earth orbit satellites', 'Monitoring', 'Satellite constellations', 'Protocols', 'Machine-to-machine communications', 'Sensors']","['Internet of things (IoT)', 'LEO satellite constellation', 'low-power wide-area network (LPWAN)', 'long range (LoRa)', 'machine-to-machine (M2M) communications', 'narrow band internet of things (NB-IoT)']"
"After many years of rigid conventional procedures of production, industrial manufacturing is going through a process of change toward flexible and intelligent manufacturing, the so-called Industry 4.0. In this paper, human-robot collaboration has an important role in smart factories since it contributes to the achievement of higher productivity and greater efficiency. However, this evolution means breaking with the established safety procedures as the separation of workspaces between robot and human is removed. These changes are reflected in safety standards related to industrial robotics since the last decade, and have led to the development of a wide field of research focusing on the prevention of human-robot impacts and/or the minimization of related risks or their consequences. This paper presents a review of the main safety systems that have been proposed and applied in industrial robotic environments that contribute to the achievement of safe collaborative human-robot work. Additionally, a review is provided of the current regulations along with new concepts that have been introduced in them. The discussion presented in this paper includes multidisciplinary approaches, such as techniques for estimation and the evaluation of injuries in human-robot collisions, mechanical and software devices designed to minimize the consequences of human-robot impact, impact detection systems, and strategies to prevent collisions or minimize their consequences when they occur.","['Service robots', 'Safety', 'Robot sensing systems', 'Collaboration', 'Standards', 'Collision avoidance']","['Safety', 'industrial robot', 'human-robot collaboration', 'industrial standards', 'Industry 4.0']"
"Blockchain technologies have recently come to the forefront of the research and industrial communities as they bring potential benefits for many industries. This is due to their practical capabilities in solving many issues currently inhibiting further advances in various industrial domains. Securely recording and sharing transactional data, establishing automated and efficient supply chain processes, and enhancing transparency across the whole value chain are some examples of these issues. Blockchain offers an effective way to tackle these issues using distributed, shared, secure, and permissioned transactional ledgers. The employment of blockchain technologies and the possibility of applying them in different situations enables many industrial applications through increased efficiency and security; enhanced traceability and transparency; and reduced costs. In this paper, different industrial application domains where the use of blockchain technologies has been proposed are reviewed. This paper explores the opportunities, benefits, and challenges of incorporating blockchain in different industrial applications. Furthermore, the paper attempts to identify the requirements that support the implementation of blockchain for different industrial applications. The review reveals that several opportunities are available for utilizing blockchain in various industrial sectors; however, there are still some challenges to be addressed to achieve better utilization of this technology.",[],[]
"In the era of smart cities, there are a plethora of applications where the localization of indoor environments is important, from monitoring and tracking in smart buildings to proximity marketing and advertising in shopping malls. The success of these applications is based on the development of a cost-efficient and robust real-time system capable of accurately localizing objects. In most outdoor localization systems, global positioning system (GPS) is used due to its ease of implementation and accuracy up to five meters. However, due to the limited space that comes with performing localization of indoor environments and the large number of obstacles found indoors, GPS is not a suitable option. Hence, accurately and efficiently locating objects is a major challenge in indoor environments. Recent advancements in the Internet of Things (IoT) along with novel wireless technologies can alleviate the problem. Small-size and cost-efficient IoT devices which use wireless protocols can provide an attractive solution. In this paper, we compare four wireless technologies for indoor localization: Wi-Fi (IEEE 802.11n-2009 at the 2.4 GHz band), Bluetooth low energy, Zigbee, and long-range wide-area network. These technologies are compared in terms of localization accuracy and power consumption when IoT devices are used. The received signal strength indicator (RSSI) values from each modality were used and trilateration was performed for localization. The RSSI data set is available online. The experimental results can be used as an indicator in the selection of a wireless technology for an indoor localization system following application requirements.","['Wireless fidelity', 'Wireless communication', 'Performance evaluation', 'Global Positioning System', 'Receivers', 'ZigBee', 'Hardware']","['Indoor localization accuracy', 'power consumption', 'Internet of Things', 'RSSI', 'WiFi', 'Bluetooth low energy', 'Zigbee', 'LoRaWAN']"
"The Blockchain technology can be defined as a distributed ledger database for recording transactions between parties verifiably and permanently. Blockchain emerged as a leading technology layer for financial applications. Nevertheless, in the past years, the attention of researchers and practitioners moved to the application of the Blockchain technologies to other domains. Recently, it represents the backbone of a new digital supply chain. Thanks to its capability of ensuring data immutability and public accessibility of data streams, Blockchain can increase the efficiency, reliability, and transparency of the overall supply chain, and optimize the inbound processes. The literature concerning Blockchain in non-financial applications mainly focused on the technological part and the Business Process Modeling, lacking in terms of standard methodology for designing a strategy to develop and validate the overall Blockchain solution and integrate it in the Business Strategy. Thus, this paper aims to overcome this lack. First, we integrate the current literature filling the lack concerning the digital strategy, creating a standard methodology to design Blockchain technology use cases, which are not related to finance applications. Second, we present the results of a use case in the fresh food delivery, showing the critical aspects of implementing a Blockchain solution. Moreover, the paper discusses how the Blockchain will help in reducing the logistics costs and in optimizing the operations and the research challenges.","['Supply chains', 'Standards']","['Blockchain', 'hyperledger', 'supply chain']"
"The Internet of Drones (IoD) is a layered network control architecture designed mainly for coordinating the access of unmanned aerial vehicles to controlled airspace, and providing navigation services between locations referred to as nodes. The IoD provides generic services for various drone applications, such as package delivery, traffic surveillance, search and rescue, and more. In this paper, we present a conceptual model of how such an architecture can be organized and we specify the features that an IoD system based on our architecture should implement. For doing so, we extract key concepts from three existing large scale networks, namely the air traffic control network, the cellular network, and the Internet, and explore their connections to our novel architecture for drone traffic management. A simulation platform for IoD is being implemented, which can be accessed from www.IoDnet.org in the future.","['Internet of things', 'Drones', 'Network architecture', 'Internet', 'Navigation', 'Atmospheric modeling', 'Surveillance', 'Traffic control']","['Layered architecture', 'Internet of Drones (IoD)', 'Internet', 'cellular network', 'air traffic control (ATC)', 'low altitude air traffic management', 'unmanned aerial vehicle (UAV)']"
"Wireless mediums, such as RF, optical, or acoustical, provide finite resources for the purposes of remote sensing (such as radar) and data communications. Often, these two functions are at odds with one another and compete for these resources. Applications for wireless technology are growing rapidly, and RF convergence is already presenting itself as a requirement for both users as consumer and military system requirements evolve. The broad solution space to this complex problem encompasses cooperation or codesigning of systems with both sensing and communications functions. By jointly considering the systems during the design phase, rather than perpetuating a notion of mutual interference, both system's performance can be improved. We provide a point of departure for future researchers that will be required to solve this problem by presenting the applications, topologies, levels of system integration, the current state of the art, and outlines of future information-centric systems.","['Radio frequency', 'Radar communication', 'Wireless sensor networks', 'Laser radar', 'Remote sensing', 'Radar remote sensing']","['RF convergence', 'radar communications co-existence', 'joint sensing-communications', 'wireless resources']"
"This paper reviews the basic concepts of rays, ray tracing algorithms, and radio propagation modeling using ray tracing methods. We focus on the fundamental concepts and the development of practical ray tracing algorithms. The most recent progress and a future perspective of ray tracing are also discussed. We envision propagation modeling in the near future as an intelligent, accurate, and real-time system in which ray tracing plays an important role. This review is especially useful for experts who are developing new ray tracing algorithms to enhance modeling accuracy and improve computational speed.","['Ray tracing', 'Radio propagation', 'Modeling', 'Acceleration', 'Algorithm design and analysis', 'Radio propagation', 'Propagation modeling']","['Radio propagation', 'propagation modeling', 'acceleration algorithm']"
"Lithium-ion battery is an appropriate choice for electric vehicle (EV) due to its promising features of high voltage, high energy density, low self-discharge and long lifecycles. The successful operation of EV is highly dependent on the operation of battery management system (BMS). State of charge (SOC) is one of the vital paraments of BMS which signifies the amount of charge left in a battery. A good estimation of SOC leads to long battery life and prevention of catastrophe from battery failure. Besides, an accurate and robust SOC estimation has great significance towards an efficient EV operation. However, SOC estimation is a complex process due to its dependency on various factors such as battery age, ambient temperature, and many unknown factors. This review presents the recent SOC estimation methods highlighting the model-based and data-driven approaches. Model-based methods attempt to model the battery behavior incorporating various factors into complex mathematical equations in order to accurately estimate the SOC while the data-driven methods adopt an approach of learning the battery's behavior by running complex algorithms with a large amount of measured battery data. The classifications of model-based and data-driven based SOC estimation are explained in terms of estimation model/algorithm, benefits, drawbacks, and estimation error. In addition, the review highlights many factors and challenges and delivers potential recommendations for the development of SOC estimation methods in EV applications. All the highlighted insights of this review will hopefully lead to increased efforts toward the enhancement of SOC estimation method of lithium-ion battery for the future high-tech EV applications.","['State of charge', 'Batteries', 'Estimation', 'Temperature measurement', 'Mathematical model', 'Integrated circuit modeling']","['State of charge', 'lithium-ion battery', 'electric vehicle', 'model-based approaches', 'data-driven approaches']"
"With the rapid development of the Internet of Everything (IoE), the number of smart devices connected to the Internet is increasing, resulting in large-scale data, which has caused problems such as bandwidth load, slow response speed, poor security, and poor privacy in traditional cloud computing models. Traditional cloud computing is no longer sufficient to support the diverse needs of today's intelligent society for data processing, so edge computing technologies have emerged. It is a new computing paradigm for performing calculations at the edge of the network. Unlike cloud computing, it emphasizes closer to the user and closer to the source of the data. At the edge of the network, it is lightweight for local, small-scale data storage and processing. This article mainly reviews the related research and results of edge computing. First, it summarizes the concept of edge computing and compares it with cloud computing. Then summarize the architecture of edge computing, keyword technology, security and privacy protection, and finally summarize the applications of edge computing.","['Cloud computing', 'Edge computing', 'Real-time systems', 'Internet of Things', 'Bandwidth', 'Security', 'Data privacy']","['Edge computing', 'cloud computing', 'Internet of Things']"
"Blockchain-based decentralized cryptocurrencies have drawn much attention and been widely-deployed in recent years. Bitcoin, the first application of blockchain, achieves great success and promotes more development in this field. However, Bitcoin encounters performance problems of low throughput and high transaction latency. Other cryptocurrencies based on proof-of-work also inherit the flaws, leading to more concerns about the scalability of blockchain. This paper attempts to cover the existing scaling solutions for blockchain and classify them by level. In addition, we make comparisons between different methods and list some potential directions for solving the scalability problem of blockchain.","['Blockchain', 'Scalability', 'Bitcoin', 'Throughput', 'Measurement']","['Blockchain', 'scalability']"
"In this paper, we review the background and state-of-the-art of the narrow-band Internet of Things (NB-IoT). We first introduce NB-IoT general background, development history, and standardization. Then, we present NB-IoT features through the review of current national and international studies on NB-IoT technology, where we focus on basic theories and key technologies, i.e., connection count analysis theory, delay analysis theory, coverage enhancement mechanism, ultra-low power consumption technology, and coupling relationship between signaling and data. Subsequently, we compare several performances of NB-IoT and other wireless and mobile communication technologies in aspects of latency, security, availability, data transmission rate, energy consumption, spectral efficiency, and coverage area. Moreover, we analyze five intelligent applications of NB-IoT, including smart cities, smart buildings, intelligent environment monitoring, intelligent user services, and smart metering. Finally, we summarize security requirements of NB-IoT, which need to be solved urgently. These discussions aim to provide a comprehensive overview of NB-IoT, which can help readers to understand clearly the scientific problems and future research directions of NB-IoT.","['Couplings', 'Security', '3GPP', 'Long Term Evolution', 'Uplink', 'Internet of Things', 'GSM']","['Intelligent application', 'Internet of Things', 'LPWAN', 'LTE', 'NB-IoT']"
"The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning.","['Education', 'Technological innovation', 'Learning (artificial intelligence)', 'Microcomputers', 'Robots']","['Education', 'artificial intelligence', 'leaner']"
"The upcoming fifth generation (5G) of wireless networks is expected to lay a foundation of intelligent networks with the provision of some isolated artificial intelligence (AI) operations. However, fully intelligent network orchestration and management for providing innovative services will only be realized in Beyond 5G (B5G) networks. To this end, we envisage that the sixth generation (6G) of wireless networks will be driven by on-demand self-reconfiguration to ensure a many-fold increase in the network performance and service types. The increasingly stringent performance requirements of emerging networks may finally trigger the deployment of some interesting new technologies, such as large intelligent surfaces, electromagnetic-orbital angular momentum, visible light communications, and cell-free communications, to name a few. Our vision for 6G is a massively connected complex network capable of rapidly responding to the users' service calls through real-time learning of the network state as described by the network edge (e.g., base-station locations and cache contents), air interface (e.g., radio spectrum and propagation channel), and the user-side (e.g., battery-life and locations). The multi-state, multi-dimensional nature of the network state, requiring the real-time knowledge, can be viewed as a quantum uncertainty problem. In this regard, the emerging paradigms of machine learning (ML), quantum computing (QC), and quantum ML (QML) and their synergies with communication networks can be considered as core 6G enablers. Considering these potentials, starting with the 5G target services and enabling technologies, we provide a comprehensive review of the related state of the art in the domains of ML (including deep learning), QC, and QML and identify their potential benefits, issues, and use cases for their applications in the B5G networks. Subsequently, we propose a novel QC-assisted and QML-based framework for 6G communication networks while articulating its challenges and potential enabling technologies at the network infrastructure, network edge, air interface, and user end. Finally, some promising future research directions for the quantum- and QML-assisted B5G networks are identified and discussed.","['5G mobile communication', 'Communication networks', 'Quantum computing', 'Machine learning', 'Wireless networks', 'Parallel processing', 'Quantum communication']","['6G', 'B5G', 'machine learning', 'quantum communications', 'quantum machine learning']"
"The combination of tomographic imaging and deep learning, or machine learning in general, promises to empower not only image analysis but also image reconstruction. The latter aspect is considered in this perspective article with an emphasis on medical imaging to develop a new generation of image reconstruction theories and techniques. This direction might lead to intelligent utilization of domain knowledge from big data, innovative approaches for image reconstruction, and superior performance in clinical and preclinical applications. To realize the full impact of machine learning for tomographic imaging, major theoretical, technical and translational efforts are immediately needed.","['Image processing', 'Tomography', 'Data acquisition', 'Image reconstruction', 'Machine learning', 'Deep learning']","['Tomographic imaging', 'medical imaging', 'data acquisition', 'image reconstruction', 'image analysis', 'big data', 'machine learning', 'deep learning']"
"Internet of Things (IoT) is a network of all devices that can be accessed through the Internet. These devices can be remotely accessed and controlled using existing network infrastructure, thus allowing a direct integration of computing systems with the physical world. This also reduces human involvement along with improving accuracy and efficiency, resulting in economic benefit. The devices in IoT facilitate the day-to-day life of people. However, the IoT has an enormous threat to security and privacy due to its heterogeneous and dynamic nature. Authentication is one of the most challenging security requirements in the IoT environment, where a user (external party) can directly access information from the devices, provided the mutual authentication between user and devices happens. In this paper, we present a new signature-based authenticated key establishment scheme for the IoT environment. The proposed scheme is tested for security with the help of the widely used Burrows-Abadi-Needham logic, informal security analysis, and also the formal security verification using the broadly accepted automated validation of Internet security protocols and applications tool. The proposed scheme is also implemented using the widely accepted NS2 simulator, and the simulation results demonstrate the practicability of the scheme. Finally, the proposed scheme provides more functionality features, and its computational and communication costs are also comparable with other existing approaches.","['Authentication', 'Privacy', 'Elliptic curves', 'Protocols', 'Adaptation models', 'Sensors']","['Internet of things (IoT)', 'authentication', 'key establishment', 'Burrows-Abadi-Needham (BAN) logic', 'AVISPA', 'NS2 simulation', 'security']"
"With the development of technologies, such as big data, cloud computing, and the Internet of Things (IoT), digital twin is being applied in industry as a precision simulation technology from concept to practice. Further, simulation plays a very important role in the healthcare field, especially in research on medical pathway planning, medical resource allocation, medical activity prediction, etc. By combining digital twin and healthcare, there will be a new and efficient way to provide more accurate and fast services for elderly healthcare. However, how to achieve personal health management throughout the entire lifecycle of elderly patients, and how to converge the medical physical world and the virtual world to realize real smart healthcare, are still two key challenges in the era of precision medicine. In this paper, a framework of the cloud healthcare system is proposed based on digital twin healthcare (CloudDTH). This is a novel, generalized, and extensible framework in the cloud environment for monitoring, diagnosing and predicting aspects of the health of individuals using, for example, wearable medical devices, toward the goal of personal health management, especially for the elderly. CloudDTH aims to achieve interaction and convergence between medical physical and virtual spaces. Accordingly, a novel concept of digital twin healthcare (DTH) is proposed and discussed, and a DTH model is implemented. Next, a reference framework of CloudDTH based on DTH is constructed, and its key enabling technologies are explored. Finally, the feasibility of some application scenarios and a case study for real-time supervision are demonstrated.","['Medical services', 'Cloud computing', 'Senior citizens', 'Medical diagnostic imaging', 'Real-time systems', 'Computational modeling']","['Digital twin', 'elderly healthcare', 'personal health management', 'cloud computing', 'precision medicine', 'interaction', 'convergence']"
"Google Colaboratory (also known as Colab) is a cloud service based on Jupyter Notebooks for disseminating machine learning education and research. It provides a runtime fully configured for deep learning and free-of-charge access to a robust GPU. This paper presents a detailed analysis of Colaboratory regarding hardware resources, performance, and limitations. This analysis is performed through the use of Colaboratory for accelerating deep learning for computer vision and other GPU-centric applications. The chosen test-cases are a parallel tree-based combinatorial search and two computer vision applications: object detection/classification and object localization/segmentation. The hardware under the accelerated runtime is compared with a mainstream workstation and a robust Linux server equipped with 20 physical cores. Results show that the performance reached using this cloud service is equivalent to the performance of the dedicated testbeds, given similar resources. Thus, this service can be effectively exploited to accelerate not only deep learning but also other classes of GPU-centric applications. For instance, it is faster to train a CNN on Colaboratory's accelerated runtime than using 20 physical cores of a Linux server. The performance of the GPU made available by Colaboratory may be enough for several profiles of researchers and students. However, these free-of-charge hardware resources are far from enough to solve demanding real-world problems and are not scalable. The most significant limitation found is the lack of CPU cores. Finally, several strengths and limitations of this cloud service are discussed, which might be useful for helping potential users.","['Google', 'Machine learning', 'Hardware', 'Graphics processing units', 'Acceleration', 'Runtime', 'Computer vision']","['Deep learning', 'Colab', 'convolutional neural networks', 'Google colaboratory', 'GPU computing']"
"Machine learning (ML) based forecasting mechanisms have proved their significance to anticipate in perioperative outcomes to improve the decision making on the future course of actions. The ML models have long been used in many application domains which needed the identification and prioritization of adverse factors for a threat. Several prediction methods are being popularly used to handle forecasting problems. This study demonstrates the capability of ML models to forecast the number of upcoming patients affected by COVID-19 which is presently considered as a potential threat to mankind. In particular, four standard forecasting models, such as linear regression (LR), least absolute shrinkage and selection operator (LASSO), support vector machine (SVM), and exponential smoothing (ES) have been used in this study to forecast the threatening factors of COVID-19. Three types of predictions are made by each of the models, such as the number of newly infected cases, the number of deaths, and the number of recoveries in the next 10 days. The results produced by the study proves it a promising mechanism to use these methods for the current scenario of the COVID-19 pandemic. The results prove that the ES performs best among all the used models followed by LR and LASSO which performs well in forecasting the new confirmed cases, death rate as well as recovery rate, while SVM performs poorly in all the prediction scenarios given the available dataset.","['Predictive models', 'Forecasting', 'Linear regression', 'Support vector machines', 'Diseases', 'Machine learning', 'Prediction algorithms', 'COVID-19']","['COVID-19', 'exponential smoothing method', 'future forecasting', 'adjusted R² score', 'supervised machine learning']"
"Supporting high mobility in millimeter wave (mmWave) systems enables a wide range of important applications, such as vehicular communications and wireless virtual/augmented reality. Realizing this in practice, though, requires overcoming several challenges. First, the use of narrow beams and the sensitivity of mmWave signals to blockage greatly impact the coverage and reliability of highly-mobile links. Second, highly-mobile users in dense mmWave deployments need to frequently hand-off between base stations (BSs), which is associated with critical control and latency overhead. Furthermore, identifying the optimal beamforming vectors in large antenna array mmWave systems requires considerable training overhead, which significantly affects the efficiency of these mobile systems. In this paper, a novel integrated machine learning and coordinated beamforming solution is developed to overcome these challenges and enable highly-mobile mmWave applications. In the proposed solution, a number of distributed yet coordinating BSs simultaneously serve a mobile user. This user ideally needs to transmit only one uplink training pilot sequence that will be jointly received at the coordinating BSs using omni or quasi-omni beam patterns. These received signals draw a defining signature not only for the user location, but also for its interaction with the surrounding environment. The developed solution then leverages a deep learning model that learns how to use these signatures to predict the beamforming vectors at the BSs. This renders a comprehensive solution that supports highly mobile mmWave applications with reliable coverage, low latency, and negligible training overhead. Extensive simulation results based on accurate ray-tracing, show that the proposed deep-learning coordinated beamforming strategy approaches the achievable rate of the genie-aided solution that knows the optimal beamforming vectors with no training overhead. Compared with traditional beamforming solutions, the results show that the proposed deep learning-based strategy attains higher rates, especially in high-mobility large-array regimes.","['Array signal processing', 'Training', 'Machine learning', 'Channel estimation', 'Radio frequency', 'Sensors', 'Wireless communication']","['Millimeter wave', 'deep learning', 'machine learning', 'beamforming', 'channel estimation', 'vehicular communications', 'wireless virtual/augmented reality']"
"Compressive Sensing (CS) is a new sensing modality, which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest toward the use of CS in several fields, such as magnetic resonance imaging, high-speed video acquisition, and ultrawideband communication. This paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this field.","['Sensors', 'Transforms', 'Mathematical model', 'Sparse matrices', 'Compressed sensing', 'Reconstruction algorithms', 'Image reconstruction']","['Compressive sensing', 'sparsity', 'CS acquisition strategies', 'random demodulator', 'CS reconstruction algorithms', 'OMP', 'CS applications']"
"Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper, we show that the outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a BadNet) that has the state-of-the-art performance on the user's training and validation samples but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our U.S. street sign detector can persist even if the network is later retrained for another task and cause a drop in an accuracy of 25% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and-because the behavior of neural networks is difficult to explicate-stealthy. This paper provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software.","['Training', 'Machine learning', 'Perturbation methods', 'Computational modeling', 'Biological neural networks', 'Security']","['Computer security', 'machine learning', 'neural networks']"
"Recent years have witnessed a paradigm shift in the storage of Electronic Health Records (EHRs) on mobile cloud environments, where mobile devices are integrated with cloud computing to facilitate medical data exchanges among patients and healthcare providers. This advanced model enables healthcare services with low operational cost, high flexibility, and EHRs availability. However, this new paradigm also raises concerns about data privacy and network security for e-health systems. How to reliably share EHRs among mobile users while guaranteeing high-security levels in the mobile cloud is a challenging issue. In this paper, we propose a novel EHRs sharing framework that combines blockchain and the decentralized interplanetary file system (IPFS) on a mobile cloud platform. Particularly, we design a trustworthy access control mechanism using smart contracts to achieve secure EHRs sharing among different patients and medical providers. We present a prototype implementation using Ethereum blockchain in a real data sharing scenario on a mobile app with Amazon cloud computing. The empirical results show that our proposal provides an effective solution for reliable data exchanges on mobile clouds while preserving sensitive health information against potential threats. The system evaluation and security analysis also demonstrate the performance improvements in lightweight access control design, minimum network latency with high security and data privacy levels, compared to the existing data sharing models.","['Blockchain', 'Cloud computing', 'Access control', 'Smart contracts', 'Medical services', 'Data privacy']","['Electronic health records (EHRs)', 'EHRs sharing', 'mobile cloud computing (MCC)', 'Internet of Medical Things (IoMT)', 'blockchain', 'smart contracts', 'access control', 'privacy', 'security']"
"In this paper, we propose a new metric to measure goodness-of-fit for classifiers: the Real World Cost function. This metric factors in information about a real world problem, such as financial impact, that other measures like accuracy or F1 do not. This metric is also more directly interpretable for users. To optimize for this metric, we introduce the Real-World-Weight Cross-Entropy loss function, in both binary classification and single-label multiclass classification variants. Both variants allow direct input of real world costs as weights. For single-label, multiclass classification, our loss function also allows direct penalization of probabilistic false positives, weighted by label, during the training of a machine learning model. We compare the design of our loss function to the binary cross-entropy and categorical cross-entropy functions, as well as their weighted variants, to discuss the potential for improvement in handling a variety of known shortcomings of machine learning, ranging from imbalanced classes to medical diagnostic error to reinforcement of social bias. We create scenarios that emulate those issues using the MNIST data set and demonstrate empirical results of our new loss function. Finally, we discuss our intuition about why this approach works and sketch a proof based on Maximum Likelihood Estimation.","['Training', 'Neural networks', 'Machine learning', 'Probabilistic logic', 'Measurement', 'Maximum likelihood estimation', 'Standards']","['Machine learning', 'class imbalance', 'oversampling', 'undersampling', 'ethnic stereotypes', 'social bias', 'maximum likelihood estimation', 'cross-entropy', 'softmax']"
"A hybrid antenna is proposed for future 4G/5G multiple input multiple output (MIMO) applications. The proposed antenna is composed of two antenna modules, namely, 4G antenna module and 5G antenna module. The 4G antenna module is a two-antenna array capable of covering the GSM850/900/1800/1900, UMTS2100, and LTE2300/2500 operating bands, while the 5G antenna module is an eight-antenna array operating in the 3.5-GHz band capable of covering the C-band (3400-3600 MHz), which could meet the demand of future 5G application. Compared with ideal uncorrelated antennas in an 8 × 8 MIMO system, the 5G antenna module has shown good ergodic channel capacity of ~40 b/s/Hz, which is only 6 b/s/Hz lower than ideal case. This multi-mode hybrid antenna is fabricated, and typically, experimental results such as S-parameter, antenna efficiency, radiation pattern, and envelope correlation coefficient are presented.","['MIMO', 'Channel capacity', '5G mobile communication', 'Smart phones', 'Antenna arrays', 'Antenna radiation', 'Channel capacity', 'Envelope correlation coefficient', 'Radiation patterns']","['MIMO', 'multi-antenna', 'multi-mode', 'channel capacity', '5G application']"
"Clustering is a fundamental problem in many data-driven application domains, and clustering performance highly depends on the quality of data representation. Hence, linear or non-linear feature transformations have been extensively used to learn a better data representation for clustering. In recent years, a lot of works focused on using deep neural networks to learn a clustering-friendly representation, resulting in a significant increase of clustering performance. In this paper, we give a systematic survey of clustering with deep learning in views of architecture. Specifically, we first introduce the preliminary knowledge for better understanding of this field. Then, a taxonomy of clustering with deep learning is proposed and some representative methods are introduced. Finally, we propose some interesting future opportunities of clustering with deep learning and give some conclusion remarks.","['Clustering methods', 'Machine learning', 'Clustering algorithms', 'Network architecture', 'Neural networks', 'Neurons', 'Gallium nitride']","['Clustering', 'deep learning', 'data representation', 'network architecture']"
"This paper aims to understand, identify, and mitigate the impacts of residential electric vehicle (EV) charging on distribution system voltages. A thorough literature review on the impacts of residential EV charging is presented, followed by a proposed method for evaluating the impacts of EV loads on the distribution system voltage quality. Practical solutions to mitigate EV load impacts are discussed as well, including infrastructural changes and indirect controlled charging with time-of-use (TOU) pricing. An optimal TOU schedule is also presented, with the aim of maximizing both customer and utility benefits. This paper also presents a discussion on implementing smart charging algorithms to directly control EV charging rates and EV charging starting times. Finally, a controlled charging algorithm is proposed to improve the voltage quality at the EV load locations while avoiding customer inconvenience. The proposed method significantly decreases the impacts of EV load charging on system peak load demand and feeder voltages.","['IEEE Standards', 'Electric vehicles', 'Pricing', 'Power system quality', 'Voltage control', 'Dynamic programming', 'Controlled charging']","['Electric vehicle charging', 'TOU pricing', 'controlled charging', 'power quality', 'voltage quality', 'distribution system', 'dynamic programming']"
"A binary version of the hybrid grey wolf optimization (GWO) and particle swarm optimization (PSO) is proposed to solve feature selection problems in this paper. The original PSOGWO is a new hybrid optimization algorithm that benefits from the strengths of both GWO and PSO. Despite the superior performance, the original hybrid approach is appropriate for problems with a continuous search space. Feature selection, however, is a binary problem. Therefore, a binary version of hybrid PSOGWO called BGWOPSO is proposed to find the best feature subset. To find the best solutions, the wrapper-based method K-nearest neighbors classifier with Euclidean separation matric is utilized. For performance evaluation of the proposed binary algorithm, 18 standard benchmark datasets from UCI repository are employed. The results show that BGWOPSO significantly outperformed the binary GWO (BGWO), the binary PSO, the binary genetic algorithm, and the whale optimization algorithm with simulated annealing when using several performance measures including accuracy, selecting the best optimal features, and the computational time.","['Feature extraction', 'Optimization', 'Classification algorithms', 'Particle swarm optimization', 'Search problems', 'Genetic algorithms', 'Data mining']","['Feature selection', 'hybrid binary optimization', 'grey wolf optimization', 'particle swarm optimization', 'classification']"
"Detecting COVID-19 early may help in devising an appropriate treatment plan and disease containment decisions. In this study, we demonstrate how transfer learning from deep learning models can be used to perform COVID-19 detection using images from three most commonly used medical imaging modes X-Ray, Ultrasound, and CT scan. The aim is to provide over-stressed medical professionals a second pair of eyes through intelligent deep learning image classification models. We identify a suitable Convolutional Neural Network (CNN) model through initial comparative study of several popular CNN models. We then optimize the selected VGG19 model for the image modalities to show how the models can be used for the highly scarce and challenging COVID-19 datasets. We highlight the challenges (including dataset size and quality) in utilizing current publicly available COVID-19 datasets for developing useful deep learning models and how it adversely impacts the trainability of complex models. We also propose an image pre-processing stage to create a trustworthy image dataset for developing and testing the deep learning models. The new approach is aimed to reduce unwanted noise from the images so that deep learning models can focus on detecting diseases with specific features from them. Our results indicate that Ultrasound images provide superior detection accuracy compared to X-Ray and CT scans. The experimental results highlight that with limited data, most of the deeper networks struggle to train well and provides less consistency over the three imaging modes we are using. The selected VGG19 model, which is then extensively tuned with appropriate parameters, performs in considerable levels of COVID-19 detection against pneumonia or normal for all three lung image modes with the precision of up to 86% for X-Ray, 100% for Ultrasound and 84% for CT scans.","['Computed tomography', 'Lung', 'X-ray imaging', 'Ultrasonic imaging', 'Machine learning', 'Diseases']","['COVID-19 detection', 'image processing', 'model comparison', 'CNN models', 'X-ray', 'ultrasound and CT based detection']"
"In this survey paper, we systematically summarize existing literature on bearing fault diagnostics with deep learning (DL) algorithms. While conventional machine learning (ML) methods, including artificial neural network, principal component analysis, support vector machines, etc., have been successfully applied to the detection and categorization of bearing faults for decades, recent developments in DL algorithms in the last five years have sparked renewed interest in both industry and academia for intelligent machine health monitoring. In this paper, we first provide a brief review of conventional ML methods, before taking a deep dive into the state-of-the-art DL algorithms for bearing fault applications. Specifically, the superiority of DL based methods are analyzed in terms of fault feature extraction and classification performances; many new functionalities enabled by DL techniques are also summarized. In addition, to obtain a more intuitive insight, a comparative study is conducted on the classification accuracy of different algorithms utilizing the open source Case Western Reserve University (CWRU) bearing dataset. Finally, to facilitate the transition on applying various DL algorithms to bearing fault diagnostics, detailed recommendations and suggestions are provided for specific application conditions. Future research directions to further enhance the performance of DL algorithms on health monitoring are also discussed.","['Induction motors', 'Vibrations', 'Sensors', 'Stators', 'Fault diagnosis', 'Machine learning algorithms', 'Monitoring']","['Bearing fault', 'deep learning', 'diagnostics', 'feature extraction', 'machine learning']"
"Various new national advanced manufacturing strategies, such as Industry 4.0, Industrial Internet, and Made in China 2025, are issued to achieve smart manufacturing, resulting in the increasing number of newly designed production lines in both developed and developing countries. Under the individualized designing demands, more realistic virtual models mirroring the real worlds of production lines are essential to bridge the gap between design and operation. This paper presents a digital twin-based approach for rapid individualized designing of the hollow glass production line. The digital twin merges physics-based system modeling and distributed real-time process data to generate an authoritative digital design of the system at pre-production phase. A digital twin-based analytical decoupling framework is also developed to provide engineering analysis capabilities and support the decision-making over the system designing and solution evaluation. Three key enabling techniques as well as a case study in hollow glass production line are addressed to validate the proposed approach.","['Optimization', 'Data models', 'Couplings', 'Glass', 'Conferences']","['Digital twin', 'individualized designing', 'mass individualization', 'multi-view synchronization', 'semi-physical simulation']"
"In this paper, we introduce an intelligent reflecting surface (IRS) to provide a programmable wireless environment for physical layer security. By adjusting the reflecting coefficients, the IRS can change the attenuation and scattering of the incident electromagnetic wave so that it can propagate in the desired way toward the intended receiver. Specifically, we consider a downlink multiple-input single-output (MISO) broadcast system, where the base station (BS) transmits independent data streams to multiple legitimate receivers and keeps them secret from multiple eavesdroppers. By jointly optimizing the beamformers at the BS and reflecting coefficients at the IRS, we formulate a minimum-secrecy-rate maximization problem under various practical constraints on the reflecting coefficients. The constraints capture the scenarios of both continuous and discrete reflecting coefficients of the reflecting elements. Due to the non-convexity of the formulated problem, we propose an efficient algorithm based on the alternating optimization and the path-following algorithm to solve it in an iterative manner. Besides, we show that the proposed algorithm can converge to a local (global) optimum. Furthermore, we develop two suboptimal algorithms with some forms of closed-form solutions to reduce computational complexity. Finally, the simulation results validate the advantages of the introduced IRS and the effectiveness of the proposed algorithms.","['Receivers', 'Signal to noise ratio', 'Wireless communication', 'MISO communication', 'Communication system security', 'Downlink', 'Optimization']","['Intelligent reflecting surface', 'programmable wireless environment', 'physical layer security', 'beamforming']"
"This paper considers a downlink cloud radio access network (C-RAN) in which all the base-stations (BSs) are connected to a central computing cloud via digital backhaul links with finite capacities. Each user is associated with a user-centric cluster of BSs; the central processor shares the user's data with the BSs in the cluster, which then cooperatively serve the user through joint beamforming. Under this setup, this paper investigates the user scheduling, BS clustering, and beamforming design problem from a network utility maximization perspective. Differing from previous works, this paper explicitly considers the per-BS backhaul capacity constraints. We formulate the network utility maximization problem for the downlink C-RAN under two different models depending on whether the BS clustering for each user is dynamic or static over different user scheduling time slots. In the former case, the user-centric BS cluster is dynamically optimized for each scheduled user along with the beamforming vector in each time-frequency slot, whereas in the latter case, the user-centric BS cluster is fixed for each user and we jointly optimize the user scheduling and the beamforming vector to account for the backhaul constraints. In both cases, the nonconvex per-BS backhaul constraints are approximated using the reweighted ℓ 1 -norm technique. This approximation allows us to reformulate the per-BS backhaul constraints into weighted per-BS power constraints and solve the weighted sum rate maximization problem through a generalized weighted minimum mean square error approach. This paper shows that the proposed dynamic clustering algorithm can achieve significant performance gain over existing naive clustering schemes. This paper also proposes two heuristic static clustering schemes that can already achieve a substantial portion of the gain.","['Array signal processing', 'Dynamic scheduling', 'Radio access networks', 'Downlink', 'Heuristic algorithms', 'Approximation methods', 'Cloud computing']","['Cloud radio access network (C-RAN)', 'network multiple-input multiple-output (MIMO)', 'multi-point (CoMP)', 'limited backhaul', 'user scheduling', 'base station clustering', 'beamforming', 'weighted sum rate', 'weighted minimum mean square error (WMMSE)']"
"The classification of electrocardiogram (ECG) signals is very important for the automatic diagnosis of heart disease. Traditionally, it is divided into two steps, including the step of feature extraction and the step of pattern classification. Owing to recent advances in artificial intelligence, it has been demonstrated that deep neural network, which trained on a huge amount of data, can carry out the task of feature extraction directly from the data and recognize cardiac arrhythmias better than professional cardiologists. This paper proposes an ECG arrhythmia classification method using two-dimensional (2D) deep convolutional neural network (CNN). The time domain signals of ECG, belonging to five heart beat types including normal beat (NOR), left bundle branch block beat (LBB), right bundle branch block beat (RBB), premature ventricular contraction beat (PVC), and atrial premature contraction beat (APC), were first transformed into time-frequency spectrograms by short-time Fourier transform. Subsequently, the spectrograms of the five arrhythmia types were utilized as input to the 2D-CNN such that the ECG arrhythmia types were identified and classified finally. Using ECG recordings from the MIT-BIH arrhythmia database as the training and testing data, the classification results show that the proposed 2D-CNN model can reach an averaged accuracy of 99.00%. On the other hand, in order to achieve optimal classification performances, the model parameter optimization was investigated. It was found when the learning rate is 0.001 and the batch size parameter is 2500, the classifier achieved the highest accuracy and the lowest loss. We also compared the proposed 2D-CNN model with a conventional one-dimensional CNN model. Comparison results show that the 1D-CNN classifier can achieve an averaged accuracy of 90.93%. Therefore, it is validated that the proposed CNN classifier using ECG spectrograms as input can achieve improved classification accuracy without additional manual pre-processing of the ECG signals.","['Electrocardiography', 'Feature extraction', 'Spectrogram', 'Convolutional neural networks', 'Heart beat', 'Diseases', 'Time-frequency analysis']","['Electrocardiogram (ECG)', 'arrhythmia classification', 'short-time Fourier transform (STFT)', 'convolutional neural network', 'model parameter optimization']"
"Prognostics and health management is an emerging discipline to scientifically manage the health condition of engineering systems and their critical components. It mainly consists of three main aspects: construction of health indicators, remaining useful life prediction, and health management. Construction of health indicators aims to evaluate the system's current health condition and its critical components. Given the observations of a health indicator, prediction of the remaining useful life is used to infer the time when an engineering systems or a critical component will no longer perform its intended function. Health management involves planning the optimal maintenance schedule according to the system's current and future health condition, its critical components and the replacement costs. Construction of health indicators is the key to predicting the remaining useful life. Bearings and gears are the most common mechanical components in rotating machines, and their health conditions are of great concern in practice. Because it is difficult to measure and quantify the health conditions of bearings and gears in many cases, numerous vibration-based methods have been proposed to construct bearing and gear health indicators. This paper presents a thorough review of vibration-based bearing and gear health indicators constructed from mechanical signal processing, modeling, and machine learning. This review paper will be helpful for designing further advanced bearing and gear health indicators and provides a basis for predicting the remaining useful life of bearings and gears. Most of the bearing and gear health indicators reviewed in this paper are highly relevant to simulated and experimental run-to-failure data rather than artificially seeded bearing and gear fault data. Finally, some problems in the literature are highlighted and areas for future study are identified.","['Gears', 'Vibrations', 'Degradation', 'Predictive models', 'Root mean square', 'Prognostics and health management', 'Signal processing']","['Ball bearings', 'condition monitoring', 'feature extraction', 'gears', 'prognostics and health management', 'signal processing algorithms', 'vibrations']"
"With the rapid development of Internet technology and social networks, a large number of comment texts are generated on the Web. In the era of big data, mining the emotional tendency of comments through artificial intelligence technology is helpful for the timely understanding of network public opinion. The technology of sentiment analysis is a part of artificial intelligence, and its research is very meaningful for obtaining the sentiment trend of the comments. The essence of sentiment analysis is the text classification task, and different words have different contributions to classification. In the current sentiment analysis studies, distributed word representation is mostly used. However, distributed word representation only considers the semantic information of word, but ignore the sentiment information of the word. In this paper, an improved word representation method is proposed, which integrates the contribution of sentiment information into the traditional TF-IDF algorithm and generates weighted word vectors. The weighted word vectors are input into bidirectional long short term memory (BiLSTM) to capture the context information effectively, and the comment vectors are better represented. The sentiment tendency of the comment is obtained by feedforward neural network classifier. Under the same conditions, the proposed sentiment analysis method is compared with the sentiment analysis methods of RNN, CNN, LSTM, and NB. The experimental results show that the proposed sentiment analysis method has higher precision, recall, and F1 score. The method is proved to be effective with high accuracy on comments.","['Sentiment analysis', 'Dictionaries', 'Neural networks', 'Semantics', 'Data mining', 'Internet', 'Task analysis']","['Sentiment analysis', 'artificial intelligence', 'social network', 'weighted word vectors', 'BiLSTM']"
"While 5G is being commercialized worldwide, research institutions around the world have started to look beyond 5G and 6G is expected to evolve into green networks, which deliver high Quality of Service and energy efficiency. To meet the demands of future applications, significant improvements need to be made in mobile network architecture. We envision 6G undergoing unprecedented breakthrough and integrating traditional terrestrial mobile networks with emerging space, aerial and underwater networks to provide anytime anywhere network access. This paper presents a detailed survey on wireless evolution towards 6G networks. In this survey, the prime focus is on the new architectural changes associated with 6G networks, characterized by ubiquitous 3D coverage, introduction of pervasive AI and enhanced network protocol stack. Along with this, we discuss related potential technologies that are helpful in forming sustainable and socially seamless networks, encompassing terahertz and visible light communication, new communication paradigm, blockchain and symbiotic radio. Our work aims to provide enlightening guidance for subsequent research of green 6G.","['5G mobile communication', 'Satellite broadcasting', 'Low earth orbit satellites', 'Wireless networks']","['6G', 'architecture', 'green networks', 'VLC', 'blockchain']"
"Network intrusion detection systems (NIDSs) provide a better solution to network security than other traditional network defense technologies, such as firewall systems. The success of NIDS is highly dependent on the performance of the algorithms and improvement methods used to increase the classification accuracy and decrease the training and testing times of the algorithms. We propose an effective deep learning approach, self-taught learning (STL)-IDS, based on the STL framework. The proposed approach is used for feature learning and dimensionality reduction. It reduces training and testing time considerably and effectively improves the prediction accuracy of support vector machines (SVM) with regard to attacks. The proposed model is built using the sparse autoencoder mechanism, which is an effective learning algorithm for reconstructing a new feature representation in an unsupervised manner. After the pre-training stage, the new features are fed into the SVM algorithm to improve its detection capability for intrusion and classification accuracy. Moreover, the efficiency of the approach in binary and multiclass classification is studied and compared with that of shallow classification methods, such as J48, naive Bayesian, random forest, and SVM. Results show that our approach has accelerated SVM training and testing times and performed better than most of the previous approaches in terms of performance metrics in binary and multiclass classification. The proposed STL-IDS approach improves network intrusion detection and provides a new research method for intrusion detection.","['Support vector machines', 'Machine learning', 'Intrusion detection', 'Feature extraction', 'Training', 'Computational modeling', 'Classification algorithms']","['Network security', 'network intrusion detection system', 'deep learning', 'sparse autoencoder', 'SVM', 'self-taught learning', 'NSL-KDD']"
"A centralized infrastructure system carries out existing data analytics and decision-making processes from our current highly virtualized platform of wireless networks and the Internet of Things (IoT) applications. There is a high possibility that these existing methods will encounter more challenges and issues in relation to network dynamics, resulting in a high overhead in the network response time, leading to latency and traffic. In order to avoid these problems in the network and achieve an optimum level of resource utilization, a new paradigm called edge computing (EC) is proposed to pave the way for the evolution of new age applications and services. With the integration of EC, the processing capabilities are pushed to the edge of network devices such as smart phones, sensor nodes, wearables, and on-board units, where data analytics and knowledge generation are performed which removes the necessity for a centralized system. Many IoT applications, such as smart cities, the smart grid, smart traffic lights, and smart vehicles, are rapidly upgrading their applications with EC, significantly improving response time as well as conserving network resources. Irrespective of the fact that EC shifts the workload from a centralized cloud to the edge, the analogy between EC and the cloud pertaining to factors such as resource management and computation optimization are still open to research studies. Hence, this paper aims to validate the efficiency and resourcefulness of EC. We extensively survey the edge systems and present a comparative study of cloud computing systems. After analyzing the different network properties in the system, the results show that EC systems perform better than cloud computing systems. Finally, the research challenges in implementing an EC system and future research directions are discussed.","['Cloud computing', 'Computer architecture', 'Edge computing', 'Ad hoc networks', 'Servers', 'Mobile computing', 'Resource management']","['IoT', 'cloud computing', 'edge computing', 'fog computing', 'multi-cloud']"
"The next-generation wireless networks are evolving into very complex systems because of the very diversified service requirements, heterogeneity in applications, devices, and networks. The network operators need to make the best use of the available resources, for example, power, spectrum, as well as infrastructures. Traditional networking approaches, i.e., reactive, centrally-managed, one-size-fits-all approaches, and conventional data analysis tools that have limited capability (space and time) are not competent anymore and cannot satisfy and serve that future complex networks regarding operation and optimization cost effectively. A novel paradigm of proactive, self-aware, self-adaptive, and predictive networking is much needed. The network operators have access to large amounts of data, especially from the network and the subscribers. Systematic exploitation of the big data dramatically helps in making the system smart, intelligent, and facilitates efficient as well as cost-effective operation and optimization. We envision data-driven next-generation wireless networks, where the network operators employ advanced data analytics, machine learning (ML), and artificial intelligence. We discuss the data sources and strong drivers for the adoption of the data analytics, and the role of ML, artificial intelligence in making the system intelligent regarding being self-aware, self-adaptive, proactive and prescriptive. A set of network design and optimization schemes are presented concerning data analytics. This paper concludes with a discussion of challenges and the benefits of adopting big data analytics, ML, and artificial intelligence in the next-generation communication systems.","['Big Data', 'Next generation networking', 'Optimization', 'Machine learning', 'Data analysis', 'Tools', 'Wireless communication']","['Big data analytics', 'machine learning', 'artificial intelligence', 'next-generation wireless']"
"Clean and environment-friendly energy harvesting are of prime interest today as it is one of the key enablers in achieving the Sustainable Development Goals (SDGs) as well as accelerates social progress and enhances living standards. India, the second-most populous nation with a population of 1.353 billion, is one of the largest consumers of fossil fuels in the world which is responsible for global warming. An ever-increasing population is projected until 2050, and consequently, the energy demand in the upcoming decades will be co-accelerated by the rapid industrial growth. The Ministry of New and Renewable Energy (MNRE) with the support of National Institution for Transforming India (NITI) Aayog is working to achieve the Indian Government's target of attaining 175 GW through renewable energy resources. Many Indian states are currently increasing their renewable energy capacity in an objective to meet future energy demand. The review paper discusses in-depth about the three Indian states, namely Karnataka, Gujarat, Tamil Nadu, which pioneers the renewable energy production in India. The global energy scenario was discussed in detail with Indian contrast. Further, the barriers to the development of renewable energy generation and policies of the Indian government are discussed in detail to promote renewable energy generation throughout India as well as globally since the challenges are similar for other nations. This study analyzed various prospects of the country in renewable energy which has been done in a purpose to help the scholars, researchers, and policymakers of the nation, as it gives an insight into the present renewable energy scenario of the country.","['Renewable energy sources', 'Production', 'Global warming', 'Fossil fuels', 'Meteorology', 'Electric potential', 'Sociology']","['Renewable energy potential', 'global energy scenario', 'Energy policy in India', 'renewable energy barriers', 'prospects of renewables in India', 'renewable energy in India']"
"Traditional power grids are being transformed into smart grids (SGs) to address the issues in the existing power system due to uni-directional information flow, energy wastage, growing energy demand, reliability, and security. SGs offer bi-directional energy flow between service providers and consumers, involving power generation, transmission, distribution, and utilization systems. SGs employ various devices for the monitoring, analysis, and control of the grid, deployed at power plants, distribution centers, and in consumers’ premises in a very large number. Hence, an SG requires connectivity, automation, and the tracking of such devices. This is achieved with the help of the Internet of Things (IoT). The IoT helps SG systems to support various network functions throughout the generation, transmission, distribution, and consumption of energy by incorporating the IoT devices (such as sensors, actuators, and smart meters), as well as by providing the connectivity, automation, and tracking for such devices. In this paper, we provide a comprehensive survey on the IoT-aided SG systems, which includes the existing architectures, applications, and prototypes of the IoT-aided SG systems. This survey also highlights the open issues, challenges, and future research directions for the IoT-aided SG systems.","['Internet of Things', 'Security', 'Power generation', 'Power grids', 'Monitoring']","['Home area network (HAN)', 'Internet of Things (IoT)', 'neighborhood area network (NAN)', 'smart grid (SG)', 'wide area network (WAN)']"
"In this paper, we investigate the feasibility of recognizing human hand gestures using micro-Doppler signatures measured by Doppler radar with a deep convolutional neural network (DCNN). Hand gesture recognition using radar can be applied to control electronic appliances. Compared with an optical recognition system, radar can work regardless of light conditions and it can be embedded in a case. We classify ten different hand gestures, with only micro-Doppler signatures on spectrograms without range information. The ten gestures, which included swiping from left to right, swiping from right to left, rotating clockwise, rotating counterclockwise, pushing, double pushing, holding, and double holding, were measured using Doppler radar and their spectrograms investigated. A DCNN was employed to classify the spectrograms, with 90% of the data utilized for training and the remaining 10% for validation. After five-fold validation, the classification accuracy of the proposed method was found to be 85.6%. With seven gestures, the accuracy increased to 93.1%.","['Doppler radar', 'Spectrogram', 'Laser radar', 'Neural networks', 'Gesture recognition', 'Spectrograms']","['Hand gesture', 'micro-Doppler signatures', 'Doppler radar', 'deep convolutional neural networks']"
"In recent decades, we have witnessed the evolution of information technologies from the development of VLSI technologies, to communication and networking infrastructure, to the standardization of multimedia compression and coding schemes, to effective multimedia content search and retrieval. As a result, multimedia devices and digital content have become ubiquitous. This path of technological evolution has naturally led to a critical issue that must be addressed next, namely, to ensure that content, devices, and intellectual property are being used by authorized users for legitimate purposes, and to be able to forensically prove with high confidence when otherwise. When security is compromised, intellectual rights are violated, or authenticity is forged, forensic methodologies and tools are employed to reconstruct what has happened to digital content in order to answer who has done what, when, where, and how. The goal of this paper is to provide an overview on what has been done over the last decade in the new and emerging field of information forensics regarding theories, methodologies, state-of-the-art techniques, major applications, and to provide an outlook of the future.","['Forensics', 'Forgery', 'Multimedia communication', 'Feature extraction', 'Fingerprint recognition', 'Computer Security', 'Information processing', 'Digital forensics', 'Very large scale integration', 'Data privacy', 'Intellectual property']","['Anti-forensics', 'information forensics', 'multimedia fingerprint', 'tampering detection']"
"Diabetic Retinopathy (DR) is an ophthalmic disease that damages retinal blood vessels. DR causes impaired vision and may even lead to blindness if it is not diagnosed in early stages. DR has five stages or classes, namely normal, mild, moderate, severe and PDR (Proliferative Diabetic Retinopathy). Normally, highly trained experts examine the colored fundus images to diagnose this fatal disease. This manual diagnosis of this condition (by clinicians) is tedious and error-prone. Therefore, various computer vision-based techniques have been proposed to automatically detect DR and its different stages from retina images. However, these methods are unable to encode the underlying complicated features and can only classify DR’s different stages with very low accuracy particularly, for the early stages. In this research, we used the publicly available Kaggle dataset of retina images to train an ensemble of five deep Convolution Neural Network (CNN) models (Resnet50, Inceptionv3, Xception, Dense121, Dense169) to encode the rich features and improve the classification for different stages of DR. The experimental results show that the proposed model detects all the stages of DR unlike the current methods and performs better compared to state-of-the-art methods on the same Kaggle dataset.","['Diabetes', 'Retinopathy', 'Training', 'Predictive models', 'Retina', 'Biomedical imaging']","['CNN', 'diabetic retinopathy', 'deep learning', 'ensemble model', 'fundus images', 'medical image analysis']"
"Emotion recognition from speech signals is an important but challenging component of Human-Computer Interaction (HCI). In the literature of speech emotion recognition (SER), many techniques have been utilized to extract emotions from signals, including many well-established speech analysis and classification techniques. Deep Learning techniques have been recently proposed as an alternative to traditional techniques in SER. This paper presents an overview of Deep Learning techniques and discusses some recent literature where these methods are utilized for speech-based emotion recognition. The review covers databases used, emotions extracted, contributions made toward speech emotion recognition and limitations related to it.","['Databases', 'Emotion recognition', 'Feature extraction', 'Speech recognition', 'Deep learning', 'Human computer interaction', 'Hidden Markov models']","['Speech emotion recognition', 'deep learning', 'deep neural network', 'deep Boltzmann machine', 'recurrent neural network', 'deep belief network', 'convolutional neural network']"
"The main vision of the Internet of Things (IoT) is to equip real-life physical objects with computing and communication power so that they can interact with each other for the social good. As one of the key members of IoT, Internet of Vehicles (IoV) has seen steep advancement in communication technologies. Now, vehicles can easily exchange safety, efficiency, infotainment, and comfort-related information with other vehicles and infrastructures using vehicular ad hoc networks (VANETs). We leverage on the cloud-based VANETs theme to propose cyber-physical architecture for the Social IoV (SIoV). SIoV is a vehicular instance of the Social IoT (SIoT), where vehicles are the key social entities in the machine-to-machine vehicular social networks. We have identified the social structures of SIoV components, their relationships, and the interaction types. We have mapped VANETs components into IoT-A architecture reference model to offer better integration of SIoV with other IoT domains. We also present a communication message structure based on automotive ontologies, the SAE J2735 message set, and the advanced traveler information system events schema that corresponds to the social graph. Finally, we provide the implementation details and the experimental analysis to demonstrate the efficacy of the proposed system as well as include different application scenarios for various user groups.","['Internet of things', 'Computer architecture', 'Ad hoc networks', 'Social network services', 'Vehicles', 'Intelligent vehicles']","['Social Network of Vehicles', 'Cyber-Physical Systems', 'Internet of Things', 'Internet of Vehicles', 'IoT Architecture Reference Model', 'Intelligent Transport Systems', 'SAE J2735']"
"Key generation from the randomness of wireless channels is a promising alternative to public key cryptography for the establishment of cryptographic keys between any two users. This paper reviews the current techniques for wireless key generation. The principles, performance metrics and key generation procedure are comprehensively surveyed. Methods for optimizing the performance of key generation are also discussed. Key generation applications in various environments are then introduced along with the challenges of applying the approach in each scenario. The paper concludes with some suggestions for future studies.","['Random processes', 'Physical layer', 'Network security', 'Wireless communication', 'Key generation', 'Cryptography']","['Physical layer security', 'key generation', 'wireless communication']"
"Electronic Health Records (EHRs) are entirely controlled by hospitals instead of patients, which complicates seeking medical advices from different hospitals. Patients face a critical need to focus on the details of their own healthcare and restore management of their own medical data. The rapid development of blockchain technology promotes population healthcare, including medical records as well as patient-related data. This technology provides patients with comprehensive, immutable records, and access to EHRs free from service providers and treatment websites. In this paper, to guarantee the validity of EHRs encapsulated in blockchain, we present an attribute-based signature scheme with multiple authorities, in which a patient endorses a message according to the attribute while disclosing no information other than the evidence that he has attested to it. Furthermore, there are multiple authorities without a trusted single or central one to generate and distribute public/private keys of the patient, which avoids the escrow problem and conforms to the mode of distributed data storage in the blockchain. By sharing the secret pseudorandom function seeds among authorities, this protocol resists collusion attack out of N from N -1 corrupted authorities. Under the assumption of the computational bilinear Diffie-Hellman, we also formally demonstrate that, in terms of the unforgeability and perfect privacy of the attribute-signer, this attribute-based signature scheme is secure in the random oracle model. The comparison shows the efficiency and properties between the proposed method and methods proposed in other studies.","['Privacy', 'Security', 'Hospitals', 'Electronic medical records', 'Standards']","['Attribute-based signature (ABS)', 'blockchain', 'electronic health records (EHRs)', 'multiple authorities', 'preserve privacy']"
"Twitter sentiment analysis technology provides the methods to survey public emotion about the events or products related to them. Most of the current researches are focusing on obtaining sentiment features by analyzing lexical and syntactic features. These features are expressed explicitly through sentiment words, emoticons, exclamation marks, and so on. In this paper, we introduce a word embeddings method obtained by unsupervised learning based on large twitter corpora, this method using latent contextual semantic relationships and co-occurrence statistical characteristics between words in tweets. These word embeddings are combined with n-grams features and word sentiment polarity score features to form a sentiment feature set of tweets. The feature set is integrated into a deep convolution neural network for training and predicting sentiment classification labels. We experimentally compare the performance of our model with the baseline model that is a word n-grams model on five Twitter data sets, the results indicate that our model performs better on the accuracy and F1-measure for twitter sentiment classification.","['Twitter', 'Neural networks', 'Convolution', 'Sentiment analysis', 'Terminology', 'Semantics']","['Twitter', 'sentiment analysis', 'word embeddings', 'convolution neural network']"
"Presently, educational institutions compile and store huge volumes of data, such as student enrolment and attendance records, as well as their examination results. Mining such data yields stimulating information that serves its handlers well. Rapid growth in educational data points to the fact that distilling massive amounts of data requires a more sophisticated set of algorithms. This issue led to the emergence of the field of educational data mining (EDM). Traditional data mining algorithms cannot be directly applied to educational problems, as they may have a specific objective and function. This implies that a preprocessing algorithm has to be enforced first and only then some specific data mining methods can be applied to the problems. One such preprocessing algorithm in EDM is clustering. Many studies on EDM have focused on the application of various data mining algorithms to educational attributes. Therefore, this paper provides over three decades long (1983-2016) systematic literature review on clustering algorithm and its applicability and usability in the context of EDM. Future insights are outlined based on the literature reviewed, and avenues for further research are identified.","['Clustering algorithms', 'Data mining', 'Partitioning algorithms', 'Classification algorithms', 'Clustering methods', 'Systematics', 'Big data']","['Data mining', 'clustering methods', 'educational technology', 'systematic review']"
"Blockchain have been an interesting research area for a long time and the benefits it provides have been used by a number of various industries. Similarly, the healthcare sector stands to benefit immensely from the blockchain technology due to security, privacy, confidentiality and decentralization. Nevertheless, the Electronic Health Record (EHR) systems face problems regarding data security, integrity and management. In this paper, we discuss how the blockchain technology can be used to transform the EHR systems and could be a solution of these issues. We present a framework that could be used for the implementation of blockchain technology in healthcare sector for EHR. The aim of our proposed framework is firstly to implement blockchain technology for EHR and secondly to provide secure storage of electronic records by defining granular access rules for the users of the proposed framework. Moreover, this framework also discusses the scalability problem faced by the blockchain technology in general via use of off-chain storage of the records. This framework provides the EHR system with the benefits of having a scalable, secure and integral blockchain-based solution.","['Blockchain', 'Peer-to-peer computing', 'Hospitals', 'Cryptography', 'Electronic medical records']","['Blockchain', 'health records', 'electronic health records', 'decentralization', 'and scalability']"
"The Internet of Things (IoT) is set to become one of the key technological developments of our times provided we are able to realize its full potential. The number of objects connected to IoT is expected to reach 50 billion by 2020 due to the massive influx of diverse objects emerging progressively. IoT, hence, is expected to be a major producer of big data. Sharing and collaboration of data and other resources would be the key for enabling sustainable ubiquitous environments, such as smart cities and societies. A timely fusion and analysis of big data, acquired from IoT and other sources, to enable highly efficient, reliable, and accurate decision making and management of ubiquitous environments would be a grand future challenge. Computational intelligence would play a key role in this challenge. A number of surveys exist on data fusion. However, these are mainly focused on specific application areas or classifications. The aim of this paper is to review literature on data fusion for IoT with a particular focus on mathematical methods (including probabilistic methods, artificial intelligence, and theory of belief) and specific IoT environments (distributed, heterogeneous, nonlinear, and object tracking environments). The opportunities and challenges for each of the mathematical methods and environments are given. Future developments, including emerging areas that would intrinsically benefit from data fusion and IoT, autonomous vehicles, deep learning for data fusion, and smart cities, are discussed.","['Data integration', 'Smart cities', 'Internet of Things', 'Big Data', 'Decision making', 'Computer science', 'Information technology']","['Internet of Things', 'big data', 'data fusion', 'computational and artificial intelligence', 'high performance computing', 'smart cities', 'smart societies', 'ubiquitous environments']"
"With the explosive growth of Internet of Things devices and massive data produced at the edge of the network, the traditional centralized cloud computing model has come to a bottleneck due to the bandwidth limitation and resources constraint. Therefore, edge computing, which enables storing and processing data at the edge of the network, has emerged as a promising technology in recent years. However, the unique features of edge computing, such as content perception, real-time computing, and parallel processing, has also introduced several new challenges in the field of data security and privacy-preserving, which are also the key concerns of the other prevailing computing paradigms, such as cloud computing, mobile cloud computing, and fog computing. Despites its importance, there still lacks a survey on the recent research advance of data security and privacy-preserving in the field of edge computing. In this paper, we present a comprehensive analysis of the data security and privacy threats, protection technologies, and countermeasures inherent in edge computing. Specifically, we first make an overview of edge computing, including forming factors, definition, architecture, and several essential applications. Next, a detailed analysis of data security and privacy requirements, challenges, and mechanisms in edge computing are presented. Then, the cryptography-based technologies for solving data security and privacy issues are summarized. The state-of-the-art data security and privacy solutions in edge-related paradigms are also surveyed. Finally, we propose several open research directions of data security in the field of edge computing.","['Edge computing', 'Cloud computing', 'Data privacy', 'Encryption', 'Computer architecture', 'Authentication']","['Edge computing', 'data security', 'cryptography', 'authentication', 'access control', 'privacy']"
"The Internet of Things (IoT) is one of the most promising technologies for the near future. Healthcare and well-being will receive great benefits with the evolution of this technology. This paper presents a review of techniques based on IoT for healthcare and ambient-assisted living, defined as the Internet of Health Things (IoHT), based on the most recent publications and products available in the market from industry for this segment. Also, this paper identifies the technological advances made so far, analyzing the challenges to be overcome and provides an approach of future trends. Through selected works, it is possible to notice that further studies are important to improve current techniques and that novel concept and technologies of IoHT are needed to overcome the identified challenges. The presented results aim to serve as a source of information for healthcare providers, researchers, technology specialists, and the general population to improve the IoHT.","['Medical services', 'Monitoring', 'Biomedical monitoring', 'Industries', 'Sensors', 'Internet of Things']","['Ambient assisted living', 'Internet of Things', 'Internet of Health Things', 'mobile health', 'remote healthcare monitoring', 'wearable']"
"Industry 4.0 can make a factory smart by applying intelligent information processing approaches, communication systems, future-oriented techniques, and more. However, the high complexity, automation, and flexibility of an intelligent factory bring new challenges to reliability and safety. Industrial big data generated by multisource sensors, intercommunication within the system and external-related information, and so on, might provide new solutions for predictive maintenance to improve system reliability. This paper puts forth attributes of industrial big data processing and actively explores industrial big data processing-based predictive maintenance. A novel framework is proposed for structuring multisource heterogeneous information, characterizing structured data with consideration of the spatiotemporal property, and modeling invisible factors, which would make the production process transparent and eventually implement predictive maintenance on facilities and energy saving in the industry 4.0 era. The effectiveness of the proposed scheme was verified by analyzing multisource heterogeneous industrial data for the remaining life prediction of key components of machining equipment.","['Big Data', 'Predictive maintenance', 'Data mining', 'Manufacturing processes', 'Industries', 'Feature extraction', 'Data models']","['Industrial big data', 'multisource heterogeneous data', 'structuralization and characterization', 'multiple invisible factors', 'predictive maintenance']"
"The whale optimization algorithm (WOA) has been shown to be powerful in searching for an optimal solution. This paper proposes an improvement to the whale optimization algorithm that is based on a Lévy flight trajectory and called the Lévy flight trajectory-based whale optimization algorithm (LWOA). The LWOA makes the WOA faster and more robust and avoids premature convergence. The Lévy flight trajectory is helpful for increasing the diversity of the population against premature convergence and enhancing the capability of jumping out of local optimal optima. This method helps obtaining a better tradeoff between the exploration and exploitation of the WOA. The proposed algorithm is characterized by quick convergence and high precision, and it can effectively get rid of a local optimum. The LWOA is further compared with other well-known nature-inspired algorithms on 23 benchmarks and solving infinite impulse response model identification. The statistical results on the benchmark functions show that the LWOA can significantly outperform others on a majority of the benchmark functions, especially in solving an optimization problem that has high dimensionality. Additionally, the superior identification capability of the proposed algorithm is evident from the results obtained through the simulation study compared with other algorithms. All the results prove the superiority of the LWOA.","['Whales', 'Optimization', 'Trajectory', 'Mathematical model', 'Convergence', 'Algorithm design and analysis', 'Spirals']","['Lévy flight trajectory', 'whale optimization algorithm', 'global optimization', 'IIR system']"
"Even after 16 years of existence, low energy adaptive clustering hierarchy (LEACH) protocol is still gaining the attention of the research community working in the area of wireless sensor network (WSN). This itself shows the importance of this protocol. Researchers have come up with various and diverse modifications of the LEACH protocol. Successors of LEACH protocol are now available from single hop to multi-hop scenarios. Extensive work has already been done related to LEACH and it is a good idea for a new research in the field of WSN to go through LEACH and its variants over the years. This paper surveys the variants of LEACH routing protocols proposed so far and discusses the enhancement and working of them. This survey classifies all the protocols in two sections, namely, single hop communication and multi-hop communication based on data transmission from the cluster head to the base station. A comparitive analysis using nine different parameters, such as energy efficiency, overhead, scalability complexity, and so on, has been provided in a chronological fashion. The article also discusses the strong and the weak points of each and every variants of LEACH. Finally the paper concludes with suggestions on future research domains in the area of WSN.","['Wireless sensor networks', 'Routing protocols', 'Routing', 'Time division multiple access', 'Schedules', 'Scalability']","['LEACH', 'Wireless Sensor Network', 'Clustering Protocol', 'Cluster Head', 'Routing']"
"The purpose of this paper is to survey and assess the state-of-the-art in automatic target recognition for synthetic aperture radar imagery (SAR-ATR). The aim is not to develop an exhaustive survey of the voluminous literature, but rather to capture in one place the various approaches for implementing the SAR-ATR system. This paper is meant to be as self-contained as possible, and it approaches the SAR-ATR problem from a holistic end-to-end perspective. A brief overview for the breadth of the SAR-ATR challenges is conducted. This is couched in terms of a single-channel SAR, and it is extendable to multi-channel SAR systems. Stages pertinent to the basic SAR-ATR system structure are defined, and the motivations of the requirements and constraints on the system constituents are addressed. For each stage in the SAR-ATR processing chain, a taxonomization methodology for surveying the numerous methods published in the open literature is proposed. Carefully selected works from the literature are presented under the taxa proposed. Novel comparisons, discussions, and comments are pinpointed throughout this paper. A two-fold benchmarking scheme for evaluating existing SAR-ATR systems and motivating new system designs is proposed. The scheme is applied to the works surveyed in this paper. Finally, a discussion is presented in which various interrelated issues, such as standard operating conditions, extended operating conditions, and target-model design, are addressed. This paper is a contribution toward fulfilling an objective of end-to-end SAR-ATR system design.","['Synthetic aperture radar', 'Classification', 'Feature recognition', 'Target recognition', 'System analysis and design', 'Benchmark testing', 'Radar tracking']","['SAR', 'radar', 'target', 'classification', 'recognition', 'features', 'model']"
"In recent decades, we have witnessed the evolution of biometric technology from the first pioneering works in face and voice recognition to the current state of development wherein a wide spectrum of highly accurate systems may be found, ranging from largely deployed modalities, such as fingerprint, face, or iris, to more marginal ones, such as signature or hand. This path of technological evolution has naturally led to a critical issue that has only started to be addressed recently: the resistance of this rapidly emerging technology to external attacks and, in particular, to spoofing. Spoofing, referred to by the term presentation attack in current standards, is a purely biometric vulnerability that is not shared with other IT security solutions. It refers to the ability to fool a biometric system into recognizing an illegitimate user as a genuine one by means of presenting a synthetic forged version of the original biometric trait to the sensor. The entire biometric community, including researchers, developers, standardizing bodies, and vendors, has thrown itself into the challenging task of proposing and developing efficient protection methods against this threat. The goal of this paper is to provide a comprehensive overview on the work that has been carried out over the last decade in the emerging field of antispoofing, with special attention to the mature and largely deployed face modality. The work covers theories, methodologies, state-of-the-art techniques, and evaluation databases and also aims at providing an outlook into the future of this very active field of research.","['Biometrics', 'Distance measurement', 'Computer security', 'Fingerprint recognition', 'Iris recognition', 'Access control', 'Speech recognition', 'Immune system', 'Biomedical monitoring', 'Authentication']","['Biometrics', 'Security', 'Anti-Spoofing']"
"The increasing demand for electricity and the emergence of smart grids have presented new opportunities for a home energy management system (HEMS) that can reduce energy usage. The HEMS incorporates a demand response (DR) tool that shifts and curtails demand to improve home energy consumption. This system commonly creates optimal consumption schedules by considering several factors, such as energy costs, environmental concerns, load profiles, and consumer comfort. With the deployment of smart meters, performing load control using the HEMS with DR-enabled appliances has become possible. This paper provides a comprehensive review on previous and current research related to the HEMS by considering various DR programs, smart technologies, and load scheduling controllers. The application of artificial intelligence for load scheduling controllers, such as artificial neural network, fuzzy logic, and adaptive neural fuzzy inference system, is also reviewed. Heuristic optimization techniques, which are widely used for optimal scheduling of various electrical devices in a smart home, are also discussed.","['Home appliances', 'Energy management', 'Energy consumption', 'Optimization', 'Schedules', 'Water heating']","['Home energy management system', 'demand response', 'smart technologies', 'integrated wireless technology', 'intelligent scheduling controller']"
"Industrial systems always prefer to reduce their operational expenses. To support such reductions, they need solutions that are capable of providing stability, fault tolerance, and flexibility. One such solution for industrial systems is cyber physical system (CPS) integration with the Internet of Things (IoT) utilizing cloud computing services. These CPSs can be considered as smart industrial systems, with their most prevalent applications in smart transportation, smart grids, smart medical and eHealthcare systems, and many more. These industrial CPSs mostly utilize supervisory control and data acquisition (SCADA) systems to control and monitor their critical infrastructure (CI). For example, WebSCADA is an application used for smart medical technologies, making improved patient monitoring and more timely decisions possible. The focus of the study presented in this paper is to highlight the security challenges that the industrial SCADA systems face in an IoT-cloud environment. Classical SCADA systems are already lacking in proper security measures; however, with the integration of complex new architectures for the future Internet based on the concepts of IoT, cloud computing, mobile wireless sensor networks, and so on, there are large issues at stakes in the security and deployment of these classical systems. Therefore, the integration of these future Internet concepts needs more research effort. This paper, along with highlighting the security challenges of these CI's, also provides the existing best practices and recommendations for improving and maintaining security. Finally, this paper briefly describes future research directions to secure these critical CPSs and help the research community in identifying the research gaps in this regard.","['Cloud computing', 'Security', 'SCADA systems', 'Power system stability', 'Fault tolerant systems', 'Wireless sensor networks', 'Internet of things', 'Stability analysis']","['APT', 'Industrial Control System', 'Internet of Things (IoT)', 'NIST', 'PRECYSE', 'Supervisory Control and Data Acquisition', 'SOA']"
"Traditional distance and density-based anomaly detection techniques are unable to detect periodic and seasonality related point anomalies which occur commonly in streaming data, leaving a big gap in time series anomaly detection in the current era of the IoT. To address this problem, we present a novel deep learning-based anomaly detection approach (DeepAnT) for time series data, which is equally applicable to the non-streaming cases. DeepAnT is capable of detecting a wide range of anomalies, i.e., point anomalies, contextual anomalies, and discords in time series data. In contrast to the anomaly detection methods where anomalies are learned, DeepAnT uses unlabeled data to capture and learn the data distribution that is used to forecast the normal behavior of a time series. DeepAnT consists of two modules: time series predictor and anomaly detector. The time series predictor module uses deep convolutional neural network (CNN) to predict the next time stamp on the defined horizon. This module takes a window of time series (used as a context) and attempts to predict the next time stamp. The predicted value is then passed to the anomaly detector module, which is responsible for tagging the corresponding time stamp as normal or abnormal. DeepAnT can be trained even without removing the anomalies from the given data set. Generally, in deep learning-based approaches, a lot of data are required to train a model. Whereas in DeepAnT, a model can be trained on relatively small data set while achieving good generalization capabilities due to the effective parameter sharing of the CNN. As the anomaly detection in DeepAnT is unsupervised, it does not rely on anomaly labels at the time of model generation. Therefore, this approach can be directly applied to real-life scenarios where it is practically impossible to label a big stream of data coming from heterogeneous sensors comprising of both normal as well as anomalous points. We have performed a detailed evaluation of 15 algorithms on 10 anomaly detection benchmarks, which contain a total of 433 real and synthetic time series. Experiments show that DeepAnT outperforms the state-of-the-art anomaly detection methods in most of the cases, while performing on par with others.","['Anomaly detection', 'Time series analysis', 'Clustering algorithms', 'Data models', 'Benchmark testing', 'Heuristic algorithms']","['Anomaly detection', 'artificial intelligence', 'convolutional neural network', 'deep neural networks', 'recurrent neural networks', 'time series analysis']"
"This paper provides a systematic review of the mutual coupling in multiple-input multiple-output (MIMO) systems, including the effects on performances of MIMO systems and various decoupling techniques. The mutual coupling changes the antenna characteristics in an array, and therefore, degrades the system performance of the MIMO system and causes the spectral regrowth. Although the system performance can be partially improved by calibrating out the mutual coupling in the digital domain, it is more effective to use decoupling techniques (from the antenna point) to overcome the mutual coupling effects. Some popular decoupling techniques for MIMO systems (especially for massive MIMO base station antennas) are also presented.","['Mutual coupling', 'MIMO communication', 'Antenna arrays', 'Signal to noise ratio', 'Interference', 'System performance']","['Capacity', 'error rate', 'MIMO antennas', 'mutual coupling']"
"This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.","['Machine learning', 'Computer architecture', 'Protocols', 'Data models', 'Data privacy', 'Computational modeling', 'Industries']","['Federated learning', 'machine learning', 'collaborative AI', 'privacy', 'security', 'decentralized data', 'on-device AI', 'peer-to-peer network']"
"Early diagnosis of gear transmission has been a significant challenge, because gear faults occur primarily at microstructure or even material level but their effects can only be observed indirectly at a system level. The performance of a gear fault diagnosis system depends significantly on the features extracted and the classifier subsequently applied. Traditionally, fault-related features are extracted and identified based on domain expertise through data preprocessing which are system-specific and may not be easily generalized. On the other hand, although recently the deep neural networks based approaches featuring adaptive feature extractions and inherent classifications have attracted attention, they usually require a substantial set of training data. Aiming at tackling these issues, this paper presents a deep convolutional neural network-based transfer learning approach. The proposed transfer learning architecture consists of two parts; the first part is constructed with a pre-trained deep neural network that serves to extract the features automatically from the input, and the second part is a fully connected stage to classify the features that needs to be trained using gear fault experimental data. Case analyses using experimental data from a benchmark gear system indicate that the proposed approach not only entertains preprocessing free adaptive feature extractions, but also requires only a small set of training data.","['Gears', 'Feature extraction', 'Fault diagnosis', 'Convolution', 'Convolutional neural networks', 'Vibrations']","['Alexnet', 'deep convolutional neural network', 'gear fault diagnosis', 'transfer learning']"
"Modern technologies of mobile computing and wireless sensing prompt the concept of pervasive social network (PSN)-based healthcare. To realize the concept, the core problem is how a PSN node can securely share health data with other nodes in the network. In this paper, we propose a secure system for PSN-based healthcare. Two protocols are designed for the system. The first one is an improved version of the IEEE 802.15.6 display authenticated association. It establishes secure links with unbalanced computational requirements for mobile devices and resource-limited sensor nodes. The second protocol uses blockchain technique to share health data among PSN nodes. We realize a protocol suite to study protocol runtime and other factors. In addition, human body channels are proposed for PSN nodes in some use cases. The proposed system illustrates a potential method of using blockchain for PSN-based applications.","['Protocols', 'Medical services', 'Mobile handsets', 'Wireless communication', 'Body area networks', 'Security', 'IEEE 802.15 Standard']","['IEEE 802.15.6', 'blockchain', 'e-health', 'healthcare', 'human body channels']"
"Internet of Things (IoT) is a new technological paradigm that can connect things from various fields through the Internet. For the IoT connected healthcare applications, the wireless body area network (WBAN) is gaining popularity as wearable devices spring into the market. This paper proposes a wearable sensor node with solar energy harvesting and Bluetooth low energy transmission that enables the implementation of an autonomous WBAN. Multiple sensor nodes can be deployed on different positions of the body to measure the subject's body temperature distribution, heartbeat, and detect falls. A web-based smartphone application is also developed for displaying the sensor data and fall notification. To extend the lifetime of the wearable sensor node, a flexible solar energy harvester with an output-based maximum power point tracking technique is used to power the sensor node. Experimental results show that the wearable sensor node works well when powered by the solar energy harvester. The autonomous 24 h operation is achieved with the experimental results. The proposed system with solar energy harvesting demonstrates that long-term continuous medical monitoring based on WBAN is possible provided that the subject stays outside for a short period of time in a day.","['Wearable sensors', 'Wireless communication', 'Body area networks', 'Solar panels', 'Solar energy', 'Maximum power point trackers', 'Temperature measurement']","['Internet of Things', 'wireless body area network', 'energy harvesting', 'maximum power point tracking', 'Bluetooth']"
"Due to the monumental growth of Internet applications in the last decade, the need for security of information network has increased manifolds. As a primary defense of network infrastructure, an intrusion detection system is expected to adapt to dynamically changing threat landscape. Many supervised and unsupervised techniques have been devised by researchers from the discipline of machine learning and data mining to achieve reliable detection of anomalies. Deep learning is an area of machine learning which applies neuron-like structure for learning tasks. Deep learning has profoundly changed the way we approach learning tasks by delivering monumental progress in different disciplines like speech processing, computer vision, and natural language processing to name a few. It is only relevant that this new technology must be investigated for information security applications. The aim of this paper is to investigate the suitability of deep learning approaches for anomaly-based intrusion detection system. For this research, we developed anomaly detection models based on different deep neural network structures, including convolutional neural networks, autoencoders, and recurrent neural networks. These deep models were trained on NSLKDD training data set and evaluated on both test data sets provided by NSLKDD, namely NSLKDDTest+ and NSLKDDTest21. All experiments in this paper are performed by authors on a GPU-based test bed. Conventional machine learning-based intrusion detection models were implemented using well-known classification techniques, including extreme learning machine, nearest neighbor, decision-tree, random-forest, support vector machine, naive-bays, and quadratic discriminant analysis. Both deep and conventional machine learning models were evaluated using well-known classification metrics, including receiver operating characteristics, area under curve, precision-recall curve, mean average precision and accuracy of classification. Experimental results of deep IDS models showed promising results for real-world application in anomaly detection systems.","['Anomaly detection', 'Machine learning', 'Training', 'Intrusion detection', 'Measurement', 'Neural networks']","['Deep learning', 'convolutional neural networks', 'autoencoders', 'LSTM', 'k_NN', 'decision_tree', 'intrusion detection', 'convnets', 'information security']"
"The boom in the capabilities and features of mobile devices, like smartphones, tablets, and wearables, combined with the ubiquitous and affordable Internet access and the advances in the areas of cooperative networking, computer vision, and mobile cloud computing transformed mobile augmented reality (MAR) from science fiction to a reality. Although mobile devices are more constrained computationalwise from traditional computers, they have a multitude of sensors that can be used to the development of more sophisticated MAR applications and can be assisted from remote servers for the execution of their intensive parts. In this paper, after introducing the reader to the basics of MAR, we present a categorization of the application fields together with some representative examples. Next, we introduce the reader to the user interface and experience in MAR applications and continue with the core system components of the MAR systems. After that, we discuss advances in tracking and registration, since their functionality is crucial to any MAR application and the network connectivity of the devices that run MAR applications together with its importance to the performance of the application. We continue with the importance of data management in MAR systems and the systems performance and sustainability, and before we conclude this survey, we present existing challenging problems.","['Mobile communication', 'Mobile computing', 'Cloud computing', 'Augmented reality', 'Smart phones', 'Sensors']","['Mobile augmented reality', 'mobile computing', 'human computer interaction']"
"Due to recent advances in digital technologies, and availability of credible data, an area of artificial intelligence, deep learning, has emerged and has demonstrated its ability and effectiveness in solving complex learning problems not possible before. In particular, convolutional neural networks (CNNs) have demonstrated their effectiveness in the image detection and recognition applications. However, they require intensive CPU operations and memory bandwidth that make general CPUs fail to achieve the desired performance levels. Consequently, hardware accelerators that use application-specific integrated circuits, field-programmable gate arrays (FPGAs), and graphic processing units have been employed to improve the throughput of CNNs. More precisely, FPGAs have been recently adopted for accelerating the implementation of deep learning networks due to their ability to maximize parallelism and their energy efficiency. In this paper, we review the recent existing techniques for accelerating deep learning networks on FPGAs. We highlight the key features employed by the various techniques for improving the acceleration performance. In addition, we provide recommendations for enhancing the utilization of FPGAs for CNNs acceleration. The techniques investigated in this paper represent the recent trends in the FPGA-based accelerators of deep learning networks. Thus, this paper is expected to direct the future advances on efficient hardware accelerators and to be useful for deep learning researchers.","['Deep learning', 'Field programmable gate arrays', 'Neural networks', 'Hardware', 'Acceleration', 'Convolution', 'Throughput']","['Adaptable architectures', 'convolutional neural networks (CNNs)', 'deep learning', 'dynamic reconfiguration', 'energy-efficient architecture', 'field programmable gate arrays (FPGAs)', 'hardware accelerator', 'machine learning', 'neural networks', 'optimization', 'parallel computer architecture', 'reconfigurable computing']"
"Neural architecture search (NAS) has significant progress in improving the accuracy of image classification. Recently, some works attempt to extend NAS to image segmentation which shows preliminary feasibility. However, all of them focus on searching architecture for semantic segmentation in natural scenes. In this paper, we design three types of primitive operation set on search space to automatically find two cell architecture DownSC and UpSC for semantic image segmentation especially medical image segmentation. Inspired by the U-net architecture and its variants successfully applied to various medical image segmentation, we propose NAS-Unet which is stacked by the same number of DownSC and UpSC on a U-like backbone network. The architectures of DownSC and UpSC updated simultaneously by a differential architecture strategy during the search stage. We demonstrate the good segmentation results of the proposed method on Promise12, Chaos, and ultrasound nerve datasets, which collected by magnetic resonance imaging, computed tomography, and ultrasound, respectively. Without any pretraining, our architecture searched on PASCAL VOC2012, attains better performances and much fewer parameters (about 0.8M) than U-net and one of its variants when evaluated on the above three types of medical image datasets.","['Computer architecture', 'Image segmentation', 'Magnetic resonance imaging', 'Medical diagnostic imaging', 'Task analysis', 'Microprocessors']","['Medical image segmentation', 'convolutional neural architecture search', 'deep learning']"
"An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded in Wuhan, China since late December 2019, which subsequently became pandemic around the world. Although COVID-19 is an acutely treated disease, it can also be fatal with a risk of fatality of 4.03% in China and the highest of 13.04% in Algeria and 12.67% Italy (as of 8th April 2020). The onset of serious illness may result in death as a consequence of substantial alveolar damage and progressive respiratory failure. Although laboratory testing, e.g., using reverse transcription polymerase chain reaction (RT-PCR), is the golden standard for clinical diagnosis, the tests may produce false negatives. Moreover, under the pandemic situation, shortage of RT-PCR testing resources may also delay the following clinical decision and treatment. Under such circumstances, chest CT imaging has become a valuable tool for both diagnosis and prognosis of COVID-19 patients. In this study, we propose a weakly supervised deep learning strategy for detecting and classifying COVID-19 infection from CT images. The proposed method can minimise the requirements of manual labelling of CT images but still be able to obtain accurate infection detection and distinguish COVID-19 from non-COVID-19 cases. Based on the promising results obtained qualitatively and quantitatively, we can envisage a wide deployment of our developed technique in large-scale clinical studies.","['COVID-19', 'Computed tomography', 'Lung', 'Deep learning', 'Hospitals']","['COVID-19', 'deep learning', 'weakly supervision', 'CT~images', 'classification', 'convolutional neural network']"
"Extending the Technology Acceptance Model (TAM) for studying the e-learning acceptance is not a new research topic, and it has been tackled by many scholars. However, the development of a comprehensive TAM that could be able to examine the e-learning acceptance under any circumstances is regarded to be an essential research direction. To identify the most widely used external factors of the TAM concerning the e-learning acceptance, a literature review comprising of 120 significant published studies from the last twelve years was conducted. The review analysis indicated that computer self-efficacy, subjective/social norm, perceived enjoyment, system quality, information quality, content quality, accessibility, and computer playfulness were the most common external factors of TAM. Accordingly, the TAM has been extended by the aforementioned factors to examine the students' acceptance of e-learning in five different universities in the United Arab of Emirates (UAE). A total of 435 students participated in the study. The results indicated that system quality, computer self-efficacy, and computer playfulness have a significant impact on perceived ease of use of e-learning system. Furthermore, information quality, perceived enjoyment, and accessibility were found to have a positive influence on perceived ease of use and perceived usefulness of e-learning system.","['Electronic learning', 'Databases', 'Media', 'Bibliographies', 'Tools']","['E-learning', 'higher education', 'TAM', 'PLS-SEM']"
"Continuous practices, i.e., continuous integration, delivery, and deployment, are the software development industry practices that enable organizations to frequently and reliably release new features and products. With the increasing interest in the literature on continuous practices, it is important to systematically review and synthesize the approaches, tools, challenges, and practices reported for adopting and implementing continuous practices. This paper aimed at systematically reviewing the state of the art of continuous practices to classify approaches and tools, identify challenges and practices in this regard, and identify the gaps for future research. We used the systematic literature review method for reviewing the peer-reviewed papers on continuous practices published between 2004 and June 1, 2016. We applied the thematic analysis method for analyzing the data extracted from reviewing 69 papers selected using predefined criteria. We have identified 30 approaches and associated tools, which facilitate the implementation of continuous practices in the following ways: (1) reducing build and test time in continuous integration (CI); (2) increasing visibility and awareness on build and test results in CI; (3) supporting (semi-) automated continuous testing; (4) detecting violations, flaws, and faults in CI; (5) addressing security and scalability issues in deployment pipeline; and (6) improving dependability and reliability of deployment process. We have also determined a list of critical factors, such as testing (effort and time), team awareness and transparency, good design principles, customer, highly skilled and motivated team, application domain, and appropriate infrastructure that should be carefully considered when introducing continuous practices in a given organization. The majority of the reviewed papers were validation (34.7%) and evaluation (36.2%) research types. This paper also reveals that continuous practices have been successfully applied to both greenfield and maintenance projects. Continuous practices have become an important area of software engineering research and practice. While the reported approaches, tools, and practices are addressing a wide range of challenges, there are several challenges and gaps, which require future research work for improving the capturing and reporting of contextual information in the studies reporting different aspects of continuous practices; gaining a deep understanding of how software-intensive systems should be (re-) architected to support continuous practices; and addressing the lack of knowledge and tools for engineering processes of designing and running secure deployment pipelines.","['Software', 'Organizations', 'Software engineering', 'Systematics', 'Bibliographies', 'Testing', 'Production']","['Continuous integration', 'continuous delivery', 'continuous deployment', 'continuous software engineering', 'systematic literature review', 'empirical software engineering']"
"Electromagnetic radars have been shown potentially to be used for remote sensing of biosignals in a more comfortable and easier way than wearable and contact devices. While there is an increasing interest in using radars for health monitoring, their performance has not been tested and reported either in practical scenarios or with acceptable low errors. Therefore, we use a frequency modulated continuous wave (FMCW) radar operating at 77 GHz in a bedroom environment to extract the respiration and heart rates of a patient, who is used to lying down on the bed. Indeed, the proposed signal processing contains advanced phase unwrapping manipulation, which is unique. In addition, the results are compared with a reliable reference sensor. Our results show that the correlations between the reference sensor and the radar estimates are in 94% and 80% for breathing and heart rates, respectively.","['Heart rate', 'Phase noise', 'Monitoring', 'Radar remote sensing', 'Radar detection', 'Receivers']","['Breathing rate monitoring', 'FMCW radar', 'heart rate monitoring', 'Hexoskin', 'mm-wave', 'non-contact monitoring', 'phase analysis', 'remote sensing', 'vital signs', 'TI']"
"Shipbuilding companies are upgrading their inner workings in order to create Shipyards 4.0, where the principles of Industry 4.0 are paving the way to further digitalized and optimized processes in an integrated network. Among the different Industry 4.0 technologies, this paper focuses on augmented reality, whose application in the industrial field has led to the concept of industrial augmented reality (IAR). This paper first describes the basics of IAR and then carries out a thorough analysis of the latest IAR systems for industrial and shipbuilding applications. Then, in order to build a practical IAR system for shipyard workers, the main hardware and software solutions are compared. Finally, as a conclusion after reviewing all the aspects related to IAR for shipbuilding, it proposed an IAR system architecture that combines cloudlets and fog computing, which reduce latency response and accelerate rendering tasks while offloading compute intensive tasks from the cloud.","['Augmented reality', 'Industries', 'Task analysis', 'Software', 'Cameras', 'Companies', 'Hardware']","['Industry 4.0', 'augmented reality', 'industrial augmented reality', 'Internet of Things', 'cyber-physical systems', 'industrial operator support', 'smart factory', 'task execution', 'cloudlet', 'edge computing']"
"This paper conducts a comprehensive study on the application of big data and machine learning in the electrical power grid introduced through the emergence of the next-generation power system-the smart grid (SG). Connectivity lies at the core of this new grid infrastructure, which is provided by the Internet of Things (IoT). This connectivity, and constant communication required in this system, also introduced a massive data volume that demands techniques far superior to conventional methods for proper analysis and decision-making. The IoT-integrated SG system can provide efficient load forecasting and data acquisition technique along with cost-effectiveness. Big data analysis and machine learning techniques are essential to reaping these benefits. In the complex connected system of SG, cyber security becomes a critical issue; IoT devices and their data turning into major targets of attacks. Such security concerns and their solutions are also included in this paper. Key information obtained through literature review is tabulated in the corresponding sections to provide a clear synopsis; and the findings of this rigorous review are listed to give a concise picture of this area of study and promising future fields of academic and industrial research, with current limitations with viable solutions along with their effectiveness.","['Smart grids', 'Big Data', 'Machine learning', 'Security', 'Internet of Things']","['Big data analysis', 'cyber security', 'IoT', 'machine learning', 'smart grid']"
"Blockchain technology has attracted tremendous attention in both academia and capital market. However, overwhelming speculations on thousands of available cryptocurrencies and numerous initial coin offering scams have also brought notorious debates on this emerging technology. This paper traces the development of blockchain systems to reveal the importance of decentralized applications (dApps) and the future value of blockchain. We survey the state-of-the-art dApps and discuss the direction of blockchain development to fulfill the desirable characteristics of dApps. The readers will gain an overview of dApp research and get familiar with recent developments in the blockchain.","['Bitcoin', 'Games', 'Contracts', 'Peer-to-peer computing', 'Software systems']","['Blockchain', 'decentralized application', 'smart contract', 'software systems', 'survey']"
"Employing large intelligent surfaces (LISs) is a promising solution for improving the coverage and rate of future wireless systems. These surfaces comprise massive numbers of nearly-passive elements that interact with the incident signals, for example by reflecting them, in a smart way that improves the wireless system performance. Prior work focused on the design of the LIS reflection matrices assuming full channel knowledge. Estimating these channels at the LIS, however, is a key challenging problem. With the massive number of LIS elements, channel estimation or reflection beam training will be associated with (i) huge training overhead if all the LIS elements are passive (not connected to a baseband) or with (ii) prohibitive hardware complexity and power consumption if all the elements are connected to the baseband through a fully-digital or hybrid analog/digital architecture. This paper proposes efficient solutions for these problems by leveraging tools from compressive sensing and deep learning. First, a novel LIS architecture based on sparse channel sensors is proposed. In this architecture, all the LIS elements are passive except for a few elements that are active (connected to the baseband). We then develop two solutions that design the LIS reflection matrices with negligible training overhead. In the first approach, we leverage compressive sensing tools to construct the channels at all the LIS elements from the channels seen only at the active elements. In the second approach, we develop a deep-learning based solution where the LIS learns how to interact with the incident signal given the channels at the active elements, which represent the state of the environment and transmitter/receiver locations. We show that the achievable rates of the proposed solutions approach the upper bound, which assumes perfect channel knowledge, with negligible training overhead and with only a few active elements, making them promising for future LIS systems.","['Training', 'Deep learning', 'Wireless communication', 'Baseband', 'Tools', 'Reflection', 'Compressed sensing']","['Large intelligent surface', 'intelligent reflecting surfaces', 'reconfigurable intelligent surface', 'smart reflect-array', 'beamforming', 'millimeter wave', 'compressive sensing', 'deep learning']"
"Traditional machine learning algorithms have made great achievements in data-driven fault diagnosis. However, they assume that all the data must be in the same working condition and have the same distribution and feature space. They are not applicable for real-world working conditions, which often change with time, so the data are hard to obtain. In order to utilize data in different working conditions to improve the performance, this paper presents a transfer learning approach for fault diagnosis with neural networks. First, it learns characteristics from massive source data and adjusts the parameters of neural networks accordingly. Second, the structure of neural networks alters for the change of data distribution. In the same time, some parameters are transferred from source task to target task. Finally, the new model is trained by a small amount of target data in another working condition. The Case Western Reserve University bearing data set is used to validate the performance of the proposed transfer learning approach. Experimental results show that the proposed transfer learning approach can improve the classification accuracy and reduce the training time comparing with the conventional neural network method when there are only a small amount of target data.","['Employee welfare', 'Fault diagnosis', 'Data models', 'Training', 'Vibrations', 'Biological neural networks']","['Fault diagnosis', 'transfer learning', 'neural networks', 'machine learning']"
"For agricultural applications, regularized smart-farming solutions are being considered, including the use of unmanned aerial vehicles (UAVs). The UAVs combine information and communication technologies, robots, artificial intelligence, big data, and the Internet of Things. The agricultural UAVs are highly capable, and their use has expanded across all areas of agriculture, including pesticide and fertilizer spraying, seed sowing, and growth assessment and mapping. Accordingly, the market for agricultural UAVs is expected to continue growing with the related technologies. In this study, we consider the latest trends and applications of leading technologies related to agricultural UAVs, control technologies, equipment, and development. We discuss the use of UAVs in real agricultural environments. Furthermore, the future development of the agricultural UAVs and their challenges are presented.","['Cameras', 'Unmanned aerial vehicles', 'Agriculture', 'Wireless sensor networks', 'Wireless communication', 'Sensors', 'Rotors']","['Agricultural applications', 'agricultural UAV', 'control technology', 'smart farming', 'unmanned aerial vehicle', 'UAV platforms']"
"This paper investigates the coexistence between two key enabling technologies for fifth generation (5G) mobile networks, non-orthogonal multiple access (NOMA), and millimeter-wave (mmWave) communications. Particularly, the application of random beamforming to mmWave-NOMA systems is considered in order to avoid the requirement that the base station know all the users' channel state information. Stochastic geometry is used to characterize the performance of the proposed mmWave-NOMA transmission scheme by using key features of mmWave systems, i.e., that mmWave transmission is highly directional and potential blockages will thin the user distribution. Two random beamforming approaches that can further reduce the system overhead are also proposed, and their performance is studied analytically in terms of sum rates and outage probabilities. Simulation results are also provided to demonstrate the performance of the proposed schemes and verify the accuracy of the developed analytical results.","['Base stations', 'NOMA', 'Array signal processing', 'Precoding', '5G mobile communication', 'Interference']","['Non-orthogonal multiple access (NOMA)', 'millimeter wave (mmWave) networks', 'mmWave-NOMA communications', 'random beamforming']"
"The public key infrastructure-based authentication protocol provides basic security services for the vehicular ad hoc networks (VANETs). However, trust and privacy are still open issues due to the unique characteristics of VANETs. It is crucial to prevent internal vehicles from broadcasting forged messages while simultaneously preserving the privacy of vehicles against the tracking attacks. In this paper, we propose a blockchain-based anonymous reputation system (BARS) to establish a privacy-preserving trust model for VANETs. The certificate and revocation transparency is implemented efficiently with the proofs of presence and absence based on the extended blockchain technology. The public keys are used as pseudonyms in communications without any information about real identities for conditional anonymity. In order to prevent the distribution of forged messages, a reputation evaluation algorithm is presented relying on both direct historical interactions and indirect opinions about vehicles. A set of experiments is conducted to evaluate BARS in terms of security, validity, and performance, and the results show that BARS is able to establish a trust model with transparency, conditional anonymity, efficiency, and robustness for VANETs.","['Privacy', 'Public key', 'Bars', 'Data models', 'Authentication']","['Vehicular ad-hoc networks', 'blockchain', 'trust management', 'reputation system', 'privacy']"
"In recent years, the classification of breast cancer has been the topic of interest in the field of Healthcare informatics, because it is the second main cause of cancer-related deaths in women. Breast cancer can be identified using a biopsy where tissue is removed and studied under microscope. The diagnosis is based on the qualification of the histopathologist, who will look for abnormal cells. However, if the histopathologist is not well-trained, this may lead to wrong diagnosis. With the recent advances in image processing and machine learning, there is an interest in attempting to develop a reliable pattern recognition based systems to improve the quality of diagnosis. In this paper, we compare two machine learning approaches for the automatic classification of breast cancer histology images into benign and malignant and into benign and malignant sub-classes. The first approach is based on the extraction of a set of handcrafted features encoded by two coding models (bag of words and locality constrained linear coding) and trained by support vector machines, while the second approach is based on the design of convolutional neural networks. We have also experimentally tested dataset augmentation techniques to enhance the accuracy of the convolutional neural network as well as “handcrafted features + convolutional neural network”and “convolutional neural network features + classifier”configurations. The results show convolutional neural networks outperformed the handcrafted feature based classifier, where we achieved accuracy between 96.15% and 98.33% for the binary classification and 83.31% and 88.23% for the multi-class classification.","['Feature extraction', 'Convolutional neural networks', 'Breast cancer', 'Image coding', 'Machine learning']","['Histology images', 'convolutional neural networks', 'engineered features', 'bag of words', 'locality constrained linear coding']"
"Mobile edge computing (MEC) provides a promising approach to significantly reduce network operational cost and improve quality of service (QoS) of mobile users by pushing computation resources to the network edges, and enables a scalable Internet of Things (IoT) architecture for time-sensitive applications (e-healthcare, real-time monitoring, and so on.). However, the mobility of mobile users and the limited coverage of edge servers can result in significant network performance degradation, dramatic drop in QoS, and even interruption of ongoing edge services; therefore, it is difficult to ensure service continuity. Service migration has great potential to address the issues, which decides when or where these services are migrated following user mobility and the changes of demand. In this paper, two conceptions similar to service migration, i.e., live migration for data centers and handover in cellular networks, are first discussed. Next, the cutting-edge research efforts on service migration in MEC are reviewed, and a devisal of taxonomy based on various research directions for efficient service migration is presented. Subsequently, a summary of three technologies for hosting services on edge servers, i.e., virtual machine, container, and agent, is provided. At last, open research challenges in service migration are identified and discussed.","['Servers', 'Virtual machining', 'Edge computing', 'Cloud computing', 'Quality of service', 'Data centers', 'Handover']","['Mobile edge computing', 'service migration', 'live migration', 'migration path selection', 'cellular handover']"
"We investigate the application of non-orthogonal multiple access (NOMA) with successive interference cancellation (SIC) in downlink multiuser multiple-input multiple-output (MIMO) cellular systems, where the total number of receive antennas at user equipment (UE) ends in a cell is more than the number of transmit antennas at the base station (BS). We first dynamically group the UE receive antennas into a number of clusters equal to or more than the number of BS transmit antennas. A single beamforming vector is then shared by all the receive antennas in a cluster. We propose a linear beamforming technique in which all the receive antennas can significantly cancel the inter-cluster interference. On the other hand, the receive antennas in each cluster are scheduled on the power domain NOMA basis with SIC at the receiver ends. For inter-cluster and intra-cluster power allocation, we provide dynamic power allocation solutions with an objective to maximizing the overall cell capacity. An extensive performance evaluation is carried out for the proposed MIMO-NOMA system and the results are compared with those for conventional orthogonal multiple access (OMA)-based MIMO systems and other existing MIMO-NOMA solutions. The numerical results quantify the capacity gain of the proposed MIMO-NOMA model over MIMO-OMA and other existing MIMO-NOMA solutions.","['NOMA', 'Resource management', 'Receiving antennas', 'Downlink', 'Transmitting antennas', 'MIMO', 'Interference']","['5G cellular', 'non-orthogonal multiple access (NOMA)', 'multiple-input multiple-output (MIMO)', 'linear beamforming', 'dynamic user clustering', 'dynamic power allocation']"
"It is an exciting time for power systems as there are many ground-breaking changes happening simultaneously. There is a global consensus in increasing the share of renewable energy-based generation in the overall mix, transitioning to a more environmental-friendly transportation with electric vehicles as well as liberalizing the electricity markets, much to the distaste of traditional utility companies. All of these changes are against the status quo and introduce new paradigms in the way the power systems operate. The generation penetrates distribution networks, renewables introduce intermittency, and liberalized markets need more competitive operation with the existing assets. All of these challenges require using some sort of storage device to develop viable power system operation solutions. There are different types of storage systems with different costs, operation characteristics, and potential applications. Understanding these is vital for the future design of power systems whether it be for short-term transient operation or long-term generation planning. In this paper, the state-of-the-art storage systems and their characteristics are thoroughly reviewed along with the cutting edge research prototypes. Based on their architectures, capacities, and operation characteristics, the potential application fields are identified. Finally, the research fields that are related to energy storage systems are studied with their impacts on the future of power systems.","['Flywheels', 'Iron', 'Renewable energy sources', 'Production', 'Smart grids']","['Storage systems', 'electric vehicles', 'power system optimization', 'market liberalization', 'renewable energy', 'new operation schemes', 'power system planning']"
"With the development of satellite technology, up to date imaging mode of synthetic aperture radar (SAR) satellite can provide higher resolution SAR imageries, which benefits ship detection and instance segmentation. Meanwhile, object detectors based on convolutional neural network (CNN) show high performance on SAR ship detection even without land-ocean segmentation; but with respective shortcomings, such as the relatively small size of SAR images for ship detection, limited SAR training samples, and inappropriate annotations, in existing SAR ship datasets, related research is hampered. To promote the development of CNN based ship detection and instance segmentation, we have constructed a High-Resolution SAR Images Dataset (HRSID). In addition to object detection, instance segmentation can also be implemented on HRSID. As for dataset construction, under the overlapped ratio of 25%, 136 panoramic SAR imageries with ranging resolution from 1m to 5m are cropped to 800 × 800 pixels SAR images. To reduce wrong annotation and missing annotation, optical remote sensing imageries are applied to reduce the interferes from harbor constructions. There are 5604 cropped SAR images and 16951 ships in HRSID, and we have divided HRSID into a training set (65% SAR images) and test set (35% SAR images) with the format of Microsoft Common Objects in Context (MS COCO). 8 state-of-the-art detectors are experimented on HRSID to build the baseline; MS COCO evaluation metrics are applicated for comprehensive evaluation. Experimental results reveal that ship detection and instance segmentation can be well implemented on HRSID.","['Marine vehicles', 'Radar polarimetry', 'Image segmentation', 'Imaging', 'Synthetic aperture radar', 'Detectors', 'Image resolution']","['High-resolution SAR images dataset', 'ship detection', 'instance segmentation', 'deep learning', 'convolutional neural network']"
"Digital twin is a significant way to achieve smart manufacturing, and provides a new paradigm for fault diagnosis. Traditional data-based fault diagnosis methods mostly assume that the training data and test data are following the same distribution and can acquire sufficient data to train a reliable diagnosis model, which is unrealistic in the dynamic changing production process. In this paper, we present a two-phase digital-twin-assisted fault diagnosis method using deep transfer learning (DFDD), which realizes fault diagnosis both in the development and maintenance phases. At first, the potential problems that are not considered at design time can be discovered through front running the ultra-high-fidelity model in the virtual space, while a deep neural network (DNN)-based diagnosis model will be fully trained. In the second phase, the previously trained diagnosis model can be migrated from the virtual space to physical space using deep transfer learning for real-time monitoring and predictive maintenance. This ensures the accuracy of the diagnosis as well as avoids wasting time and knowledge. A case study about fault diagnosis using DFDD in a car body-side production line is presented. The results show the superiority and feasibility of our proposed method.","['Fault diagnosis', 'Data models', 'Manufacturing', 'Training data', 'Maintenance engineering', 'Predictive models', 'Solid modeling']","['Digital twin', 'deep transfer learning', 'fault diagnosis', 'smart manufacturing']"
"For task-scheduling problems in cloud computing, a multi-objective optimization method is proposed here. First, with an aim toward the biodiversity of resources and tasks in cloud computing, we propose a resource cost model that defines the demand of tasks on resources with more details. This model reflects the relationship between the user's resource costs and the budget costs. A multi-objective optimization scheduling method has been proposed based on this resource cost model. This method considers the makespan and the user's budget costs as constraints of the optimization problem, achieving multi-objective optimization of both performance and cost. An improved ant colony algorithm has been proposed to solve this problem. Two constraint functions were used to evaluate and provide feedback regarding the performance and budget cost. These two constraint functions made the algorithm adjust the quality of the solution in a timely manner based on feedback in order to achieve the optimal solution. Some simulation experiments were designed to evaluate this method's performance using four metrics: 1) the makespan; 2) cost; 3) deadline violation rate; and 4) resource utilization. Experimental results show that based on these four metrics, a multi-objective optimization method is better than other similar methods, especially as it increased 56.6% in the best case scenario.","['Scheduling', 'Optimization', 'Processor scheduling', 'Cloud computing', 'Ant colony optimization', 'Memory management', 'Resource management']","['Cloud computing', 'Ant colony', 'Task scheduling']"
"Texture analysis is used in a very broad range of fields and applications, from texture classification (e.g., for remote sensing) to segmentation (e.g., in biomedical imaging), passing through image synthesis or pattern recognition (e.g., for image inpainting). For each of these image processing procedures, first, it is necessary to extract—from raw images—meaningful features that describe the texture properties. Various feature extraction methods have been proposed in the last decades. Each of them has its advantages and limitations: performances of some of them are not modified by translation, rotation, affine, and perspective transform; others have a low computational complexity; others, again, are easy to implement; and so on. This paper provides a comprehensive survey of the texture feature extraction methods. The latter are categorized into seven classes: statistical approaches, structural approaches, transform-based approaches, model-based approaches, graph-based approaches, learning-based approaches, and entropy-based approaches. For each method in these seven classes, we present the concept, the advantages, and the drawbacks and give examples of application. This survey allows us to identify two classes of methods that, particularly, deserve attention in the future, as their performances seem interesting, but their thorough study is not performed yet.",[],[]
"Cell-free (CF) massive multiple-input-multiple-output (MIMO) systems have a large number of individually controllable antennas distributed over a wide area for simultaneously serving a small number of user equipments (UEs). This solution has been considered as a promising next-generation technology due to its ability to offer a similar quality of service to all UEs despite its low-complexity signal processing. In this paper, we provide a comprehensive survey of CF massive MIMO systems. To be more specific, the benefit of the so-called channel hardening and the favorable propagation conditions are exploited. Furthermore, we quantify the advantages of CF massive MIMO systems in terms of their energy- and cost-efficiency. Additionally, the signal processing techniques invoked for reducing the fronthaul burden for joint channel estimation and for transmit precoding are analyzed. Finally, the open research challenges in both its deployment and network management are highlighted.","['MIMO communication', 'Central Processing Unit', 'Power demand', 'Antenna arrays', 'Signal processing', 'Time-frequency analysis']","['Cell-free massive MIMO', 'B5G', 'signal processing', 'performance analysis']"
"The era of artificial neural network (ANN) began with a simplified application in many fields and remarkable success in pattern recognition (PR) even in manufacturing industries. Although significant progress achieved and surveyed in addressing ANN application to PR challenges, nevertheless, some problems are yet to be resolved like whimsical orientation (the unknown path that cannot be accurately calculated due to its directional position). Other problem includes; object classification, location, scaling, neurons behavior analysis in hidden layers, rule, and template matching. Also, the lack of extant literature on the issues associated with ANN application to PR seems to slow down research focus and progress in the field. Hence, there is a need for state-of-the-art in neural networks application to PR to urgently address the above-highlights problems for more successes. The study furnishes readers with a clearer understanding of the current, and new trend in ANN models that effectively addresses PR challenges to enable research focus and topics. Similarly, the comprehensive review reveals the diverse areas of the success of ANN models and their application to PR. In evaluating the performance of ANN models, some statistical indicators for measuring the performance of the ANN model in many studies were adopted. Such as the use of mean absolute percentage error (MAPE), mean absolute error (MAE), root mean squared error (RMSE), and variance of absolute percentage error (VAPE). The result shows that the current ANN models such as GAN, SAE, DBN, RBM, RNN, RBFN, PNN, CNN, SLP, MLP, MLNN, Reservoir computing, and Transformer models are performing excellently in their application to PR tasks. Therefore, the study recommends the research focus on current models and the development of new models concurrently for more successes in the field.","['Artificial neural networks', 'Task analysis', 'Fingerprint recognition', 'Computational modeling', 'Image recognition', 'Agriculture']","['Artificial neural networks', 'application to pattern recognition', 'feedforward neural networks', 'feedback neural networks', 'hybrid models']"
"Fog computing (FC) and Internet of Everything (IoE) are two emerging technological paradigms that, to date, have been considered standing-alone. However, because of their complementary features, we expect that their integration can foster a number of computing and network-intensive pervasive applications under the incoming realm of the future Internet. Motivated by this consideration, the goal of this position paper is fivefold. First, we review the technological attributes and platforms proposed in the current literature for the standing-alone FC and IoE paradigms. Second, by leveraging some use cases as illustrative examples, we point out that the integration of the FC and IoE paradigms may give rise to opportunities for new applications in the realms of the IoE, Smart City, Industry 4.0, and Big Data Streaming, while introducing new open issues. Third, we propose a novel technological paradigm, the Fog of Everything (FoE) paradigm, that integrates FC and IoE and then we detail the main building blocks and services of the corresponding technological platform and protocol stack. Fourth, as a proof-of-concept, we present the simulated energy-delay performance of a small-scale FoE prototype, namely, the V-FoE prototype. Afterward, we compare the obtained performance with the corresponding one of a benchmark technological platform, e.g., the V-D2D one. It exploits only device-to-device links to establish inter-thing “ad hoc” communication. Last, we point out the position of the proposed FoE paradigm over a spectrum of seemingly related recent research projects.","['Cloud computing', 'Big Data', 'Edge computing', 'Biological system modeling', 'Ecosystems', 'Smart cities']","['Fog of IoE', 'virtualized networked computing platforms for IoE', 'context-aware networking-plus-computing distributed resource management', 'Internet of Energy', 'Smart City', 'Industry 4.0', 'Big Data Streaming', 'future Internet']"
"Accurate prediction of remaining useful life (RUL) of lithium-ion battery plays an increasingly crucial role in the intelligent battery health management systems. The advances in deep learning introduce new data-driven approaches to this problem. This paper proposes an integrated deep learning approach for RUL prediction of lithium-ion battery by integrating autoencoder with deep neural network (DNN). First, we present a multi-dimensional feature extraction method with autoencoder model to represent battery health degradation. Then, the RUL prediction model-based DNN is trained for multi-battery remaining cycle life estimation. The proposed approach is applied to the real data set of lithium-ion battery cycle life from NASA, and the experiment results show that the proposed approach can improve the accuracy of RUL prediction.","['Lithium-ion batteries', 'Feature extraction', 'Predictive models', 'Voltage measurement', 'Temperature measurement', 'Machine learning']","['Lithium-ion battery', 'remaining useful life', 'RUL prediction model', 'deep learning', 'deep neural network']"
"Security breaches due to attacks by malicious software (malware) continue to escalate posing a major security concern in this digital age. With many computer users, corporations, and governments affected due to an exponential growth in malware attacks, malware detection continues to be a hot research topic. Current malware detection solutions that adopt the static and dynamic analysis of malware signatures and behavior patterns are time consuming and have proven to be ineffective in identifying unknown malwares in real-time. Recent malwares use polymorphic, metamorphic, and other evasive techniques to change the malware behaviors quickly and to generate a large number of new malwares. Such new malwares are predominantly variants of existing malwares, and machine learning algorithms (MLAs) are being employed recently to conduct an effective malware analysis. However, such approaches are time consuming as they require extensive feature engineering, feature learning, and feature representation. By using the advanced MLAs such as deep learning, the feature engineering phase can be completely avoided. Recently reported research studies in this direction show the performance of their algorithms with a biased training data, which limits their practical use in real-time situations. There is a compelling need to mitigate bias and evaluate these methods independently in order to arrive at a new enhanced method for effective zero-day malware detection. To fill the gap in the literature, this paper, first, evaluates the classical MLAs and deep learning architectures for malware detection, classification, and categorization using different public and private datasets. Second, we remove all the dataset bias removed in the experimental analysis by having different splits of the public and private datasets to train and test the model in a disjoint way using different timescales. Third, our major contribution is in proposing a novel image processing technique with optimal parameters for MLAs and deep learning architectures to arrive at an effective zero-day malware detection model. A comprehensive comparative study of our model demonstrates that our proposed deep learning architectures outperform classical MLAs. Our novelty in combining visualization and deep learning architectures for static, dynamic, and image processing-based hybrid approach applied in a big data environment is the first of its kind toward achieving robust intelligent zero-day malware detection. Overall, this paper paves way for an effective visual detection of malware using a scalable and hybrid deep learning framework for real-time deployments.","['Malware', 'Deep learning', 'Feature extraction', 'Computer architecture', 'Computer security']","['Cyber security', 'cybercrime', 'malware detection', 'static and dynamic analysis', 'artificial intelligence', 'machine learning', 'deep learning', 'image processing', 'scalable and hybrid framework']"
"Internet of Things (IoT) and smart computing technologies have revolutionized every sphere of 21 st century humans. IoT technologies and the data driven services they offer were beyond imagination just a decade ago. Now, they surround us and influence a variety of domains such as automobile, smart home, healthcare, etc. In particular, the Agriculture and Farming industries have also embraced this technological intervention. Smart devices are widely used by a range of people from farmers to entrepreneurs. These technologies are used in a variety of ways, from finding real-time status of crops and soil moisture content to deploying drones to assist with tasks such as applying pesticide spray. However, the use of IoT and smart communication technologies introduce a vast exposure to cybersecurity threats and vulnerabilities in smart farming environments. Such cyber attacks have the potential to disrupt the economies of countries that are widely dependent on agriculture. In this paper, we present a holistic study on security and privacy in a smart farming ecosystem. The paper outlines a multi layered architecture relevant to the precision agriculture domain and discusses the security and privacy issues in this dynamic and distributed cyber physical environment. Further more, the paper elaborates on potential cyber attack scenarios and highlights open research challenges and future directions.","['Privacy', 'Real-time systems', 'Computer security']","['Security', 'privacy', 'smart farming', 'precision agriculture', 'cloud computing', 'edge computing', 'cyber physical systems', 'IoT', 'artificial intelligence (AI)', 'machine learning', 'layered architecture']"
"Machine learning is one of the most prevailing techniques in computer science, and it has been widely applied in image processing, natural language processing, pattern recognition, cybersecurity, and other fields. Regardless of successful applications of machine learning algorithms in many scenarios, e.g., facial recognition, malware detection, automatic driving, and intrusion detection, these algorithms and corresponding training data are vulnerable to a variety of security threats, inducing a significant performance decrease. Hence, it is vital to call for further attention regarding security threats and corresponding defensive techniques of machine learning, which motivates a comprehensive survey in this paper. Until now, researchers from academia and industry have found out many security threats against a variety of learning algorithms, including naive Bayes, logistic regression, decision tree, support vector machine (SVM), principle component analysis, clustering, and prevailing deep neural networks. Thus, we revisit existing security threats and give a systematic survey on them from two aspects, the training phase and the testing/inferring phase. After that, we categorize current defensive techniques of machine learning into four groups: security assessment mechanisms, countermeasures in the training phase, those in the testing or inferring phase, data security, and privacy. Finally, we provide five notable trends in the research on security threats and defensive techniques of machine learning, which are worth doing in-depth studies in future.","['Security', 'Training', 'Machine learning algorithms', 'Training data', 'Support vector machines', 'Testing', 'Taxonomy']","['Machine learning', 'adversarial samples', 'security threats', 'defensive techniques']"
"In recent years, advanced threat attacks are increasing, but the traditional network intrusion detection system based on feature filtering has some drawbacks which make it difficult to find new attacks in time. This paper takes NSL-KDD data set as the research object, analyses the latest progress and existing problems in the field of intrusion detection technology, and proposes an adaptive ensemble learning model. By adjusting the proportion of training data and setting up multiple decision trees, we construct a MultiTree algorithm. In order to improve the overall detection effect, we choose several base classifiers, including decision tree, random forest, kNN, DNN, and design an ensemble adaptive voting algorithm. We use NSL-KDD Test+ to verify our approach, the accuracy of the MultiTree algorithm is 84.2%, while the final accuracy of the adaptive voting algorithm reaches 85.2%. Compared with other research papers, it is proved that our ensemble model effectively improves detection accuracy. In addition, through the analysis of data, it is found that the quality of data features is an important factor to determine the detection effect. In the future, we should optimize the feature selection and preprocessing of intrusion detection data to achieve better results.","['Intrusion detection', 'Feature extraction', 'Classification algorithms', 'Adaptation models', 'Machine learning algorithms', 'Neural networks', 'Prediction algorithms']","['Intrusion detection', 'ensemble learning', 'deep neural network', 'voting', 'MultiTree', 'NSL-KDD']"
"Nature computing has evolved with exciting performance to solve complex real-world combinatorial optimization problems. These problems span across engineering, medical sciences, and sciences generally. The Ebola virus has a propagation strategy that allows individuals in a population to move among susceptible, infected, quarantined, hospitalized, recovered, and dead sub-population groups. Motivated by the effectiveness of this strategy of propagation of the disease, a new bio-inspired and population-based optimization algorithm is proposed. This study presents a novel metaheuristic algorithm named Ebola Optimization Search Algorithm (EOSA) based on the propagation mechanism of the Ebola virus disease. First, we designed an improved SIR model of the disease, namely SEIR-HVQD: Susceptible (S), Exposed (E), Infected (I), Recovered (R), Hospitalized (H), Vaccinated (V), Quarantine (Q), and Death or Dead (D). Secondly, we represented the new model using a mathematical model based on a system of first-order differential equations. A combination of the propagation and mathematical models was adapted for developing the new metaheuristic algorithm. To evaluate the performance and capability of the proposed method in comparison with other optimization methods, two sets of benchmark functions consisting of forty-seven (47) classical and thirty (30) constrained IEEE-CEC benchmark functions were investigated. The results indicate that the performance of the proposed algorithm is competitive with other state-of-the-art optimization methods based on scalability, convergence, and sensitivity analyses. Extensive simulation results show that the EOSA outperforms popular metaheuristic algorithms such as the Particle Swarm Optimization Algorithm (PSO), Genetic Algorithm (GA), and Artificial Bee Colony Algorithm (ABC). Also, the algorithm was applied to address the complex problem of selecting the best combination of convolutional neural network (CNN) hyperparameters in the image classification of digital mammography. Results obtained showed the optimized CNN architecture successfully detected breast cancer from digital images at an accuracy of 96.0%. The source code of EOSA is publicly available at https://github.com/NathanielOy/EOSA_Metaheuristic .","['Optimization', 'Viruses (medical)', 'Diseases', 'Metaheuristics', 'Mathematical models', 'Heuristic algorithms', 'Statistics']","['Ebola virus', 'metaheuristic algorithm', 'optimization problems', 'constrained benchmark functions', 'image classification', 'convolutional neural network']"
"Wireless sensor networks (WSNs) will be integrated into the future Internet as one of the components of the Internet of Things, and will become globally addressable by any entity connected to the Internet. Despite the great potential of this integration, it also brings new threats, such as the exposure of sensor nodes to attacks originating from the Internet. In this context, lightweight authentication and key agreement protocols must be in place to enable end-to-end secure communication. Recently, Amin et al. proposed a three-factor mutual authentication protocol for WSNs. However, we identified several flaws in their protocol. We found that their protocol suffers from smart card loss attack where the user identity and password can be guessed using offline brute force techniques. Moreover, the protocol suffers from known session-specific temporary information attack, which leads to the disclosure of session keys in other sessions. Furthermore, the protocol is vulnerable to tracking attack and fails to fulfill user untraceability. To address these deficiencies, we present a lightweight and secure user authentication protocol based on the Rabin cryptosystem, which has the characteristic of computational asymmetry. We conduct a formal verification of our proposed protocol using ProVerif in order to demonstrate that our scheme fulfills the required security properties. We also present a comprehensive heuristic security analysis to show that our protocol is secure against all the possible attacks and provides the desired security features. The results we obtained show that our new protocol is a secure and lightweight solution for authentication and key agreement for Internet-integrated WSNs.","['Protocols', 'Wireless sensor networks', 'Internet', 'Authentication', 'Smart cards', 'Cryptography']","['Authentication', 'biometrics', 'key management', 'privacy', 'Rabin cryptosystem', 'smart card', 'wireless sensor networks']"
"The rapid development of blockchain technology and their numerous emerging applications has received huge attention in recent years. The distributed consensus mechanism is the backbone of a blockchain network. It plays a key role in ensuring the network's security, integrity, and performance. Most current blockchain networks have been deploying the proof-of-work consensus mechanisms, in which the consensus is reached through intensive mining processes. However, this mechanism has several limitations, e.g., energy inefficiency, delay, and vulnerable to security threats. To overcome these problems, a new consensus mechanism has been developed recently, namely proof of stake, which enables to achieve the consensus via proving the stake ownership. This mechanism is expected to become a cutting-edge technology for future blockchain networks. This paper is dedicated to investigating proof-of-stake mechanisms, from fundamental knowledge to advanced proof-of-stake-based protocols along with performance analysis, e.g., energy consumption, delay, and security, as well as their promising applications, particularly in the field of Internet of Vehicles. The formation of stake pools and their effects on the network stake distribution are also analyzed and simulated. The results show that the ratio between the block reward and the total network stake has a significant impact on the decentralization of the network. Technical challenges and potential solutions are also discussed.","['Blockchain', 'Cryptography', 'Games', 'Delays', 'Hash functions', 'Distributed databases']","['Blockchain', 'consensus mechanisms', 'energy', 'game theory', 'proof-of-stake', 'proof-of-work', 'security', 'and mining process']"
"In recent years, with the rapid development of Internet technology, online shopping has become a mainstream way for users to purchase and consume. Sentiment analysis of a large number of user reviews on e-commerce platforms can effectively improve user satisfaction. This paper proposes a new sentiment analysis model-SLCABG, which is based on the sentiment lexicon and combines Convolutional Neural Network (CNN) and attention-based Bidirectional Gated Recurrent Unit (BiGRU). In terms of methods, the SLCABG model combines the advantages of sentiment lexicon and deep learning technology, and overcomes the shortcomings of existing sentiment analysis model of product reviews. The SLCABG model combines the advantages of the sentiment lexicon and deep learning techniques. First, the sentiment lexicon is used to enhance the sentiment features in the reviews. Then the CNN and the Gated Recurrent Unit (GRU) network are used to extract the main sentiment features and context features in the reviews and use the attention mechanism to weight. And finally classify the weighted sentiment features. In terms of data, this paper crawls and cleans the real book evaluation of dangdang.com, a famous Chinese e-commerce website, for training and testing, all of which are based on Chinese. The scale of the data has reached 100000 orders of magnitude, which can be widely used in the field of Chinese sentiment analysis. The experimental results show that the model can effectively improve the performance of text sentiment analysis.","['Sentiment analysis', 'Analytical models', 'Feature extraction', 'Deep learning', 'Support vector machines']","['Attention mechanism', 'CNN', 'BiGRU', 'sentiment analysis', 'sentiment lexicon']"
"One of the biggest concerns of big data is privacy. However, the study on big data privacy is still at a very early stage. We believe the forthcoming solutions and theories of big data privacy root from the in place research output of the privacy discipline. Motivated by these factors, we extensively survey the existing research outputs and achievements of the privacy field in both application and theoretical angles, aiming to pave a solid starting ground for interested readers to address the challenges in the big data case. We first present an overview of the battle ground by defining the roles and operations of privacy systems. Second, we review the milestones of the current two major research categories of privacy: data clustering and privacy frameworks. Third, we discuss the effort of privacy study from the perspectives of different disciplines, respectively. Fourth, the mathematical description, measurement, and modeling on privacy are presented. We summarize the challenges and opportunities of this promising topic at the end of this paper, hoping to shed light on the exciting and almost uncharted land.","['Big data', 'Privacy', 'Clustering', 'Differential equations', 'Data privacy', 'Mathematical models']","['Big data', 'privacy', 'data clustering', 'differential privacy']"
"Driven by the demand to accommodate today's growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the ever-increasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications.","['Wireless communication', 'Training', '5G mobile communication', 'Supervised learning', 'Task analysis', 'Reinforcement learning']","['Machine learning', '5G mobile communication', 'B5G', 'wireless communication', 'mobile communication', 'artificial intelligence']"
"A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks. There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method, which we call smart augmentation and we show how to use it to increase the accuracy and reduce over fitting on a target network. Smart augmentation works, by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network. Smart augmentation has shown the potential to increase accuracy by demonstrably significant measures on all data sets tested. In addition, it has shown potential to achieve similar or improved performance levels with significantly smaller network sizes in a number of tested cases.","['Training', 'Biological neural networks', 'Informatics', 'Electronic mail', 'Machine learning', 'Data models']","['Artificial intelligence', 'artificial neural networks', 'machine learning', 'computer vision supervised learning', 'machine learning algorithms', 'image databases']"
"The concept of a digital twin has been used in some industries where an accurate digital model of the equipment can be used for predictive maintenance. The use of a digital twin for performance is critical, and for capital-intensive equipment such as jet engines it proved to be successful in terms of cost savings and reliability improvements. In this paper, we aim to study the expansion of the digital twin in including building life cycle management and explore the benefits and shortcomings of such implementation. In four rounds of experimentation, more than 25,000 sensor reading instances were collected, analyzed, and utilized to create and test a limited digital twin of an office building facade element. This is performed to point out the method of implementation, highlight the benefits gained from digital twin, and to uncover some of the technical shortcomings of the current Internet of Things systems for this purpose.","['Buildings', 'Solid modeling', 'Object oriented modeling', 'Three-dimensional displays', 'Real-time systems']","['Building information modeling', 'digital twin', 'life cycle management', 'Internet of Things', 'wireless sensor network']"
"The Internet of Energy (IoE) provides an effective networking technology for distributed green energy, which allows the connection of energy anywhere at any time. As an important part of the IoE, electric vehicles (EVs), and charging pile management are of great significance to the development of the IoE industry. Previous work has mainly focused on network performance optimization for its management, and few studies have considered the security of the management between EVs and charging piles. Therefore, this paper proposes a decentralized security model based on the lightning network and smart contract in the blockchain ecosystem; this proposed model is called the lightning network and smart contract (LNSC). The overall model involves registration, scheduling, authentication, and charging phases. The new proposed security model can be easily integrated with current scheduling mechanisms to enhance the security of trading between EVs and charging piles. Experimental results according to a realistic infrastructure are presented in this paper. These experimental results demonstrate that our scheme can effectively enhance vehicle security. Different performances of LNSC-based scheduling strategies are also presented.","['Contracts', 'Lightning', 'Charging stations', 'Electric vehicle charging']","['Blockchain', 'smart contract', 'vehicle charging', 'mutual authentication', 'Internet of Energy']"
"Detecting outliers is a significant problem that has been studied in various research and application areas. Researchers continue to design robust schemes to provide solutions to detect outliers efficiently. In this survey, we present a comprehensive and organized review of the progress of outlier detection methods from 2000 to 2019. First, we offer the fundamental concepts of outlier detection and then categorize them into different techniques from diverse outlier detection techniques, such as distance-, clustering-, density-, ensemble-, and learning-based methods. In each category, we introduce some state-of-the-art outlier detection methods and further discuss them in detail in terms of their performance. Second, we delineate their pros, cons, and challenges to provide researchers with a concise overview of each technique and recommend solutions and possible research directions. This paper gives current progress of outlier detection techniques and provides a better understanding of the different outlier detection methods. The open research issues and challenges at the end will provide researchers with a clear path for the future of outlier detection methods.","['Anomaly detection', 'Tools', 'Distributed databases', 'Trajectory', 'Deep learning']","['Outlier detection', 'distance-based', 'clustering-based', 'density-based', 'ensemble-based']"
"Bitcoin has recently attracted considerable attention in the fields of economics, cryptography, and computer science due to its inherent nature of combining encryption technology and monetary units. This paper reveals the effect of Bayesian neural networks (BNNs) by analyzing the time series of Bitcoin process. We also select the most relevant features from Blockchain information that is deeply involved in Bitcoin's supply and demand and use them to train models to improve the predictive performance of the latest Bitcoin pricing process. We conduct the empirical study that compares the Bayesian neural network with other linear and non-linear benchmark models on modeling and predicting the Bitcoin process. Our empirical studies show that BNN performs well in predicting Bitcoin price time series and explaining the high volatility of the recent Bitcoin price.","['Bitcoin', 'Predictive models', 'Neural networks', 'Time series analysis', 'Bayes methods', 'Biological system modeling']","['Bitcoin', 'blockchain', 'Bayesian neural network', 'time-series analysis', 'predictive model']"
"Today, the stability of the electric power grid is maintained through real time balancing of generation and demand. Grid scale energy storage systems are increasingly being deployed to provide grid operators the flexibility needed to maintain this balance. Energy storage also imparts resiliency and robustness to the grid infrastructure. Over the last few years, there has been a significant increase in the deployment of large scale energy storage systems. This growth has been driven by improvements in the cost and performance of energy storage technologies and the need to accommodate distributed generation, as well as incentives and government mandates. Energy management systems (EMSs) and optimization methods are required to effectively and safely utilize energy storage as a flexible grid asset that can provide multiple grid services. The EMS needs to be able to accommodate a variety of use cases and regulatory environments. In this paper, we provide a brief history of grid-scale energy storage, an overview of EMS architectures, and a summary of the leading applications for storage. These serve as a foundation for a discussion of EMS optimization methods and design.","['Energy management', 'Batteries', 'Frequency control', 'Optimization methods', 'Power system stability']","['Energy storage system (ESS)', 'energy management system (EMS)', 'battery energy storage system (BESS)', 'optimization methods', 'optimal control', 'linear programming (LP)', 'mixed integer linear programming (MILP)', 'battery management system (BMS)']"
"Although the Internet of Things (IoT) can increase efficiency and productivity through intelligent and remote management, it also increases the risk of cyber-attacks. The potential threats to IoT applications and the need to reduce risk have recently become an interesting research topic. It is crucial that effective Intrusion Detection Systems (IDSs) tailored to IoT applications be developed. Such IDSs require an updated and representative IoT dataset for training and evaluation. However, there is a lack of benchmark IoT and IIoT datasets for assessing IDSs-enabled IoT systems. This paper addresses this issue and proposes a new data-driven IoT/IIoT dataset with the ground truth that incorporates a label feature indicating normal and attack classes, as well as a type feature indicating the sub-classes of attacks targeting IoT/IIoT applications for multi-classification problems. The proposed dataset, which is named TON_IoT, includes Telemetry data of IoT/IIoT services, as well as Operating Systems logs and Network traffic of IoT network, collected from a realistic representation of a medium-scale network at the Cyber Range and IoT Labs at the UNSW Canberra (Australia). This paper also describes the proposed dataset of the Telemetry data of IoT/IIoT services and their characteristics. TON_IoT has various advantages that are currently lacking in the state-of-the-art datasets: i) it has various normal and attack events for different IoT/IIoT services, and ii) it includes heterogeneous data sources. We evaluated the performance of several popular Machine Learning (ML) methods and a Deep Learning model in both binary and multi-class classification problems for intrusion detection purposes using the proposed Telemetry dataset.","['Intrusion detection', 'Telemetry', 'Sensors', 'Internet of Things', 'Machine learning', 'Australia']","['Internet of Things (IoT)', 'Industrial Internet of Things (IIoT)', 'cybersecurity', 'intrusion detection systems (IDSs)', 'dataset']"
"The impending environmental issues and growing concerns for global energy crises are driving the need for new opportunities and technologies that can meet significantly higher demand for cleaner and sustainable energy systems. This necessitates the development of transportation and power generation systems. The electrification of the transportation system is a promising approach to green the transportation systems and to reduce the issues of climate change. This paper inspects the present status, latest deployment, and challenging issues in the implementation of Electric vehicles (EVs) infrastructural and charging systems in conjunction with several international standards and charging codes. It further analyzes EVs impacts and prospects in society. A complete assessment of charging systems for EVs with battery charging techniques is explained. Moreover, the beneficial and harmful impacts of EVs are categorized and thoroughly reviewed. Remedial measures for harmful impacts are presented and benefits obtained therefrom are highlighted. Bidirectional charging offers the fundamental feature of vehicle to grid technology. In this paper, the current challenging issues due to the massive deployment of EVs, and upcoming research trends are also presented. It is envisioned that the researchers interested in such areas can find this paper valuable and an informative one-stop source.","['Climate change', 'Electric vehicles', 'Batteries', 'Connectors', 'Fossil fuels', 'Power grids']","['Electric vehicles (EVs)', 'international standards', 'infrastructure of charging systems', 'plug-in hybrid electric vehicles (PHEVs)', 'impacts and challenging issues', 'vehicle to gird (V2G) technology']"
"In recent years, food safety issues have drawn growing concerns from society. In order to efficiently detect and prevent food safety problems and trace the accountability, building a reliable traceability system is indispensable. It is especially essential to accurately record, share, and trace the specific data within the whole food supply chain, including the process of production, processing, warehousing, transportation, and retail. The traditional traceability systems have issues, such as data invisibility, tampering, and sensitive information disclosure. The blockchain is a promising technology for the food safety traceability system because of the characteristics, such as the irreversible time vector, smart contract, and consensus algorithm. This paper proposes a food safety traceability system based on the blockchain and the EPC Information Services and develops a prototype system. The management architecture of on-chain & off-chain data is proposed as well, through which the traceability system can alleviate the data explosion issue of the blockchain for the Internet of Things. Furthermore, the enterprise-level smart contract is designed to prevent data tampering and sensitive information disclosure during information interaction among participants. The prototype system was implemented based on the Ethereum. According to the test results, the average time of information query response is around 2 ms, while the amount of on-chain data and query counts are 1 GB and 1000 times/s, respectively.","['Blockchain', 'Supply chains', 'Smart contracts', 'Explosions', 'Supply chain management', 'Prototypes']","['Food safety', 'traceability', 'blockchain', 'EPCIS', 'on-chain & off-chain', 'smart contract']"
"Agriculture plays a vital role in the economic growth of any country. With the increase of population, frequent changes in climatic conditions and limited resources, it becomes a challenging task to fulfil the food requirement of the present population. Precision agriculture also known as smart farming have emerged as an innovative tool to address current challenges in agricultural sustainability. The mechanism that drives this cutting edge technology is machine learning (ML). It gives the machine ability to learn without being explicitly programmed. ML together with IoT (Internet of Things) enabled farm machinery are key components of the next agriculture revolution. In this article, authors present a systematic review of ML applications in the field of agriculture. The areas that are focused are prediction of soil parameters such as organic carbon and moisture content, crop yield prediction, disease and weed detection in crops and species detection. ML with computer vision are reviewed for the classification of a different set of crop images in order to monitor the crop quality and yield assessment. This approach can be integrated for enhanced livestock production by predicting fertility patterns, diagnosing eating disorders, cattle behaviour based on ML models using data collected by collar sensors, etc. Intelligent irrigation which includes drip irrigation and intelligent harvesting techniques are also reviewed that reduces human labour to a great extent. This article demonstrates how knowledge-based agriculture can improve the sustainable productivity and quality of the product.","['Agriculture', 'Artificial intelligence', 'Internet of Things', 'Irrigation', 'Wireless sensor networks', 'Soil', 'Sensors']","['Agricultural engineering', 'machine learning', 'intelligent irrigation', 'IoT', 'prediction']"
"Fog computing is an architectural style in which network components between devices and the cloud execute application-specific logic. We present the first review on fog computing within healthcare informatics, and explore, classify, and discuss different application use cases presented in the literature. For that, we categorize applications into use case classes and list an inventory of application-specific tasks that can be handled by fog computing. We discuss on which level of the network such fog computing tasks can be executed, and provide tradeoffs with respect to requirements relevant to healthcare. Our review indicates that: 1) there is a significant number of computing tasks in healthcare that require or can benefit from fog computing principles; 2) processing on higher network tiers is required due to constraints in wireless devices and the need to aggregate data; and 3) privacy concerns and dependability prevent computation tasks to be completely moved to the cloud. These findings substantiate the need for a coherent approach toward fog computing in healthcare, for which we present a list of recommended research and development actions.","['Edge computing', 'Medical services', 'Wireless sensor networks', 'Cloud computing', 'Computer architecture', 'Wireless communication', 'Monitoring']","['Body sensor networks', 'fog computing', 'healthcare', 'health information management', 'internet of things', 'sensor devices', 'wireless sensor networks']"
"Multi-modality image fusion provides more comprehensive and sophisticated information in modern medical diagnosis, remote sensing, video surveillance, and so on. This paper presents a novel multi-modality medical image fusion method based on phase congruency and local Laplacian energy. In the proposed method, the non-subsampled contourlet transform is performed on medical image pairs to decompose the source images into high-pass and low-pass subbands. The high-pass subbands are integrated by a phase congruency-based fusion rule that can enhance the detailed features of the fused image for medical diagnosis. A local Laplacian energy-based fusion rule is proposed for low-pass subbands. The local Laplacian energy consists of weighted local energy and the weighted sum of Laplacian coefficients that describe the structured information and the detailed features of source image pairs, respectively. Thus, the proposed fusion rule can simultaneously integrate two key components for the fusion of low-pass subbands. The fused high-pass and low-pass subbands are inversely transformed to obtain the fused image. In the comparative experiments, three categories of multi-modality medical image pairs are used to verify the effectiveness of the proposed method. The experiment results show that the proposed method achieves competitive performance in both the image quantity and computational costs.","['Image fusion', 'Transforms', 'Laplace equations', 'Medical diagnostic imaging', 'Feature extraction', 'Medical diagnosis']","['Medical image fusion', 'multi-modality sensor fusion', 'NSCT', 'phase congruency', 'Laplacian energy']"
"The potential of blockchain has been extensively discussed in the literature and media mainly in finance and payment industry. One relatively recent trend is at the enterprise-level, where blockchain serves as the infrastructure for internet security and immutability. Emerging application domains include Industry 4.0 and Industrial Internet of Things (IIoT). Therefore, in this paper, we comprehensively review existing blockchain applications in Industry 4.0 and IIoT settings. Specifically, we present the current research trends in each of the related industrial sectors, as well as successful commercial implementations of blockchain in these relevant sectors. We also discuss industry-specific challenges for the implementation of blockchain in each sector. Further, we present currently open issues in the adoption of the blockchain technology in Industry 4.0 and discuss newer application areas. We hope that our findings pave the way for empowering and facilitating research in this domain, and assist decision-makers in their blockchain adoption and investment in Industry 4.0 and IIoT space.","['Industries', 'Medical services', 'Peer-to-peer computing', 'Internet of Things', 'Contracts', 'Production']","['Internet of Things', 'industry 40', 'industrial IoT', 'blockchain', 'smart contracts']"
"Approximate message passing (AMP) is a low-cost iterative signal recovery algorithm for linear system models. When the system transform matrix has independent identically distributed (IID) Gaussian entries, the performance of AMP can be asymptotically characterized by a simple scalar recursion called state evolution (SE). However, SE may become unreliable for other matrix ensembles, especially for ill-conditioned ones. This imposes limits on the applications of AMP. In this paper, we propose an orthogonal AMP (OAMP) algorithm based on de-correlated linear estimation (LE) and divergence-free non-linear estimation (NLE). The Onsager term in standard AMP vanishes as a result of the divergence-free constraint on NLE. We develop an SE procedure for OAMP and show numerically that the SE for OAMP is accurate for general unitarily-invariant matrices, including IID Gaussian matrices and partial orthogonal matrices. We further derive optimized options for OAMP and show that the corresponding SE fixed point coincides with the optimal performance obtained via the replica method. Our numerical results demonstrate that OAMP can be advantageous over AMP, especially for ill-conditioned matrices.","['Discrete cosine transforms', 'Estimation', 'Message passing', 'Algorithm design and analysis', 'Sparse matrices', 'Gaussian processes', 'Orthogonal matrices']","['Compressed sensing', 'approximate message passing (AMP)', 'replica method', 'state evolution', 'unitarily-invariant', 'IID Gaussian', 'partial orthogonal matrix']"
"With the accelerated development of Internet-of-Things (IoT), wireless sensor networks (WSNs) are gaining importance in the continued advancement of information and communication technologies, and have been connected and integrated with the Internet in vast industrial applications. However, given the fact that most wireless sensor devices are resource constrained and operate on batteries, the communication overhead and power consumption are therefore important issues for WSNs design. In order to efficiently manage these wireless sensor devices in a unified manner, the industrial authorities should be able to provide a network infrastructure supporting various WSN applications and services that facilitate the management of sensor-equipped real-world entities. This paper presents an overview of industrial ecosystem, technical architecture, industrial device management standards, and our latest research activity in developing a WSN management system. The key approach to enable efficient and reliable management of WSN within such an infrastructure is a cross-layer design of lightweight and cloud-based RESTful Web service.","['Urban areas', 'Wireless sensor networks', 'Monitoring', 'Industries', 'Standards', 'Security', 'Transportation']","['Internet-of-Things', 'device management', 'IEEE 802.15.4', 'RESTful', 'error correction coding (ECC)', 'cloud']"
"This paper presents the latest progress on cloud RAN (C-RAN) in the areas of centralization and virtualization. A C-RAN system centralizes the baseband processing resources into a pool and virtualizes soft base-band units on demand. The major challenges for C-RAN including front-haul and virtualization are analyzed with potential solutions proposed. Extensive field trials verify the viability of various front-haul solutions, including common public radio interface compression, single fiber bidirection and wavelength-division multiplexing. In addition, C-RANs facilitation of coordinated multipoint (CoMP) implementation is demonstrated with 50%-100% uplink CoMP gain observed in field trials. Finally, a test bed is established based on general purpose platform with assisted accelerators. It is demonstrated that this test bed can support multi-RAT, i.e., Time-Division Duplexing Long Term Evolution, Frequency-Division Duplexing Long Term Evolution, and Global System for Mobile Communications efficiently and presents similar performance to traditional systems.","['Optical fiber networks', 'Wavelength division multiplexing', 'Virtualization', 'Optical fiber devices', 'Radio access networks', 'Optical fiber testing', 'Mobile communication']","['C-RAN', 'CoMP', 'virtualization', 'cloud', 'front-haul']"
"Fog computing, an extension of cloud computing services to the edge of the network to decrease latency and network congestion, is a relatively recent research trend. Although both cloud and fog offer similar resources and services, the latter is characterized by low latency with a wider spread and geographically distributed nodes to support mobility and real-time interaction. In this paper, we describe the fog computing architecture and review its different services and applications. We then discuss security and privacy issues in fog computing, focusing on service and resource availability. Virtualization is a vital technology in both fog and cloud computing that enables virtual machines (VMs) to coexist in a physical server (host) to share resources. These VMs could be subject to malicious attacks or the physical server hosting it could experience system failure, both of which result in unavailability of services and resources. Therefore, a conceptual smart pre-copy live migration approach is presented for VM migration. Using this approach, we can estimate the downtime after each iteration to determine whether to proceed to the stop-and-copy stage during a system failure or an attack on a fog computing node. This will minimize both the downtime and the migration time to guarantee resource and service availability to the end users of fog computing. Last, future research directions are outlined.","['Edge computing', 'Cloud computing', 'Computer architecture', 'Real-time systems', 'Wireless sensor networks', 'Servers', 'Sensors']","['Cloud computing', 'edge computing', 'fog computing', 'live VM migration framework', 'virtualization']"
"Research on machine assisted text analysis follows the rapid development of digital media, and sentiment analysis is among the prevalent applications. Traditional sentiment analysis methods require complex feature engineering, and embedding representations have dominated leaderboards for a long time. However, the context-independent nature limits their representative power in rich context, hurting performance in Natural Language Processing (NLP) tasks. Bidirectional Encoder Representations from Transformers (BERT), among other pre-trained language models, beats existing best results in eleven NLP tasks (including sentence-level sentiment classification) by a large margin, which makes it the new baseline of text representation. As a more challenging task, fewer applications of BERT have been observed for sentiment classification at the aspect level. We implement three target-dependent variations of the BERT base model, with positioned output at the target terms and an optional sentence with the target built in. Experiments on three data collections show that our TD-BERT model achieves new state-of-the-art performance, in comparison to traditional feature engineering methods, embedding-based models and earlier applications of BERT. With the successful application of BERT in many NLP tasks, our experiments try to verify if its context-aware representation can achieve similar performance improvement in aspect-based sentiment analysis. Surprisingly, coupling it with complex neural networks that used to work well with embedding representations does not show much value, sometimes with performance below the vanilla BERT-FC implementation. On the other hand, incorporation of target information shows stable accuracy improvement, and the most effective way of utilizing that information is displayed through the experiment.","['Bit error rate', 'Task analysis', 'Neural networks', 'Sentiment analysis', 'Context modeling', 'Media']","['Deep learning', 'neural networks', 'sentiment analysis', 'BERT']"
"This paper presents end-to-end learning from spectrum data-an umbrella term for new sophisticated wireless signal identification approaches in spectrum monitoring applications based on deep neural networks. End-to-end learning allows to: 1) automatically learn features directly from simple wireless signal representations, without requiring design of hand-crafted expert features like higher order cyclic moments and 2) train wireless signal classifiers in one end-to-end step which eliminates the need for complex multi-stage machine learning processing pipelines. The purpose of this paper is to present the conceptual framework of end-to-end learning for spectrum monitoring and systematically introduce a generic methodology to easily design and implement wireless signal classifiers. Furthermore, we investigate the importance of the choice of wireless data representation to various spectrum monitoring tasks. In particular, two case studies are elaborated: 1) modulation recognition and 2) wireless technology interference detection. For each case study three convolutional neural networks are evaluated for the following wireless signal representations: temporal IQ data, the amplitude/phase representation, and the frequency domain representation. From our analysis, we prove that the wireless data representation impacts the accuracy depending on the specifics and similarities of the wireless signals that need to be differentiated, with different data representations resulting in accuracy variations of up to 29%. Experimental results show that using the amplitude/phase representation for recognizing modulation formats can lead to performance improvements up to 2% and 12% for medium to high SNR compared to IQ and frequency domain data, respectively. For the task of detecting interference, frequency domain representation outperformed amplitude/phase and IQ data representation up to 20%.","['Wireless communication', 'Wireless sensor networks', 'Monitoring', 'Machine learning', 'Interference', 'Modulation', 'Pipelines']","['Big spectrum data', 'spectrum monitoring', 'end-to-end learning', 'deep learning', 'convolutional neural networks', 'wireless signal identification', 'IoT']"
"We demonstrate use of iteratively pruned deep learning model ensembles for detecting pulmonary manifestations of COVID-19 with chest X-rays. This disease is caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom convolutional neural network and a selection of ImageNet pretrained models are trained and evaluated at patient-level on publicly available CXR collections to learn modality-specific feature representations. The learned knowledge is transferred and fine-tuned to improve performance and generalization in the related task of classifying CXRs as normal, showing bacterial pneumonia, or COVID-19-viral abnormalities. The best performing models are iteratively pruned to reduce complexity and improve memory efficiency. The predictions of the best-performing pruned models are combined through different ensemble strategies to improve classification performance. Empirical evaluations demonstrate that the weighted average of the best-performing pruned models significantly improves performance resulting in an accuracy of 99.01% and area under the curve of 0.9972 in detecting COVID-19 findings on CXRs. The combined use of modality-specific knowledge transfer, iterative model pruning, and ensemble learning resulted in improved predictions. We expect that this model can be quickly adopted for COVID-19 screening using chest radiographs.","['Lung', 'COVID-19', 'Microorganisms', 'Computational modeling', 'National Institutes of Health', 'Predictive models']","['COVID-19', 'convolutional neural network', 'deep learning', 'ensemble', 'iterative pruning']"
"Nowadays synthetic aperture radar (SAR) and multiple-input-multiple-output (MIMO) antenna systems with the capability to radiate waves in more than one pattern and polarization are playing a key role in modern telecommunication and radar systems. This is possible with the use of antenna arrays as they offer advantages of high gain and beamforming capability, which can be utilized for controlling radiation pattern for electromagnetic (EM) interference immunity in wireless systems. However, with the growing demand for compact array antennas, the physical footprint of the arrays needs to be smaller and the consequent of this is severe degradation in the performance of the array resulting from strong mutual-coupling and crosstalk effects between adjacent radiating elements. This review presents a detailed systematic and theoretical study of various mutual-coupling suppression (decoupling) techniques with a strong focus on metamaterial (MTM) and metasurface (MTS) approaches. While the performance of systems employing antenna arrays can be enhanced by calibrating out the interferences digitally, however it is more efficient to apply decoupling techniques at the antenna itself. Previously various simple and cost-effective approaches have been demonstrated to effectively suppress unwanted mutual-coupling in arrays. Such techniques include the use of defected ground structure (DGS), parasitic or slot element, dielectric resonator antenna (DRA), complementary split-ring resonators (CSRR), decoupling networks, P.I.N or varactor diodes, electromagnetic bandgap (EBG) structures, etc. In this review, it is shown that the mutual-coupling reduction methods inspired By MTM and MTS concepts can provide a higher level of isolation between neighbouring radiating elements using easily realizable and cost-effective decoupling configurations that have negligible consequence on the array's characteristics such as bandwidth, gain and radiation efficiency, and physical footprint.","['Antenna arrays', 'MIMO communication', 'Mutual coupling', 'Synthetic aperture radar', 'Metamaterials']","['Decoupling methods', 'metamaterial (MTM)', 'metasurface (MTS)', 'multiple-input-multiple-output (MIMO)', 'synthetic aperture radar (SAR)', 'isolation enhancement', 'array antennas']"
"Providing reliable broadband wireless communications in high mobility environments, such as high-speed railway systems, remains one of the main challenges faced by the development of the next generation wireless systems. This paper provides a systematic review of high mobility communications. We first summarize a list of key challenges and opportunities in high mobility communication systems, then provide comprehensive reviews of techniques that can address these challenges and utilize the unique opportunities. The review covers a wide spectrum of communication operations, including the accurate modeling of high mobility channels, the transceiver structures that can exploit the properties of high mobility environments, the signal processing techniques that can harvest the benefits (e.g., Doppler diversity) and mitigate the impairments (e.g., carrier frequency offset, intercarrier interference, channel estimation errors) in high mobility systems, and the mobility management and network architectures that are designed specifically for high mobility systems. The survey focuses primarily on physical layer operations, which are affected the most by the mobile environment, with some additional discussions on higher layer operations, such as handover management and control-plane/user-plane decoupling, which are essential to high mobility operations. Future research directions on high mobility communications are summarized at the end of this paper.","['Doppler effect', 'Handover', 'Fading channels', 'OFDM', 'Wireless communication', 'Channel estimation', 'Mobility management']","['High mobility communications', 'fast time-varying fading', 'CFO', 'ICI', 'Doppler diversity', 'mobility management']"
"Internet of Things (IoT) connects sensing devices to the Internet for the purpose of exchanging information. Location information is one of the most crucial pieces of information required to achieve intelligent and context-aware IoT systems. Recently, positioning and localization functions have been realized in a large amount of IoT systems. However, security and privacy threats related to positioning in IoT have not been sufficiently addressed so far. In this paper, we survey solutions for improving the robustness, security, and privacy of location-based services in IoT systems. First, we provide an in-depth evaluation of the threats and solutions related to both global navigation satellite system (GNSS) and non-GNSS-based solutions. Second, we describe certain cryptographic solutions for security and privacy of positioning and location-based services in IoT. Finally, we discuss the state-of-the-art of policy regulations regarding security of positioning solutions and legal instruments to location data privacy in detail. This survey paper addresses a broad range of security and privacy aspects in IoT-based positioning and localization from both technical and legal points of view and aims to give insight and recommendations for future IoT systems providing more robust, secure, and privacy-preserving location-based services.","['Security', 'Robustness', 'Satellites', 'Receivers', 'Privacy', 'Law', 'Terrestrial atmosphere']","['Positioning', 'wireless localization', 'navigation', 'Internet of Things', 'GNSS', 'vulnerabilities', 'security', 'privacy', 'cryptography', 'trustworthiness', 'literature study']"
"Smart cities contain intelligent things which can intelligently automatically and collaboratively enhance life quality, save people's lives, and act a sustainable resource ecosystem. To achieve these advanced collaborative technologies such as drones, robotics, artificial intelligence, and Internet of Things (IoT) are required to increase the smartness of smart cities by improving the connectivity, energy efficiency, and quality of services (QoS). Therefore, collaborative drones and IoT play a vital role in supporting a lot of smart-city applications such as those involved in communication, transportation, agriculture,safety and security, disaster mitigation, environmental protection, service delivery, energy saving, e-waste reduction, weather monitoring, healthcare, etc. This paper presents a survey of the potential techniques and applications of collaborative drones and IoT which have recently been proposed in order to increase the smartness of smart cities. It provides a comprehensive overview highlighting the recent and ongoing research on collaborative drone and IoT in improving the real-time application of smart cities. This survey is different from previous ones in term of breadth, scope, and focus. In particular, we focus on the new concept of collaborative drones and IoT for improving smart-city applications. This survey attempts to show how collaborative drones and IoT improve the smartness of smart cities based on data collection, privacy and security, public safety, disaster management, energy consumption and quality of life in smart cities. It mainly focuses on the measurement of the smartness of smart cities, i.e., environmental aspects, life quality, public safety, and disaster management.","['Drones', 'Smart cities', 'Internet of Things', 'Collaboration', 'Monitoring', 'Safety', 'Security']","['ICT', 'smart city', 'energy consumption', 'smart drone', 'IoT', 'pollutions', 'gathering data', 'IoD', 'disaster', 'public safety', 'security and privacy', 'collaborative drone', 'IoT']"
"Deep learning is a branch of artificial intelligence. In recent years, with the advantages of automatic learning and feature extraction, it has been widely concerned by academic and industrial circles. It has been widely used in image and video processing, voice processing, and natural language processing. At the same time, it has also become a research hotspot in the field of agricultural plant protection, such as plant disease recognition and pest range assessment, etc. The application of deep learning in plant disease recognition can avoid the disadvantages caused by artificial selection of disease spot features, make plant disease feature extraction more objective, and improve the research efficiency and technology transformation speed. This review provides the research progress of deep learning technology in the field of crop leaf disease identification in recent years. In this paper, we present the current trends and challenges for the detection of plant leaf disease using deep learning and advanced imaging techniques. We hope that this work will be a valuable resource for researchers who study the detection of plant diseases and insect pests. At the same time, we also discussed some of the current challenges and problems that need to be resolved.","['Diseases', 'Deep learning', 'Feature extraction', 'Image recognition', 'Plants (biology)', 'Agriculture', 'Image color analysis']","['Deep learning', 'plant leaf disease detection', 'visualization', 'small sample', 'hyperspectral imaging']"
"Motor bearing is subjected to the joint effects of much more loads, transmissions, and shocks that cause bearing fault and machinery breakdown. A vibration signal analysis method is the most popular technique that is used to monitor and diagnose the fault of motor bearing. However, the application of the vibration signal analysis method for motor bearing is very limited in engineering practice. In this paper, on the basis of comparing fault feature extraction by using empirical wavelet transform (EWT) and Hilbert transform with the theoretical calculation, a new motor bearing fault diagnosis method based on integrating EWT, fuzzy entropy, and support vector machine (SVM) called EWTFSFD is proposed. In the proposed method, a novel signal processing method called EWT is used to decompose vibration signal into multiple components in order to extract a series of amplitude modulated-frequency modulated (AM-FM) components with supporting Fourier spectrum under an orthogonal basis. Then, fuzzy entropy is utilized to measure the complexity of vibration signal, reflect the complexity changes of intrinsic oscillation, and compute the fuzzy entropy values of AM-FM components, which are regarded as the inputs of the SVM model to train and construct an SVM classifier for fulfilling fault pattern recognition. Finally, the effectiveness of the proposed method is validated by using the simulated signal and real motor bearing vibration signals. The experiment results show that the EWT outperforms empirical mode decomposition for decomposing the signal into multiple components, and the proposed EWTFSFD method can accurately and effectively achieve the fault diagnosis of motor bearing.","['Fault diagnosis', 'Wavelet transforms', 'Entropy', 'Vibrations', 'Feature extraction', 'Support vector machines']","['Motor bearing', 'fault diagnosis', 'empirical wavelet transform', 'fuzzy entropy', 'support vector machine', 'Fourier spectrum segmentation', 'AM-FM components']"
"Fifth-generation (5G) cellular networks will almost certainly operate in the high-bandwidth, underutilized millimeter-wave (mmWave) frequency spectrum, which offers the potentiality of high-capacity wireless transmission of multi-gigabit-per-second (Gbps) data rates. Despite the enormous available bandwidth potential, mmWave signal transmissions suffer from fundamental technical challenges like severe path loss, sensitivity to blockage, directivity, and narrow beamwidth, due to its short wavelengths. To effectively support system design and deployment, accurate channel modeling comprising several 5G technologies and scenarios is essential. This survey provides a comprehensive overview of several emerging technologies for 5G systems, such as massive multiple-input multiple-output (MIMO) technologies, multiple access technologies, hybrid analog-digital precoding and combining, non-orthogonal multiple access (NOMA), cell-free massive MIMO, and simultaneous wireless information and power transfer (SWIPT) technologies. These technologies induce distinct propagation characteristics and establish specific requirements on 5G channel modeling. To tackle these challenges, we first provide a survey of existing solutions and standards and discuss the radio-frequency (RF) spectrum and regulatory issues for mmWave communications. Second, we compared existing wireless communication techniques like sub-6-GHz WiFi and sub-6 GHz 4G LTE over mmWave communications which come with benefits comprising narrow beam, high signal quality, large capacity data transmission, and strong detection potential. Third, we describe the fundamental propagation characteristics of the mmWave band and survey the existing channel models for mmWave communications. Fourth, we track evolution and advancements in hybrid beamforming for massive MIMO systems in terms of system models of hybrid precoding architectures, hybrid analog and digital precoding/combining matrices, with the potential antenna configuration scenarios and mmWave channel estimation (CE) techniques. Fifth, we extend the scope of the discussion by including multiple access technologies for mmWave systems such as non-orthogonal multiple access (NOMA) and space-division multiple access (SDMA), with limited RF chains at the base station. Lastly, we explore the integration of SWIPT in mmWave massive MIMO systems, with limited RF chains, to realize spectrally and energy-efficient communications.","['5G mobile communication', 'Millimeter wave communication', 'NOMA', 'MIMO communication', 'Wireless communication', 'Precoding', 'Radio frequency']","['Millimeter wave communications', 'propagation', 'channel measurements', 'channel models', 'MIMO', 'hybrid precoding', 'non-orthogonal multiple access (NOMA)', 'multiple access techniques', 'simultaneous wireless information and power transfer (SWIPT)', 'RF energy harvesting']"
"With the development of wireless communication technology, the need for bandwidth is increasing continuously, and the growing need makes wireless spectrum resources more and more scarce. Cognitive radio (CR) has been identified as a promising solution for the spectrum scarcity, and its core idea is the dynamic spectrum access. It can dynamically utilize the idle spectrum without affecting the rights of primary users, so that multiple services or users can share a part of the spectrum, thus achieving the goal of avoiding the high cost of spectrum resetting and improving the utilization of spectrum resources. In order to meet the critical requirements of the fifth generation (5G) mobile network, especially the Wider-Coverage , Massive-Capacity , Massive-Connectivity , and Low-Latency four application scenarios, the spectrum range used in 5G will be further expanded into the full spectrum era, possibly from 1 GHz to 100 GHz. In this paper, we conduct a comprehensive survey of CR technology and focus on the current significant research progress in the full spectrum sharing towards the four scenarios. In addition, the key enabling technologies that may be closely related to the study of 5G in the near future are presented in terms of full-duplex spectrum sensing, spectrum-database based spectrum sensing, auction based spectrum allocation, carrier aggregation based spectrum access. Subsequently, other issues that play a positive role for the development research and practical application of CR, such as common control channel, energy harvesting, non-orthogonal multiple access, and CR based aeronautical communication are discussed. The comprehensive overview provided by this survey is expected to help researchers develop CR technology in the field of 5G further.","['5G mobile communication', 'Sensors', 'Resource management', 'Internet', 'Cognitive radio']","['5G', 'cognitive radio', 'spectrum sharing', 'full-duplex spectrum sensing', 'carrier aggregation', 'energy harvesting']"
"A compact, high performance, and novel-shaped ultra-wideband (UWB) multiple-input multiple-output (MIMO) antenna with low mutual coupling is presented in this paper. The proposed antenna consists of two radiating elements with shared ground plane having an area of 50 x 30 mm 2 . F-shaped stubs are introduced in the shared ground plane of the proposed antenna to produce high isolation between the MIMO antenna elements. The designed MIMO antenna has very low mutual coupling of (S 21 <; -20 dB), low envelop correlation coefficient (ECC <; 0.04), high diversity gain (DG > 7.4 dB), high multiplexing efficiency (η Mux > -3.5), and high peak gain over the entire UWB frequencies. The antenna performance is studied in terms of S-Parameters, radiation properties, peak gain, diversity gain, envelop correlation coefficient, and multiplexing efficiency. A good agreement between the simulated and measured results is observed.","['MIMO communication', 'Mutual coupling', 'Ultra wideband antennas', 'Antenna measurements', 'Diversity methods', 'Multiplexing']","['MIMO antenna', 'diversity gain', 'multiplexing efficiency', 'microstrip patch']"
"Photovoltaic power generation forecasting is an important topic in the field of sustainable power system design, energy conversion management, and smart grid construction. Difficulties arise while the generated PV power is usually unstable due to the variability of solar irradiance, temperature, and other meteorological factors. In this paper, a hybrid ensemble deep learning framework is proposed to forecast short-term photovoltaic power generation in a time series manner. Two LSTM neural networks are employed working on temperature and power outputs forecasting, respectively. The forecasting results are flattened and combined with a fully connected layer to enhance forecasting accuracy. Moreover, we adopted the attention mechanism for the two LSTM neural networks to adaptively focus on input features that are more significant in forecasting. Comprehensive experiments are conducted with recently collected real-world photovoltaic power generation datasets. Three error metrics were adopted to compare the forecasting results produced by attention LSTM model with state-of-art methods, including the persistent model, the auto-regressive integrated moving average model with exogenous variable (ARIMAX), multi-layer perceptron (MLP), and the traditional LSTM model in all four seasons and various forecasting horizons to show the effectiveness and robustness of the proposed method.","['Forecasting', 'Predictive models', 'Logic gates', 'Power generation', 'Time series analysis', 'Neural networks', 'Deep learning']","['PV power generation', 'short-term forecasting', 'long short term memory', 'attention mechanism']"
"Since the early 1990s, a large number of chaos-based communication systems have been proposed exploiting the properties of chaotic waveforms. The motivation lies in the significant advantages provided by this class of non-linear signals. For this aim, many communication schemes and applications have been specially designed for chaos-based communication systems where energy, data rate, and synchronization awareness are considered in most designs. Recently, the major focus, however, has been given to the non-coherent chaos-based systems to benefit from the advantages of chaotic signals and non-coherent detection and to avoid the use of chaotic synchronization, which suffers from weak performance in the presence of additive noise. This paper presents a comprehensive survey of the entire wireless radio frequency chaos-based communication systems. First, it outlines the challenges of chaos implementations and synchronization methods, followed by comprehensive literature review and analysis of chaos-based coherent techniques and their applications. In the second part of the survey, we offer a taxonomy of the current literature by focusing on non-coherent detection methods. For each modulation class, this paper categorizes different transmission techniques by elaborating on its modulation, receiver type, data rate, complexity, energy efficiency, multiple access scheme, and performance. In addition, this survey reports on the analysis of tradeoff between different chaos-based communication systems. Finally, several concluding remarks are discussed.","['Chaotic communication', 'Synchronization', 'Coherent systems', 'Telecommunication services', 'Performance evaluation', 'Additive noise', 'Noise measurement', 'Nonlinear systems', 'Modulation']","['Chaos-based communication systems', 'chaos implementation', 'chaotic synchronization', 'coherent systems', 'noncoherent systems', 'applications', 'performance analysis']"
"An Internet of Vehicles (IoV) allows forming a self-organized network and broadcasting messages for the vehicles on roads. However, as the data are transmitted in an insecure network, it is essential to use an authentication mechanism to protect the privacy of vehicle users. Recently, Ying et al. proposed an authentication protocol for IoV and claimed that the protocol could resist various attacks. Unfortunately, we discovered that their protocol suffered from an offline identity guessing attack, location spoofing attack, and replay attack, and consumed a considerable amount of time for authentication. To resolve these shortcomings, we propose an improved protocol. In addition, we provide a formal proof to the proposed protocol to demonstrate that our protocol is indeed secure. Compared with previous methods, the proposed protocol performs better in terms of security and performance.","['Protocols', 'Authentication', 'Vehicular ad hoc networks', 'Smart cards', 'Cloud computing', 'Privacy']","['Internet of Vehicles', 'authentication', 'anonymity', 'smart card']"
"Internet of Things (IoT) is an emerging concept, which aims to connect billions of devices with each other. The IoT devices sense, collect, and transmit important information from their surroundings. This exchange of very large amount of information amongst billions of devices creates a massive energy need. Green IoT envisions the concept of reducing the energy consumption of IoT devices and making the environment safe. Inspired by achieving a sustainable environment for IoT, we first give the overview of green IoT and the challenges that are faced due to excessive usage of energy hungry IoT devices. We then discuss and evaluate the strategies that can be used to minimize the energy consumption in IoT, such as designing energy efficient datacenters, energy efficient transmission of data from sensors, and design of energy efficient policies. Moreover, we critically analyze the green IoT strategies and propose five principles that can be adopted to achieve green IoT. Finally, we consider a case study of very important aspect of IoT, i.e., smart phones and we provide an easy and concise view for improving the current practices to make the IoT greener for the world in 2020 and beyond.","['Green products', 'Air pollution', 'Energy efficiency', 'Radiofrequency identification', 'Internet', 'Energy consumption']","['Internet of things', 'green IoT', 'datacenter', 'green computing', 'smart phones']"
"In recent years, the emergence of blockchain technology (BT) has become a unique, most disruptive, and trending technology. The decentralized database in BT emphasizes data security and privacy. Also, the consensus mechanism in it makes sure that data is secured and legitimate. Still, it raises new security issues such as majority attack and double-spending. To handle the aforementioned issues, data analytics is required on blockchain based secure data. Analytics on these data raises the importance of arisen technology Machine Learning (ML). ML involves the rational amount of data to make precise decisions. Data reliability and its sharing are very crucial in ML to improve the accuracy of results. The combination of these two technologies (ML and BT) can provide highly precise results. In this paper, we present a detailed study on ML adoption for making BT-based smart applications more resilient against attacks. There are various traditional ML techniques, for instance, Support Vector Machines (SVM), clustering, bagging, and Deep Learning (DL) algorithms such as Convolutional Neural Network (CNN) and Long short-term memory (LSTM) can be used to analyse the attacks on a blockchain-based network. Further, we include how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities. Then, future research issues and challenges are explored. At last, a case study is presented with a conclusion.","['Blockchain', 'Security', 'Machine learning', 'Taxonomy', 'Databases', 'Prediction algorithms', 'Malware']","['Blockchain', 'machine learning', 'smart grid', 'data security and privacy', 'data analytics', 'smart applications']"
"Brain cancer classification is an important step that depends on the physician's knowledge and experience. An automated tumor classification system is very essential to support radiologists and physicians to identify brain tumors. However, the accuracy of current systems needs to be improved for suitable treatments. In this paper, we propose a hybrid feature extraction method with a regularized extreme learning machine (RELM) for developing an accurate brain tumor classification approach. The approach starts by preprocessing the brain images by using a min-max normalization rule to enhance the contrast of brain edges and regions. Then, the brain tumor features are extracted based on a hybrid method of feature extraction. Finally, a RELM is used for classifying the type of brain tumor. To evaluate and compare the proposed approach, a set of experiments is conducted on a new public dataset of brain images. The experimental results proved that the approach is more effective compared with the existing state-of-the-art approaches, and the performance in terms of classification accuracy improved from 91.51% to 94.233% for the experiment of the random holdout technique.","['Feature extraction', 'Tumors', 'Brain', 'Image segmentation', 'Gabor filters', 'Principal component analysis', 'Training']","['Brain tumor classification', 'hybrid feature extraction', 'NGIST features', 'PCA', 'regularized extreme learning machine']"
"Forecasting of fast fluctuated and high-frequency financial data is always a challenging problem in the field of economics and modelling. In this study, a novel hybrid model with the strength of fractional order derivative is presented with their dynamical features of deep learning, long-short term memory (LSTM) networks, to predict the abrupt stochastic variation of the financial market. Stock market prices are dynamic, highly sensitive, nonlinear and chaotic. There are different techniques for forecast prices in the time-variant domain and due to variability and uncertain behavior in stock prices, traditional methods, such as data mining, statistical approaches, and non-deep neural networks models are not suited for prediction and generalized forecasting stock prices. While autoregressive fractional integrated moving average (ARFIMA) model provides a flexible tool for classes of long-memory models. The advancement of machine learning-based deep non-linear modelling confirms that the hybrid model efficiently extracts profound features and model non-linear functions. LSTM networks are a special kind of recurrent neural network (RNN) that map sequences of input observations to output observations with capabilities of long-term dependencies. A novel ARFIMA-LSTM hybrid recurrent network is presented in which ARFIMA model-based filters having the linear tendencies better than ARIMA model in the data and passes the residual to the LSTM model that captures nonlinearity in the residual values with the help of exogenous dependent variables. The model not only minimizes the volatility problem but also overcome the over fitting problem of neural networks. The model is evaluated using PSX company data of the stock market based on RMSE, MSE and MAPE along with a comparison of ARIMA, LSTM model and generalized regression radial basis neural network (GRNN) ensemble method independently. The forecasting performance indicates the effectiveness of the proposed AFRIMA-LSTM hybrid model to improve around 80% accuracy on RMSE as compared to traditional forecasting counterparts.","['Data models', 'Predictive models', 'Forecasting', 'Time series analysis', 'Neural networks', 'Stock markets', 'Mathematical model']","['ARIMA model', 'ARFIMA model', 'GARCH model', 'RNN', 'LSTM model', 'RMSE', 'MSE', 'MAPE']"
"Contrastive Learning has recently received interest due to its success in self-supervised representation learning in the computer vision domain. However, the origins of Contrastive Learning date as far back as the 1990s and its development has spanned across many fields and domains including Metric Learning and natural language processing. In this paper, we provide a comprehensive literature review and we propose a general Contrastive Representation Learning framework that simplifies and unifies many different contrastive learning methods. We also provide a taxonomy for each of the components of contrastive learning in order to summarise it and distinguish it from other forms of machine learning. We then discuss the inductive biases which are present in any contrastive learning system and we analyse our framework under different views from various sub-fields of Machine Learning. Examples of how contrastive learning has been applied in computer vision, natural language processing, audio processing, and others, as well as in Reinforcement Learning are also presented. Finally, we discuss the challenges and some of the most promising future research directions ahead.","['Task analysis', 'Feature extraction', 'Computational modeling', 'Data models', 'Machine learning', 'Learning systems', 'Natural language processing']","['Contrastive learning', 'representation learning', 'self-supervised learning', 'unsupervised learning', 'deep learning', 'machine learning']"
"Electroencephalogram (EEG) comprises valuable details related to the different physiological state of the brain. In this paper, a framework is offered for detecting the epileptic seizures from EEG data recorded from normal subjects and epileptic patients. This framework is based on a discrete wavelet transform (DWT) analysis of EEG signals using linear and nonlinear classifiers. The performance of the 14 different combinations of two-class epilepsy detection is studied using naïve Bayes (NB) and k-nearest neighbor (k-NN) classifiers for the derived statistical features from DWT. It has been found that the NB classifier performs better and shows an accuracy of 100% for the individual and combined statistical features derived from the DWT values of normal eyes open and epileptic EEG data provided by the University of Bonn, Germany. It has been found that the computation time of NB classifier is lesser than k-NN to provide better accuracy. So, the detection of an epileptic seizure based on DWT statistical features using NB classifiers is more suitable in real time for a reliable, automatic epileptic seizure detection system to enhance the patient's care and the quality of life.","['Discrete wavelet transforms', 'Electroencephalography', 'Feature extraction', 'Bayes methods', 'Physiology', 'Brain models', 'Seizures']","['Electroencephalograms (EEG)', 'epilepsy', 'discrete wavelet transform (DWT)', 'naïve Bayes (NB)', 'k-nearest neighbor (k-NN)']"
"Index modulation has become a promising technique in the context of orthogonal frequency division multiplexing (OFDM), whereby the specific activation of the frequency domain subcarriers is used for implicitly conveying extra information, hence improving the achievable throughput at a given bit error ratio (BER) performance. In this paper, a dual-mode OFDM technique (DM-OFDM) is proposed, which is combined with index modulation and enhances the attainable throughput of conventional index-modulation-based OFDM. In particular, the subcarriers are divided into several subblocks, and in each subblock, all the subcarriers are partitioned into two groups, modulated by a pair of distinguishable modem-mode constellations, respectively. Hence, the information bits are conveyed not only by the classic constellation symbols, but also implicitly by the specific activated subcarrier indices, representing the subcarriers' constellation mode. At the receiver, a maximum likelihood (ML) detector and a reduced-complexity near optimal log-likelihood ratio-based detector are invoked for demodulation. The minimum distance between the different legitimate realizations of the OFDM subblocks is calculated for characterizing the performance of DM-OFDM. Then, the associated theoretical analysis based on the pairwise error probability is carried out for estimating the BER of DM-OFDM. Furthermore, the simulation results confirm that at a given throughput, DM-OFDM achieves a considerably better BER performance than other OFDM systems using index modulation, while imposing the same or lower computational complexity. The results also demonstrate that the performance of the proposed low-complexity detector is indistinguishable from that of the ML detector, provided that the system's signal to noise ratio is sufficiently high.","['Indexes', 'OFDM', 'Detectors', 'Phase shift keying', 'Throughput', 'Signal to noise ratio']","['Orthogonal frequency division multiplexing (OFDM)', 'index modulation', 'index pattern', 'constellation', 'maximum likelihood detection', 'log-likelihood ratio based detection']"
"Heart disease is one of the complex diseases and globally many people suffered from this disease. On time and efficient identification of heart disease plays a key role in healthcare, particularly in the field of cardiology. In this article, we proposed an efficient and accurate system to diagnosis heart disease and the system is based on machine learning techniques. The system is developed based on classification algorithms includes Support vector machine, Logistic regression, Artificial neural network, K-nearest neighbor, Naïve bays, and Decision tree while standard features selection algorithms have been used such as Relief, Minimal redundancy maximal relevance, Least absolute shrinkage selection operator and Local learning for removing irrelevant and redundant features. We also proposed novel fast conditional mutual information feature selection algorithm to solve feature selection problem. The features selection algorithms are used for features selection to increase the classification accuracy and reduce the execution time of classification system. Furthermore, the leave one subject out cross-validation method has been used for learning the best practices of model assessment and for hyperparameter tuning. The performance measuring metrics are used for assessment of the performances of the classifiers. The performances of the classifiers have been checked on the selected features as selected by features selection algorithms. The experimental results show that the proposed feature selection algorithm (FCMIM) is feasible with classifier support vector machine for designing a high-level intelligent system to identify heart disease. The suggested diagnosis system (FCMIM-SVM) achieved good accuracy as compared to previously proposed methods. Additionally, the proposed system can easily be implemented in healthcare for the identification of heart disease.","['Feature extraction', 'Diseases', 'Machine learning', 'Heart', 'Prediction algorithms', 'Machine learning algorithms', 'Support vector machines']","['Heart disease classification', 'features selection', 'disease diagnosis', 'intelligent system', 'medical data analytics']"
"With the sharp increase in the number of intelligent devices, the Internet of Things (IoT) has gained more and more attention and rapid development in recent years. It effectively integrates the physical world with the Internet over existing network infrastructure to facilitate sharing data among intelligent devices. However, its complex and large-scale network structure brings new security risks and challenges to IoT systems. To ensure the security of data, traditional access control technologies are not suitable to be directly used for implementing access control in IoT systems because of their complicated access management and the lack of credibility due to centralization. In this paper, we proposed a novel attribute-based access control scheme for IoT systems, which simplifies greatly the access management. We use blockchain technology to record the distribution of attributes in order to avoid single point failure and data tampering. The access control process has also been optimized to meet the need for high efficiency and lightweight calculation for IoT devices. The security and performance analysis show that our scheme could effectively resist multiple attacks and be efficiently implemented in IoT systems.","['Blockchain', 'Internet of Things', 'Authorization', 'Authentication']","['Access control', 'attribute-based access control', 'blockchain', 'consortium blockchain', 'Internet of Things']"
This paper introduces a novel algorithm that increases the efficiency of the current cloud-based smart-parking system and develops a network architecture based on the Internet-of-Things technology. This paper proposed a system that helps users automatically find a free parking space at the least cost based on new performance metrics to calculate the user parking cost by considering the distance and the total number of free places in each car park. This cost will be used to offer a solution of finding an available parking space upon a request by the user and a solution of suggesting a new car park if the current car park is full. The simulation results show that the algorithm helps improve the probability of successful parking and minimizes the user waiting time. We also successfully implemented the proposed system in the real world.,"['Smart systems', 'Performance evaluation', 'Algorithm design and analysis', 'Cloud computing', 'Internet of things']","['Smart-parking system', 'performance metrics']"
"Twitter sentiment analysis offers organizations ability to monitor public feeling towards the products and events related to them in real time. The first step of the sentiment analysis is the text pre-processing of Twitter data. Most existing researches about Twitter sentiment analysis are focused on the extraction of new sentiment features. However, to select the pre-processing method is ignored. This paper discussed the effects of text pre-processing method on sentiment classification performance in two types of classification tasks, and summed up the classification performances of six pre-processing methods using two feature models and four classifiers on five Twitter datasets. The experiments show that the accuracy and F1-measure of Twitter sentiment classification classifier are improved when using the pre-processing methods of expanding acronyms and replacing negation, but barely changes when removing URLs, removing numbers or stop words. The Naive Bayes and Random Forest classifiers are more sensitive than Logistic Regression and support vector machine classifiers when various pre-processing methods were applied.",[],[]
"Crowdsensing applications utilize the pervasive smartphone users to collect large-scale sensing data efficiently. The quality of sensing data depends on the participation of highly skilled users. To motivate these skilled users to participate, they should receive enough rewards for compensating their resource consumption. Available incentive mechanisms mainly consider the truthfulness of the mechanism, but mostly ignore the issues of security and privacy caused by a “trustful” center. In this paper, we propose a privacy-preserving blockchain incentive mechanism in crowdsensing applications, in which a cryptocurrency built on blockchains is used as a secure incentive way. High quality contributors will get their payments that are recorded in transaction blocks. The miners will verify the transaction according to the sensing data assessment criteria published by the server. As the transaction information can disclose users’ privacy, a node cooperation verification approach is proposed to achieve k -anonymity privacy protection. Through theoretical analysis and simulation experiments, we show the feasibility and security of our incentive mechanism.","['Sensors', 'Servers', 'Task analysis', 'Data privacy', 'Privacy']","['Blockchain', 'crowdsensing', 'incentive mechanism', 'node cooperation', 'privacy-preserving', 'signcryption']"
"Diabetes, also known as chronic illness, is a group of metabolic diseases due to a high level of sugar in the blood over a long period. The risk factor and severity of diabetes can be reduced significantly if the precise early prediction is possible. The robust and accurate prediction of diabetes is highly challenging due to the limited number of labeled data and also the presence of outliers (or missing values) in the diabetes datasets. In this literature, we are proposing a robust framework for diabetes prediction where the outlier rejection, filling the missing values, data standardization, feature selection, K-fold cross-validation, and different Machine Learning (ML) classifiers (k-nearest Neighbour, Decision Trees, Random Forest, AdaBoost, Naive Bayes, and XGBoost) and Multilayer Perceptron (MLP) were employed. The weighted ensembling of different ML models is also proposed, in this literature, to improve the prediction of diabetes where the weights are estimated from the corresponding Area Under ROC Curve (AUC) of the ML model. AUC is chosen as the performance metric, which is then maximized during hyperparameter tuning using the grid search technique. All the experiments, in this literature, were conducted under the same experimental conditions using the Pima Indian Diabetes Dataset. From all the extensive experiments, our proposed ensembling classifier is the best performing classifier with the sensitivity, specificity, false omission rate, diagnostic odds ratio, and AUC as 0.789, 0.934, 0.092, 66.234, and 0.950 respectively which outperforms the state-of-the-art results by 2.00 % in AUC. Our proposed framework for the diabetes prediction outperforms the other methods discussed in the article. It can also provide better results on the same dataset which can lead to better performance in diabetes prediction. Our source code for diabetes prediction is made publicly available.","['Diabetes', 'Measurement', 'Maximum likelihood estimation', 'Machine learning', 'Standardization', 'Feature extraction', 'Predictive models']","['Diabetes prediction', 'ensembling classifier', 'machine learning', 'multilayer perceptron', 'missing values and outliers', 'Pima Indian Diabetic dataset']"
"The strengthening of electric energy security and the reduction of greenhouse gas emissions have gained enormous momentum in previous decades. The integration of large-scale intermittent renewable energy resources (RER) like wind energy into the existing electricity grids has increased significantly in the last decade. However, this integration poses many operational and control challenges that hamper the reliable and stable operation of the grids. This article aims to review the reported challenges caused by the integration of wind energy and the proposed solutions methodologies. Among the various challenges, the generation uncertainty, power quality issues, angular and voltage stability, reactive power support, and fault ride-through capability are reviewed and discussed. Besides, socioeconomic, environmental, and electricity market challenges due to the grid integration of wind power are also investigated. Many of the solutions used and proposed to mitigate the impact of these challenges, such as energy storage systems, wind energy policy, and grid codes, are also reviewed and discussed. This paper will assist the enthusiastic readers in seeing the full picture of wind energy integration challenges. It also puts in the hands of policymakers all aspects of the challenges so that they can adopt sustainable policies that support and overcome the difficulties facing the integration of wind energy into electricity grids.","['Power system stability', 'Wind turbines', 'Wind energy', 'Wind power generation', 'Reactive power', 'Wind forecasting', 'Mathematical model']","['Angular stability', 'energy storage system', 'fault ride-through capability', 'frequency response', 'grid codes', 'reactive power support', 'voltage stability', 'wind intermittency']"
"Healthcare is undergoing a rapid transformation from traditional hospital and specialist focused approach to a distributed patient-centric approach. Advances in several technologies fuel this rapid transformation of healthcare vertical. Among various technologies, communication technologies have enabled to deliver personalized and remote healthcare services. At present, healthcare widely uses the existing 4G network and other communication technologies for smart healthcare applications and are continually evolving to accommodate the needs of future intelligent healthcare applications. As the smart healthcare market expands the number of applications connecting to the network will generate data that will vary in size and formats. This will place complex demands on the network in terms of bandwidth, data rate, and latency, among other factors. As this smart healthcare market matures, the connectivity needs for a large number of devices and machines with sensor-based applications in hospitals will necessitate the need to implement Massive-Machine Type Communication. Further use cases such as remote surgeries and Tactile Internet will spur the need for Ultra Reliability and Low Latency Communications or Critical Machine Type Communication. The existing communication technologies are unable to fulfill the complex and dynamic need that is put on the communication networks by the diverse smart healthcare applications. Therefore, the emerging 5G network is expected to support smart healthcare applications, which can fulfill most of the requirements such as ultra-low latency, high bandwidth, ultra-high reliability, high density, and high energy efficiency. The future smart healthcare networks are expected to be a combination of the 5G and IoT devices which are expected to increase cellular coverage, network performance and address security-related concerns. This paper provides a state-of-the-art review of the 5G and IoT enabled smart healthcare, Taxonomy, research trends, challenges, and future research directions.","['Medical services', '5G mobile communication', 'Computer architecture', 'Internet of Things', 'Monitoring', 'Wireless communication', 'Biomedical monitoring']","['5G', 'smart healthcare', 'software-defined network', 'network function virtualization', 'the Internet of Things (IoT)', 'device-to-device (D2D)', 'ultra reliability and low latency communications']"
"Network slicing is born as an emerging business to operators by allowing them to sell the customized slices to various tenants at different prices. In order to provide better-performing and costefficient services, network slicing involves challenging technical issues and urgently looks forward to intelligent innovations to make the resource management consistent with users' activities per slice. In that regard, deep reinforcement learning (DRL), which focuses on how to interact with the environment by trying alternative actions and reinforcing the tendency actions producing more rewarding consequences, is assumed to be a promising solution. In this paper, after briefly reviewing the fundamental concepts of DRL, we investigate the application of DRL in solving some typical resource management for network slicing scenarios, which include radio resource slicing and priority-based core network slicing, and demonstrate the advantage of DRL over several competing schemes through extensive simulations. Finally, we also discuss the possible challenges to apply DRL in network slicing from a general perspective.","['Network slicing', 'Resource management', 'Neural networks', '5G mobile communication', 'Quality of experience']","['Deep reinforcement learning', 'network slicing', 'neural networks', 'Q-learning', 'resource management']"
"Synthetic aperture radar (SAR) images have been widely used for ship monitoring. The traditional methods of SAR ship detection are difficult to detect small scale ships and avoid the interference of inshore complex background. Deep learning detection methods have shown great performance on various object detection tasks recently but using deep learning methods for SAR ship detection does not show an excellent performance it should have. One of the important reasons is that there is no effective model to handle the detection of multiscale ships in multiresolution SAR images. Another important reason is it is difficult to handle multiscene SAR ship detection including offshore and inshore, especially it cannot effectively distinguish between inshore complex background and ships. In this paper, we propose a densely connected multiscale neural network based on faster-RCNN framework to solve multiscale and multiscene SAR ship detection. Instead of using a single feature map to generate proposals, we densely connect one feature map to every other feature maps from top to down and generate proposals from each fused feature map. In addition, we propose a training strategy to reduce the weight of easy examples in the loss function, so that the training process more focus on the hard examples to reduce false alarm. Experiments on expanded public SAR ship detection dataset, verify the proposed method can achieve an excellent performance on multiscale SAR ship detection in multiscene.","['Marine vehicles', 'Feature extraction', 'Synthetic aperture radar', 'Proposals', 'Object detection', 'Machine learning', 'Image resolution']","['Ship detection', 'multiscale', 'neural network', 'synthetic aperture radar (SAR)']"
"Nowadays, in the international scientific community of machine learning, there exists an enormous discussion about the use of black-box models or explainable models; especially in practical problems. On the one hand, a part of the community defends that black-box models are more accurate than explainable models in some contexts, like image preprocessing. On the other hand, there exist another part of the community alleging that explainable models are better than black-box models because they can obtain comparable results and also they can explain these results in a language close to a human expert by using patterns. In this paper, advantages and weaknesses for each approach are shown; taking into account a state-of-the-art review for both approaches, their practical applications, trends, and future challenges. This paper shows that both approaches are suitable for solving practical problems, but experts in machine learning need to understand the input data, the problem to solve, and the best way for showing the output data before applying a machine learning model. Also, we propose some ideas for fusing both, explainable and black-box, approaches to provide better solutions to experts in real-world domains. Additionally, we show one way to measure the effectiveness of the applied machine learning model by using expert opinions jointly with statistical methods. Throughout this paper, we show the impact of using explainable and black-box models on the security and medical applications.","['Machine learning', 'Mathematical model', 'Biological system modeling', 'Gallium nitride', 'Biological neural networks', 'Statistical analysis', 'Computational modeling']","['Black-box', 'white-box', 'explainable artificial intelligence', 'deep learning']"
"Credit card fraud is a serious problem in financial services. Billions of dollars are lost due to credit card fraud every year. There is a lack of research studies on analyzing real-world credit card data owing to confidentiality issues. In this paper, machine learning algorithms are used to detect credit card fraud. Standard models are first used. Then, hybrid methods which use AdaBoost and majority voting methods are applied. To evaluate the model efficacy, a publicly available credit card data set is used. Then, a real-world credit card data set from a financial institution is analyzed. In addition, noise is added to the data samples to further assess the robustness of the algorithms. The experimental results positively indicate that the majority voting method achieves good accuracy rates in detecting fraud cases in credit cards.","['Credit cards', 'Machine learning algorithms', 'Support vector machines', 'Radio frequency', 'Vegetation', 'Classification algorithms', 'Self-organizing feature maps']","['AdaBoost', 'classification', 'credit card', 'fraud detection', 'predictive modelling', 'voting']"
"With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more “cyber”conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. While most of the online social networks and microblogging websites forbid the use of hate speech, the size of these networks and websites makes it almost impossible to control all of their content. Therefore, arises the necessity to detect such speech automatically and filter any content that presents hateful language or language inciting to hatred. In this paper, we propose an approach to detect hate expressions on Twitter. Our approach is based on unigrams and patterns that are automatically collected from the training set. These patterns and unigrams are later used, among others, as features to train a machine learning algorithm. Our experiments on a test set composed of 2010 tweets show that our approach reaches an accuracy equal to 87.4% on detecting whether a tweet is offensive or not (binary classification), and an accuracy equal to 78.4% on detecting whether a tweet is hateful, offensive, or clean (ternary classification).","['Speech', 'Feature extraction', 'Twitter', 'Voice activity detection', 'Task analysis', 'Sentiment analysis']","['Twitter', 'hate speech', 'machine learning', 'sentiment analysis']"
"Iris recognition refers to the automated process of recognizing individuals based on their iris patterns. The seemingly stochastic nature of the iris stroma makes it a distinctive cue for biometric recognition. The textural nuances of an individual's iris pattern can be effectively extracted and encoded by projecting them onto Gabor wavelets and transforming the ensuing phasor response into a binary code - a technique pioneered by Daugman. This textural descriptor has been observed to be a robust feature descriptor with very low false match rates and low computational complexity. However, recent advancements in deep learning and computer vision indicate that generic descriptors extracted using convolutional neural networks (CNNs) are able to represent complex image characteristics. Given the superior performance of CNNs on the ImageNet large scale visual recognition challenge and a large number of other computer vision tasks, in this paper, we explore the performance of state-of-the-art pre-trained CNNs on iris recognition. We show that the off-the-shelf CNN features, while originally trained for classifying generic objects, are also extremely good at representing iris images, effectively extracting discriminative visual features and achieving promising recognition results on two iris datasets: ND-CrossSensor-2013 and CASIA-IrisThousand. We also discuss the challenges and future research directions in leveraging deep learning methods for the problem of iris recognition.","['Iris recognition', 'Machine learning', 'Computer architecture', 'Visualization', 'Computer vision', 'Feature extraction']","['Iris recognition', 'biometrics', 'deep learning', 'convolutional neural network']"
"The growing interest and recent breakthroughs in artificial intelligence and machine learning (ML) have actively contributed to an increase in research and development of new methods to estimate the states of electrified vehicle batteries. Data-driven approaches, such as ML, are becoming more popular for estimating the state of charge (SOC) and state of health (SOH) due to greater availability of battery data and improved computing power capabilities. This paper provides a survey of battery state estimation methods based on ML approaches such as feedforward neural networks (FNNs), recurrent neural networks (RNNs), support vector machines (SVM), radial basis functions (RBF), and Hamming networks. Comparisons between methods are shown in terms of data quality, inputs and outputs, test conditions, battery types, and stated accuracy to give readers a bigger picture view of the ML landscape for SOC and SOH estimation. Additionally, to provide insight into how to best approach with the comparison of different neural network structures, an FNN and long short-term memory (LSTM) RNN are trained fifty times each for 3000 epochs. The error is somewhat different for each training repetition due to the random initial values of the trainable parameters, demonstrating that it is important to train networks multiple times to achieve the best result. Furthermore, it is recommended that when performing a comparison among estimation techniques such as those presented in this review paper, the compared networks should have a similar number of learnable parameters and be trained and tested with identical data. Otherwise, it is difficult to make a general conclusion regarding the quality of a given estimation technique.","['Batteries', 'State of charge', 'Machine learning', 'Maximum likelihood estimation', 'Training', 'Temperature measurement']","['Machine learning', 'artificial intelligence', 'deep learning', 'battery management systems (BMS)', 'electric vehicles', 'state of charge', 'state of health']"
"This paper discusses the power quality issues for distributed generation systems based on renewable energy sources, such as solar and wind energy. A thorough discussion about the power quality issues is conducted here. This paper starts with the power quality issues, followed by discussions of basic standards. A comprehensive study of power quality in power systems, including the systems with dc and renewable sources is done in this paper. Power quality monitoring techniques and possible solutions of the power quality issues for the power systems are elaborately studied. Then, we analyze the methods of mitigation of these problems using custom power devices, such as D-STATCOM, UPQC, UPS, TVSS, DVR, etc., for micro grid systems. For renewable energy systems, STATCOM can be a potential choice due to its several advantages, whereas spinning reserve can enhance the power quality in traditional systems. At Last, we study the power quality in dc systems. Simpler arrangement and higher reliability are two main advantages of the dc systems though it faces other power quality issues, such as instability and poor detection of faults.","['Power quality', 'Voltage fluctuations', 'Harmonic analysis', 'Power system harmonics', 'Renewable energy sources', 'Voltage control']","['DC system', 'mitigation', 'monitor', 'power quality', 'renewable energy', 'spinning reserve', 'standards']"
"Fungal diseases not only influence the economic importance of the plants and its products but also abate their ecological prominence. Mango tree, specifically the fruits and the leaves are highly affected by the fungal disease named as Anthracnose. The main aim of this paper is to develop an appropriate and effective method for diagnosis of the disease and its symptoms, therefore espousing a suitable system for an early and cost-effective solution of this problem. Over the last few years, due to their higher performance capability in terms of computation and accuracy, computer vision, and deep learning methodologies have gained popularity in assorted fungal diseases classification. Therefore, for this paper, a multilayer convolutional neural network (MCNN) is proposed for the classification of the Mango leaves infected by the Anthracnose fungal disease. This paper is validated on a real-time dataset captured at the Shri Mata Vaishno Devi University, Katra, J&K, India consists of 1070 images of the Mango tree leaves. The dataset contains both healthy and infected leaf images. The results envisage the higher classification accuracy of the proposed MCNN model when compared to the other state-of-the-art approaches.","['Diseases', 'Deep learning', 'Convolutional neural networks', 'Agriculture', 'Training', 'Real-time systems', 'Biological system modeling']","['Convolutional neural network', 'image classification', 'plant pathology', 'precision agriculture']"
"The role-based access control (RBAC) framework is a mechanism that describes the access control principle. As a common interaction, an organization provides a service to a user who owns a certain role that was issued by a different organization. Such trans-organizational RBAC is common in face-toface communication but not in a computer network, because it is difficult to establish both the security that prohibits the malicious impersonation of roles and the flexibility that allows small organizations to participate and users to fully control their own roles. In this paper, we present an RBAC using smart contract (RBAC-SC), a platform that makes use of Ethereum's smart contract technology to realize a trans organizational utilization of roles. Ethereum is an open blockchain platform that is designed to be secure, adaptable, and flexible. It pioneered smart contracts, which are decentralized applications that serve as “autonomous agents”running exactly as programmed and are deployed on a blockchain. The RBAC-SC uses smart contracts and blockchain technology as versatile infrastructures to represent the trust and endorsement relationship that are essential in the RBAC and to realize a challenge-response authentication protocol that verifies a user's ownership of roles. We describe the RBAC-SC framework, which is composed of two main parts, namely, the smart contract and the challenge-response protocol, and present a performance analysis. A prototype of the smart contract is created and deployed on Ethereum's Testnet blockchain, and the source code is publicly available.","['Organizations', 'Contracts', 'Access control', 'Protocols', 'Standards organizations', 'Computer networks']","['Blockchain technology', 'role-based access control', 'smart contracts']"
"In the last century, the automotive industry has arguably transformed society, being one of the most complex, sophisticated, and technologically advanced industries, with innovations ranging from the hybrid, electric, and self-driving smart cars to the development of IoT-connected cars. Due to its complexity, it requires the involvement of many Industry 4.0 technologies, like robotics, advanced manufacturing systems, cyber-physical systems, or augmented reality. One of the latest technologies that can benefit the automotive industry is blockchain, which can enhance its data security, privacy, anonymity, traceability, accountability, integrity, robustness, transparency, trustworthiness, and authentication, as well as provide long-term sustainability and a higher operational efficiency to the whole industry. This review analyzes the great potential of applying blockchain technologies to the automotive industry emphasizing its cybersecurity features. Thus, the applicability of blockchain is evaluated after examining the state-of-the-art and devising the main stakeholders' current challenges. Furthermore, the article describes the most relevant use cases, since the broad adoption of blockchain unlocks a wide area of short- and medium-term promising automotive applications that can create new business models and even disrupt the car-sharing economy as we know it. Finally, after strengths, weaknesses, opportunities, and threats analysis, some recommendations are enumerated with the aim of guiding researchers and companies in future cyber-resilient automotive industry developments.","['Blockchain', 'Industries', 'Automotive engineering', 'Computer security', 'Biological system modeling', 'Automobiles']","['Blockchain', 'distributed ledger technology (DLT)', 'Industry 4.0', 'IIoT', 'cyber-physical system', 'cryptography', 'cybersecurity', 'tamper-proof data', 'privacy', 'traceability']"
"Sarcasm identification on text documents is one of the most challenging tasks in natural language processing (NLP), has become an essential research direction, due to its prevalence on social media data. The purpose of our research is to present an effective sarcasm identification framework on social media data by pursuing the paradigms of neural language models and deep neural networks. To represent text documents, we introduce inverse gravity moment based term weighted word embedding model with trigrams. In this way, critical words/terms have higher values by keeping the word-ordering information. In our model, we present a three-layer stacked bidirectional long short-term memory architecture to identify sarcastic text documents. For the evaluation task, the presented framework has been evaluated on three-sarcasm identification corpus. In the empirical analysis, three neural language models (i.e., word2vec, fastText and GloVe), two unsupervised term weighting functions (i.e., term-frequency, and TF-IDF) and eight supervised term weighting functions (i.e., odds ratio, relevance frequency, balanced distributional concentration, inverse question frequency-question frequency-inverse category frequency, short text weighting, inverse gravity moment, regularized entropy and inverse false negative-true positive-inverse category frequency) have been evaluated. For sarcasm identification task, the presented model yields promising results with a classification accuracy of 95.30%.","['Task analysis', 'Social networking (online)', 'Blogs', 'Long short term memory', 'Predictive models', 'Gravity', 'Analytical models']","['Sarcasm identification', 'term weighting', 'neural language model', 'bidirectional long shortterm memory']"
"Mobile edge computing (MEC) providing information technology and cloud-computing capabilities within the radio access network is an emerging technique in fifth-generation networks. MEC can extend the computational capacity of smart mobile devices (SMDs) and economize SMDs' energy consumption by migrating the computation-intensive task to the MEC server. In this paper, we consider a multi-mobile-users MEC system, where multiple SMDs ask for computation offloading to a MEC server. In order to minimize the energy consumption on SMDs, we jointly optimize the offloading selection, radio resource allocation, and computational resource allocation coordinately. We formulate the energy consumption minimization problem as a mixed interger nonlinear programming (MINLP) problem, which is subject to specific application latency constraints. In order to solve the problem, we propose a reformulation-linearization-technique-based Branch-and-Bound (RLTBB) method, which can obtain the optimal result or a suboptimal result by setting the solving accuracy. Considering the complexity of RTLBB cannot be guaranteed, we further design a Gini coefficient-based greedy heuristic (GCGH) to solve the MINLP problem in polynomial complexity by degrading the MINLP problem into the convex problem. Many simulation results demonstrate the energy saving enhancements of RLTBB and GCGH.","['Energy consumption', 'Servers', 'Resource management', 'Mobile communication', 'Computational modeling', 'Minimization', 'Radio spectrum management']","['Mobile edge computing', 'computation offloading', 'energy minimization', 'branch-and-bound method', 'reformulation-linearization-technique', 'Gini coefficient']"
"Herein, we focus on convergent 6G communication, localization and sensing systems by identifying key technology enablers, discussing their underlying challenges, implementation issues, and recommending potential solutions. Moreover, we discuss exciting new opportunities for integrated localization and sensing applications, which will disrupt traditional design principles and revolutionize the way we live, interact with our environment, and do business. Regarding potential enabling technologies, 6G will continue to develop towards even higher frequency ranges, wider bandwidths, and massive antenna arrays. In turn, this will enable sensing solutions with very fine range, Doppler, and angular resolutions, as well as localization to cm-level degree of accuracy. Besides, new materials, device types, and reconfigurable surfaces will allow network operators to reshape and control the electromagnetic response of the environment. At the same time, machine learning and artificial intelligence will leverage the unprecedented availability of data and computing resources to tackle the biggest and hardest problems in wireless communication systems. As a result, 6G will be truly intelligent wireless systems that will provide not only ubiquitous communication but also empower high accuracy localization and high-resolution sensing services. They will become the catalyst for this revolution by bringing about a unique new set of features and service capabilities, where localization and sensing will coexist with communication, continuously sharing the available resources in time, frequency, and space. This work concludes by highlighting foundational research challenges, as well as implications and opportunities related to privacy, security, and trust.","['Sensors', 'Location awareness', '6G mobile communication', '5G mobile communication', 'Robot sensing systems', 'Frequency measurement', 'Protocols']","['6G', 'beamforming', 'cmWave', 'context-aware', 'IRS', 'ML/AI', 'mmWave', 'radar', 'security', 'sensing', 'SLAM', 'THz']"
"While augment reality applications are becoming popular, more and more data-hungry and computation-intensive tasks are delay-sensitive. Mobile edge computing is expected to an effective solution to meet the low latency demand. In contrast to previous work on mobile edge computing, which mainly focus on computation offloading, this paper introduces a new concept of task caching. Task caching refers to the caching of completed task application and their related data in edge cloud. Then, we investigate the problem of joint optimization of task caching and offloading on edge cloud with the computing and storage resource constraint. We formulate this problem as mixed integer programming which is hard to solve. To solve the problem, we propose efficient algorithm, called task caching and offloading (TCO), based on alternating iterative algorithm. Finally, the simulation experimental results show that our proposed TCO algorithm outperforms others in terms of less energy cost.","['Task analysis', 'Cloud computing', 'Mobile handsets', 'Edge computing', 'Delays', 'Solid modeling', 'Streaming media']","['Caching', 'computation offloading', 'mobile edge computing', 'energy efficient']"
"Recently, multilevel inverters (MLIs) have gained lots of interest in industry and academia, as they are changing into a viable technology for numerous applications, such as renewable power conversion system and drives. For these high power and high/medium voltage applications, MLIs are widely used as one of the advanced power converter topologies. To produce high-quality output without the need for a large number of switches, development of reduced switch MLI (RS MLI) topologies has been a major focus of current research. Therefore, this review paper focuses on a number of recently developed MLIs used in various applications. To assist with advanced current research in this field and in the selection of suitable inverter for various applications, significant understanding on these topologies is clearly summarized based on the three categories, i.e., symmetrical, asymmetrical, and modified topologies. This review paper also includes a comparison based on important performance parameters, detailed technical challenges, current focus, and future development trends. By a suitable combination of switches, the MLI produces a staircase output with low harmonic distortion. For a better understanding of the working principle, a single-phase RS MLI topology is experimentally illustrated for different level generation using both fundamental and high switching frequency techniques which will help the readers to gain the utmost knowledge for advance research.","['Topology', 'Switches', 'Pulse width modulation', 'Inverters', 'Harmonic analysis', 'Power harmonic filters', 'Renewable energy sources']","['Control techniques', 'drives application', 'fundamental switching frequency', 'high switching frequency', 'multilevel inverter (MLI)', 'performance parameters', 'photovoltaic (PV) systems', 'reduced component count', 'renewable energy application']"
"In recent years, unmanned aerial vehicles (UAVs) have received considerable attention from regulators, industry and research community, due to rapid growth in a broad range of applications. Particularly, UAVs are being used to provide a promising solution to reliable and cost-effective wireless communications from the sky. The deployment of UAVs has been regarded as an alternative complement of existing cellular systems, to achieve higher transmission efficiency with enhanced coverage and capacity. However, heavily utilized microwave spectrum bands below 6 GHz utilized by legacy wireless systems are insufficient to attain remarkable data rate enhancement for numerous emerging applications. To resolve the spectrum crunch crisis and satisfy the requirements of 5G and beyond mobile communications, one potential solution is to use the abundance of unoccupied bandwidth available at millimeter wave (mmWave) frequencies. Inspired by the technique potentials, mmWave communications have also paved the way into the widespread use of UAVs to assist wireless networks for future 5G and beyond wireless applications. In this paper, we provide a comprehensive survey on current achievements in the integration of 5G mmWave communications into UAV-assisted wireless networks. More precisely, a taxonomy to classify the existing research issues is presented, by considering seven cutting-edge solutions. Subsequently, we provide a brief overview of 5G mmWave communications for UAV-assisted wireless networks from two aspects, i.e., key technical advantages and challenges as well as potential applications. Based on the proposed taxonomy, we further discuss in detail the state-of-the-art issues, solutions, and open challenges for this newly emerging area. Lastly, we complete this survey by pointing out open issues and shedding new light on future directions for further research on this area.","['Drones', '5G mobile communication', 'Wireless networks', 'Wireless sensor networks', 'Ad hoc networks', 'Millimeter wave communication']","['Millimeter wave (mmWave) communications', 'unmanned aerial vehicle (UAV)', 'mmWave UAV communications', 'UAV-assisted wireless networks', '5G and beyond']"
"Prosumer concept and digitilization offer the exciting potential of microgrid transactive energy systems at distribution level for reducing transmission losses, decreasing electric infrastructure expenditure, improving reliability, enhancing local energy use, and minimizing customers' electricity bills. Distributed energy resources, demand response, distributed ledger technologies, and local energy markets are integral parts of transaction energy system for emergence of decentralized smart grid system. Hence, this paper discusses transactive energy concept and proposes seven functional layers architecture for designing transactive energy system. The proposed architecture is compared with practical case study of Brooklyn microgrid. Moreover, this paper reviews the existing architectures and explains the widely known distributed ledger technologies (blockchain, directed acyclic graph, hashgraph, holochain, and tempo) alongwith their advantages and challenges. The local energy market concept is presented and critically analyzed for energy trade within a transactive energy system. This paper also reviews the potential and challenges of peer-to-peer and community-based energy markets. Proposed architecture and analytical review of distributed ledger technologies and local energy markets pave the way for advanced research and industrialization of transactive energy systems.","['Transactive energy', 'Microgrids', 'Distributed ledger', 'Load management', 'Blockchain', 'Computer architecture']","['Blockchain', 'decentralization', 'demand response', 'distributed ledger technologies', 'energy trading', 'local energy market', 'microgrid', 'peer-to-peer market', 'prosumer', 'renewable energy sources', 'smart grid', 'system architectures', 'transactive energy']"
"Advances in technology are not only changing the world around us but also driving the wireless industry to develop the next generation of network technology. There is a lot of buzz building over the advent of 5G that will facilitate the entire planet through continuous and ubiquitous communication connecting anybody to anything, anywhere, anytime, and anyhow regardless of the device, service, network, or geographical existence. 5G will also prove to be a paradigm shift including high carrier frequencies with massive bandwidths, having a large number of antennas, and with an extreme base station and device densities. In this paper, we investigate the potential beneficiaries of 5G and identify the use-cases, where 5G can make an impact. In particular, we consider three main use-cases: vehicle-to-everything (V2X) communication, drones, and healthcare. We explore and highlight the problems and deficiencies of current cellular technologies with respect to these use-cases and identify how 5G will overcome those deficiencies. We also identified the open research problems and provide possible future directions to cope with those issues.","['5G mobile communication', 'Vehicle-to-everything', 'Medical services', 'Drones', 'Reliability', 'Vehicular ad hoc networks', 'Wireless communication']","['5G', 'V2X communication', 'drones', 'healthcare', 'ultra-low-latency', 'ultra-high-reliability']"
This paper presents a complete approach to a successful utilization of a high-performance extreme learning machines (ELMs) Toolbox for Big Data. It summarizes recent advantages in algorithmic performance; gives a fresh view on the ELM solution in relation to the traditional linear algebraic performance; and reaps the latest software and hardware performance achievements. The results are applicable to a wide range of machine learning problems and thus provide a solid ground for tackling numerous Big Data challenges. The included toolbox is targeted at enabling the full potential of ELMs to the widest range of users.,"['Learning systems', 'Performance evaluation', 'Machine learning']","['Learning systems', 'Supervised learning', 'Machine learning', 'Prediction methods', 'Predictive models', 'Neural networks', 'Artificial neural networks', 'Feedforward neural networks', 'Radial basis function networks', 'Computer applications', 'Scientific computing', 'Performance analysis', 'High performance computing Software', 'Open source software', 'Utility programs']"
"Smart grid technology increases reliability, security, and efficiency of the electrical grids. However, its strong dependencies on digital communication technology bring up new vulnerabilities that need to be considered for efficient and reliable power distribution. In this paper, an unsupervised anomaly detection based on statistical correlation between measurements is proposed. The goal is to design a scalable anomaly detection engine suitable for large-scale smart grids, which can differentiate an actual fault from a disturbance and an intelligent cyber-attack. The proposed method applies feature extraction utilizing symbolic dynamic filtering (SDF) to reduce computational burden while discovering causal interactions between the subsystems. The simulation results on IEEE 39, 118, and 2848 bus systems verify the performance of the proposed method under different operation conditions. The results show an accuracy of 99%, true positive rate of 98%, and false positive rate of less than 2%","['Smart grids', 'Generators', 'Power system reliability', 'Reliability', 'Feature extraction', 'Security']","['Anomaly', 'cyber-attack', 'smart grid', 'statistical property', 'machine learning', 'unsupervised learning']"
"Unmanned aerial vehicles (UAVs) have stroke great interested both by the academic community and the industrial community due to their diverse military applications and civilian applications. Furthermore, UAVs are also envisioned to be part of future airspace traffic. The application functions delivery relies on information exchange among UAVs as well as between UAVs and ground stations (GSs), which further closely depends on aeronautical channels. However, there is a paucity of comprehensive surveys on aeronautical channel modeling in line with the specific aeronautical characteristics and scenarios. To fill this gap, this paper focuses on reviewing the air-to-ground (A2G), ground-to-ground (G2G), and air-to-air (A2A) channel measurements and modeling for UAV communications and aeronautical communications under various scenarios. We also provide the design guideline for managing the link budget of UAV communications taking account of link losses and channel fading effects. Moreover, we also analyze the receive/transmit diversity gain and spatial multiplexing gain achieved by multiple-antenna-aided UAV communications. Finally, we discuss the remaining challenge and open issues for the future development of UAV communication channel modeling.","['Atmospheric modeling', 'Solid modeling', 'Analytical models', 'Unmanned aerial vehicles', 'Airports', 'Sea measurements', 'Shadow mapping']","['UAV communication', 'aeronautical communication', 'channel characterization', 'statistical channel', 'air-to-ground', 'cellular networks', 'evaporation duct', 'shadowing', 'MIMO']"
"Massive multiple-input multiple-output is a promising physical layer technology for 5G wireless communications due to its capability of high spectrum and energy efficiency, high spatial resolution, and simple transceiver design. To embrace its potential gains, the acquisition of channel state information is crucial, which unfortunately faces a number of challenges, such as the uplink pilot contamination, the overhead of downlink training and feedback, and the computational complexity. In order to reduce the effective channel dimensions, researchers have been investigating the low-rank (sparse) properties of channel environments from different viewpoints. This paper then provides a general overview of the current low-rank channel estimation approaches, including their basic assumptions, key results, as well as pros and cons on addressing the aforementioned tricky challenges. Comparisons among all these methods are provided for better understanding and some future research prospects for these low-rank approaches are also forecasted.","['MIMO', 'Physical layer', '5G mobile communication', 'Energy efficiency', 'Spatial resolution', 'Transceivers']","['Massive MIMO', 'channel estimation', 'low-rank property', 'channel sparsity', 'angle reciprocity']"
"This paper focuses on bearing fault diagnosis with limited training data. A major challenge in fault diagnosis is the infeasibility of obtaining sufficient training samples for every fault type under all working conditions. Recently deep learning based fault diagnosis methods have achieved promising results. However, most of these methods require large amount of training data. In this study, we propose a deep neural network based few-shot learning approach for rolling bearing fault diagnosis with limited data. Our model is based on the siamese neural network, which learns by exploiting sample pairs of the same or different categories. Experimental results over the standard Case Western Reserve University (CWRU) bearing fault diagnosis benchmark dataset showed that our few-shot learning approach is more effective in fault diagnosis with limited data availability. When tested over different noise environments with minimal amount of training data, the performance of our few-shot learning model surpasses the one of the baseline with reasonable noise level. When evaluated over test sets with new fault types or new working conditions, few-shot models work better than the baseline trained with all fault types. All our models and datasets in this study are open sourced and can be downloaded from https://mekhub.cn/as/fault_diagnosis_with_few-shot_learning/.","['Fault diagnosis', 'Neural networks', 'Training', 'Employee welfare', 'Kernel', 'Mathematical model', 'Deep learning']","['Deep learning', 'few-shot learning', 'bearing fault diagnosis', 'limited data']"
"This study aims to explore the current status, potential applications, and future directions of blockchain technology in supply chain management. A literature survey, along with an analytical review, of blockchain-based supply chain research was conducted to better understand the trajectory of related research and shed light on the benefits, issues, and challenges in the blockchain-supply-chain paradigm. A selected corpus comprising 106 review articles was analyzed to provide an overview of the use of blockchain and smart contracts in supply chain management. The diverse industrial applications of these technologies in various sectors have increasingly received attention by researchers, engineers, and practitioners. Four major issues: traceability and transparency, stakeholder involvement and collaboration, supply chain integration and digitalization, and common frameworks on blockchain-based platforms, are critical for future orientation. Traditional supply chain activities involve several intermediaries, trust, and performance issues. The potential of blockchain can be leveraged to disrupt supply chain operations for better performance, distributed governance, and process automation. This study contributes to the comprehension of blockchain applications in supply chain management and provides a blueprint for these applications from the perspective of literature analysis. Future efforts regarding technical adoption/diffusion, block-supply chain integration, and their social impacts were highlighted to enrich the research scope.","['Blockchain', 'Smart contracts', 'Supply chains', 'Peer-to-peer computing', 'Distributed ledger', 'Systematics', 'Bibliographies']","['Blockchain', 'digital ledger', 'distributed ledger technology', 'logistics', 'shared ledger', 'smart contract', 'supply chain management', 'systematic literature review', 'value chain']"
"The proliferation of smartphones has significantly facilitated people's daily life, and diverse and powerful embedded sensors make smartphone a ubiquitous platform to acquire and analyze data, which may also provide great potential for efficient human activity recognition. This paper presents a systematic performance analysis of motion-sensor behavior for human activity recognition via smartphones. Sensory data sequences are collected via smartphones, when participants perform typical and daily human activities. A cycle detection algorithm is applied to segment the data sequence for obtaining the activity unit, which is then characterized by time-, frequency-, and wavelet-domain features. Then both personalized and generalized model using diverse classification algorithms are developed and implemented to perform activity recognition. Analyses are conducted using 27 681 sensory samples from 10 subjects, and the performance is measured in the form of F-score under various placement settings, and in terms of sensitivity to user space, stability to combination of motion sensors, and impact of data imbalance. Extensive results show that each individual has its own specific and discriminative movement patterns, and the F-score for personalized model and generalized model can reach 95.95% and 96.26%, respectively, which indicates our approach is accurate and efficient for practical implementation.","['Activity recognition', 'Smart phones', 'Accelerometers', 'Feature extraction', 'Legged locomotion', 'Gyroscopes']","['Smartphone', 'motion sensor', 'behavior analysis', 'human activity recognition', 'performance analysis']"
"Phasor measurement units (PMUs) are rapidly being deployed in electric power networks across the globe. Wide-area measurement system (WAMS), which builds upon PMUs and fast communication links, is consequently emerging as an advanced monitoring and control infrastructure. Rapid adaptation of such devices and technologies has led the researchers to investigate multitude of challenges and pursue opportunities in synchrophasor measurement technology, PMU structural design, PMU placement, miscellaneous applications of PMU from local perspectives, and various WAMS functionalities from the system perspective. Relevant research articles appeared in the IEEE and IET publications from 1983 through 2014 are rigorously surveyed in this paper to represent a panorama of research progress lines. This bibliography will aid academic researchers and practicing engineers in adopting appropriate topics and will stimulate utilities toward development and implementation of software packages.","['Phasor measurement', 'Synchronization', 'Bibliographies', 'Wide area measurement', 'Measurement']","['Phasor measurement unit (PMU)', 'synchrophasor measurement technology (SMT)', 'wide-area measurement system (WAMS)']"
"The network intrusion detection system is an important tool for protecting computer networks against threats and malicious attacks. Many techniques have recently been proposed; however, these face significant challenges due to the continuous emergence of new threats that are not recognized by existing systems. In this paper, we propose a novel two-stage deep learning (TSDL) model, based on a stacked auto-encoder with a soft-max classifier, for efficient network intrusion detection. The model comprises two decision stages: an initial stage responsible for classifying network traffic as normal or abnormal, using a probability score value. This is then used in the final decision stage as an additional feature, for detecting the normal state and other classes of attacks. The proposed model is able to learn useful feature representations from large amounts of unlabeled data and classifies them automatically and efficiently. To evaluate its effectiveness, several experiments are conducted on two public datasets, specifically the benchmark KDD99 and UNSW-NB15 datasets. Comparative simulation results demonstrate that our proposed model significantly outperforms existing approaches, achieving high recognition rates, up to 99.996% and 89.134%, for the KDD99 and UNSW-NB15 datasets respectively. We conclude that our model has the potential to serve as a future benchmark for the deep learning and network security research communities.","['Intrusion detection', 'Deep learning', 'Feature extraction', 'Computational modeling', 'Benchmark testing', 'Neural networks', 'Tools']","['Computational intelligence', 'two-stage deep learning model', 'feature representation', 'network intrusion detection', 'stacked auto-encoder']"
"Blockchain and other Distributed Ledger Technologies (DLTs) have evolved significantly in the last years and their use has been suggested for numerous applications due to their ability to provide transparency, redundancy and accountability. In the case of blockchain, such characteristics are provided through public-key cryptography and hash functions. However, the fast progress of quantum computing has opened the possibility of performing attacks based on Grover's and Shor's algorithms in the near future. Such algorithms threaten both public-key cryptography and hash functions, forcing to redesign blockchains to make use of cryptosystems that withstand quantum attacks, thus creating which are known as post-quantum, quantum-proof, quantum-safe or quantum-resistant cryptosystems. For such a purpose, this article first studies current state of the art on post-quantum cryptosystems and how they can be applied to blockchains and DLTs. Moreover, the most relevant post-quantum blockchain systems are studied, as well as their main challenges. Furthermore, extensive comparisons are provided on the characteristics and performance of the most promising post-quantum public-key encryption and digital signature schemes for blockchains. Thus, this article seeks to provide a broad view and useful guidelines on post-quantum blockchain security to future blockchain researchers and developers.","['Blockchain', 'Hash functions', 'Elliptic curve cryptography', 'Quantum computing']","['Blockchain', 'blockchain security', 'DLT', 'post-quantum', 'quantum-safe', 'quantum-resistant', 'quantum computing', 'cryptography', 'cryptosystem', 'cybersecurity']"
"According to the recent studies, malicious software (malware) is increasing at an alarming rate, and some malware can hide in the system by using different obfuscation techniques. In order to protect computer systems and the Internet from the malware, the malware needs to be detected before it affects a large number of systems. Recently, there have been made several studies on malware detection approaches. However, the detection of malware still remains problematic. Signature-based and heuristic-based detection approaches are fast and efficient to detect known malware, but especially signature-based detection approach has failed to detect unknown malware. On the other hand, behavior-based, model checking-based, and cloud-based approaches perform well for unknown and complicated malware; and deep learning-based, mobile devices-based, and IoT-based approaches also emerge to detect some portion of known and unknown malware. However, no approach can detect all malware in the wild. This shows that to build an effective method to detect malware is a very challenging task, and there is a huge gap for new studies and methods. This paper presents a detailed review on malware detection approaches and recent detection methods which use these approaches. Paper goal is to help researchers to have a general idea of the malware detection approaches, pros and cons of each detection approach, and methods that are used in these approaches.","['Computer viruses', 'Feature extraction', 'Encryption', 'Internet']","['Cyber security', 'malware classification', 'malware detection approaches', 'malware features']"
"Big data is considered to be the key to unlocking the next great waves of growth in productivity. The amount of collected data in our world has been exploding due to a number of new applications and technologies that permeate our daily lives, including mobile and social networking applications, and Internet of Thing-based smart-world systems (smart grid, smart transportation, smart cities, and so on). With the exponential growth of data, how to efficiently utilize the data becomes a critical issue. This calls for the development of a big data market that enables efficient data trading. Via pushing data as a kind of commodity into a digital market, the data owners and consumers are able to connect with each other, sharing and further increasing the utility of data. Nonetheless, to enable such an effective market for data trading, several challenges need to be addressed, such as determining proper pricing for the data to be sold or purchased, designing a trading platform and schemes to enable the maximization of social welfare of trading participants with efficiency and privacy preservation, and protecting the traded data from being resold to maintain the value of the data. In this paper, we conduct a comprehensive survey on the lifecycle of data and data trading. To be specific, we first study a variety of data pricing models, categorize them into different groups, and conduct a comprehensive comparison of the pros and cons of these models. Then, we focus on the design of data trading platforms and schemes, supporting efficient, secure, and privacy-preserving data trading. Finally, we review digital copyright protection mechanisms, including digital copyright identifier, digital rights management, digital encryption, watermarking, and others, and outline challenges in data protection in the data trading lifecycle.","['Pricing', 'Copyright protection', 'Data models', 'Data mining', 'Data analysis', 'Big Data applications']","['Big data', 'data pricing', 'privacy and digital copyright protection', 'data trading', 'data utilization', 'Internet of Things']"
"With the advent of the Internet of Things (IoT), the security of the network layer in the IoT is getting more and more attention. The traditional intrusion detection technologies cannot be well adapted in the complex Internet environment of IoT. For the deep learning algorithm of intrusion detection, a neural network structure may have fine detection accuracy for one kind of attack, but it may not have a good detection effect when facing other attacks. Therefore, it is urgent to design a self-adaptive model to change the network structure for different attack types. This paper presents an intrusion detection model based on improved genetic algorithm (GA) and deep belief network (DBN). Facing different types of attacks, through multiple iterations of the GA, the optimal number of hidden layers and number of neurons in each layer are generated adaptively, so that the intrusion detection model based on the DBN achieves a high detection rate with a compact structure. Finally, the NSL-KDD dataset was used to simulate and evaluate the model and algorithms. The experimental results show that the improved intrusion detection model combined with DBN can effectively improve the recognition rate of intrusion attacks and reduce the complexity of the neural network structure.","['Intrusion detection', 'Neurons', 'Genetic algorithms', 'Neural networks', 'Internet of Things', 'Deep learning']","['Internet of Things security', 'intrusion detection', 'deep belief network', 'genetic algorithm']"
"Tuberculosis (TB) is a chronic lung disease that occurs due to bacterial infection and is one of the top 10 leading causes of death. Accurate and early detection of TB is very important, otherwise, it could be life-threatening. In this work, we have detected TB reliably from the chest X-ray images using image pre-processing, data augmentation, image segmentation, and deep-learning classification techniques. Several public databases were used to create a database of 3500 TB infected and 3500 normal chest X-ray images for this study. Nine different deep CNNs (ResNet18, ResNet50, ResNet101, ChexNet, InceptionV3, Vgg19, DenseNet201, SqueezeNet, and MobileNet) were used for transfer learning from their pre-trained initial weights and were trained, validated and tested for classifying TB and non-TB normal cases. Three different experiments were carried out in this work: segmentation of X-ray images using two different U-net models, classification using X-ray images and that using segmented lung images. The accuracy, precision, sensitivity, F1-score and specificity of best performing model, ChexNet in the detection of tuberculosis using X-ray images were 96.47%, 96.62%, 96.47%, 96.47%, and 96.51% respectively. However, classification using segmented lung images outperformed that with whole X-ray images; the accuracy, precision, sensitivity, F1-score and specificity of DenseNet201 were 98.6%, 98.57%, 98.56%, 98.56%, and 98.54% respectively for the segmented lung images. The paper also used a visualization technique to confirm that CNN learns dominantly from the segmented lung regions that resulted in higher detection accuracy. The proposed method with state-of-the-art performance can be useful in the computer-aided faster diagnosis of tuberculosis.","['X-ray imaging', 'Lung', 'Image segmentation', 'Deep learning', 'Diseases', 'Medical diagnostic imaging']","['Tuberculosis detection', 'TB screening', 'deep learning', 'transfer learning', 'lungs segmentation', 'image processing']"
"Supply chains are evolving into automated and highly complex networks and are becoming an important source of potential benefits in the modern world. At the same time, consumers are now more interested in food product quality. However, it is challenging to track the provenance of data and maintain its traceability throughout the supply chain network. The traditional supply chains are centralized and they depend on a third party for trading. These centralized systems lack transparency, accountability and auditability. In our proposed solution, we have presented a complete solution for blockchain-based Agriculture and Food (Agri-Food) supply chain. It leverages the key features of blockchain and smart contracts, deployed over ethereum blockchain network. Although blockchain provides immutability of data and records in the network, it still fails to solve some major problems in supply chain management like credibility of the involved entities, accountability of the trading process and traceability of the products. Therefore, there is a need of a reliable system that ensures traceability, trust and delivery mechanism in Agri-Food supply chain. In the proposed system, all transactions are written to blockchain which ultimately uploads the data to Interplanetary File Storage System (IPFS). The storage system returns a hash of the data which is stored on blockchain and ensures efficient, secure and reliable solution. Our system provides smart contracts along with their algorithms to show interaction of entities in the system. Furthermore, simulations and evaluation of smart contracts along with the security and vulnerability analyses are also presented in this work.","['Supply chains', 'Blockchain', 'Supply chain management', 'Agricultural products', 'Storage management']","['Accountability', 'blockchain', 'credibility', 'reputation', 'supply chain', 'traceability', 'trust']"
"With the continued development of artificial intelligence (AI) technology, research on interaction technology has become more popular. Facial expression recognition (FER) is an important type of visual information that can be used to understand a human's emotional situation. In particular, the importance of AI systems has recently increased due to advancements in research on AI systems applied to AI robots. In this paper, we propose a new scheme for FER system based on hierarchical deep learning. The feature extracted from the appearance feature-based network is fused with the geometric feature in a hierarchical structure. The appearance feature-based network extracts holistic features of the face using the preprocessed LBP image, whereas the geometric feature-based network learns the coordinate change of action units (AUs) landmark, which is a muscle that moves mainly when making facial expressions. The proposed method combines the result of the softmax function of two features by considering the error associated with the second highest emotion (Top-2) prediction result. In addition, we propose a technique to generate facial images with neutral emotion using the autoencoder technique. By this technique, we can extract the dynamic facial features between the neutral and emotional images without sequence data. We compare the proposed algorithm with the other recent algorithms for CK+ and JAFFE dataset, which are typically considered to be verified datasets in the facial expression recognition. The ten-fold cross validation results show 96.46% of accuracy in the CK+ dataset and 91.27% of accuracy in the JAFFE dataset. When comparing with other methods, the result of the proposed hierarchical deep network structure shows up to about 3% of the accuracy improvement and 1.3% of average improvement in CK+ dataset, respectively. In JAFFE datasets, up to about 7% of the accuracy is enhanced, and the average improvement is verified by about 1.5%.","['Feature extraction', 'Face recognition', 'Face', 'Deep learning', 'Emotion recognition', 'Data mining']","['Artificial intelligence (AI)', 'facial expression recognition (FER)', 'emotion recognition', 'deep learning', 'LBP feature', 'geometric feature', 'convolutional neural network (CNN)']"
"Attention deficit hyperactivity disorder (ADHD) is one of the most common mental health disorders. As a neuro development disorder, neuroimaging technologies, such as magnetic resonance imaging (MRI), coupled with machine learning algorithms, are being increasingly explored as biomarkers in ADHD. Among various machine learning methods, deep learning has demonstrated excellent performance on many imaging tasks. With the availability of publically-available, large neuroimaging data sets for training purposes, deep learning-based automatic diagnosis of psychiatric disorders can become feasible. In this paper, we develop a deep learning-based ADHD classification method via 3-D convolutional neural networks (CNNs) applied to MRI scans. Since deep neural networks may utilize millions of parameters, even the large number of MRI samples in pooled data sets is still relatively limited if one is to learn discriminative features from the raw data. Instead, here we propose to first extract meaningful 3-D low-level features from functional MRI (fMRI) and structural MRI (sMRI) data. Furthermore, inspired by radiologists' typical approach for examining brain images, we design a 3-D CNN model to investigate the local spatial patterns of MRI features. Finally, we discover that brain functional and structural information are complementary, and design a multi-modality CNN architecture to combine fMRI and sMRI features. Evaluations on the hold-out testing data of the ADHD-200 global competition shows that the proposed multi-modality 3-D CNN approach achieves the state-of-the-art accuracy of 69.15% and outperforms reported classifiers in the literature, even with fewer training samples. We suggest that multi-modality classification will be a promising direction to find potential neuroimaging biomarkers of neuro development disorders.","['Feature extraction', 'Three-dimensional displays', 'Testing', 'Training', 'Neuroimaging', 'Biological neural networks']","['Attention deficit hyperactive disorder', '3D CNN', 'magnetic resonance imaging', 'multi-modality analysis']"
"With the popularity and development of network technology and the Internet, intrusion detection systems (IDSs), which can identify attacks, have been developed. Traditional intrusion detection algorithms typically employ mining association rules to identify intrusion behaviors. However, they fail to fully extract the characteristic information of user behaviors and encounter various problems, such as high false alarm rate (FAR), poor generalization capability, and poor timeliness. In this paper, we propose a network intrusion detection model based on a convolutional neural network-IDS (CNN-IDS). Redundant and irrelevant features in the network traffic data are first removed using different dimensionality reduction methods. Features of the dimensionality reduction data are automatically extracted using the CNN, and more effective information for identifying intrusion is extracted by supervised learning. To reduce the computational cost, we convert the original traffic vector format into an image format and use a standard KDD-CUP99 dataset to evaluate the performance of the proposed CNN model. The experimental results indicate that the AC, FAR, and timeliness of the CNN-IDS model are higher than those of traditional algorithms. Therefore, the model we propose has not only research significance but also practical value.","['Intrusion detection', 'Feature extraction', 'Convolution', 'Data models', 'Machine learning', 'Principal component analysis', 'Data mining']","['Communication technology', 'convolutional neural network', 'data dimensionality reduction', 'intrusion detection']"
"A smart factory is a highly digitized and connected production facility that relies on smart manufacturing. Additionally, artificial intelligence is the core technology of smart factories. The use of machine learning and deep learning algorithms has produced fruitful results in many fields like image processing, speech recognition, fault detection, object detection, or medical sciences. With the increment in the use of smart machinery, the faults in the machinery equipment are expected to increase. Machinery fault detection and diagnosis through various deep learning algorithms has increased day by day. Many types of research have been done and published using both open-source and closed-source datasets, implementing the deep learning algorithms. Out of many publicly available datasets, Case Western Reserve University (CWRU) bearing dataset has been widely used to detect and diagnose machinery bearing fault and is accepted as a standard reference for validating the models. This paper summarizes the recent works which use the CWRU bearing dataset in machinery fault detection and diagnosis employing deep learning algorithms. We have reviewed the published works and presented the working algorithm, result, and other necessary details in this paper. This paper, we believe, can be of good help for future researchers to start their work on machinery fault detection and diagnosis using the CWRU dataset.","['Fault detection', 'Machinery', 'Deep learning', 'Vibrations', 'Frequency-domain analysis', 'Wavelet transforms']","['Bearing', 'deep learning', 'machine learning', 'machinery fault detection and diagnosis', 'CWRU dataset']"
"In this paper, we propose a Blockchain-based infrastructure to support security- and privacy-oriented spatio-temporal smart contract services for the sustainable Internet of Things (IoT)-enabled sharing economy in mega smart cities. The infrastructure leverages cognitive fog nodes at the edge to host and process off loaded geo-tagged multimedia payload and transactions from a mobile edge and IoT nodes, uses AI for processing and extracting significant event information, produces semantic digital analytics, and saves results in Blockchain and decentralized cloud repositories to facilitate sharing economy services. The framework offers a sustainable incentive mechanism, which can potentially support secure smart city services, such as sharing economy, smart contracts, and cyber-physical interaction with Blockchain and IoT. Our unique contribution is justified by detailed system design and implementation of the framework.","['Sharing economy', 'Blockchain', 'Smart cities', 'Cognitive systems', 'Security', 'Business']","['Sharing economy', 'cognitive processing at the edge', 'mobile edge computing', 'Blockchain', 'smart city']"
"A feature of the Internet of Things (IoT) is that some users in the system need to be served quickly for small packet transmission. To address this requirement, a new multiple-input multiple-output non-orthogonal multiple access (MIMO-NOMA) scheme is designed in this paper, where one user is served with its quality of service requirement strictly met, and the other user is served opportunistically by using the NOMA concept. The novelty of this new scheme is that it confronts the challenge that the existing MIMO-NOMA schemes rely on the assumption that users' channel conditions are different, a strong assumption which may not be valid in practice. The developed precoding and detection strategies can effectively create a significant difference between the users' effective channel gains, and therefore, the potential of NOMA can be realized even if the users' original channel conditions are similar. Analytical and numerical results are provided to demonstrate the performance of the proposed MIMO-NOMA scheme.","['Internet of Things', 'MIMO', 'Precoding', 'Quality of service', 'Packet switching', 'NOMA']","['Non-orthogonal multiple access (NOMA)', 'multiple-input multiple-output (MIMO)', 'QR decomposition', 'MIMO precoding', 'power allocation']"
"The prognostic and health management (PHM) of lithium-ion batteries has received increasing attention in recent years. The remaining useful life (RUL) prediction and state of health (SOH) monitoring are two important parts in PHM of the lithium-ion battery. Nowadays, the development of signal processing technology and neural network technology introduces new data-driven methods to RUL prediction and SOH monitoring of the lithium-ion battery. This paper presents a neural-network-based method that combines long short-term memory (LSTM) network with particle swarm optimization and attention mechanism for RUL prediction and SOH monitoring of the lithium-ion battery. Before predicting RUL of the lithium-ion battery, the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) is utilized for the raw data denoising, which can improve the accuracy of prediction. A real-life cycle dataset of lithium-ion batteries from NASA is used to evaluate the proposed method, and the experiment results show that when compared with traditional methods, the proposed method has higher accuracy.","['Lithium-ion batteries', 'Monitoring', 'Prognostics and health management', 'Support vector machines', 'Data models', 'Load modeling']","['Lithium-ion battery', 'prognostic and health management (PHM)', 'long short-term memory (LSTM)', 'attention mechanism']"
"Optimization of deep learning is no longer an imminent problem, due to various gradient descent methods and the improvements of network structure, including activation functions, the connectivity style, and so on. Then the actual application depends on the generalization ability, which determines whether a network is effective. Regularization is an efficient way to improve the generalization ability of deep CNN, because it makes it possible to train more complex models while maintaining a lower overfitting. In this paper, we propose to optimize the feature boundary of deep CNN through a two-stage training method (pre-training process and implicit regularization training process) to reduce the overfitting problem. In the pre-training stage, we train a network model to extract the image representation for anomaly detection. In the implicit regularization training stage, we re-train the network based on the anomaly detection results to regularize the feature boundary and make it converge in the proper position. Experimental results on five image classification benchmarks show that the two-stage training method achieves a state-of-the-art performance and that it, in conjunction with more complicated anomaly detection algorithm, obtains better results. Finally, we use a variety of strategies to explore and analyze how implicit regularization plays a role in the two-stage training process. Furthermore, we explain how implicit regularization can be interpreted as data augmentation and model ensemble.","['Training', 'Anomaly detection', 'Feature extraction', 'Image representation', 'Production', 'Principal component analysis', 'Machine learning']","['Deep CNN', 'image classification', 'overfitting', 'generalization', 'anomaly detection', 'implicit regularization']"
"Feature selection is a critical and prominent task in machine learning. To reduce the dimension of the feature set while maintaining the accuracy of the performance is the main aim of the feature selection problem. Various methods have been developed to classify the datasets. However, metaheuristic algorithms have achieved great attention in solving numerous optimization problem. Therefore, this paper presents an extensive literature review on solving feature selection problem using metaheuristic algorithms which are developed in the ten years (2009-2019). Further, metaheuristic algorithms have been classified into four categories based on their behaviour. Moreover, a categorical list of more than a hundred metaheuristic algorithms is presented. To solve the feature selection problem, only binary variants of metaheuristic algorithms have been reviewed and corresponding to their categories, a detailed description of them explained. The metaheuristic algorithms in solving feature selection problem are given with their binary classification, name of the classifier used, datasets and the evaluation metrics. After reviewing the papers, challenges and issues are also identified in obtaining the best feature subset using different metaheuristic algorithms. Finally, some research gaps are also highlighted for the researchers who want to pursue their research in developing or modifying metaheuristic algorithms for classification. For an application, a case study is presented in which datasets are adopted from the UCI repository and numerous metaheuristic algorithms are employed to obtain the optimal feature subset.","['Feature extraction', 'Search problems', 'Biomedical imaging', 'Task analysis', 'Particle swarm optimization', 'Measurement', 'Machine learning algorithms']","['Binary variants', 'classification', 'feature selection', 'literature review', 'metaheuristic algorithms']"
"This paper presents research challenges on security and privacy issues in the field of green IoT-based agriculture. We start by describing a four-tier green IoT-based agriculture architecture and summarizing the existing surveys that deal with smart agriculture. Then, we provide a classification of threat models against green IoT-based agriculture into five categories, including, attacks against privacy, authentication, confidentiality, availability, and integrity properties. Moreover, we provide a taxonomy and a side-by-side comparison of the state-of-the-art methods toward secure and privacy-preserving technologies for IoT applications and how they will be adapted for green IoT-based agriculture. In addition, we analyze the privacy-oriented blockchain-based solutions as well as consensus algorithms for IoT applications and how they will be adapted for green IoT-based agriculture. Based on the current survey, we highlight open research challenges and discuss possible future research directions in the security and privacy of green IoT-based agriculture.","['Internet of Things', 'Security', 'Privacy', 'Green products', 'Production', 'Agricultural products']","['Security', 'privacy', 'authentication', 'blockchain', 'smart agriculture', 'greenhouse']"
"Industry 4.0 is a concept devised for improving the way modern factories operate through the use of some of the latest technologies, like the ones used for creating the Industrial Internet of Things (IIoT), robotics, or Big Data applications. One of such technologies is blockchain, which is able to add trust, security, and decentralization to different industrial fields. This article focuses on analyzing the benefits and challenges that arise when using blockchain and smart contracts to develop Industry 4.0 applications. In addition, this paper presents a thorough review of the most relevant blockchain-based applications for Industry 4.0 technologies. Thus, its aim is to provide a detailed guide for the future Industry 4.0 developers that allows for determining how the blockchain can enhance the next generation of cybersecure industrial applications.","['Blockchain', 'Industries', 'Smart manufacturing', 'Production facilities', 'Next generation networking', 'Internet', 'Computer crime']","['Blockchain', 'Industry 4.0', 'cybersecurity', 'IIoT', 'smart factory', 'industrial augmented reality', 'cyber-physical system', 'fog and edge computing', 'cloud computing', 'Big Data']"
"Cloud Computing provides an effective platform for executing large-scale and complex workflow applications with a pay-as-you-go model. Nevertheless, various challenges, especially its optimal scheduling for multiple conflicting objectives, are yet to be addressed properly. The existing multi-objective workflow scheduling approaches are still limited in many ways, e.g., encoding is restricted by prior experts’ knowledge when handling a dynamic real-time problem, which strongly influences the performance of scheduling. In this paper, we apply a deep-Q-network model in a multi-agent reinforcement learning setting to guide the scheduling of multi-workflows over infrastructure-as-a-service clouds. To optimize multi-workflow completion time and user’s cost, we consider a Markov game model, which takes the number of workflow applications and heterogeneous virtual machines as state input and the maximum completion time and cost as rewards. The game model is capable of seeking for correlated equilibrium between make-span and cost criteria without prior experts’ knowledge and converges to the correlated equilibrium policy in a dynamic real-time environment. To validate our proposed approach, we conduct extensive case studies based on multiple well-known scientific workflow templates and Amazon EC2 cloud. The experimental results clearly suggest that our proposed approach outperforms traditional ones, e.g., non-dominated sorting genetic algorithm-II, multi-objective particle swarm optimization, and game-theoretic-based greedy algorithms, in terms of optimality of scheduling plans generated.","['Optimal scheduling', 'Games', 'Task analysis', 'Cloud computing', 'Reinforcement learning', 'Markov processes', 'Scheduling']","['Multi-objective workflow scheduling', 'deep-Q-network (DQN)', 'multi-agent reinforcement learning (MARL)', 'infrastructure-as-a-service (IaaS) cloud', 'quality-of-service (QoS)']"
"The volatility and uncertainty of wind power often affect the quality of electric energy, the security of the power grid, the stability of the power system, and the fluctuation of the power market. In this case, the research on wind power forecasting is of great significance for ensuring the better development of wind power grids and the higher quality of electric energy. Therefore, a lot of new forecasting methods have been put forward. In this paper, a new forecasting model based on a convolution neural network and LightGBM is constructed. The procedure is shown as follows. First, we construct new feature sets by analyzing the characteristics of the raw data on the time series from the wind field and adjacent wind field. Second, the convolutional neural network (CNN) is proposed to extract information from input data, and the network parameters are adjusted by comparing the actual results. Third, in consideration of the limitations of the single-convolution model in predicting wind power, we innovatively integrated the LightGBM classification algorithm at the model to improve the forecasting accuracy and robustness. Finally, compared with the existing support vector machines, LightGBM, and CNN, the fusion model has better performance in accuracy and efficiency.","['Forecasting', 'Wind power generation', 'Convolution', 'Feature extraction', 'Predictive models', 'Data mining', 'Kernel']","['Convolutional neural network', 'fusion model', 'LightGBM', 'ultra-short-term wind power forecasting', 'wind energy']"
"More and more network traffic data have brought great challenge to traditional intrusion detection system. The detection performance is tightly related to selected features and classifiers, but traditional feature selection algorithms and classification algorithms can't perform well in massive data environment. Also the raw traffic data are imbalanced, which has a serious impact on the classification results. In this paper, we propose a novel network intrusion detection model utilizing convolutional neural networks (CNNs). We use CNN to select traffic features from raw data set automatically, and we set the cost function weight coefficient of each class based on its numbers to solve the imbalanced data set problem. The model not only reduces the false alarm rate (FAR) but also improves the accuracy of the class with small numbers. To reduce the calculation cost further, we convert the raw traffic vector format into image format. We use the standard NSL-KDD data set to evaluate the performance of the proposed CNN model. The experimental results show that the accuracy, FAR, and calculation cost of the proposed model perform better than traditional standard algorithms. It is an effective and reliable solution for the intrusion detection of a massive network.","['Intrusion detection', 'Feature extraction', 'Training', 'Data models', 'Data preprocessing', 'Convolutional neural networks']","['Network intrusion detection', 'convolutional neural networks', 'image data format conversion', 'cost function weight', 'imbalanced dataset']"
"Nowadays, learning-based modeling system is adopted to establish an accurate prediction model for renewable energy resources. Computational Intelligence (CI) methods have become significant tools in production and optimization of renewable energies. The complexity of this type of energy lies in its coverage of large volumes of data and variables which have to be analyzed carefully. The present study discusses different types of Deep Learning (DL) algorithms applied in the field of solar and wind energy resources and evaluates their performance through a novel taxonomy. It also presents a comprehensive state-of-the-art of the literature leading to an assessment and performance evaluation of DL techniques as well as a discussion about major challenges and opportunities for comprehensive research. Based on results, differences on accuracy, robustness, precision values as well as the generalization ability are the most common challenges for the employment of DL techniques. In case of big dataset, the performance of DL techniques is significantly higher than that for other CI techniques. However, using and developing hybrid DL techniques with other optimization techniques in order to improve and optimize the structure of the techniques is preferably emphasized. In all cases, hybrid networks have better performance compared with single networks, because hybrid techniques take the advantages of two or more methods for preparing an accurate prediction. It is recommended to use hybrid methods in DL techniques.","['Wind energy', 'Solar energy', 'Renewable energy sources', 'Wind', 'Neural networks', 'Mathematical model', 'Computational modeling']","['Big dataset', 'deep learning', 'modeling', 'optimizing', 'solar energy', 'wind energy']"
"As the technique that determines the position of a target device based on wireless measurements, Wi-Fi localization is attracting increasing attention due to its numerous applications and the widespread deployment of Wi-Fi infrastructure. In this paper, we propose ConFi, the first convolutional neural network (CNN)-based Wi-Fi localization algorithm. Channel state information (CSI), which contains more position related information than traditional received signal strength, is organized into a time-frequency matrix that resembles image and utilized as the feature for localization. The ConFi models localization as a classification problem and addresses it with a five layer CNN that consists of three convolutional layers and two fully connected layers. The ConFi has a training stage and a localization stage. In the training stage, the CSI is collected at a number of reference points (RPs) and used to train the CNN via stochastic gradient descent algorithm. In the localization stage, the CSI of the target device is fed to the CNN and the localization result is calculated as the weighted centroid of the RPs with high output value. Extensive experiments are conducted to select appropriate parameters for the CNN and demonstrate the superior performance of the ConFi over existing methods.","['Antennas', 'Wireless fidelity', 'Artificial neural networks', 'Training', 'Antenna measurements', 'Feature extraction', 'Fading channels']","['Wi-Fi localization', 'channel state information', 'convolutional neural network', 'pattern recognition']"
"5G is the next generation cellular network that aspires to achieve substantial improvement on quality of service, such as higher throughput and lower latency. Edge computing is an emerging technology that enables the evolution to 5G by bringing cloud capabilities near to the end users (or user equipment, UEs) in order to overcome the intrinsic problems of the traditional cloud, such as high latency and the lack of security. In this paper, we establish a taxonomy of edge computing in 5G, which gives an overview of existing state-of-the-art solutions of edge computing in 5G on the basis of objectives, computational platforms, attributes, 5G functions, performance measures, and roles. We also present other important aspects, including the key requirements for its successful deployment in 5G and the applications of edge computing in 5G. Then, we explore, highlight, and categorize recent advancements in edge computing for 5G. By doing so, we reveal the salient features of different edge computing paradigms for 5G. Finally, open research issues are outlined.","['Edge computing', '5G mobile communication', 'Cloud computing', 'Real-time systems', 'Servers', 'Quality of service', 'Throughput']","['5G', 'cloud computing', 'edge computing', 'fog computing']"
"Emotion recognition represents the position and motion of facial muscles. It contributes significantly in many fields. Current approaches have not obtained good results. This paper aimed to propose a new emotion recognition system based on facial expression images. We enrolled 20 subjects and let each subject pose seven different emotions: happy, sadness, surprise, anger, disgust, fear, and neutral. Afterward, we employed biorthogonal wavelet entropy to extract multiscale features, and used fuzzy multiclass support vector machine to be the classifier. The stratified cross validation was employed as a strict validation model. The statistical analysis showed our method achieved an overall accuracy of 96.77±0.10%. Besides, our method is superior to three state-of-the-art methods. In all, this proposed method is efficient.","['Support vector machines', 'Wavelet transforms', 'Entropy', 'Feature extraction', 'Face recognition', 'Low-pass filters', 'Fuzzy logic', 'Emotion recognition']","['Facial emotion recognition', 'facial expression', 'biorthogonal wavelet entropy', 'support vector machine', 'fuzzy logic']"
"In the last few years, Internet of Things, Cloud computing, Edge computing, and Fog computing have gained a lot of attention in both industry and academia. However, a clear and neat definition of these computing paradigms and their correlation is hard to find in the literature. This makes it difficult for researchers new to this area to get a concrete picture of these paradigms. This work tackles this deficiency, representing a helpful resource for those who will start next. First, we show the evolution of modern computing paradigms and related research interest. Then, we address each paradigm, neatly delineating its key points and its relation with the others. Thereafter, we extensively address Fog computing, remarking its outstanding role as the glue between IoT, Cloud, and Edge computing. In the end, we briefly present open challenges and future research directions for IoT, Cloud, Edge, and Fog computing.","['Cloud computing', 'Edge computing', 'Internet of Things', 'Market research', 'Computer architecture', 'Libraries']","['Fog computing', 'cloud computing', 'edge computing', 'Internet of Things', 'mobile cloud computing', 'mobile edge computing']"
"The advancement of technologies over years has poised Internet of Things (IoT) to scoop out untapped information and communication technology opportunities. It is anticipated that IoT will handle the gigantic network of billions of devices to deliver plenty of smart services to the users. Undoubtedly, this will make our life more resourceful but at the cost of high energy consumption and carbon footprint. Consequently, there is a high demand for green communication to reduce energy consumption, which requires optimal resource availability and controlled power levels. In contrast to this, IoT devices are constrained in terms of resources-memory, power, and computation. Low power wide area (LPWA) technology is a response to the need for efficient utilization of power resource, as it evinces characteristics such as the capability to proffer low power connectivity to a huge number of devices spread over wide geographical areas at low cost. Various LPWA technologies, such as LoRa and SigFox, exist in the market, offering a proficient solution to the users. However, in order to abstain the need of new infrastructure (like base station) that is required for proprietary technologies, a new cellular-based licensed technology, narrowband IoT (NBIoT), is introduced by 3GPP in Rel-13. This technology presents a good candidature to handle LPWA market because of its characteristics like enhanced indoor coverage, low power consumption, latency insensitivity, and massive connection support towards NBIoT. This survey presents a profound view of IoT and NBIoT, subsuming their technical features, resource allocation, and energy-efficiency techniques and applications. The challenges that hinder the NBIoT path to success are also identified and discussed. In this paper, two novel energy-efficient techniques “zonal thermal pattern analysis” and energy-efficient adaptive health monitoring system have been proposed towards green IoT.","['Energy efficiency', 'Internet of Things', 'Power demand', 'Resource management', 'Agriculture', 'Computer architecture', 'Monitoring']","['Internet of Things (IoT)', 'narrowband Internet of Things (NBIoT)', 'low power wide area network (LPWAN)', 'green communication', 'smart agriculture', 'smart health']"
"Today, internet and device ubiquity are paramount in individual, formal and societal considerations. Next generation communication technologies, such as Blockchains (BC), Internet of Things (IoT), cloud computing, etc. offer limitless capabilities for different applications and scenarios including industries, cities, healthcare systems, etc. Sustainable integration of healthcare nodes (i.e. devices, users, providers, etc.) resulting in healthcare IoT (or simply IoHT) provides a platform for efficient service delivery for the benefit of care givers (doctors, nurses, etc.) and patients. Whereas confidentiality, accessibility and reliability of medical data are accorded high premium in IoHT, semantic gaps and lack of appropriate assets or properties remain impediments to reliable information exchange in federated trust management frameworks. Consequently, We propose a Blockchain Decentralised Interoperable Trust framework (DIT) for IoT zones where a smart contract guarantees authentication of budgets and Indirect Trust Inference System (ITIS) reduces semantic gaps and enhances trustworthy factor (TF) estimation via the network nodes and edges. Our DIT IoHT makes use of a private Blockchain ripple chain to establish trustworthy communication by validating nodes based on their inter-operable structure so that controlled communication required to solve fusion and integration issues are facilitated via different zones of the IoHT infrastructure. Further, C# implementation using Ethereum and ripple Blockchain are introduced as frameworks to associate and aggregate requests over trusted zones.","['Semantics', 'Ontologies', 'Internet of Things', 'Interoperability', 'Data models', 'Sensors', 'Medical services']","['Trustworthness', 'blockchain', 'security', 'interoperability', 'sustainable healthcare IoT systems']"
"In this paper, an edge computing system for IoT-based (Internet of Things) smart grids is proposed to overcome the drawbacks in the current cloud computing paradigm in power systems, where many problems have yet to be addressed such as fully realizing the requirements of high bandwidth with low latency. The new system mainly introduces edge computing in the traditional cloud-based power system and establishes a new hardware and software architecture. Therefore, a considerable amount of data generated in the electrical grid will be analyzed, processed, and stored at the edge of the network. Aided with edge computing paradigm, the IoT-based smart grids will realize the connection and management of substantial terminals, provide the real-time analysis and processing of massive data, and foster the digitalization of smart grids. In addition, we propose a privacy protection strategy via edge computing, data prediction strategy, and preprocessing strategy of hierarchical decision-making based on task grading (HDTG) for the IoT-based smart girds. The effectiveness of our proposed approaches has been demonstrated via the numerical simulations.","['Smart grids', 'Edge computing', 'Cloud computing', 'Industries', 'Sensors', 'Real-time systems']","['Edge computing', 'IoT-based smart grids', 'data prediction', 'artificial intelligence', 'data privacy protection', 'cloud computing']"
"Gesture recognition aims to recognize meaningful movements of human bodies, and is of utmost importance in intelligent human-computer/robot interactions. In this paper, we present a multimodal gesture recognition method based on 3-D convolution and convolutional long-short-term-memory (LSTM) networks. The proposed method first learns short-term spatiotemporal features of gestures through the 3-D convolutional neural network, and then learns long-term spatiotemporal features by convolutional LSTM networks based on the extracted short-term spatiotemporal features. In addition, fine-tuning among multimodal data is evaluated, and we find that it can be considered as an optional skill to prevent overfitting when no pre-trained models exist. The proposed method is verified on the ChaLearn LAP large-scale isolated gesture data set (IsoGD) and the Sheffield Kinect gesture (SKIG) data set. The results show that our proposed method can obtain the state-of-the-art recognition accuracy (51.02% on the validation set of IsoGD and 98.89% on SKIG).","['Gesture recognition', 'Three-dimensional displays', 'Spatiotemporal phenomena', 'Feature extraction', 'Neural networks', 'Convolution', 'Solid modeling']","['3-D convolution', 'convolutional LSTM', 'gesture recognition', 'multimodal']"
"Blockchains offer a decentralized, immutable and verifiable ledger that can record transactions of digital assets, provoking a radical change in several innovative scenarios, such as smart cities, eHealth or eGovernment. However, blockchains are subject to different scalability, security and potential privacy issues, such as transaction linkability, crypto-keys management (e.g. recovery), on-chain data privacy, or compliance with privacy regulations (e.g. GDPR). To deal with these challenges, novel privacy-preserving solutions for blockchain based on crypto-privacy techniques are emerging to empower users with mechanisms to become anonymous and take control of their personal data during their digital transactions of any kind in the ledger, following a Self-Sovereign Identity (SSI) model. In this sense, this paper performs a systematic review of the current state of the art on privacy-preserving research solutions and mechanisms in blockchain, as well as the main associated privacy challenges in this promising and disrupting technology. The survey covers privacy techniques in public and permissionless blockchains, e.g. Bitcoin and Ethereum, as well as privacy-preserving research proposals and solutions in permissioned and private blockchains. Diverse blockchain scenarios are analyzed, encompassing, eGovernment, eHealth, cryptocurrencies, Smart cities, and Cooperative ITS.","['Blockchain', 'Privacy', 'Data privacy', 'Proposals', 'Bitcoin']","['Blockchain', 'privacy', 'security', 'survey', 'bitcoin']"
"In recent years, multiple-input-multiple-output (MIMO) antennas with the ability to radiate waves in more than one pattern and polarization play a great role in modern telecommunication systems. This paper provides a theoretical review of different mutual coupling reduction techniques in MIMO antenna systems. The increase in the mutual coupling can affect the antenna characteristics drastically and therefore degrades the performance of the MIMO systems. It is possible to improve the performance partially by calibrating the mutual coupling in the digital domain. However, the simple and effective approach is to use the techniques, such as defected ground structure, parasitic or slot element, complementary split ring resonator, and decoupling networks which can overcome the mutual coupling effects by means of physical implementation. An extensive discussion on the basis of different mutual coupling reduction techniques, their examples, and comparative study is still rare in the literature. Therefore, in this paper, different MIMO antenna design techniques and all of their mutual coupling reduction techniques through various structures and mechanisms are presented with multiple examples and characteristics comparison.","['Mutual coupling', 'MIMO communication', 'Antenna radiation patterns', 'Correlation', 'Correlation coefficient', 'Topology']","['Diversity gain', 'ECC', 'MIMO', 'mutual coupling', 'PCB', 'UWB', 'WLAN']"
"The inherent flexibility of hierarchical structure scheme with main-servo loop control structure is proposed to the problem of integrated chassis control system for the vehicle. It includes both main loop, which calculates and allocates the aim force using the optimal robust control algorithm and servo loop control systems, which track and achieve the target force using the onboard independent brake actuators. In fact, for the brake actuator, the aim friction is obtained by tracking the corresponding slip ratio of target force. For the coefficient of tire-road friction varying with different road surface, to get the nonlinear time-varying target slip ratio, the most famous quasi-static magic formula is proposed to estimate and predict real-time coefficient of different road surface and the constrained hybrid genetic algorithm (GA) is used to identify the key parameters of the magic formula on-line. Then, a self-tuning longitudinal slip ratio controller (LSC) based on the nonsingular and fast terminal sliding mode (NFTSM) control method is designed to improve the tracking accuracy and response speed of the actuators. At last, the proposed integrated chassis control strategies and the self-tuning control strategies are verified by computer simulations.","['Friction', 'Force', 'Tires', 'Brakes', 'Genetic algorithms', 'Vehicle dynamics']","['Main-servo loop control structure', 'parameters identification', 'tire-road friction control', 'constrained hybrid genetic algorithm', 'nonlinear sliding mode control']"
"Industrial cyber-physical systems (ICPSs) are the backbones of Industry 4.0 and as such, have become a core transdisciplinary area of research, both in industry and academia. New challenges brought about by the growing scale and complexity of systems, insufficient information exchange, and the exploitation of knowledge available have started threatening the overall system safety and stability. This work is motivated by these challenges and the strategic and practical demands of developing ICPSs for safety critical systems such as the intelligent factory and the smart grid. It investigates the current status of research in ICPS monitoring and control, and reviews the recent advances in monitoring, fault diagnosis, and control approaches based on data-driven realization, which can take full advantage of the abundant data available from past observations and those collected online in realtime. The practical requirements in the typical ICPS applications are summarized as the major issues to be addressed for the monitoring and the safety control tasks. The key challenges and the research directions are proposed as references to the future work.","['Monitoring', 'Sensors', 'Iterative closest point algorithm', 'Observers', 'Smart grids', 'Fault diagnosis', 'Cyber-physical systems']","['Cyber-physical system (CPS)', 'data-driven', 'system monitoring', 'fault diagnosis', 'smart grid', 'plug-and-play control']"
"Q-learning is arguably one of the most applied representative reinforcement learning approaches and one of the off-policy strategies. Since the emergence of Q-learning, many studies have described its uses in reinforcement learning and artificial intelligence problems. However, there is an information gap as to how these powerful algorithms can be leveraged and incorporated into general artificial intelligence workflow. Early Q-learning algorithms were unsatisfactory in several aspects and covered a narrow range of applications. It has also been observed that sometimes, this rather powerful algorithm learns unrealistically and overestimates the action values hence abating the overall performance. Recently with the general advances of machine learning, more variants of Q-learning like Deep Q-learning which combines basic Q learning with deep neural networks have been discovered and applied extensively. In this paper, we thoroughly explain how Q-learning evolved by unraveling the mathematical complexities behind it as well its flow from reinforcement learning family of algorithms. Improved variants are fully described, and we categorize Q-learning algorithms into single-agent and multi-agent approaches. Finally, we thoroughly investigate up-to-date research trends and key applications that leverage Q-learning algorithms.","['Reinforcement learning', 'Mathematical model', 'Classification algorithms', 'Machine learning algorithms', 'Market research']","['Reinforcement learning', 'Q-learning', 'single-agent', 'multi-agent']"
"Intrusion detection systems (IDSs) play a pivotal role in computer security by discovering and repealing malicious activities in computer networks. Anomaly-based IDS, in particular, rely on classification models trained using historical data to discover such malicious activities. In this paper, an improved IDS based on hybrid feature selection and two-level classifier ensembles are proposed. A hybrid feature selection technique comprising three methods, i.e., particle swarm optimization, ant colony algorithm, and genetic algorithm, is utilized to reduce the feature size of the training datasets (NSL-KDD and UNSW-NB15 are considered in this paper). Features are selected based on the classification performance of a reduced error pruning tree (REPT) classifier. Then, a two-level classifier ensemble based on two meta learners, i.e., rotation forest and bagging, is proposed. On the NSL-KDD dataset, the proposed classifier shows 85.8% accuracy, 86.8% sensitivity, and 88.0% detection rate, which remarkably outperform other classification techniques recently proposed in the literature. The results regarding the UNSW-NB15 dataset also improve the ones achieved by several state-of-the-art techniques. Finally, to verify the results, a two-step statistical significance test is conducted. This is not usually considered by the IDS research thus far and, therefore, adds value to the experimental results achieved by the proposed classifier.","['Feature extraction', 'Internet of Things', 'Training', 'Intrusion detection', 'Bagging', 'Anomaly detection']","['Two-stage meta classifier', 'network anomaly detection', 'hybrid feature selection', 'intrusion detection system', 'statistical significance test']"
"Rotating machines have been widely used in industrial engineering. The fault diagnosis of rotating machines plays a vital important role to reduce the catastrophic failures and heavy economic loss. However, the measured vibration signal of rotating machinery often represents non-linear and non-stationary characteristics, resulting in difficulty in the fault feature extraction. As a statistical measure, entropy can quantify the complexity and detect dynamic change through taking into account the non-linear behavior of time series. Therefore, entropy can be served as a promising tool to extract the dynamic characteristics of rotating machines. Recently, many studies have applied entropy in fault diagnosis of rotating machinery. This paper aims to investigate the applications of entropy for the fault characteristics extraction of rotating machines. First, various entropy methods are briefly introduced. Its foundation, application, and some improvements are described and discussed. The review is divided into eight parts: Shannon entropy, Rényi entropy, approximate entropy, sample entropy, fuzzy entropy, permutation entropy, and other entropy methods. In each part, we will review the applications using the original entropy method and the improved entropy methods, respectively. In the end, a summary and some research prospects are given.","['Entropy', 'Time series analysis', 'Fault diagnosis', 'Complexity theory', 'Rotating machines', 'Vibrations']","['Entropy', 'fault diagnosis', 'fault feature extraction', 'rotating machinery', 'condition-based maintenance']"
"Federated learning is a newly emerged distributed machine learning paradigm, where the clients are allowed to individually train local deep neural network (DNN) models with local data and then jointly aggregate a global DNN model at the central server. Vehicular edge computing (VEC) aims at exploiting the computation and communication resources at the edge of vehicular networks. Federated learning in VEC is promising to meet the ever-increasing demands of artificial intelligence (AI) applications in intelligent connected vehicles (ICV). Considering image classification as a typical AI application in VEC, the diversity of image quality and computation capability in vehicular clients potentially affects the accuracy and efficiency of federated learning. Accordingly, we propose a selective model aggregation approach, where “fine” local DNN models are selected and sent to the central server by evaluating the local image quality and computation capability. Regarding the implementation of model selection, the central server is not aware of the image quality and computation capability in the vehicular clients, whose privacy is protected under such a federated learning framework. To overcome this information asymmetry, we employ two-dimension contract theory as a distributed framework to facilitate the interactions between the central server and vehicular clients. The formulated problem is then transformed into a tractable problem through successively relaxing and simplifying the constraints, and eventually solved by a greedy algorithm. Using two datasets, i.e., MNIST and BelgiumTSC, our selective model aggregation approach is demonstrated to outperform the original federated averaging (FedAvg) approach in terms of accuracy and efficiency. Meanwhile, our approach also achieves higher utility at the central server compared with the baseline approaches.","['Computational modeling', 'Servers', 'Image quality', 'Training', 'Contracts', 'Artificial intelligence', 'Data models']","['Federated learning', 'vehicular edge computing', 'model aggregation', 'contract theory']"
"With the significant development of practicability in deep learning and the ultra-high-speed information transmission rate of 5G communication technology will overcome the barrier of data transmission on the Internet of Vehicles, automated driving is becoming a pivotal technology affecting the future industry. Sensors are the key to the perception of the outside world in the automated driving system and whose cooperation performance directly determines the safety of automated driving vehicles. In this survey, we mainly discuss the different strategies of multi-sensor fusion in automated driving in recent years. The performance of conventional sensors and the necessity of multi-sensor fusion are analyzed, including radar, LiDAR, camera, ultrasonic, GPS, IMU, and V2X. According to the differences in the latest studies, we divide the fusion strategies into four categories and point out some shortcomings. Sensor fusion is mainly applied for multi-target tracking and environment reconstruction. We discuss the method of establishing a motion model and data association in multi-target tracking. At the end of the paper, we analyzed the deficiencies in the current studies and put forward some suggestions for further improvement in the future. Through this investigation, we hope to analyze the current situation of multi-sensor fusion in the automated driving process and provide more efficient and reliable fusion strategies.","['Sensor fusion', 'Sensor systems', 'Sensor phenomena and characterization', 'Cameras', 'Laser radar']","['Automated driving', 'multi-sensor fusion strategy', 'multi-target tracking', 'environmental reconstruction', 'data association', 'intent analysis', 'deep learning']"
"Underwater communication remains a challenging technology via communication cables and the cost of underwater sensor network (UWSN) deployment is still very high. As an alternative, underwater wireless communication has been proposed and have received more attention in the last decade. Preliminary research indicated that the Radio Frequency (RF) and Magneto-Inductive (MI) communication achieve higher data rate in the near field communication. The optical communication achieves good performance when limited to the line-of-sight positioning. The acoustic communication allows long transmission range. However, it suffers from transmission losses and time-varying signal distortion due to its dependency on environmental properties. These latter are salinity, temperature, pressure, depth of transceivers, and the environment geometry. This paper is focused on both the acoustic and magneto-inductive communications, which are the most used technologies for underwater networking. Such as acoustic communication is employed for applications requiring long communication range while the MI is used for real-time communication. Moreover, this paper highlights the trade-off between underwater properties, wireless communication technologies, and communication quality. This can help the researcher community by providing clear insight for further research.","['Wireless communication', 'Absorption', 'Wireless sensor networks', 'Propagation losses', 'Ocean temperature', 'Acoustic communication (telecommunication)']","['Underwater wireless sensor networks', 'underwater wireless communications', 'magneto-inductive communications', 'acoustic communications', 'simultaneous wireless power', 'information transfer', 'Internet of Underwater Things']"
"Multimodal representation learning, which aims to narrow the heterogeneity gap among different modalities, plays an indispensable role in the utilization of ubiquitous multimodal data. Due to the powerful representation ability with multiple levels of abstraction, deep learning-based multimodal representation learning has attracted much attention in recent years. In this paper, we provided a comprehensive survey on deep multimodal representation learning which has never been concentrated entirely. To facilitate the discussion on how the heterogeneity gap is narrowed, according to the underlying structures in which different modalities are integrated, we category deep multimodal representation learning methods into three frameworks: joint representation, coordinated representation, and encoder-decoder. Additionally, we review some typical models in this area ranging from conventional models to newly developed technologies. This paper highlights on the key issues of newly developed technologies, such as encoder-decoder model, generative adversarial networks, and attention mechanism in a multimodal representation learning perspective, which, to the best of our knowledge, have never been reviewed previously, even though they have become the major focuses of much contemporary research. For each framework or model, we discuss its basic structure, learning objective, application scenes, key issues, advantages, and disadvantages, such that both novel and experienced researchers can benefit from this survey. Finally, we suggest some important directions for future work.","['Semantics', 'Feature extraction', 'Deep learning', 'Task analysis', 'Speech recognition', 'Data mining', 'Decoding']","['Multimodal representation learning', 'multimodal deep learning', 'deep multimodal fusion', 'multimodal translation', 'multimodal adversarial learning']"
"Although an Internet-of-Things-based smart home solution can provide an improved and better approach to healthcare management, yet its end user adoption is very low. With elderly people as the main target, these conservative users pose a serious challenge to the successful implementation of smart home healthcare services. The objective of this research was to develop and test a theoretical framework empirically for determining the core factors that can affect the elderly users' acceptance of smart home services for healthcare. Accordingly, an online survey was conducted with 254 elderly people aged 55 years and above across four Asian countries. Partial least square structural equation modeling was applied to analyze the effect of eight hypothesized predicting constructs. The user perceptions were measured on a conceptual level rather than the actual usage intention toward a specific service. Performance expectancy, effort expectancy, expert advice, and perceived trust have a positive impact on the behavioral intention. The same association is negative for technology anxiety and perceived cost. Facilitating conditions and social influence do not have any effect on the behavioral intention. The model could explain 81.4% of the total variance in the dependent variable i.e., behavioral intention. Effort expectancy is the leading predictor of smart homes for healthcare acceptance among the elderly. Together with expert advice, perceived trust, and perceived cost, these four factors represent the key influence of the elderly peoples' acceptance behavior. This paper provides the groundwork to explore the process of the actual adoption of smart home services for healthcare by the elderly people with potential future research areas.","['Senior citizens', 'Smart homes', 'Medical services', 'Wearable sensors', 'Bibliographies', 'Sensor systems']","['Elderly', 'healthcare', 'smart homes']"
"The imminent arrival of the Internet of Things (IoT), which consists of a vast number of devices with heterogeneous characteristics, means that future networks need a new architecture to accommodate the expected increase in data generation. Software defined networking (SDN) and network virtualization (NV) are two technologies that promise to cost-effectively provide the scale and versatility necessary for IoT services. In this paper, we survey the state of the art on the application of SDN and NV to IoT. To the best of our knowledge, we are the first to provide a comprehensive description of every possible IoT implementation aspect for the two technologies. We start by outlining the ways of combining SDN and NV. Subsequently, we present how the two technologies can be used in the mobile and cellular context, with emphasis on forthcoming 5G networks. Afterward, we move to the study of wireless sensor networks, arguably the current foremost example of an IoT network. Finally, we review some general SDN-NV-enabled IoT architectures, along with real-life deployments and use-cases. We conclude by giving directions for future research on this topic.","['Virtualization', 'Internet of things', 'Wireless sensor networks', 'Computer architecture', 'Software defined network', 'Wireless communication', 'Mobile computing']","['Internet of things (IoT)', 'software defined networking (SDN)', 'network virtualization (NV)', 'network functions virtualization (NFV)', '5G', 'wireless sensor network (WSN)']"
"In order to meet the intense user demands, the 5G networks are evolving, and will be available by 2020. The unfolding cellular technology has raised the energy consumption in mobile networks with the carbon footprint surging to alarming rates. This is causing an adverse effect on the environment and human health. Addressing these aspects, this paper presents a survey on techniques for making the next generation cellular networks GREEN. A number of technologies form a part of the 5G networks, in order to support the drastic user demands, and are receiving substantial attention from the perspective of green communication. These include device-to-device communication, spectrum sharing, ultra dense networks, massive MIMO, and the Internet of Things. Also, a prime concern in the current scenario is the battery life of the mobile terminals. For enhancing the battery life of the user terminals, a proposal is given in this paper, with spectrum sharing as its basis, to overcome the energy crunch. Major research challenges have been discussed, and the ongoing projects and standardization activities also stated in this paper.","['Energy efficiency', 'Green products', '5G mobile communication', 'Batteries', 'Air pollution', 'Cellular networks']","['Carbon footprint', 'D2D communication', 'ultra dense networks (UDNs)', 'massive MIMO', 'spectrum sharing', 'Internet of Things (IoT)', 'small cell access point (SCA)']"
"A multi-band 10-antenna array working at the sub-6-GHz spectrum (LTE bands 42/43 and LTE band 46) for massive multiple-input multiple-output (MIMO) applications in future 5G smartphones is proposed. To realize $10\times 10$ MIMO applications in three LTE bands, 10 T-shaped coupled-fed slot antenna elements that can excite dual resonant modes are integrated into a system circuit board. Spatial and polarization diversity techniques are implemented on these elements so that the improved isolation and mitigated coupling effects can be achieved. The proposed antenna array was manufactured and experimentally measured. Desirable antenna efficiencies of higher than 42% and 62% were measured in the low band and high band, respectively. Vital results, such as the envelope correlation coefficient, channel capacity, and mean effective gain ratio, have also been computed and analyzed. The calculated ergodic channel capacities of the $10\times 10$ MIMO system working in the LTE bands 42/43 and LTE band 46 reached up to 48 and 51.4 b/s/Hz, respectively.","['MIMO communication', 'Slot antennas', '5G mobile communication', 'Smart phones', 'Microstrip antenna arrays']","['Sub-6 GHz', '5G', 'MIMO antenna', 'massive MIMO']"
"While machine learning and artificial intelligence have long been applied in networking research, the bulk of such works has focused on supervised learning. Recently, there has been a rising trend of employing unsupervised machine learning using unstructured raw network data to improve network performance and provide services, such as traffic engineering, anomaly detection, Internet traffic classification, and quality of service optimization. The growing interest in applying unsupervised learning techniques in networking stems from their great success in other fields, such as computer vision, natural language processing, speech recognition, and optimal control (e.g., for developing autonomous self-driving cars). In addition, unsupervised learning can unconstrain us from the need for labeled data and manual handcrafted feature engineering, thereby facilitating flexible, general, and automated methods of machine learning. The focus of this survey paper is to provide an overview of applications of unsupervised learning in the domain of networking. We provide a comprehensive survey highlighting recent advancements in unsupervised learning techniques, and describe their applications in various learning tasks, in the context of networking. We also provide a discussion on future directions and open research issues, while identifying potential pitfalls. While a few survey papers focusing on applications of machine learning in networking have previously been published, a survey of similar scope and breadth is missing in the literature. Through this timely review, we aim to advance the current state of knowledge, by carefully synthesizing insights from previous survey papers, while providing contemporary coverage of the recent advances and innovations.","['Unsupervised learning', 'Deep learning', 'Anomaly detection', 'Internet of Things', 'Quality of service']","['Machine learning', 'deep learning', 'unsupervised learning', 'computer networks']"
"Magnetic resonance imaging (MRI), which assists doctors in determining clinical staging and expected surgical range, has high medical value. A large number of MRI images require a large amount of storage space and the transmission bandwidth of the PACS system in offline storage and remote diagnosis. Therefore, high-quality compression of MRI images is very research-oriented. Current compression methods for MRI images with high compression ratio cause loss of information on lesions, leading to misdiagnosis; compression methods for MRI images with low compression ratio does not achieve the desired effect. Therefore, a fast fractal-based compression algorithm for MRI images is proposed in this paper. First, three-dimensional (3D) MRI images are converted into a two-dimensional (2D) image sequence, which facilitates the image sequence based on the fractal compression method. Then, range and domain blocks are classified according to the inherent spatiotemporal similarity of 3D objects. By using self-similarity, the number of blocks in the matching pool is reduced to improve the matching speed of the proposed method. Finally, a residual compensation mechanism is introduced to achieve compression of MRI images with high decompression quality. The experimental results show that compression speed is improved by 2-3 times, and the PSNR is improved by nearly 10. It indicates the proposed algorithm is effective and solves the contradiction between high compression ratio and high quality of MRI medical images.","['Image coding', 'Magnetic resonance imaging', 'Medical diagnostic imaging', 'Fractals', 'Compression algorithms', 'Classification algorithms']","['MRI', 'image compression', 'fractal compression', 'spatiotemporal similarity', 'lossy compression']"
"Intelligent systems are wanting for cities to cope with limited spaces and resources across the world. As a result, smart cities emerged mainly as a result of highly innovative ICT industries and markets, and additionally, they have started to use novel solutions taking advantage of the Internet of Things (IoT), big data and cloud computing technologies to establish a profound connection between each component and layer of a city. Several key technologies congregate to build a working smart city considering human requirements. Even though the smart city concept is an advanced solution for today's cities, recently, more living spaces should be discovered, and the concept of a smart city could be moved to these alternative living spaces, namely floating cities. The concept of a floating city emerged as a novel solution due to rising sea levels and land scarcity in order to provide alternative living spaces for humanity. In this article, our main research question is to raise awareness on the current state of smart city concepts across the world by understanding the key future trends, including floating cities, by motivating researchers and scientists through new IoT technologies and applications. Therefore, we present a survey of smart city initiatives and analyze their key concepts and different data management techniques. We performed a detailed literature survey and review by applying a complex literature matrix including terms, like smart people, smart economy, smart governance, smart mobility, smart environment, and smart living. We also discuss multiple perspectives of smart floating cities in detail. With the proposed approach, recent advances and practical future opportunities for smart cities can be revealed.","['Smart cities', 'Internet of Things', 'Sea level', 'Market research', 'Big Data', 'Cloud computing']","['Smart city', 'floating cities', 'IoT', 'survey']"
"Encoder-decoder networks are state-of-the-art approaches to biomedical image segmentation, but have two problems: i.e., the widely used pooling operations may discard spatial information, and therefore low-level semantics are lost. Feature fusion methods can mitigate these problems but feature maps of different scales cannot be easily fused because downand upsampling change the spatial resolution of feature map. To address these issues, we propose INet, which enlarges receptive fields by increasing the kernel sizes of convolutional layers in steps (e.g., from 3 × 3 to 7 × 7 and then 15 × 15) instead of downsampling. Inspired by an Inception module, INet extracts features by kernels of different sizes through concatenating the output feature maps of all preceding convolutional layers. We also find that the large kernel makes the network feasible for biomedical image segmentation. In addition, INet uses two overlapping max-poolings, i.e., max-poolings with stride 1, to extract the sharpest features. Fixed-size and fixed-channel feature maps enable INet to concatenate feature maps and add multiple shortcuts across layers. In this way, INet can recover low-level semantics by concatenating the feature maps of all preceding layers and expedite the training by adding multiple shortcuts. Because INet has additional residual shortcuts, we compare INet with a UNet system that also has residual shortcuts (ResUNet). To confirm INet as a backbone architecture for biomedical image segmentation, we implement dense connections on INet (called DenseINet) and compare it to a DenseUNet system with residual shortcuts (ResDenseUNet). INet and DenseINet require 16.9% and 37.6% fewer parameters than ResUNet and ResDenseUNet, respectively. In comparison with six encoder- decoder approaches using nine public datasets, INet and DenseINet demonstrate efficient improvements in biomedical image segmentation. INet outperforms DeepLabV3, which implementing atrous convolution instead of downsampling to increase receptive fields. INet also outperforms two recent methods (named HRNet and MS-NAS) that maintain high-resolution representations and repeatedly exchange the information across resolutions.","['Image segmentation', 'Biomedical imaging', 'Semantics', 'Feature extraction', 'Kernel', 'Convolution', 'Tumors']","['Biomedical image', 'convolutional networks', 'encoder–decoder networks', 'semantic segmentation']"
"Intrusion detection system (IDS) plays an important role in network security by discovering and preventing malicious activities. Due to the complex and time-varying network environment, the network intrusion samples are submerged into a large number of normal samples, which leads to insufficient samples for model training and detection results with a high false detection rate. According to the problem of data imbalance, we propose a network intrusion detection algorithm combined hybrid sampling with deep hierarchical network. Firstly, we use the one-side selection (OSS) to reduce the noise samples in majority category, and then increase the minority samples by Synthetic Minority Over-sampling Technique (SMOTE). In this way, a balanced dataset can be established to make the model fully learn the features of minority samples and greatly reduce the model training time. Secondly, we use convolution neural network (CNN) to extract spatial features and Bi-directional long short-term memory (BiLSTM) to extract temporal features, which forms a deep hierarchical network model. The proposed network intrusion detection algorithm was verified by experiments on the NSL-KDD and UNSW-NB15 dataset, and the classification accuracy can achieve 83.58% and 77.16%, respectively.","['Intrusion detection', 'Feature extraction', 'Data models', 'Support vector machines', 'Telecommunication traffic', 'Training', 'Classification algorithms']","['Network intrusion detection', 'hybrid sampling', 'deep hierarchical network', 'convolution neural network', 'bi-directional long short-term memory']"
"Multilevel inverters (MLIs) are a great development for industrial and renewable energy applications due to their dominance over conventional two-level inverter with respect to size, rating of switches, filter requirement, and efficiency. A new single-phase cascaded MLI topology is suggested in this paper. The proposed MLI topology is designed with the aim of reducing the number of switches and the number of dc voltage sources with modularity while having a higher number of levels at the output. For the determination of the magnitude of dc voltage sources and a number of levels in the cascade connection, three different algorithms are proposed. The optimization of the proposed topology is aimed at achieving a higher number of levels while minimizing other parameters. A detailed comparison is made with other comparable MLI topologies to prove the superiority of the proposed structure. A selective harmonic elimination pulse width modulation technique is used to produce the pulses for the switches to achieve high-quality voltage at the output. Finally, the experimental results are provided for the basic unit with 11 levels and for cascading of two such units to achieve 71 levels at the output.","['Topology', 'Switches', 'Inverters', 'Through-silicon vias', 'Power harmonic filters', 'Optimization', 'Harmonic analysis']","['Basic unit', 'cascaded inverter', 'multilevel inverter (MLI)', 'selective harmonic elimination', 'SHEPWM', 'optimization', 'reduce switch count']"
"The advanced features of 5G mobile wireless network systems yield new security requirements and challenges. This paper presents a comprehensive study on the security of 5G wireless network systems compared with the traditional cellular networks. The paper starts with a review on 5G wireless networks particularities as well as on the new requirements and motivations of 5G wireless security. The potential attacks and security services are summarized with the consideration of new service requirements and new use cases in 5G wireless networks. The recent development and the existing schemes for the 5G wireless security are presented based on the corresponding security services, including authentication, availability, data confidentiality, key management, and privacy. This paper further discusses the new security features involving different technologies applied to 5G, such as heterogeneous networks, device-to-device communications, massive multiple-input multiple-output, software-defined networks, and Internet of Things. Motivated by these security research and development activities, we propose a new 5G wireless security architecture, based on which the analysis of identity management and flexible authentication is provided. As a case study, we explore a handover procedure as well as a signaling load scheme to show the advantages of the proposed security architecture. The challenges and future directions of 5G wireless security are finally summarized.","['5G mobile communication', 'Wireless networks', 'Computer architecture', 'Communication system security', 'Cryptography']","['5G wireless network systems', 'security', 'authentication', 'availability', 'confidentiality', 'key management', 'privacy', 'heterogenous networks', 'device-to-device communications', 'massive multiple-input multiple-output', 'software-defined networks', 'Internet of Things', '5G wireless security architecture']"
"This paper deals with the problem of fault detection and diagnosis in sensors considering erratic, drift, hard-over, spike, and stuck faults. The data set containing samples of the above mentioned fault signals was acquired as follows: normal data signals were obtained from a temperature-to-voltage converter by using an Arduino Uno microcontroller board and MATLAB. Then, faults were simulated in normal data to get 100 samples of each fault, in which one sample is composed of 1000 data elements. A support vector machine (SVM) was used for data classification in a one-versus-rest manner. The statistical time-domain features, extracted from a sample, were used as a single observation for training and testing SVM. The number of features varied from 5 to 10 to examine the effect on accuracy of SVM. Three different kernel functions used to train SVM include linear, polynomial, and radial-basis function kernels. The fault occurrence event in fault samples was chosen randomly in some cases to replicate a practical scenario in industrial systems. The results show that an increase in the number of features from 5 to 10 hardly increases the total accuracy of the classifier. However, using ten features gives the highest accuracy for fault classification in an SVM. An increase in the number of training samples from 40 to 60 caused an overfitting problem. The k-fold cross-validation technique was adopted to overcome this issue. The increase in number of data elements per sample to 2500 increases the efficiency of the classifier. However, an increase in the number of training samples to 400 reduces the capability of SVM to classify stuck fault. The receiver operating characteristics curve comparison shows the efficiency of SVM over a neural network.","['Support vector machines', 'Feature extraction', 'Fault detection', 'Kernel', 'Training', 'Time-domain analysis', 'Fault diagnosis']","['Sensor faults', 'fault detection', 'support vector machine', 'drift fault', 'erratic fault', 'hard-over fault', 'spike fault', 'stuck fault']"
"As a breakthrough in the field of machine fault diagnosis, deep learning has great potential to extract more abstract and discriminative features automatically without much prior knowledge compared with other methods, such as the signal processing and analysis-based methods and machine learning methods with shallow architectures. One of the most important aspects in measuring the extracted features is whether they can explore more information of the inputs and avoid redundancy to be representative. Thus, a stacked sparse autoencoder (SAE)-based machine fault diagnosis method is proposed in this paper. The penalty term of the SAE can help mine essential information and avoid redundancy. To help the constructed diagnosis network further mine more abstract and representative high-level features, the collected non-stationary and transient signals are preprocessed with ensemble empirical mode decomposition and autoregressive (AR) models to obtain AR parameters, which are extracted based on the intrinsic mode functions (IMFs) and regarded as the low-level features for the inputs of the proposed diagnosis network. Only the first four IMFs are considered, because fault information is mainly reflected in high-frequency IMFs. Experiments and comparisons are complemented to validate the superiority of the presented diagnosis network. Results fully demonstrate that the stacked SAE-based diagnosis method can extract more discriminative high-level features and has a better performance in rotating machinery fault diagnosis compared with the traditional machine learning methods with shallow architectures.","['Feature extraction', 'Fault diagnosis', 'Machinery', 'Machine learning', 'Support vector machines', 'Data mining', 'Learning systems']","['Sparse autoencoder', 'ensemble empirical mode decomposition', 'autoregressive model', 'fault diagnosis']"
"A 12-port antenna array operating in the long term evolution (LTE) band 42 (3400-3600 MHz), LTE band 43 (3600-3800 MHz), and LTE band 46 (5150-5925 MHz) for 5G massive multiple-input multiple-output (MIMO) applications in mobile handsets is presented. The proposed MIMO antenna is composed of three different antenna element types, namely, inverted π-shaped antenna, longer inverted L-shaped open slot antenna, and shorter inverted L-shaped open slot antenna. In total, eight antenna elements are used for the 8×8 MIMO in LTE bands 42/43, and six antenna elements are designed for the 6×6 MIMO in LTE band 46. The proposed antenna was simulated, and a prototype was fabricated and tested. The measured results show that the LTE bands 42/43/46 are satisfied with reflection coefficient better than -6 dB, isolation lower than -12 dB, and total efficiencies of higher than 40%. In addition to that, the proposed antenna array has also shown good MIMO performances with an envelope correlation coefficient lower than 0.15, and ergodic channel capacities higher than 34 and 26.5 b/s/Hz in the LTE bands 42/43 and LTE band 46, respectively. The hand phantom effects are also investigated, and the results show that the proposed antenna array can still exhibit good radiation and MIMO performances when operating under data mode and read mode conditions.","['MIMO', 'Long Term Evolution', 'Antenna arrays', '5G mobile communication', 'Slot antennas', 'Mobile antennas']","['Handset antenna', 'MIMO antenna', 'sub-6GHz', 'massive MIMO']"
"The fifth generation (5G) of mobile communication system aims to deliver a ubiquitous mobile service with enhanced quality of service (QoS). It is also expected to enable new use-cases for various vertical industrial applications—such as automobiles, public transportation, medical care, energy, public safety, agriculture, entertainment, manufacturing, and so on. Rapid increases are predicted to occur in user density, traffic volume, and data rate. This calls for novel solutions to the requirements of both mobile users and vertical industries in the next decade. Among various available options, one that appears attractive is to redesign the network architecture—more specifically, to reconstruct the radio access network (RAN). In this paper, we present an inclusive and comprehensive survey on various RAN architectures toward 5G, namely cloud-RAN, heterogeneous cloud-RAN, virtualized cloud-RAN, and fog-RAN. We compare them from various perspectives, such as energy consumption, operations expenditure, resource allocation, spectrum efficiency, system architecture, and network performance. Moreover, we review the key enabling technologies for 5G systems, such as multi-access edge computing, network function virtualization, software-defined networking, and network slicing; and some crucial radio access technologies (RATs), such as millimeter wave, massive multi-input multi-output, device-to-device communication, and massive machine-type communication. Last but not least, we discuss the major research challenges in 5G RAN and 5G RATs and identify several possible directions of future research.","['5G mobile communication', 'Radio access networks', 'Cloud computing', 'Computer architecture', 'Radio access technologies', 'Quality of service', 'Systems architecture']","['5G', 'radio access network', 'network architecture', 'cloud-RAN', 'distributed-RAN', 'fog-RAN', 'heterogeneous-CRAN', 'RATs', 'virtualized-CRAN']"
"Customer retention is a major issue for various service-based organizations particularly telecom industry, wherein predictive models for observing the behavior of customers are one of the great instruments in customer retention process and inferring the future behavior of the customers. However, the performances of predictive models are greatly affected when the real-world data set is highly imbalanced. A data set is called imbalanced if the samples size from one class is very much smaller or larger than the other classes. The most commonly used technique is over/under sampling for handling the class-imbalance problem (CIP) in various domains. In this paper, we survey six well-known sampling techniques and compare the performances of these key techniques, i.e., mega-trend diffusion function (MTDF), synthetic minority oversampling technique, adaptive synthetic sampling approach, couples top-N reverse k-nearest neighbor, majority weighted minority oversampling technique, and immune centroids oversampling technique. Moreover, this paper also reveals the evaluation of four rules-generation algorithms (the learning from example module, version 2 (LEM2), covering, exhaustive, and genetic algorithms) using publicly available data sets. The empirical results demonstrate that the overall predictive performance of MTDF and rules-generation based on genetic algorithms performed the best as compared with the rest of the evaluated oversampling methods and rule-generation algorithms.","['Predictive models', 'Prediction algorithms', 'Genetic algorithms', 'Sampling methods', 'Customer retention', 'Learning systems', 'Customer satisfaction', 'Customer profiles']","['SMOTE', 'ADASYN', 'mega trend diffusion function', 'class imbalance', 'rough set', 'customer churn', 'mRMR. ICOTE', 'MWMOTE', 'TRkNN']"
"Human activity recognition (HAR) based on sensor networks is an important research direction in the fields of pervasive computing and body area network. Existing researches often use statistical machine learning methods to manually extract and construct features of different motions. However, in the face of extremely fast-growing waveform data with no obvious laws, the traditional feature engineering methods are becoming more and more incapable. With the development of deep learning technology, we do not need to manually extract features and can improve the performance in complex human activity recognition problems. By migrating deep neural network experience in image recognition, we propose a deep learning model (InnoHAR) based on the combination of inception neural network and recurrent neural network. The model inputs the waveform data of multi-channel sensors end-to-end. Multi-dimensional features are extracted by inception-like modules by using various kernel-based convolution layers. Combined with GRU, modeling for time series features is realized, making full use of data characteristics to complete classification tasks. Through experimental verification on three most widely used public HAR datasets, our proposed method shows consistent superior performance and has good generalization performance, when compared with the state-of-the-art.","['Feature extraction', 'Activity recognition', 'Deep learning', 'Convolution', 'Wearable sensors', 'Convolutional neural networks']","['Complex human activity', 'inception neural network', 'wearable sensor', 'computational efficiency']"
"Mobile devices are increasingly becoming an indispensable part of people's daily life, facilitating to perform a variety of useful tasks. Mobile cloud computing integrates mobile and cloud computing to expand their capabilities and benefits and overcomes their limitations, such as limited memory, CPU power, and battery life. Big data analytics technologies enable extracting value from data having four Vs: volume, variety, velocity, and veracity. This paper discusses networked healthcare and the role of mobile cloud computing and big data analytics in its enablement. The motivation and development of networked healthcare applications and systems is presented along with the adoption of cloud computing in healthcare. A cloudlet-based mobile cloud-computing infrastructure to be used for healthcare big data applications is described. The techniques, tools, and applications of big data analytics are reviewed. Conclusions are drawn concerning the design of networked healthcare systems using big data and mobile cloud-computing technologies. An outlook on networked healthcare is given.","['Cloud computing', 'Medical services', 'Mobile communication', 'Mobile handsets', 'Big data', 'Mobile computing', 'Computational modeling']","['Healthcare systems', 'big data analytics', 'mobile cloud computing', 'cloudlet infrastructure', 'health applications']"
"The state of charge (SOC) is a critical evaluation index of battery residual capacity. The significance of an accurate SOC estimation is great for a lithium-ion battery to ensure its safe operation and to prevent from over-charging or over-discharging. However, to estimate an accurate capacity of SOC of the lithium-ion battery has become a major concern for the electric vehicle (EV) industry. Therefore, numerous researches are being conducted to address the challenges and to enhance the battery performance. The main objective of this paper is to develop an accurate SOC estimation approach for a lithium-ion battery by improving back-propagation neural network (BPNN) capability using backtracking search algorithm (BSA). BSA optimization is utilized to improve the accuracy and robustness of BPNN model by finding the optimal value of hidden layer neurons and learning rate. In this paper, Dynamic Stress Test and Federal Urban Driving Schedule drive profiles are applied for testing the model at three different temperatures. The obtained results of the BPNN based BSA model are compared with the radial basis function neural network, generalized regression neural network and extreme learning machine model using statistical error values of root mean square error, mean absolute error, mean absolute percentage error, and SOC error to check and validate the model performance. The obtained results show that the BPNN based BSA model outperforms other neural network models in estimating SOC with high accuracy under different EV profiles and temperatures.","['State of charge', 'Lithium-ion batteries', 'Estimation', 'Neurons', 'Temperature measurement', 'Algorithm design and analysis']","['Lithium-ion battery', 'the state of charge', 'back propagation neural network', 'backtracking search algorithm', 'electric vehicle']"
"This paper demonstrates an innovative and simple solution for obstacle detection and collision avoidance of unmanned aerial vehicles (UAVs) optimized for and evaluated with quadrotors. The sensors exploited in this paper are low-cost ultrasonic and infrared range finders, which are much cheaper though noisier than more expensive sensors such as laser scanners. This needs to be taken into consideration for the design, implementation, and parametrization of the signal processing and control algorithm for such a system, which is the topic of this paper. For improved data fusion, inertial and optical flow sensors are used as a distance derivative for reference. As a result, a UAV is capable of distance controlled collision avoidance, which is more complex and powerful than comparable simple solutions. At the same time, the solution remains simple with a low computational burden. Thus, memory and time-consuming simultaneous localization and mapping is not required for collision avoidance.","['Collision avoidance', 'Obstacle detection', 'Infrared detection', 'Quadrotors', 'Unmanned aerial vehicles', 'Sensors']","['collision avoidance', 'obstacle detection', 'ultrasonic', 'infrared', 'autonomous', 'UAV', 'quadrotor', 'quadrocopter']"
"Fault diagnosis of chemical process data becomes one of the most important directions in research and practice. Conventional fault diagnosis and classification methods first extract features from the raw process data. Then certain classifiers are adopted to make diagnosis. However, these conventional methods suffer from the expertise of feature extraction and classifier design. They also lack the adaptive processing of the dynamic information in raw data. This paper proposes a fault diagnosis method based on long short-term memory (LSTM) neural network. The novel method can directly classify the raw process data without specific feature extraction and classifier design. It is also able to adaptively learn the dynamic information in raw data. First, raw process data are used to train the LSTM neural network until the cost function of LSTM converges below certain predefined small positive value. In this step, the dynamic information of raw process data is adaptively learned by LSTM. Then testing data are used to obtain the diagnosis results of the trained LSTM neural network. The application of LSTM to fault identification and analysis is evaluated in the Tennessee Eastman benchmark process. Extensive experimental results show LSTM can better separate different faults and provide more promising fault diagnosis performance.","['Fault diagnosis', 'Feature extraction', 'Recurrent neural networks', 'Monitoring', 'Training', 'Standards']","['Process monitoring', 'fault diagnosis', 'recurrent neural network', 'long short-term memory (LSTM) neural network']"
"We present an approach that combines automatic features learned by convolutional neural networks (CNN) and handcrafted features computed by the bag-of-visual-words (BOVW) model in order to achieve the state-of-the-art results in facial expression recognition (FER). To obtain automatic features, we experiment with multiple CNN architectures, pre-trained models, and training procedures, e.g., Dense-Sparse-Dense. After fusing the two types of features, we employ a local learning framework to predict the class label for each test image. The local learning framework is based on three steps. First, a k-nearest neighbors model is applied in order to select the nearest training samples for an input test image. Second, a one-versus-all support vector machines (SVM) classifier is trained on the selected training samples. Finally, the SVM classifier is used to predict the class label only for the test image it was trained for. Although we have used local learning in combination with handcrafted features in our previous work, to the best of our knowledge, local learning has never been employed in combination with deep features. The experiments on the 2013 FER Challenge data set, the FER+ data set, and the AffectNet data set demonstrate that our approach achieves the state-of-the-art results. With a top accuracy of 75.42% on the FER 2013, 87.76% on the FER+, 59.58% on the AffectNet eight-way classification, and 63.31% on the AffectNet seven-way classification, we surpass the state-of-the-art methods by more than 1% on all data sets.","['Face recognition', 'Training', 'Computational modeling', 'Support vector machines', 'Convolutional neural networks', 'Deep learning', 'Task analysis']","['Facial expression recognition', 'local learning', 'convolutional neural networks', 'bag-of-visual-words', 'dense-sparse-dense training']"
"Particle swarm optimization (PSO) is one of the most well-regarded swarm-based algorithms in the literature. Although the original PSO has shown good optimization performance, it still severely suffers from premature convergence. As a result, many researchers have been modifying it resulting in a large number of PSO variants with either slightly or significantly better performance. Mainly, the standard PSO has been modified by four main strategies: modification of the PSO controlling parameters, hybridizing PSO with other well-known meta-heuristic algorithms such as genetic algorithm (GA) and differential evolution (DE), cooperation and multi-swarm techniques. This paper attempts to provide a comprehensive review of PSO, including the basic concepts of PSO, binary PSO, neighborhood topologies in PSO, recent and historical PSO variants, remarkable engineering applications of PSO, and its drawbacks. Moreover, this paper reviews recent studies that utilize PSO to solve feature selection problems. Finally, eight potential research directions that can help researchers further enhance the performance of PSO are provided.","['Signal processing algorithms', 'Optimization', 'Particle swarm optimization', 'Feature extraction', 'Topology', 'Birds', 'Statistics']","['Applications of PSO', 'binary PSO', 'evolutionary computation', 'feature selection', 'hybrid algorithms', 'meta-heuristic algorithms', 'particle swarm optimization', 'PSO variants']"
"In this review paper, a comprehensive study on the concept, theory, and applications of composite right/left-handed transmission lines (CRLH-TLs) by considering their use in antenna system designs have been provided. It is shown that CRLH-TLs with negative permittivity (ε <; 0) and negative permeability (μ <; 0) have unique properties that do not occur naturally. Therefore, they are referred to as artificial structures called “metamaterials”. These artificial structures include series left-handed (LH) capacitances (C L ), shunt LH inductances (L L ), series right-handed (RH) inductances (LR), and shunt RH capacitances (CR) that are realized by slots or interdigital capacitors, stubs or via-holes, unwanted current flowing on the surface, and gap distance between the surface and ground-plane, respectively. In the most cases, it is also shown that structures based on CRLH metamaterial-TLs are superior than their conventional alternatives, since they have smaller dimensions, lower-profile, wider bandwidth, better radiation patterns, higher gain and efficiency, which make them easier and more cost-effective to manufacture and mass produce. Hence, a broad range of metamaterial-based design possibilities are introduced to highlight the improvement of the performance parameters that are rare and not often discussed in available literature. Therefore, this survey provides a wide overview of key early-stage concepts of metematerial-based designs as a thorough reference for specialist antennas and microwave circuits designers. To analyze the critical features of metamaterial theory and concept, several examples are used. Comparisons on the basis of physical size, bandwidth, materials, gain, efficiency, and radiation patterns are made for all the examples that are based on CRLH metamaterialTLs. As revealed in all the metematerial design examples, foot-print area decrement is an important issue of study that have a strong impact for the enlargement of the next generation wireless communication systems.","['Metamaterials', 'Power transmission lines', 'Dispersion', 'Impedance', 'Integrated circuit modeling', 'Capacitance', 'Permittivity']","['Metamaterials (MTMs)', 'artificial structures', 'antennas', 'negative permittivity (ε < 0)', 'negative permeability (μ < 0)', 'high performances', 'composite right/left-handed transmission lines (CRLH-TLs)', 'next generation wireless communication systems']"
"Brain tumor is a deadly disease and its classification is a challenging task for radiologists because of the heterogeneous nature of the tumor cells. Recently, computer-aided diagnosis-based systems have promised, as an assistive technology, to diagnose the brain tumor, through magnetic resonance imaging (MRI). In recent applications of pre-trained models, normally features are extracted from bottom layers which are different from natural images to medical images. To overcome this problem, this study proposes a method of multi-level features extraction and concatenation for early diagnosis of brain tumor. Two pre-trained deep learning models i.e. Inception-v3 and DensNet201 make this model valid. With the help of these two models, two different scenarios of brain tumor detection and its classification were evaluated. First, the features from different Inception modules were extracted from pre-trained Inception-v3 model and concatenated these features for brain tumor classification. Then, these features were passed to softmax classifier to classify the brain tumor. Second, pre-trained DensNet201 was used to extract features from various DensNet blocks. Then, these features were concatenated and passed to softmax classifier to classify the brain tumor. Both scenarios were evaluated with the help of three-class brain tumor dataset that is available publicly. The proposed method produced 99.34 %, and 99.51% testing accuracies respectively with Inception-v3 and DensNet201 on testing samples and achieved highest performance in the detection of brain tumor. As results indicated, the proposed method based on features concatenation using pre-trained models outperformed as compared to existing state-of-the-art deep learning and machine learning based methods for brain tumor classification.","['Tumors', 'Feature extraction', 'Machine learning', 'Brain modeling', 'Magnetic resonance imaging', 'Biomedical imaging', 'Diseases']","['Deep learning', 'magnetic resonance imaging', 'brain tumor classification', 'pre-trained model', 'dataset']"
"It is a challenging task to recognize smoke from images due to large variance of smoke color, texture, and shapes. There are smoke detection methods that have been proposed, but most of them are based on hand-crafted features. To improve the performance of smoke detection, we propose a novel deep normalization and convolutional neural network (DNCNN) with 14 layers to implement automatic feature extraction and classification. In DNCNN, traditional convolutional layers are replaced with normalization and convolutional layers to accelerate the training process and boost the performance of smoke detection. To reduce overfitting caused by imbalanced and insufficient training samples, we generate more training samples from original training data sets by using a variety of data enhancement techniques. Experimental results show that our method achieved very low false alarm rates below 0.60% with detection rates above 96.37% on our smoke data sets.","['Feature extraction', 'Fires', 'Training', 'Temperature sensors', 'Neurons']","['Deep neural networks', 'deep learning', 'smoke detection', 'image classification']"
"A high performance electrocardiogram (ECG)-based arrhythmic beats classification system is presented in this paper. The classifier was designed based on convolutional neural network (CNN). Single channel ECG signal was segmented into heartbeats in accordance with the changing heartbeat rate. The beats were transformed into dual beat coupling matrix as 2-D inputs to the CNN classifier, which captured both beat morphology and beat-to-beat correlation in ECG. A systematic training beat selection procedure was also proposed which automatically include the most representative beats into the training set to improve classification performance. The classification system was evaluated for the detection of supraventricular ectopic beats (SVEB or S beats) and VEB using the MIT-BIH arrhythmia database. Our proposed method has demonstrated superior performance than several state-of-the-art detectors. In particular, our proposed CNN system has improved sensitivity and positive predictive rate for S beats by more than 12.2% and 11.9%, respectively, over these top performing algorithms. Our proposed CNN classifier with an automatic training beats selection process has shown to outperform the previous methods. The classifier is also a personalized one by combining training set from a common pool and a subject-specific set of ECG data. Our proposed system provides a reliable and fully automatic tool for detection of arrhythmia heartbeat without the need for manual feature extraction or expert assistant. It can potentially be implemented on portable device for the long-term monitoring of cardiac arrhythmia.","['Electrocardiography', 'Heart beat', 'Heart rate variability', 'Training', 'Databases', 'Couplings', 'Morphology']","['Convolutional neural network (CNN)', 'ECG classification', 'arrhythmia', 'patient-specific']"
"A vehicular ad-hoc network (VANET) can improve the flow of traffic to facilitate intelligent transportation and to provide convenient information services, where the goal is to provide self-organizing data transmission capabilities for vehicles on the road to enable applications, such as assisted vehicle driving and safety warnings. VANETs are affected by issues such as identity validity and message reliability when vehicle nodes share data with other nodes. The method used to allow the vehicle nodes to upload sensor data to a trusted center for storage is susceptible to security risks, such as malicious tampering and data leakage. To address these security challenges, we propose a data security sharing and storage system based on the consortium blockchain (DSSCB). This digital signature technique based on the nature of bilinear pairing for elliptic curves is used to ensure the reliability and integrity when transmitting data to a node. The emerging consortium blockchain technology provides a decentralized, secure, and reliable database, which is maintained by the entire network node. In DSSCB, smart contracts are used to limit the triggering conditions for preselected nodes when transmitting and storing data and for allocating data coins to vehicles that participate in the contribution of data. The security analysis and performance evaluations demonstrated that our DSSCB solution is more secure and reliable in terms of data sharing and storage. Compared with the traditional blockchain system, the time required to confirm the data block was reduced by nearly six times and the transmission efficiency was improved by 83.33%.","['Blockchain', 'Elliptic curves', 'Vehicular ad hoc networks', 'Elliptic curve cryptography', 'Safety', 'Reliability']","['Consortium blockchain', 'data sharing', 'data storage', 'signature verification', 'vehicular ad-hoc network (VANET)']"
"Body area networks, including smart sensors, are widely reshaping health applications in the new era of smart cities. To meet increasing security and privacy requirements, physiological signalbased biometric human identification is gaining tremendous attention. This paper focuses on two major impediments: the signal processing technique is usually both complicated and data-dependent and the feature engineering is time-consuming and can fit only specific datasets . To enable a data-independent and highly generalizable signal processing and feature learning process, a novel wavelet domain multiresolution convolutional neural network is proposed. Specifically, it allows for blindly selecting a physiological signal segment for identification purpose, avoiding the complicated signal fiducial characteristics extraction process. To enrich the data representation, the random chosen signal segment is then transformed to the wavelet domain, where multiresolution time-frequency representation is achieved. An auto-correlation operation is applied to the transformed data to remove the phase difference as the result of the blind segmentation operation. Afterward, a multiresolution 1-D-convolutional neural network (1-D-CNN) is introduced to automatically learn the intrinsic hierarchical features from the wavelet domain raw data without datadependent and heavy feature engineering, and perform the user identification task. The effectiveness of the proposed algorithm is thoroughly evaluated on eight electrocardiogram datasets with diverse behaviors, such as with or without severe heart diseases, and with different sensor placement methods. Our evaluation is much more extensive than the state-of-the-art works, and an average identification rate of 93.5% is achieved. The proposed multiresolution 1-D-CNN algorithm can effectively identify human subjects, even from randomly selected signal segments and without heavy feature engineering. This paper is expected to demonstrate the feasibility and effectiveness of applying the blind signal processing and deep learning techniques to biometric human identification, to enable a low algorithm engineering effort and also a high generalization ability.","['Electrocardiography', 'Signal resolution', 'Feature extraction', 'Heart rate variability', 'Convolution', 'Wavelet domain', 'Wavelet transforms']","['ECG', 'wavelet transformation', 'convolutional neural network', 'deep learning', 'machine learning', 'feature learning', 'blind signal processing', 'data representation']"
"This paper presents a comprehensive review of current literature on drone detection and classification using machine learning with different modalities. This research area has emerged in the last few years due to the rapid development of commercial and recreational drones and the associated risk to airspace safety. Addressed technologies encompass radar, visual, acoustic, and radio-frequency sensing systems. The general finding of this study demonstrates that machine learning-based classification of drones seems to be promising with many successful individual contributions. However, most of the performed research is experimental and the outcomes from different papers can hardly be compared. A general requirement-driven specification for the problem of drone detection and classification is still missing as well as reference datasets which would help in evaluating different solutions.","['Drones', 'Radar cross-sections', 'Birds', 'Radar detection', 'Acoustics', 'Data models']","['Drone detection', 'drone classification', 'machine learning', 'radar', 'vision', 'acoustics', 'radio-frequency']"
"Nowadays, 5G is in its initial phase of commercialization. The 5G network will revolutionize the existing wireless network with its enhanced capabilities and novel features. 5G New Radio (5G NR), referred to as the global standardization of 5G, is presently under the 3 rd Generation Partnership Project (3GPP) and can be operable over the wide range of frequency bands from less than 6GHz to mmWave (100GHz). 3GPP mainly focuses on the three major use cases of 5G NR that are comprised of Ultra-Reliable and Low Latency Communication (uRLLC), Massive Machine Type Communication (mMTC), Enhanced Mobile Broadband (eMBB). For meeting the targets of 5G NR, multiple features like scalable numerology, flexible spectrum, forward compatibility, and ultra-lean design are added as compared to the LTE systems. This paper presents a brief overview of the added features and key performance indicators of 5G NR. The issues related to the adaptation of higher modulation schemes and inter-RAT handover synchronization are well addressed in this paper. With the consideration of these challenges, a next-generation wireless communication architecture is proposed. The architecture acts as the platform for migration towards beyond 5G/6G networks. Along with this, various technologies and applications of 6G networks are also overviewed in this paper. 6G network will incorporate Artificial intelligence (AI) based services, edge computing, quantum computing, optical wireless communication, hybrid access, and tactile services. For enabling these diverse services, a virtualized network slicing based architecture of 6G is proposed. Various ongoing projects on 6G and its technologies are also listed in this paper.","['6G mobile communication', 'Computer architecture', 'Ultra reliable low latency communication', '3GPP', 'Next generation networking', 'New Radio']","['5G', '5G NR', 'eMBB', 'mMTC', 'uRLLC', 'EVM', 'inter-RAT', '6G', 'network slicing', 'Tactile Internet']"
"Intrusion detection can identify unknown attacks from network traffics and has been an effective means of network security. Nowadays, existing methods for network anomaly detection are usually based on traditional machine learning models, such as KNN, SVM, etc. Although these methods can obtain some outstanding features, they get a relatively low accuracy and rely heavily on manual design of traffic features, which has been obsolete in the age of big data. To solve the problems of low accuracy and feature engineering in intrusion detection, a traffic anomaly detection model BAT is proposed. The BAT model combines BLSTM (Bidirectional Long Short-term memory) and attention mechanism. Attention mechanism is used to screen the network flow vector composed of packet vectors generated by the BLSTM model, which can obtain the key features for network traffic classification. In addition, we adopt multiple convolutional layers to capture the local features of traffic data. As multiple convolutional layers are used to process data samples, we refer BAT model as BAT-MC. The softmax classifier is used for network traffic classification. The proposed end-to-end model does not use any feature engineering skills and can automatically learn the key features of the hierarchy. It can well describe the network traffic behavior and improve the ability of anomaly detection effectively. We test our model on a public benchmark dataset, and the experimental results demonstrate our model has better performance than other comparison methods.","['Intrusion detection', 'Feature extraction', 'Deep learning', 'Anomaly detection', 'Machine learning algorithms', 'Pattern matching']","['Network traffic', 'intrusion detection', 'deep learning', 'BLSTM', 'attention mechanism']"
"The 6G vision of creating authentic digital twin representations of the physical world calls for new sensing solutions to compose multi-layered maps of our environments. Radio sensing using the mobile communication network as a sensor has the potential to become an essential component of the solution. With the evolution of cellular systems to mmWave bands in 5G and potentially sub-THz bands in 6G, small cell deployments will begin to dominate. Large bandwidth systems deployed in small cell configurations provide an unprecedented opportunity to employ the mobile network for sensing. In this paper, we focus on the major design aspects of such a cellular joint communication and sensing (JCAS) system. We present an analysis of the choice of the waveform that points towards choosing the one that is best suited for communication also for radar sensing. We discuss several techniques for efficiently integrating the sensing capability into the JCAS system, some of which are applicable with NR air-interface for evolved 5G systems. Specifically, methods for reducing sensing overhead by appropriate sensing signal design or by configuring separate numerologies for communications and sensing are presented. Sophisticated use of the sensing signals is shown to reduce the signaling overhead by a factor of 2.67 for an exemplary road traffic monitoring use case. We then present a vision for future advanced JCAS systems building upon distributed massive MIMO and discuss various other research challenges for JCAS that need to be addressed in order to pave the way towards natively integrated JCAS in 6G.","['Sensors', '5G mobile communication', 'Radar', '6G mobile communication', 'Location awareness', 'Industries', 'Bandwidth']","['5G', 'beyond 5G', '6G', 'air interface', 'artificial intelligence', 'cellular', 'communication', 'Industry 40', 'JCAS', 'localization', 'machine learning', 'positioning', 'radar', 'radcom', 'sensing', 'system design', 'vertical industries', 'wireless']"
"The immense increase in multimedia-on-demand traffic that refers to audio, video, and images, has drastically shifted the vision of the Internet of Things (IoT) from scalar to Multimedia Internet of Things (M-IoT). IoT devices are constrained in terms of energy, computing, size, and storage memory. Delay-sensitive and bandwidth-hungry multimedia applications over constrained IoT networks require revision of IoT architecture for M-IoT. This paper provides a comprehensive survey of M-IoT with an emphasis on architecture, protocols, and applications. This article starts by providing a horizontal overview of the IoT. Then, we discuss the issues considering the characteristics of multimedia and provide a summary of related M-IoT architectures. Various multimedia applications supported by IoT are surveyed, and numerous use cases related to road traffic management, security, industry, and health are illustrated to show how different M-IoT applications are revolutionizing human life. We explore the importance of Quality-of-Experience (QoE) and Quality-of-Service (QoS) for multimedia transmission over IoT. Moreover, we explore the limitations of IoT for multimedia computing and present the relationship between the M-IoT and emerging technologies including event processing, feature extraction, cloud computing, Fog/Edge computing and Software-Defined-Networks (SDNs). We also present the need for better routing and Physical-Medium Access Control (PHY-MAC) protocols for M-IoT. Finally, we present a detailed discussion on the open research issues and several potential research areas related to emerging multimedia communication in IoT.","['Internet of Things', 'Computer architecture', 'Multimedia communication', 'Quality of service', 'Streaming media']","['Multimedia Internet of Things (M-IoT)', 'multimedia communication', 'Internet of Multimedia Things (IoMT)', 'multimedia computing', 'Quality-of-Experience (QoE)', 'Quality-of-Service (QoS)', 'multimedia routing', 'medium access control (MAC)']"
"Novel coronavirus (COVID-19) outbreak, has raised a calamitous situation all over the world and has become one of the most acute and severe ailments in the past hundred years. The prevalence rate of COVID-19 is rapidly rising every day throughout the globe. Although no vaccines for this pandemic have been discovered yet, deep learning techniques proved themselves to be a powerful tool in the arsenal used by clinicians for the automatic diagnosis of COVID-19. This paper aims to overview the recently developed systems based on deep learning techniques using different medical imaging modalities like Computer Tomography (CT) and X-ray. This review specifically discusses the systems developed for COVID-19 diagnosis using deep learning techniques and provides insights on well-known data sets used to train these networks. It also highlights the data partitioning techniques and various performance measures developed by researchers in this field. A taxonomy is drawn to categorize the recent works for proper insight. Finally, we conclude by addressing the challenges associated with the use of deep learning methods for COVID-19 detection and probable future trends in this research area. The aim of this paper is to facilitate experts (medical or otherwise) and technicians in understanding the ways deep learning techniques are used in this regard and how they can be potentially further utilized to combat the outbreak of COVID-19.","['COVID-19', 'Deep learning', 'Computed tomography', 'X-ray imaging', 'Transfer learning', 'Feature extraction', 'Taxonomy']","['Coronavirus', 'COVID-19', 'deep learning', 'deep transfer learning', 'diagnosis', 'x-ray', 'computer tomography']"
"Food traceability has been one of the emerging blockchain applications in recent years, for improving the areas of anti-counterfeiting and quality assurance. Existing food traceability systems do not guarantee a high level of system reliability, scalability, and information accuracy. Moreover, the traceability process is time-consuming and complicated in modern supply chain networks. To alleviate these concerns, blockchain technology is promising to create a new ontology for supply chain traceability. However, most consensus mechanisms and data flow in blockchain are developed for cryptocurrency, not for supply chain traceability; hence, simply applying blockchain technology to food traceability is impractical. In this paper, a blockchain-IoT-based food traceability system (BIFTS) is proposed to integrate the novel deployment of blockchain, IoT technology, and fuzzy logic into a total traceability shelf life management system for managing perishable food. To address the needs for food traceability, lightweight and vaporized characteristics are deployed in the blockchain, while an integrated consensus mechanism that considers shipment transit time, stakeholder assessment, and shipment volume is developed. The data flow of blockchain is then aligned to the deployment of IoT technologies according to the level of traceable resource units. Subsequently, the decision support can be established in the food supply chain by using reliable and accurate data for shelf life adjustment, and by using fuzzy logic for quality decay evaluation.","['Supply chains', 'Blockchain', 'Reliability', 'Quality assurance', 'Radiofrequency identification', 'Monitoring', 'Fuzzy logic']","['Food traceability', 'blockchain', 'consensus mechanism', 'Internet of Things', 'shelf life management']"
"How different cultures react and respond given a crisis is predominant in a society’s norms and political will to combat the situation. Often, the decisions made are necessitated by events, social pressure, or the need of the hour, which may not represent the nation’s will. While some are pleased with it, others might show resentment. Coronavirus (COVID-19) brought a mix of similar emotions from the nations towards the decisions taken by their respective governments. Social media was bombarded with posts containing both positive and negative sentiments on the COVID-19, pandemic, lockdown, and hashtags past couple of months. Despite geographically close, many neighboring countries reacted differently to one another. For instance, Denmark and Sweden, which share many similarities, stood poles apart on the decision taken by their respective governments. Yet, their nation’s support was mostly unanimous, unlike the South Asian neighboring countries where people showed a lot of anxiety and resentment. The purpose of this study is to analyze reaction of citizens from different cultures to the novel Coronavirus and people’s sentiment about subsequent actions taken by different countries. Deep long short-term memory (LSTM) models used for estimating the sentiment polarity and emotions from extracted tweets have been trained to achieve state-of-the-art accuracy on the sentiment140 dataset. The use of emoticons showed a unique and novel way of validating the supervised deep learning models on tweets extracted from Twitter.","['Machine learning', 'Twitter', 'Analytical models', 'Cultural differences', 'Training', 'Natural language processing']","['Behaviour analysis', 'COVID-19', 'crisis', 'deep learning', 'emotion detection', 'LSTM', 'natural language processing', 'neural network', 'outbreak', 'opinion mining', 'pandemic', 'polarity assessment', 'sentiment analysis', 'tweets', 'twitter', 'virus']"
"The concept of digital twin (DT) has emerged to enable the benefits of future paradigms such as the industrial Internet of Things and Industry 4.0. The idea is to bring every data source and control interface description related to a product or process available through a single interface, for auto-discovery and automated communication establishment. However, designing the architecture of a DT to serve every future application is an ambitious task. Therefore, the prototyping systems for specific applications are required to design the DT incrementally. We developed a novel DT prototype to analyze the requirements of communication in a mission-critical application such as mobile networks supported remote surgery. Such operations require low latency and high levels of security and reliability and therefore are a perfect subject for analyzing DT communication and cybersecurity. The system comprised of a robotic arm and HTC vive virtual reality (VR) system connected over a 4G mobile network. More than 70 test users were employed to assess the system. To address the cybersecurity of the system, we incorporated a network manipulation module to test the effect of network outages and attacks; we studied state of the art practices and their utilization within DTs. The capability of the system for actual remote surgery is limited by capabilities of the VR system and insufficient feedback from the robot. However, simulations and research of remote surgeries could be conducted with the system. As a result, we propose ideas for communication establishment and necessary cybersecurity technologies that will help in developing the DT architecture. Furthermore, we concluded that developing the DT requires cross-disciplinary development in several different engineering fields. Each field makes use of its own tools and methods, which do not always fit together perfectly. This is a potentially major obstacle in the realization of Industry 4.0 and similar concepts.","['Robots', 'Surgery', 'Real-time systems', 'Computer security', 'Task analysis', 'Reliability']","['Digital twin', 'virtual reality', 'robot control', 'mobile networks', 'network security']"
"Unmanned aerial vehicle (UAV) systems are one of the most rapidly developing, highest level and most practical applied unmanned aerial systems. Collision avoidance and trajectory planning are the core areas of any UAV system. However, there are theoretical and practical problems associated with the existing methods. To manage these problems, this paper presents an optimized artificial potential field (APF) algorithm for multi-UAV operation in 3-D dynamic space. The classic APF algorithm is restricted to single UAV trajectory planning and usually fails to guarantee the avoidance of collisions. To overcome this challenge, a method is proposed with a distance factor and jump strategy to solve common problems, such as unreachable targets, and ensure that the UAV will not collide with any obstacles. The method considers the UAV companions as dynamic obstacles to realize collaborative trajectory planning. Furthermore, the jitter problem is solved using the dynamic step adjustment method. Several resolution scenarios are illustrated. The method has been validated in quantitative test simulation models and satisfactory results were obtained in a simulated urban environment.","['Trajectory', 'Force', 'Planning', 'Unmanned aerial vehicles', 'Collision avoidance', 'Jitter', 'Algorithm design and analysis']","['Multi-UAV', 'trajectory planning', 'collision avoidance', 'artificial potential field', 'jitter problem']"
"Recently, a chaotic image encryption algorithm based on information entropy (IEAIE) was proposed. This paper scrutinizes the security properties of the algorithm and evaluates the validity of the used quantifiable security metrics. When the round number is only one, the equivalent secret key of every basic operation of IEAIE can be recovered with a differential attack separately. Some common insecurity problems in the field of chaotic image encryption are found in IEAIE, e.g., the short orbits of the digital chaotic system and the invalid sensitivity mechanism built on information entropy of the plain image. Even worse, each security metric is questionable, which undermines the security credibility of IEAIE. Hence, IEAIE can only serve as a counterexample for illustrating common pitfalls in designing secure communication method for image data.","['Encryption', 'Chaotic communication', 'Information entropy', 'Sensitivity']","['Chaotic cryptanalysis', 'multimedia cryptography', 'image encryption', 'secure communication', 'privacy protection']"
"The fifth generation of cellular communication systems is foreseen to enable a multitude of new applications and use cases with very different requirements. A new 5G multi-service air interface needs to enhance broadband performance as well as provide new levels of reliability, latency, and supported number of users. In this paper, we focus on the massive Machine Type Communications (mMTC) service within a multi-service air interface. Specifically, we present an overview of different physical and medium access techniques to address the problem of a massive number of access attempts in mMTC and discuss the protocol performance of these solutions in a common evaluation framework.","['5G mobile communication', 'Interference', 'Long Term Evolution', 'Power control', 'Media Access Protocol']","['5G', 'mMTC', 'massive access', 'massive connectivity', 'random access']"
"To improve the performance of network intrusion detection systems (IDS), we applied deep learning theory to intrusion detection and developed a deep network model with automatic feature extraction. In this paper, we consider the characteristics of the time-related intrusion and propose a novel IDS that consists of a recurrent neural network with gated recurrent units (GRU), multilayer perceptron (MLP), and softmax module. Experiments on the well-known KDD 99 and NSL-KDD data sets show that the system has leading performance. The overall detection rate was 99.42% using KDD 99 and 99.31% using NSL-KDD with false positive rates as low as 0.05% and 0.84%, respectively. In particular, for detecting the denial of service attacks, the system achieved detection rates of 99.98% and 99.55%, respectively. Comparative experiments showed that the GRU is more suitable as a memory unit for IDS than LSTM, and proved that it is an effective simplification and improvement of LSTM. Moreover, the bidirectional GRU can reach the best performance compared with the recently published methods.","['Intrusion detection', 'Feature extraction', 'Machine learning', 'Support vector machines', 'Recurrent neural networks', 'Logic gates']","['Intrusion detection', 'deep learning', 'recurrent neural network', 'gated recurrent unit']"
"Depression is viewed as the largest contributor to global disability and a major reason for suicide. It has an impact on the language usage reflected in the written text. The key objective of our study is to examine Reddit users' posts to detect any factors that may reveal the depression attitudes of relevant online users. For such purpose, we employ the Natural Language Processing (NLP) techniques and machine learning approaches to train the data and evaluate the efficiency of our proposed method. We identify a lexicon of terms that are more common among depressed accounts. The results show that our proposed method can significantly improve performance accuracy. The best single feature is bigram with the Support Vector Machine (SVM) classifier to detect depression with 80% accuracy and 0.80 F1 scores. The strength and effectiveness of the combined features (LIWC+LDA+bigram) are most successfully demonstrated with the Multilayer Perceptron (MLP) classifier resulting in the top performance for depression detection reaching 91% accuracy and 0.93 F1 scores. According to our study, better performance improvement can be achieved by proper feature selections and their multiple feature combinations.","['Feature extraction', 'Task analysis', 'Linguistics', 'Twitter', 'Natural language processing', 'Support vector machines']","['Natural language processing', 'machine learning', 'Reddit', 'social networks', 'depression']"
"Vehicular edge computing (VEC) is introduced to extend computing capacity to vehicular network edge recently. With the advent of VEC, service providers directly host services in close proximity of mobile vehicles for great improvements. As a result, a new networking paradigm, vehicular edge networks is emerged along with the development of VEC. However, it is necessary to address security issues for facilitating VEC well. In this paper, we focus on reputation management to ensure security protection and improve network efficiency in the implementation of VEC. A distributed reputation management system (DREAMS) is proposed, wherein VEC servers are adopted to execute local reputation management tasks for vehicles. This system has remarkable features for improving overall performance: 1) distributed reputation maintenance; 2) trusted reputation manifestation; 3) accurate reputation update; and 4) available reputation usage. In particular, we utilize multi-weighted subjective logic for accurate reputation update in DREAMS. To enrich reputation usage in DREAMS, service providers optimize resource allocation in computation offloading by considering reputation of vehicles. Numerical results indicate that DREAMS has great advantages in optimizing misbehavior detection and improving the recognition rate of misbehaving vehicles. Meanwhile, we demonstrate the effectiveness of our reputation-based resource allocation algorithm.","['Edge computing', 'Mobile communication', 'Servers', 'Resource management', 'Optimization', 'Security']","['Edge computing', 'security management', 'intelligent vehicles', 'optimization']"
"Speech emotion recognition is a vital and challenging task that the feature extraction plays a significant role in the SER performance. With the development of deep learning, we put our eyes on the structure of end-to-end and authenticate the algorithm that is extraordinary effective. In this paper, we introduce a novel architecture ADRNN (dilated CNN with residual block and BiLSTM based on the attention mechanism) to apply for the speech emotion recognition which can take advantage of the strengths of diverse networks and overcome the shortcomings of utilizing alone, and are evaluated in the popular IEMOCAP database and Berlin EMODB corpus. Dilated CNN can assist the model to acquire more receptive fields than using the pooling layer. Then, the skip connection can keep more historic info from the shallow layer and BiLSTM layer are adopted to learn long-term dependencies from the learned local features. And we utilize the attention mechanism to enhance further extraction of speech features. Furthermore, we improve the loss function to apply softmax together with the center loss that achieves better classification performance. As emotional dialogues are transformed of the spectrograms, we pick up the values of the 3-D Log-Mel spectrums from raw signals and put them into our proposed algorithm and obtain a notable performance to get the 74.96% unweighted accuracy in the speaker-dependent and the 69.32% unweighted accuracy in the speaker-independent experiment. It is better than the 64.74% from previous state-of-the-art methods in the spontaneous emotional speech of the IEMOCAP database. In addition, we propose the networks that achieve recognition accuracies of 90.78% and 85.39% on Berlin EMODB of speaker-dependent and speaker-independent experiment respectively, which are better than the accuracy of 88.30% and 82.82% obtained by previous work. For validating the robustness and generalization, we also make an experiment for cross-corpus between above databases and get the preferable 63.84% recognition accuracy in final.","['Speech recognition', 'Feature extraction', 'Emotion recognition', 'Convolution', 'Databases', 'Deep learning', 'Three-dimensional displays']","['3-D Log-Mel', 'dilated CNN', 'residual block', 'center loss', 'BiLSTM', 'attention mechanism']"
"Autonomous mobile robots are becoming more prominent in recent time because of their relevance and applications to the world today. Their ability to navigate in an environment without a need for physical or electro-mechanical guidance devices has made it more promising and useful. The use of autonomous mobile robots is emerging in different sectors such as companies, industries, hospital, institutions, agriculture and homes to improve services and daily activities. Due to technology advancement, the demand for mobile robot has increased due to the task they perform and services they render such as carrying heavy objects, monitoring, search and rescue missions, etc. Various studies have been carried out by researchers on the importance of mobile robot, its applications and challenges. This survey paper unravels the current literatures, the challenges mobile robot is being faced with. A comprehensive study on devices/sensors and prevalent sensor fusion techniques developed for tackling issues like localization, estimation and navigation in mobile robot are presented as well in which they are organised according to relevance, strengths and weaknesses. The study therefore gives good direction for further investigation on developing methods to deal with the discrepancies faced with autonomous mobile robot.","['Mobile robots', 'Robot sensing systems', 'Navigation', 'Wheels', 'Task analysis', 'Robot kinematics']","['Autonomous mobile robot', 'sensor fusion', 'devices', 'estimation', 'localization', 'navigation']"
"Due to the real working conditions and data acquisition equipment, the collected working data of bearings are actually limited. Meanwhile, as the rolling bearing works in the normal state at most times, it is easy to raise the imbalance problem of fault types which restricts the diagnosis accuracy and stability. To solve these problems, we present an imbalanced fault diagnosis method based on the generative adversarial network (GAN) and provide a comparative study in detail. The key idea is utilizing GAN, a kind of deep learning technique, to generate synthetic samples for minority fault class and then improve the generalization ability of the fault diagnosis model. First, this method applies fast Fourier transform to pre-process the original vibration signal and then obtains the frequency spectrum of fault samples. Second, it uses the spectrum data as the input of GAN to generate the synthetic minority samples following the data distribution of the real samples. Finally, it puts the synthetic samples into the training set and builds a stacked denoising auto encoder model for fault diagnosis. To testify the effectiveness of the proposed method, a series of comparative experiments is carried out on the CWRU bearing dataset. The results show that the proposed method can provide a better solution for imbalanced fault diagnosis on the basis of generating similar fault samples. As a comparative study, the proposed method is compared to several diagnostic methods with traditional time-frequency domain characteristics. Moreover, we also demonstrate that the proposed method outperforms three widely used sample synthesis techniques, such as random oversampling, synthetic minority oversampling technique, and the principal curve-based oversampling method in terms of diagnosis accuracy and numerical stability.","['Gallium nitride', 'Fault diagnosis', 'Generative adversarial networks', 'Feature extraction', 'Training', 'Rolling bearings', 'Neural networks']","['Generative adversarial network', 'fault diagnosis', 'imbalanced fault', 'SDAE']"
"Droop control is a well-known strategy for the parallel operation of inverters. However, the droop control strategy changes its form for inverters with different types of output impedance, and so far, it is impossible to operate inverters with inductive and capacitive output impedances in parallel. In this paper, it is shown that there exists a universal droop control principle for inverters with output impedance having a phase angle between -(π/2) rad and (π/2) rad. It takes the form of the droop control for inverters with resistive output impedance (R-inverters). Hence, the robust droop controller recently proposed in the literature for R-inverters actually provides one way to implement such a universal droop controller that can be applied to all practical inverters without the need of knowing the impedance angle. The small-signal stability of an inverter equipped with the universal droop controller is analyzed, and it is shown to be stable when the phase angle of the output impedance changes from -(π/2) rad to (π/2) rad. Both real-time simulation results and experimental results from a test rig consisting of an R-inverter, an L-inverter, and a C-inverter operated in parallel are presented to validate the proposed strategy.","['Inverters', 'Impedance', 'Reactive power', 'Robustness', 'Voltage control', 'Stability analysis', 'Frequency control', 'Droop controllers', 'Stability analysis', 'Real-time systems']","['C-inverters', 'L-inverters', 'output impedance', 'parallel operation of inverters', 'R-inverters', 'robust droop controller', 'universal droop controller']"
"The number of used batteries is increasing in quantity as time passes by, and this amount is to expand drastically, as electric vehicles are getting increasingly popular. Proper disposal of the spent batteries has always been a concern, but it has also been discovered that these batteries often retain enough energy perfectly suited for other uses, which can extend the batteries' operational lifetime into a second one. Such use of batteries has been termed as the “second-life,” and it is high time to adopt such usage in large scale to properly exploit the energy and economics that went into battery production and reduce the environmental impacts of battery waste ending up in landfills. This paper aids in that quest by providing a complete picture of the current state of the second-life battery (SLB) technology by reviewing all the prominent work done in this field previously. The second-life background, manufacturing process of energy storage systems using the SLBs, applications, and impacts of this technology, required business strategies and policies, and current barriers of this technology along with potential solutions are discussed in detail in this paper to act as a major stepping stone for future research in this ever-expanding field.","['Batteries', 'Resistance', 'Business', 'Recycling', 'Second Life', 'Discharges (electric)']","['Second life battery', 'battery energy storage system', 'electric vehicle', 'battery management system', 'disposal', 'battery aging', 'economic and environmental values', 'recycling and waste management']"
"Due to the imbalanced distribution of business data, missing user features, and many other reasons, directly using big data techniques on realistic business data tends to deviate from the business goals. It is difficult to model the insurance business data by classification algorithms, such as logistic regression and support vector machine (SVM). In this paper, we exploit a heuristic bootstrap sampling approach combined with the ensemble learning algorithm on the large-scale insurance business data mining, and propose an ensemble random forest algorithm that uses the parallel computing capability and memory-cache mechanism optimized by Spark. We collected the insurance business data from China Life Insurance Company to analyze the potential customers using the proposed algorithm. We use F-Measure and G-mean to evaluate the performance of the algorithm. Experiment result shows that the ensemble random forest algorithm outperformed SVM and other classification algorithms in both performance and accuracy within the imbalanced data, and it is useful for improving the accuracy of product marketing compared to the traditional artificial approach.","['Insurance', 'Big Data', 'Sparks', 'Companies', 'Industries', 'Data models']","['Classification algorithms', 'ensemble learning', 'random forest', 'big data', 'spark']"
"In recent years, due to the wide utilization of direct current (DC) power sources, such as solar photovoltaic (PV), fuel cells, different DC loads, high-level integration of different energy storage systems such as batteries, supercapacitors, DC microgrids have been gaining more importance. Furthermore, unlike conventional AC systems, DC microgrids do not have issues such as synchronization, harmonics, reactive power control, and frequency control. However, the incorporation of different distributed generators, such as PV, wind, fuel cell, loads, and energy storage devices in the common DC bus complicates the control of DC bus voltage as well as the power-sharing. In order to ensure the secure and safe operation of DC microgrids, different control techniques, such as centralized, decentralized, distributed, multilevel, and hierarchical control, are presented. The optimal planning of DC microgrids has an impact on operation and control algorithms; thus, coordination among them is required. A detailed review of the planning, operation, and control of DC microgrids is missing in the existing literature. Thus, this article documents developments in the planning, operation, and control of DC microgrids covered in research in the past 15 years. DC microgrid planning, operation, and control challenges and opportunities are discussed. Different planning, control, and operation methods are well documented with their advantages and disadvantages to provide an excellent foundation for industry personnel and researchers. Power-sharing and energy management operation, control, and planning issues are summarized for both grid-connected and islanded DC microgrids. Also, key research areas in DC microgrid planning, operation, and control are identified to adopt cutting-edge technologies. This review explicitly helps readers understand existing developments on DC microgrid planning, operation, and control as well as identify the need for additional research in order to further contribute to the topic.","['Microgrids', 'Planning', 'Reliability', 'Energy storage', 'Renewable energy sources', 'Supercapacitors', 'Batteries']","['DC microgrids', 'renewable energy sources', 'batteries', 'supercapacitors', 'dc bus voltage', 'power management', 'state of charge', 'microgrid operation', 'planning']"
"In this paper, a novel swarm intelligent algorithm is proposed, known as the fitness dependent optimizer (FDO). The bee swarming the reproductive process and their collective decision-making have inspired this algorithm; it has no algorithmic connection with the honey bee algorithm or the artificial bee colony algorithm. It is worth mentioning that the FDO is considered a particle swarm optimization (PSO)-based algorithm that updates the search agent position by adding velocity (pace). However, the FDO calculates velocity differently; it uses the problem fitness function value to produce weights, and these weights guide the search agents during both the exploration and exploitation phases. Throughout this paper, the FDO algorithm is presented, and the motivation behind the idea is explained. Moreover, the FDO is tested on a group of 19 classical benchmark test functions, and the results are compared with three well-known algorithms: PSO, the genetic algorithm (GA), and the dragonfly algorithm (DA); in addition, the FDO is tested on the IEEE Congress of Evolutionary Computation Benchmark Test Functions (CEC-C06, 2019 Competition) [1]. The results are compared with three modern algorithms: (DA), the whale optimization algorithm (WOA), and the salp swarm algorithm (SSA). The FDO results show better performance in most cases and comparative results in other cases. Furthermore, the results are statistically tested with the Wilcoxon rank-sum test to show the significance of the results. Likewise, the FDO stability in both the exploration and exploitation phases is verified and performance-proofed using different standard measurements. Finally, the FDO is applied to real-world applications as evidence of its feasibility.","['Optimization', 'Heuristic algorithms', 'Classification algorithms', 'Genetic algorithms', 'Artificial bee colony algorithm', 'Particle swarm optimization']","['Optimization', 'swarm intelligence', 'evolutionary computation', 'metaheuristic algorithms', 'fitness dependent optimizer', 'FDO']"
"The nature of stock market movement has always been ambiguous for investors because of various influential factors. This study aims to significantly reduce the risk of trend prediction with machine learning and deep learning algorithms. Four stock market groups, namely diversified financials, petroleum, non-metallic minerals and basic metals from Tehran stock exchange, are chosen for experimental evaluations. This study compares nine machine learning models (Decision Tree, Random Forest, Adaptive Boosting (Adaboost), eXtreme Gradient Boosting (XGBoost), Support Vector Classifier (SVC), Naïve Bayes, K-Nearest Neighbors (KNN), Logistic Regression and Artificial Neural Network (ANN)) and two powerful deep learning methods (Recurrent Neural Network (RNN) and Long short-term memory (LSTM). Ten technical indicators from ten years of historical data are our input values, and two ways are supposed for employing them. Firstly, calculating the indicators by stock trading values as continuous data, and secondly converting indicators to binary data before using. Each prediction model is evaluated by three metrics based on the input ways. The evaluation results indicate that for the continuous data, RNN and LSTM outperform other prediction models with a considerable difference. Also, results show that in the binary data evaluation, those deep learning methods are the best; however, the difference becomes less because of the noticeable improvement of models' performance in the second way.","['Stock markets', 'Machine learning', 'Predictive models', 'Market research', 'Prediction algorithms', 'Support vector machines', 'Indexes']","['Stock market', 'trends prediction', 'classification', 'machine learning', 'deep learning']"
"Near-field magnetic wireless systems have distinct advantages over their conventional farfield counterparts in water-rich environments, such as underwater, underground, and in biological tissues, due to lower power absorption. This paper presents a comprehensive review of near-field magnetic wireless power transfer (WPT) and communication technologies in a variety of applications from general free-space systems, to implantable biomedical devices we find of particular interest. To implement a fully wirelessly-powered implantable system, both high-efficiency power transfer and high-rate data communication are essential. This paper first presents the history and the fundamentals of near-field WPT and communication in free-space systems, followed by technical details for their specific use in implantable biomedical devices. Finally, this paper reviews recent advances in simultaneous wireless information and power transfer and highlights their applications in implantable biomedical systems. The knowledge reviewed in the paper could provide intuition in the design of various wireless and mobile systems such as wireless body area networks, small-cell 5G cellular, as well as in-body biomedical applications, especially for efficient power and data management and higher security.","['Wireless communication', 'Implants', 'Communication system security', 'Radiofrequency identification', 'Couplings', 'Absorption', 'Wireless sensor networks']","['Near-field wireless power', 'near-field wireless communication', 'biomedical applications', 'implantable device']"
"Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence/machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2019. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 176 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.","['Optical character recognition software', 'Character recognition', 'Databases', 'Optical imaging', 'Bibliographies', 'Protocols', 'Systematics']","['Optical character recognition', 'classification', 'languages', 'feature extraction', 'deep learning']"
"PM2.5 is one of the most important pollutants related to air quality, and the increase of its concentration will aggravate the threat to people's health. Therefore, the prediction of surface PM2.5 concentration is of great significance to human health protection. In this study, A hybrid CNN-LSTM model is developed by combining the convolutional neural network (CNN) with the long short-term memory (LSTM) neural network for forecasting the next 24h PM2.5 concentration in Beijing, which makes full use of their advantages that CNN can effectively extract the features related to air quality and the LSTM can reflect the long term historical process of input time series data. The air quality data of the last 7days and the PM2.5 concentration of the next day are first set as the input and output of the model due to the periodicity, respectively. Subsequently four models namely univariate LSTM model, multivariate LSTM model, univariate CNN-LSTM model and multivariate CNN-LSTM model, are established for PM2.5 concentration prediction. Finally, mean absolute error (MAE) and root mean square error (RMSE) are employed to evaluate the performance of these models and results show that the proposed multivariate CNN-LSTM model performs the best results due to low error and short training time.","['Predictive models', 'Atmospheric modeling', 'Time series analysis', 'Forecasting', 'Data models', 'Deep learning', 'Feature extraction']","['Deep learning', 'CNN', 'LSTM', 'PM2.5 concentration prediction']"
"Lightweight virtualization technologies have revolutionized the world of software development by introducing flexibility and innovation to this domain. Although the benefits introduced by these emerging solutions have been widely acknowledged in cloud computing, recent advances have led to the spread of such technologies in different contexts. As an example, the Internet of Things (IoT) and mobile edge computing benefit from container virtualization by exploiting the possibility of using these technologies not only in data centers but also on devices, which are characterized by fewer computational resources, such as single-board computers. This has led to a growing trend to more efficiently redesign the critical components of IoT/edge scenarios (e.g., gateways) to enable the concept of device virtualization. The possibility for efficiently deploying virtualized instances on single-board computers has already been addressed in recent studies; however, these studies considered only a limited number of devices and omitted important performance metrics from their empirical assessments. This paper seeks to fill this gap and to provide insights for future deployments through a comprehensive performance evaluation that aims to show the strengths and weaknesses of several low-power devices when handling container-virtualized instances.","['Containers', 'Virtualization', 'Logic gates', 'Performance evaluation', 'Cloud computing', 'Hardware']","['Internet of Things', 'edge computing', 'container virtualization', 'docker', 'performance evaluation']"
"Rapid advance of location acquisition technologies boosts the generation of trajectory data, which track the traces of moving objects. A trajectory is typically represented by a sequence of timestamped geographical locations. A wide spectrum of applications can benefit from the trajectory data mining. Bringing unprecedented opportunities, large-scale trajectory data also pose great challenges. In this paper, we survey various applications of trajectory data mining, e.g., path discovery, location prediction, movement behavior analysis, and so on. Furthermore, this paper reviews an extensive collection of existing trajectory data mining techniques and discusses them in a framework of trajectory data mining. This framework and the survey can be used as a guideline for designing future trajectory data mining solutions.","['Data mining', 'Trajectory', 'Big data', 'Data analytics', 'Data processing', 'Location awareness']","['Trajectory data mining', 'big data applications', 'data mining techniques']"
"Due to the advances in computer-based communication and health services over the past decade, the need for image security becomes urgent to address the requirements of both safety and non-safety in medical applications. This paper proposes a new fragile watermarking-based scheme for image authentication and self-recovery for medical applications. The proposed scheme locates image tampering as well as recovers the original image. A host image is broken into 4\times 4 blocks and singular value decomposition (SVD) is applied by inserting the traces of block wise SVD into the least significant bit of the image pixels to figure out the transformation in the original image. Two authentication bits namely block authentication and self-recovery bits are used to survive the vector quantization attack. The insertion of self-recovery bits is determined with Arnold transformation, which recovers the original image even after a high tampering rate. SVD-based watermarking information improves the image authentication and provides a way to detect different attacked area of the watermarked image. The proposed scheme is tested against different types of attacks such as text removal attack, text insertion attack, and copy and paste attack. Compared with the state-of-the art methods, the proposed scheme greatly improves both tamper localization accuracy and the peak signal to noise ratio of self-recovered image.","['Watermarking', 'Matrix decomposition', 'Authentication', 'Transforms', 'Biomedical imaging', 'Symmetric matrices']","['Medical image security', 'tamper localization', 'singular value decomposition', 'fragile watermarking', 'arnold transformation', 'image security', 'authentication']"
"Solid-state transformer (SST) is an emerging technology integrating with a transformer power electronics converters and control circuitry. This paper comprehensively reviews the SST topologies suitable for different voltage levels and with varied stages, their control operation, and different trends in applications. The paper discusses various SST configurations with their design and characteristics to convert the input to output under unipolar and bipolar operation. A comparison between the topologies, control operation and applications are included. Different control models and schemes are explained. Potential benefits of SST in many applications in terms of controllability and the synergy of AC and DC systems are highlighted to appreciate the importance of SST technologies. This review highlights many factors including existing issues and challenges and provides recommendations for the improvement of future SST configuration and development.","['Topology', 'Switches', 'Voltage control', 'Reactive power', 'Bridge circuits', 'Bidirectional control', 'Power conversion']","['Converter control', 'power distribution', 'solid-state transformer', 'transformer topologies', 'power converter']"
"This paper analyzes the notion of resilience in power systems from a fundamental viewpoint and thoroughly examines its practical implications. This paper aims to describe and classify different high-impact rare (HR) events, provide a more technical definition of power system resilience, and discuss linkages between resilience and other well-established concepts, such as security and reliability. Most relevant decisions of system operators in the face of HR events involve a significant level of stress and strain. In order to make informed decisions within this context, it is crucial to have an all-inclusive picture of the state of the system. This paper provides an appropriate framework that not only characterizes the various states of the system but also derives informed decisions from a resilience-oriented perspective. It also describes and analyzes diverse resilience improvement strategies. Comprehensive models and classifications are provided to clearly capture various aspects of power system resilience.","['Resilience', 'Power system stability', 'Uncertainty', 'Meteorology', 'Power system reliability', 'Power grids']","['High-impact rare (HR) events', 'power system restoration', 'proactive management', 'resilience assessment', 'resilience improvement']"
"The state-of-the-art technologies in new generation information technologies (New IT) greatly stimulate the development of smart manufacturing. In a smart manufacturing environment, more and more devices would be connected to the Internet so that a large volume of data can be obtained during all phases of the product lifecycle. Cloud-based smart manufacturing paradigm facilitates a new variety of applications and services to analyze a large volume of data and enable large-scale manufacturing collaboration. However, different factors, such as the network unavailability, overfull bandwidth, and latency time, restrict its availability for high-speed and low-latency real-time applications. Fog computing and edge computing extended the compute, storage, and networking capabilities of the cloud to the edge, which will respond to the above-mentioned issues. Based on cloud computing, fog computing, and edge computing, in this paper, a hierarchy reference architecture is introduced for smart manufacturing. The architecture is expected to be applied in the digital twin shop floor, which opens a bright perspective of new applications within the field of manufacturing.","['Cloud computing', 'Edge computing', 'Smart manufacturing', 'Computer architecture', 'Manufacturing systems', 'Real-time systems']","['Cloud computing', 'digital twin', 'edge computing', 'fog computing', 'hierarchical architecture', 'smart manufacturing']"
"Originally conceived as a mechanism to enable a trustless cryptocurrency-Bitcoin, blockchain has since unbound itself from its original purpose as an increasing number of industries and stakeholders' eye the technology as an attractive alternative to solve existing business solutions as well as disrupt mature industries. This paper presents a systematic literature review of the blockchain technology, tracking its increase in popularity in relation to similar technologies, such as cryptocurrencies and Bitcoin. The objective of this paper is to identify the current standing of the blockchain technology within the literature while also identifying the major fields of study and areas of application for which blockchain offers a valuable solution. This paper finds that unique features to the blockchain, such as privacy, security, anonymity, decentralization, and immutability, provide valuable benefits to various fields and subjects. This paper also finds that exploring the application of blockchain has only begun with some limited studies in areas, such as the Internet of Things, energy, finance, healthcare, and government, that also stand to benefit disproportionately from its implementation.","['Blockchain', 'Industries', 'Bitcoin', 'Bibliographies', 'Public key']","['Blockchain', 'cryptocurrency', 'energy', 'eGovernment', 'finance', 'healthcare', 'Internet of Things', 'applications', 'review']"
"Emotional state recognition of a speaker is a difficult task for machine learning algorithms which plays an important role in the field of speech emotion recognition (SER). SER plays a significant role in many real-time applications such as human behavior assessment, human-robot interaction, virtual reality, and emergency centers to analyze the emotional state of speakers. Previous research in this field is mostly focused on handcrafted features and traditional convolutional neural network (CNN) models used to extract high-level features from speech spectrograms to increase the recognition accuracy and overall model cost complexity. In contrast, we introduce a novel framework for SER using a key sequence segment selection based on redial based function network (RBFN) similarity measurement in clusters. The selected sequence is converted into a spectrogram by applying the STFT algorithm and passed into the CNN model to extract the discriminative and salient features from the speech spectrogram. Furthermore, we normalize the CNN features to ensure precise recognition performance and feed them to the deep bi-directional long short-term memory (BiLSTM) to learn the temporal information for recognizing the final state of emotion. In the proposed technique, we process the key segments instead of the whole utterance to reduce the computational complexity of the overall model and normalize the CNN features before their actual processing, so that it can easily recognize the Spatio-temporal information. The proposed system is evaluated over different standard dataset including IEMOCAP, EMO-DB, and RAVDESS to improve the recognition accuracy and reduce the processing time of the model, respectively. The robustness and effectiveness of the suggested SER model is proved from the experimentations when compared to state-of-the-art SER methods with an achieve up to 72.25%, 85.57%, and 77.02% accuracy over IEMOCAP, EMO-DB, and RAVDESS dataset, respectively.","['Feature extraction', 'Speech recognition', 'Emotion recognition', 'Spectrogram', 'Task analysis', 'Deep learning', 'Data mining']","['Speech emotion recognition', 'deep bidirectional long shot term memory', 'key segment sequence selection', 'normalization of CNN features', 'radial-based function network (RBFN)']"
"In this paper, we propose a distributed joint computation offloading and resource allocation optimization (JCORAO) scheme in heterogeneous networks with mobile edge computing. An optimization problem is formulated to provide the optimal computation offloading strategy policy, uplink subchannel allocation, uplink transmission power allocation, and computation resource scheduling. The optimization problem is decomposed into two sub-problems due to the NP-hard property. In order to analyze the offloading strategy, a sub-algorithm named distributed potential game is built. The existence of Nash equilibrium is proved. To jointly allocate uplink subchannel, uplink transmission power, and computation resource for the offloading mobile terminals, a sub-algorithm named cloud and wireless resource allocation algorithm is designed. The solutions for subchannel allocation consist of uniform zero frequency reuse method without interference and fractional frequency reuse method based on Hungarian and graph coloring with interference. A distributed JCORAO scheme is proposed to solve the optimization problem by the mutual iteration of the two sub-algorithms. Simulation results show that the distributed JCORAO scheme can effectively decrease the energy consumption and task completion time with lower complexity.","['Resource management', 'Task analysis', 'Servers', 'Optimization', 'Uplink', 'Wireless communication', 'Computational modeling']","['Mobile edge computing', 'heterogeneous networks', 'offloading strategy', 'resource allocation', 'game theory']"
"Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions.","['Cloud computing', 'Wireless communication', 'Data analysis', 'Big Data', 'Wireless sensor networks', 'Edge computing', 'Distributed databases']","['Big data', 'data analytics', 'internet of things (IoT)', 'cloud computing', 'edge computing', 'fog computing']"
"As a prerequisite for cell detection, cell classification, and cancer grading, nuclei segmentation in histology images has attracted wide attention in recent years. It is quite a challenging task due to the diversity in staining procedure, cell morphology, and cell arrangement between different histopathology images, especially with different color contrasts. In this paper, an Unet-based neural network, RIC-Unet (residual-inception-channel attention-Unet), for nuclei segmentation is proposed. The techniques of residual blocks, multi-scale and channel attention mechanism are applied on RIC-Unet to segment nuclei more accurately. RIC-Unet is compared with two traditional segmentation methods: CP and Fiji, two original CNN methods: CNN2, CNN3, and original U-net on The Cancer Genomic Atlas (TCGA) dataset. Besides, in this paper, we use Dice, F1-score, and aggregated Jaccard index to evaluate these methods. The average of RIC-Unet and U-net on these three indicators are 0.8008 versus 0.7844, 0.8278 versus 0.8155, and 0.5635 versus 0.5462. In addition, our method won the third place in the computational precision medicine nuclei segmentation challenge together with MICCAI 2018.","['Image segmentation', 'Computer architecture', 'Feature extraction', 'Microprocessors', 'Pathology', 'Semantics', 'Task analysis']","['Computational pathology', 'nuclei segmentation', 'residual block', 'deep learning']"
"This paper presents a technical overview for low-noise switched reluctance motor (SRM) drives in electric vehicle (EV) applications. With ever-increasing concerns over environmental and cost issues associated with permanent magnet machines, there is a technical trend to utilize SRMs in some mass production markets. The SRM is gaining much interest for EVs due to its rare-earth-free characteristic and excellent performance. In spite of many advantages compared with conventional adjustable-speed drives, SRMs suffer from torque ripple and radial distortion (and thus noise and vibration) by their nature. Therefore, for high-performance vehicle applications, it is important and urgent to optimize the SRM system to overcome the drawbacks of the noise and vibration. In order to present clear solutions to the acoustic noise in SRMs, this paper starts by analyzing the mechanism of the radial vibration and torque ripples inherent in the motors, and then focuses on the state-of-the-art technologies to mitigate the radial force and torque ripples. It highlights two categories for low-noise SRMs, including the machine topology improvement and control strategy design for radial vibration mitigation and torque ripple reduction. Advanced technologies are reviewed, classified, and compared accordingly. In addition to these methodologies, the schemes that have been developed by authors are also presented and discussed. Finally, the research status on this topic is summarized and forecast research hotspots are presented. It is our intention that this paper provides the guidance on performance improvements for low-noise SRM drives in EV applications.","['Reluctance motors', 'Force', 'Vibrations', 'Stator windings', 'Rotors']","['Switched reluctance motor (SRM)', 'low noise', 'torque ripple', 'radial distortion', 'control', 'motor structure']"
"The diagnosis of blood-related diseases involves the identification and characterization of a patient's blood sample. As such, automated methods for detecting and classifying the types of blood cells have important medical applications in this field. Although deep convolutional neural network (CNN) and the traditional machine learning methods have shown good results in the classification of blood cell images, they are unable to fully exploit the long-term dependence relationship between certain key features of images and image labels. To resolve this problem, we have introduced the recurrent neural networks (RNNs). Specifically, we combined the CNN and RNN in order to propose the CNN-RNN framework that can deepen the understanding of image content and learn the structured features of images and to begin endto-end training of big data in medical image analysis. In particular, we apply the transfer learning method to transfer the weight parameters that were pre-trained on the ImageNet dataset to the CNN section and adopted a custom loss function to allow our network to train and converge faster and with more accurate weight parameters. Experimental results show that compared with the other CNN models such as ResNet and Inception V3, our proposed network model is more accurate and efficient in classifying blood cell images.","['Classification algorithms', 'Feature extraction', 'Convolutional neural networks', 'Support vector machines', 'White blood cells', 'Image classification']","['Artificial intelligence', 'convolutional neural network', 'recurrent neural network', 'transfer learning']"
"The Internet of Things (IoT) has facilitated services without human intervention for a wide range of applications, including continuous remote patient monitoring (RPM). However, the complexity of RPM architectures, the size of data sets generated and limited power capacity of devices make RPM challenging. In this paper, we propose a tier-based End to End architecture for continuous patient monitoring that has a patient centric agent (PCA) as its center piece. The PCA manages a blockchain component to preserve privacy when data streaming from body area sensors needs to be stored securely. The PCA based architecture includes a lightweight communication protocol to enforce security of data through different segments of a continuous, real time patient monitoring architecture. The architecture includes the insertion of data into a personal blockchain to facilitate data sharing amongst healthcare professionals and integration into electronic health records while ensuring privacy is maintained. The blockchain is customized for RPM with modifications that include having the PCA select a Miner to reduce computational effort, enabling the PCA to manage multiple blockchains for the same patient, and the modification of each block with a prefix tree to minimize energy consumption and incorporate secure transaction payments. Simulation results demonstrate that security and privacy can be enhanced in RPM with the PCA based End to End architecture.","['Computer architecture', 'Medical services', 'Principal component analysis', 'Sensors', 'Biomedical monitoring']","['Blockchain', 'body area sensor network', 'healthcare', 'remote patient monitoring', 'patient centric agent', 'proof of work', 'streamed data', 'Internet of Things', 'dynamically generated session key', 'patient record encryption key']"
"Cardiovascular diseases (CVD) are among the most common serious illnesses affecting human health. CVDs may be prevented or mitigated by early diagnosis, and this may reduce mortality rates. Identifying risk factors using machine learning models is a promising approach. We would like to propose a model that incorporates different methods to achieve effective prediction of heart disease. For our proposed model to be successful, we have used efficient Data Collection, Data Pre-processing and Data Transformation methods to create accurate information for the training model. We have used a combined dataset (Cleveland, Long Beach VA, Switzerland, Hungarian and Stat log). Suitable features are selected by using the Relief, and Least Absolute Shrinkage and Selection Operator (LASSO) techniques. New hybrid classifiers like Decision Tree Bagging Method (DTBM), Random Forest Bagging Method (RFBM), K-Nearest Neighbors Bagging Method (KNNBM), AdaBoost Boosting Method (ABBM), and Gradient Boosting Boosting Method (GBBM) are developed by integrating the traditional classifiers with bagging and boosting methods, which are used in the training process. We have also instrumented some machine learning algorithms to calculate the Accuracy (ACC), Sensitivity (SEN), Error Rate, Precision (PRE) and F1 Score (F1) of our model, along with the Negative Predictive Value (NPR), False Positive Rate (FPR), and False Negative Rate (FNR). The results are shown separately to provide comparisons. Based on the result analysis, we can conclude that our proposed model produced the highest accuracy while using RFBM and Relief feature selection methods (99.05%).","['Heart', 'Predictive models', 'Prediction algorithms', 'Boosting', 'Support vector machines', 'Feature extraction', 'Classification algorithms']","['Heart disease', 'machine learning', 'CVD', 'relief feature selection', 'LASSO feature selection', 'decision tree', 'random forest', 'K-nearest neighbors', 'AdaBoost', 'gradient boosting']"
"Bidirectional DC-DC power converters are increasingly employed in diverse applications whereby power flow in both forward and reverse directions are required. These include but not limited to energy storage systems, uninterruptable power supplies, electric vehicles, and renewable energy systems, to name a few. This paper aims to review these converters from the point of view of topology as well as control schemes. From the point of view of topology, these converters are divided into two main categories, namely non-isolated and isolated configurations. Each category is divided into eight groups along with their respective schematics and a table of summary. Furthermore, the common control schemes and switching strategies for these converters are also reviewed. Some of the control schemes are typically applied to all DC-DC power converters such as PID, sliding mode, fuzzy, model predictive, digital control, etc. In this context, it should be noted that some switching strategies were designed specifically for isolated bidirectional DC-DC converters in order to improve their performance such as single phase shift, dual phase shift, triple phase shift, etc. The features of each topology and control scheme along with their typical applications are discussed, in order to provide a ground of comparison for realizing new configurations or finding the appropriate converter for the specific application.","['DC-DC power converters', 'Topology', 'Switches', 'Load flow', 'Inductors', 'Batteries']","['Batteries', 'bidirectional power flow', 'control systems', 'dc-dc power converters']"
"Modern power systems face different challenges such as the ever-increasing electrical energy demand, the massive growth of renewable energy with distributed generations, the large-scale Internet of Things (IoT) devices adaptation, the emerging cyber-physical security threats, and the main goal of maintaining the system's stability and reliability. These challenges pose extreme pressure on finding advanced technologies and sustainable solutions for secure and reliable operations of the power system. The blockchain is one of the recent technologies that have gained lots of attention in different applications including smart grid for its uniqueness and decentralized nature. In the last few years, this technology grew a momentum specifically with the cryptocurrencies' industry such as the Bitcoin and Etherium. The Blockchain's applications in the smart grids could offer many innovative and affordable solutions to some of the challenges that the future and the current smart grids will be facing. This paper reviews different prospects, advantages, approaches, and technical challenges of utilizing the blockchain technology in the smart grid, and presents frameworks for key smart grid blockchain-based applications; more specifically, it is shown that how the blockchain can be used as the smart grid's cyber-physical layer.","['Blockchain', 'Smart grids', 'Consensus algorithm', 'Cryptography', 'Industries', 'Renewable energy sources']","['Blockchain applications', 'cyber-physical security', 'energy trading', 'electric vehicles', 'microgrid monitoring and control', 'smart grids']"
"Our world and our lives are changing in many ways. Communication, networking, and computing technologies are among the most influential enablers that shape our lives today. Digital data and connected worlds of physical objects, people, and devices are rapidly changing the way we work, travel, socialize, and interact with our surroundings, and they have a profound impact on different domains, such as healthcare, environmental monitoring, urban systems, and control and management applications, among several other areas. Cities currently face an increasing demand for providing services that can have an impact on people's everyday lives. The CityPulse framework supports smart city service creation by means of a distributed system for semantic discovery, data analytics, and interpretation of large-scale (near-)real-time Internet of Things data and social media data streams. To goal is to break away from silo applications and enable cross-domain data integration. The CityPulse framework integrates multimodal, mixed quality, uncertain and incomplete data to create reliable, dependable information and continuously adapts data processing techniques to meet the quality of information requirements from end users. Different than existing solutions that mainly offer unified views of the data, the CityPulse framework is also equipped with powerful data analytics modules that perform intelligent data aggregation, event detection, quality assessment, contextual filtering, and decision support. This paper presents the framework, describes its components, and demonstrates how they interact to support easy development of custom-made applications for citizens. The benefits and the effectiveness of the framework are demonstrated in a use-case scenario implementation presented in this paper.","['Smart cities', 'Data analytics', 'Distributed databases', 'Semantics', 'Control systems', 'Environmental monitoring', 'Telecommunication services', 'Medical services', 'Digital systems', 'Knowledge discovery']","['Data analytics framework', 'smart cities']"
"The collection and analysis of data are continuously growing due to the pervasiveness of computing devices. The analysis of such information is fostering businesses and contributing beneficially to the society in many different fields. However, this storage and flow of possibly sensitive data poses serious privacy concerns. Methods that allow the knowledge extraction from data, while preserving privacy, are known as privacy-preserving data mining (PPDM) techniques. This paper surveys the most relevant PPDM techniques from the literature and the metrics used to evaluate such techniques and presents typical applications of PPDM methods in relevant fields. Furthermore, the current challenges and open issues in PPDM are discussed.",[],[]
"The upcoming fifth-generation (5G) mobile technology, which includes advanced communication features, is posing new challenges on cybersecurity defense systems. Although innovative approaches have evolved in the last few years, 5G will make existing intrusion detection and defense procedures become obsolete, in case they are not adapted accordingly. In this sense, this paper proposes a novel 5G-oriented cyberdefense architecture to identify cyberthreats in 5G mobile networks efficient and quickly enough. For this, our architecture uses deep learning techniques to analyze network traffic by extracting features from network flows. Moreover, our proposal allows adapting, automatically, the configuration of the cyberdefense architecture in order to manage traffic fluctuation, aiming both to optimize the computing resources needed in each particular moment and to fine tune the behavior and the performance of analysis and detection processes. Experiments using a well-known botnet data set depict how a neural network model reaches a sufficient classification accuracy in our anomaly detection system. Extended experiments using diverse deep learning solutions analyze and determine their suitability and performance for different network traffic loads. The experimental results show how our architecture can self-adapt the anomaly detection system based on the volume of network flows gathered from 5G subscribers' user equipments in real-time and optimizing the resource consumption.","['Anomaly detection', '5G mobile communication', 'Machine learning', 'Botnet', 'Computer architecture', 'Feature extraction']","['5G', 'anomaly detection', 'botnets', 'deep learning', 'performance evaluation']"
"Deep learning (DL) algorithms are considered as a methodology of choice for remote-sensing image analysis over the past few years. Due to its effective applications, deep learning has also been introduced for automatic change detection and achieved great success. The present study attempts to provide a comprehensive review and a meta-analysis of the recent progress in this subfield. Specifically, we first introduce the fundamentals of deep learning methods which are frequently adopted for change detection. Secondly, we present the details of the meta-analysis conducted to examine the status of change detection DL studies. Then, we focus on deep learning-based change detection methodologies for remote sensing images by giving a general overview of the existing methods. Specifically, these deep learning-based methods were classified into three groups; fully supervised learning-based methods, fully unsupervised learning-based methods and transfer learning-based techniques. As a result of these investigations, promising new directions were identified for future research. This study will contribute in several ways to our understanding of deep learning for change detection and will provide a basis for further research. Some source codes of the methods discussed in this paper are available from: https://github.com/lazharkhelifi/deeplearning_changedetection_remotesensing_review.","['Deep learning', 'Remote sensing', 'Task analysis', 'Learning systems', 'Biological neural networks', 'Computer vision', 'Change detection algorithms']","['Change detection', 'remote sensing images', 'deep learning', 'feature learning', 'weakly supervised learning', 'review']"
"Smart city advancements are driving massive transformations of healthcare, the largest global industry. The drivers include increasing demands for ubiquitous, preventive, and personalized healthcare, to be provided to the public at reduced risks and costs. Mobile cloud computing could potentially meet the future healthcare demands by enabling anytime, anywhere capture and analyses of patients' data. However, network latency, bandwidth, and reliability are among the many challenges hindering the realization of next-generation healthcare. This paper proposes a ubiquitous healthcare framework, UbeHealth, that leverages edge computing, deep learning, big data, high-performance computing (HPC), and the Internet of Things (IoT) to address the aforementioned challenges. The framework enables an enhanced network quality of service using its three main components and four layers. Deep learning, big data, and HPC are used to predict network traffic, which in turn are used by the Cloudlet and network layers to optimize data rates, data caching, and routing decisions. Application protocols of the traffic flows are classified, enabling the network layer to meet applications' communication requirements better and to detect malicious traffic and anomalous data. Clustering is used to identify the different kinds of data originating from the same application protocols. A proof of concept UbeHealth system has been developed based on the framework. A detailed literature review is used to capture the design requirements for the proposed system. The system is described in detail including the algorithmic implementation of the three components and four layers. Three widely used data sets are used to evaluate the UbeHealth system.","['Medical services', 'Cloud computing', 'Edge computing', 'Quality of service', 'Machine learning', 'Smart cities', 'Internet of Things']","['Cloudlets', 'deep learning', 'Internet of Things (IoT)', 'mobile edge computing', 'mobile healthcare', 'preventive healthcare', 'traffic classification', 'traffic prediction', 'survey', 'fog computing', 'cloud computing', 'multimedia applications', 'smart cities']"
"Wearable antennas have gained much attention in recent years due to their attractive features and possibilities in enabling lightweight, flexible, low cost, and portable wireless communication and sensing. Such antennas need to be conformal when used on different parts of the human body, thus need to be implemented using flexible materials and designed in a low profile structure. Ultimately, these antennas need to be capable of operating with minimum degradation in proximity to the human body. Such requirements render the design of wearable antennas challenging, especially when considering aspects such as their size compactness, effects of structural deformation and coupling to the body, and fabrication complexity and accuracy. Despite slight variations in severity according to applications, most of these issues exist in the context of body-worn implementation. This review aims to present different challenges and issues in designing wearable antennas, their material selection, and fabrication techniques. More importantly, recent innovative methods in back radiations reduction techniques, circular polarization (CP) generation methods, dual polarization techniques, and providing additional robustness against environmental effects are first presented. This is followed by a discussion of innovative features and their respective methods in alleviating these issues recently proposed by the scientific community researching in this field.","['Antennas', 'Biomedical monitoring', 'Substrates', 'Fabrics', 'Polymers', 'Fabrication', 'Conductivity']","['Wearable devices', 'Internet of Things (IoT)', 'wearable antennas', 'flexible', 'reconfigurable antennas', 'energy harvesting for wearable devices', 'specific absorption rate (SAR)']"
"The fifth generation (5G) mobile networks are envisaged to enable a plethora of breakthrough advancements in wireless technologies, providing support of a diverse set of services over a single platform. While the deployment of 5G systems is scaling up globally, it is time to look ahead for beyond 5G systems. This is mainly driven by the emerging societal trends, calling for fully automated systems and intelligent services supported by extended reality and haptics communications. To accommodate the stringent requirements of their prospective applications, which are data-driven and defined by extremely low-latency, ultra-reliable, fast and seamless wireless connectivity, research initiatives are currently focusing on a progressive roadmap towards the sixth generation (6G) networks, which are expected to bring transformative changes to this premise. In this article, we shed light on some of the major enabling technologies for 6G, which are expected to revolutionize the fundamental architectures of cellular networks and provide multiple homogeneous artificial intelligence-empowered services, including distributed communications, control, computing, sensing, and energy, from its core to its end nodes. In particular, the present paper aims to answer several 6G framework related questions: What are the driving forces for the development of 6G? How will the enabling technologies of 6G differ from those in 5G? What kind of applications and interactions will they support which would not be supported by 5G? We address these questions by presenting a comprehensive study of the 6G vision and outlining seven of its disruptive technologies, i.e., mmWave communications, terahertz communications, optical wireless communications, programmable metasurfaces, drone-based communications, backscatter communications and tactile internet, as well as their potential applications. Then, by leveraging the state-of-the-art literature surveyed for each technology, we discuss the associated requirements, key challenges, and open research problems. These discussions are thereafter used to open up the horizon for future research directions.","['5G mobile communication', 'Wireless communication', 'Wireless sensor networks', 'Market research', 'Artificial intelligence', 'Reliability', 'Haptic interfaces']","['6G', 'backscatter communications', 'drone-based communications', 'terahertz communications', 'metasurfaces', 'mm-wave', 'optical wireless communications', 'tactile internet']"
"In vehicular ad hoc networks (VANETs), trust establishment among vehicles is important to secure integrity and reliability of applications. In general, trust and reliability help vehicles to collect correct and credible information from surrounding vehicles. On top of that, a secure trust model can deal with uncertainties and risk taking from unreliable information in vehicular environments. However, inaccurate, incomplete, and imprecise information collected by vehicles as well as movable/immovable obstacles have interrupting effects on VANET. In this paper, a fuzzy trust model based on experience and plausibility is proposed to secure the vehicular network. The proposed trust model executes a series of security checks to ensure the correctness of the information received from authorized vehicles. Moreover, fog nodes are adopted as a facility to evaluate the level of accuracy of event's location. The analyses show that the proposed solution not only detects malicious attackers and faulty nodes, but also overcomes the uncertainty and imprecision of data in vehicular networks in both line of sight and non-line of sight environments.","['Security', 'Vehicular ad hoc networks', 'Reliability', 'Computational modeling', 'Edge computing', 'Fuzzy logic', 'Data models']","['Trust', 'plausibility', 'experience', 'fog node', 'fuzzy logic', 'VANET']"
"RGB-D (red, green, blue, and depth) salient object detection aims to identify the most visually distinctive objects in a pair of color and depth images. Based upon an observation that most of the salient objects may stand out at least in one modality, this paper proposes an adaptive fusion scheme to fuse saliency predictions generated from two modalities. Specifically, we design two-streamed convolutional neural networks (CNN), each of which extracts features and predicts a saliency map from either RGB or depth modality. Then, a saliency fusion module learns a switch map that is used to adaptively fuse the predicted saliency maps. A loss function composed of saliency supervision, switch map supervision, and edge-preserving constraints are designed to make full supervision, and the entire network is trained in an end-to-end manner. Benefited from the adaptive fusion strategy and the edge-preserving constraint, our approach outperforms state-of-the-art methods on three publicly available datasets.","['Switches', 'Feature extraction', 'Fuses', 'Image color analysis', 'Saliency detection', 'Streaming media', 'Object detection']","['RGB-D salient object detection', 'switch map', 'edge-preserving']"
"Air pollution forecasting can provide reliable information about the future pollution situation, which is useful for an efficient operation of air pollution control and helps to plan for prevention. Dynamics of air pollution are usually reflected by various factors, such as the temperature, humidity, wind direction, wind speed, snowfall, rainfall, and so on, which increase the difficulty in understanding the change of air pollutant concentration. In this paper, a short-term forecasting model based on deep learning is proposed for PM2.5 (particulate matter with an aerodynamic diameter less than or equal to 2.5~\mu \text{m} ) concentration, and the convolutional-based bidirectional gated recurrent unit (CBGRU) method is presented, which combines 1D convnets (convolutional neural networks) and bidirectional GRU (gated recurrent unit) neural networks. The case is carried out by using the Beijing PM2.5 data set in UCI Machine Learning Repository. Comparing the prediction results with the traditional ones, it is proved that the error of the CBGRU model is lower and the prediction performance is better.","['Predictive models', 'Forecasting', 'Wind speed', 'Atmospheric modeling', 'Time series analysis', 'Air pollution', 'Correlation']","['Air pollution forecasting', 'deep learning', '1D convolutional neural networks', 'bidirectional gated recurrent unit']"
"Disastrous events are cordially involved with the momentum of nature. As such mishaps have been showing off own mastery, situations have gone beyond the control of human resistive mechanisms far ago. Fortunately, several technologies are in service to gain affirmative knowledge and analysis of a disaster's occurrence. Recently, Internet of Things (IoT) paradigm has opened a promising door toward catering of multitude problems related to agriculture, industry, security, and medicine due to its attractive features, such as heterogeneity, interoperability, light-weight, and flexibility. This paper surveys existing approaches to encounter the relevant issues with disasters, such as early warning, notification, data analytics, knowledge aggregation, remote monitoring, real-time analytics, and victim localization. Simultaneous interventions with IoT are also given utmost importance while presenting these facts. A comprehensive discussion on the state-of-the-art scenarios to handle disastrous events is presented. Furthermore, IoT-supported protocols and market-ready deployable products are summarized to address these issues. Finally, this survey highlights open challenges and research trends in IoT-enabled disaster management systems.","['Protocols', 'Disaster management', 'Wireless sensor networks', 'Security', 'Real-time systems', 'Earthquakes', 'Nanoscale devices']","['Internet of Things', 'disaster management', 'cloud-assisted services']"
"The frequency of extreme events (e.g., hurricanes, earthquakes, and floods) and man-made attacks (cyber and physical attacks) has increased dramatically in recent years. These events have severely impacted power systems ranging from long outage times to major equipment (e.g., substations, transmission lines, and power plants) destructions. This calls for developing control and operation methods and planning strategies to improve grid resilience against such events. The first step toward this goal is to develop resilience metrics and evaluation methods to compare planning and operation alternatives and to provide techno-economic justifications for resilience enhancement. Although several power system resilience definitions, metrics, and evaluation methods have been proposed in the literature, they have not been universally accepted or standardized. This paper provides a comprehensive and critical review of current practices of power system resilience metrics and evaluation methods and discusses future directions and recommendations to contribute to the development of universally accepted and standardized definitions, metrics, evaluation methods, and enhancement strategies. This paper thoroughly examines the consensus on the power system resilience concept provided by different organizations and scholars and existing and currently practiced resilience enhancement methods. Research gaps, associated challenges, and potential solutions to existing limitations are also provided.","['Resilience', 'Measurement', 'Power system reliability', 'Meteorology', 'Hurricanes', 'Reliability']","['Critical review', 'extreme events', 'power system resilience', 'resilience definitions', 'metrics', 'enhancement strategies']"
"Technology and the rapid growth in the area of brain imaging technologies have forever made for a pivotal role in analyzing and focusing the new views of brain anatomy and functions. The mechanism of image processing has widespread usage in the area of medical science for improving the early detection and treatment phases. Deep neural networks (DNN), till date, have demonstrated wonderful performance in classification and segmentation task. Carrying this idea into consideration, in this paper, a technique for image compression using a deep wavelet autoencoder (DWA), which blends the basic feature reduction property of autoencoder along with the image decomposition property of wavelet transform is proposed. The combination of both has a tremendous effect on sinking the size of the feature set for enduring further classification task by using DNN. A brain image dataset was taken and the proposed DWA-DNN image classifier was considered. The performance criterion for the DWA-DNN classifier was compared with other existing classifiers such as autoencoder-DNN or DNN, and it was noted that the proposed method outshines the existing methods.","['Image segmentation', 'Magnetic resonance imaging', 'Tumors', 'Biological neural networks', 'Biomedical imaging', 'Task analysis']","['Neural network (NN)', 'deep neural network (DNN)', 'autoencoder (AE)', 'image classification']"
"As the amount of unstructured text data that humanity produces overall and on the Internet grows, so does the need to intelligently to process it and extract different types of knowledge from it. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been applied to natural language processing systems with comparative, remarkable results. The CNN is a noble approach to extract higher level features that are invariant to local translation. However, it requires stacking multiple convolutional layers in order to capture long-term dependencies, due to the locality of the convolutional and pooling layers. In this paper, we describe a joint CNN and RNN framework to overcome this problem. Briefly, we use an unsupervised neural language model to train initial word embeddings that are further tuned by our deep learning network, then, the pre-trained parameters of the network are used to initialize the model. At a final stage, the proposed framework combines former information with a set of feature maps learned by a convolutional layer with long-term dependencies learned via long-short-term memory. Empirically, we show that our approach, with slight hyperparameter tuning and static vectors, achieves outstanding results on multiple sentiment analysis benchmarks. Our approach outperforms several existing approaches in term of accuracy; our results are also competitive with the state-of-the-art results on the Stanford Large Movie Review data set with 93.3% accuracy, and the Stanford Sentiment Treebank data set with 48.8% fine-grained and 89.2% binary accuracy, respectively. Our approach has a significant role in reducing the number of parameters and constructing the convolutional layer followed by the recurrent layer as a substitute for the pooling layer. Our results show that we were able to reduce the loss of detailed, local information and capture long-term dependencies with an efficient framework that has fewer parameters and a high level of performance.","['Feature extraction', 'Task analysis', 'Machine learning', 'Computational modeling', 'Convolutional neural networks', 'Sentiment analysis']","['Convolutional neural network', 'recurrent neural network', 'natural language processing', 'deep learning', 'sentiment analysis', 'long-term dependencies']"
"The parameters of physical layer radio frame for 5th generation (5G) mobile cellular systems are expected to be flexibly configured to cope with diverse requirements of different scenarios and services. This paper presents a frame structure and design, which is specifically targeting Internet of Things (IoT) provision in 5G wireless communication systems. We design a suitable radio numerology to support the typical characteristics, that is, massive connection density and small and bursty packet transmissions with the constraint of low-cost and low complexity operation of IoT devices. We also elaborate on the design of parameters for random access channel enabling massive connection requests by IoT devices to support the required connection density. The proposed design is validated by link level simulation results to show that the proposed numerology can cope with transceiver imperfections and channel impairments. Furthermore, the results are also presented to show the impact of different values of guard band on system performance using different subcarrier spacing sizes for data and random access channels, which show the effectiveness of the selected waveform and guard bandwidth. Finally, we present system-level simulation results that validate the proposed design under realistic cell deployments and inter-cell interference conditions.","['Physical layer', '5G mobile communication', 'Cellular networks', 'Mobile communication', 'Internet of things', 'Complexity theory', 'Wireless communication']","['5G', 'frame structure', 'Internet of Things', 'random access channel']"
"As a significant application of energy, smart grid is a complicated interconnected power grid that involves sensors, deployment strategies, smart meters, and real-time data processing. It continuously generates data with large volume, high velocity, and diverse variety. In this paper, we first give a brief introduction on big data, smart grid, and big data application in the smart grid scenario. Then, recent studies and developments are summarized in the context of integrated architecture and key enabling technologies. Meanwhile, security issues are specifically addressed. Finally, we introduce several typical big data applications and point out future challenges in the energy domain.","['Big data', 'Smart grids', 'Data mining', 'Phasor measurement units', 'Real-time systems']","['Big data', 'energy', 'smart grids', 'data processing', 'data mining', 'energy internet', 'survey']"
"This paper presents robust virtual inertia control of an islanded microgrid considering high penetration of renewable energy sources (RESs). In such microgrids, the lack of system inertia due to the replacement of traditional generating units with a large amount of RESs causes undesirable influence to microgrid frequency stability, leading to weakening of the microgrid. In order to handle this challenge, the H robust control method is implemented to the virtual inertial control loop, taking into account the high penetration of RESs, thus enhancing the robust performance and stability of the microgrid during contingencies. The controller's robustness and performance are determined along with numerous disturbances and parametric uncertainties. The comparative study between H and optimal proportionalintegral (PI)-based virtual inertia controller is also presented. The results show the superior robustness and control effect of the proposed H controller in terms of precise reference frequency tracking and disturbance attenuation over the optimal PI controller. It is validated that the proposed H -based virtual inertia controller successfully provides desired robust frequency support to a low-inertia islanded microgrid against high RESs penetration.","['Microgrids', 'Frequency control', 'Power system stability', 'Robustness', 'Stability analysis', 'Uncertainty', 'Robust control']","['Frequency control', 'H∞', 'islanded microgrid', 'renewable energy', 'robust control', 'virtual inertia control', 'virtual synchronous generator']"
"Smart cities are expected to improve the quality of daily life, promote sustainable development, and improve the functionality of urban systems. Now that many smart systems have been implemented, security and privacy issues have become a major challenge that requires effective countermeasures. However, traditional cybersecurity protection strategies cannot be applied directly to these intelligent applications because of the heterogeneity, scalability, and dynamic characteristics of smart cities. Furthermore, it is necessary to be aware of security and privacy threats when designing and implementing new mechanisms or systems. Motivated by these factors, we survey the current situations of smart cities with respect to security and privacy to provide an overview of both the academic and industrial fields and to pave the way for further exploration. Specifically, this survey begins with an overview of smart cities to provide an integrated context for readers. Then, we discuss the privacy and security issues in current smart applications along with the corresponding requirements","['Smart cities', 'Security', 'Privacy', 'Computer architecture', 'Sensors']","['Smart city', 'Internet of Things', 'security', 'privacy']"
"The explosive popularity of small-cell and Internet of Everything devices has tremendously increased traffic loads. This increase has revolutionised the current network into 5G technology, which demands increased capacity, high data rate and ultra-low latency. Two of the research focus areas for meeting these demands are exploring the spectrum resource and maximising the utilisation of its bands. However, the scarcity of the spectrum resource creates a serious challenge in achieving an efficient management scheme. This work aims to conduct an in-depth survey on recent spectrum sharing (SS) technologies towards 5G development and recent 5G-enabling technologies. SS techniques are classified, and SS surveys and related studies on SS techniques relevant to 5G networks are reviewed. The surveys and studies are categorised into one of the main SS techniques on the basis of network architecture, spectrum allocation behaviour and spectrum access method. Moreover, a detailed survey on cognitive radio (CR) technology in SS related to 5G implementation is performed. For a complete survey, discussions are conducted on the issues and challenges in the current implementation of SS and CR, and the means to support efficient 5G advancement are provided.","['5G mobile communication', 'Wireless communication', 'Massive MIMO', 'Wireless sensor networks', 'Internet of Things', 'Computer architecture', 'Resource management']","['5G', 'new radio', 'spectrum sharing', 'spectrum efficiency', 'cognitive radio', 'enabling technologies']"
"In recent years, the deep learning is applied to the field of traffic sign detection methods which achieves excellent performance. However, there are two main challenges in traffic sign detection to be solve urgently. For one thing, some traffic signs of small size are more difficult to detect than those of large size so that the small traffic signs are undetected. For another, some false signs are always detected because of interferences caused by the illumination variation, bad weather and some signs similar to the true traffic signs. Therefore, to solve the undetection and false detection, we first propose a cascaded R-CNN to obtain the multiscale features in pyramids. Each layer of the cascaded network except the first layer fuses the output bounding box of the previous one layer for joint training. This method contributes to the traffic sign detection. Then, we propose a multiscale attention method to obtain the weighted multiscale features by dot-product and softmax, which is summed to fine the features to highlight the traffic sign features and improve the accuracy of the traffic sign detection. Finally, we increase the number of difficult negative samples for dataset balance and data augmentation in the training to relieve the interference by complex environment and similar false traffic signs. The data augment method expands the German traffic sign training dataset by simulation of complex environment changes. We conduct numerous experiments to verify the effectiveness of our proposed algorithm. The accuracy and recall rate of our method are 98.7% and 90.5% in GTSDB, 99.7% and 83.62% in CCTSDB and 98.9% and 85.6% in Lisa dataset respectively.","['Feature extraction', 'Object detection', 'Image color analysis', 'Deep learning', 'Detection algorithms', 'Training', 'Shape']","['Traffic sign detection', 'convolutional neural network', 'attention', 'object detection', 'Multiscale']"
"Electric energy forecasting domain attracts researchers due to its key role in saving energy resources, where mainstream existing models are based on Gradient Boosting Regression (GBR), Artificial Neural Networks (ANNs), Extreme Learning Machine (ELM) and Support Vector Machine (SVM). These models encounter high-level of non-linearity between input data and output predictions and limited adoptability in real-world scenarios. Meanwhile, energy forecasting domain demands more robustness, higher prediction accuracy and generalization ability for real-world implementation. In this paper, we achieve the mentioned tasks by developing a hybrid sequential learning-based energy forecasting model that employs Convolution Neural Network (CNN) and Gated Recurrent Units (GRU) into a unified framework for accurate energy consumption prediction. The proposed framework has two major phases: (1) data refinement and (2) training, where the data refinement phase applies preprocessing strategies over raw data. In the training phase, CNN features are extracted from input dataset and fed in to GRU, that is selected as optimal and observed to have enhanced sequence learning abilities after extensive experiments. The proposed model is an effective alternative to the previous hybrid models in terms of computational complexity as well prediction accuracy, due to the representative features' extraction potentials of CNNs and effectual gated structure of multi-layered GRU. The experimental evaluation over existing energy forecasting datasets reveal the better performance of our method in terms of preciseness and efficiency. The proposed method achieved the smallest error rate on Appliances Energy Prediction (AEP) and Individual Household Electric Power Consumption (IHEPC) datasets, when compared to other baseline models.","['Predictive models', 'Machine learning', 'Load modeling', 'Data models', 'Forecasting', 'Energy consumption', 'Support vector machines']","['CNN', 'CNN-GRU', 'deep learning', 'energy forecasting', 'electricity consumption prediction', 'GRU', 'LSTM', 'short-term load forecasting']"
"The vision of the Internet of Things (IoT) is to enable systems across the globe to share data using advanced communication technologies. With the recent technological advancements, IoT-based solutions are no longer a challenging vision. IoT will offer numerous and potentially revolutionary benefits to today’s digital world. Future personalized and connected healthcare is one of the promising areas to see the benefits of IoT. This paper surveys emerging healthcare applications, including detailed technical aspects required for the realization of a complete end-to-end solution for each application. The survey explores the key application-specific requirements from the perspective of communication technologies. Furthermore, a detailed exploration from the existing to the emerging technologies and standards that would enable such applications is presented, highlighting the critical consideration of short-range and long-range communications. Finally, the survey highlights important open research challenges and issues specifically related to IoT-based future healthcare systems.","['Medical services', 'Communications technology', 'Biomedical monitoring', 'Standards', 'Monitoring', 'Security', 'Temperature measurement']","['Internet of Things', 'network communication technologies', 'personalized healthcare', 'wearable sensors', 'standards', 'challenges']"
"The very first infected novel coronavirus case (COVID-19) was found in Hubei, China in Dec. 2019. The COVID-19 pandemic has spread over 214 countries and areas in the world, and has significantly affected every aspect of our daily lives. At the time of writing this article, the numbers of infected cases and deaths still increase significantly and have no sign of a well-controlled situation, e.g., as of 13 July 2020, from a total number of around 13.1 million positive cases, 571,527 deaths were reported in the world. Motivated by recent advances and applications of artificial intelligence (AI) and big data in various areas, this paper aims at emphasizing their importance in responding to the COVID-19 outbreak and preventing the severe effects of the COVID-19 pandemic. We firstly present an overview of AI and big data, then identify the applications aimed at fighting against COVID-19, next highlight challenges and issues associated with state-of-the-art solutions, and finally come up with recommendations for the communications to effectively control the COVID-19 situation. It is expected that this paper provides researchers and communities with new insights into the ways AI and big data improve the COVID-19 situation, and drives further studies in stopping the COVID-19 outbreak.","['Artificial intelligence', 'Big Data', 'Drugs', 'Government', 'Viruses (medical)', 'Computational modeling', 'COVID-19']","['Artificial intelligence (AI)', 'big data', 'COVID-19', 'coronavirus', 'epidemic outbreak', 'deep learning', 'data analytics', 'machine learning']"
"The modern intelligent transportation system brings not only new opportunities for vehicular Internet of Things (IoT) services but also new challenges for vehicular ad-hoc networks (VANETs). Apart from enhanced network performance, a practical and reliable security scheme is needed to handle the trust management while preserving user privacy at the same time. The emerging 5G mobile communication system is viewed as a prominent technology for ultra-reliable, low-latency wireless communication services. Furthermore, incorporating software-defined network (SDN) architecture into the 5G-VANET enables global information gathering and network control. Hence, real-time IoT services on transportation monitoring and reporting can be well supported. Both pave the way for an innovative vehicular security scheme. This paper investigates the security and privacy issue in the transportation system and the vehicular IoT environment in SDN-enabled 5G-VANET. Due to the decentralized and immutable characteristics of blockchain, a blockchain-based security framework is designed to support the vehicular IoT services, i.e., real-time cloud-based video report and trust management on vehicular messages. This paper explicitly illustrates the SDN-enabled 5G-VANET model and the scheduling procedures of the blockchain-based framework. The numerical simulation results also show that malicious vehicular nodes or messages can be well detected while the overhead and impact on the network performance are acceptable for large-scale scenarios. Through case studies and theoretical analysis, we demonstrate our design substantially guarantees a secure and trustworthy vehicular IoT environment with user privacy preserved.","['Roads', 'Internet of Things', 'Blockchain', 'Trust management', 'Vehicular ad hoc networks', 'Privacy']","['Blockchain', '5G-VANET', 'IoT', 'security and privacy', 'SDN', 'trust']"
"Internet of everything (IoE)-based smart services are expected to gain immense popularity in the future, which raises the need for next-generation wireless networks. Although fifth-generation (5G) networks can support various IoE services, they might not be able to completely fulfill the requirements of novel applications. Sixth-generation (6G) wireless systems are envisioned to overcome 5G network limitations. In this article, we explore recent advances made toward enabling 6G systems. We devise a taxonomy based on key enabling technologies, use cases, emerging machine learning schemes, communication technologies, networking technologies, and computing technologies. Furthermore, we identify and discuss open research challenges, such as artificial-intelligence-based adaptive transceivers, intelligent wireless energy harvesting, decentralized and secure business models, intelligent cell-less architecture, and distributed security models. We propose practical guidelines including deep Q-learning and federated learning-based transceivers, blockchain-based secure business models, homomorphic encryption, and distributed-ledger-based authentication schemes to cope with these challenges. Finally, we outline and recommend several future directions.","['5G mobile communication', 'Tutorials', 'Wireless networks', 'Machine learning', 'Computational modeling']","['6G', '5G', 'Internet of Things', 'Internet of Everything', 'federated learning', 'meta learning', 'blockchain']"
"With the spread of Internet of Things' (IoT) applications, security has become extremely important. A recent distributed denial-of-service (DDoS) attack revealed the ubiquity of vulnerabilities in IoT, and many IoT devices unwittingly contributed to the DDoS attack. The emerging software-defined anything (SDx) paradigm provides a way to safely manage IoT devices. In this paper, we first present a general framework for software-defined Internet of Things (SD-IoT) based on the SDx paradigm. The proposed framework consists of a controller pool containing SD-IoT controllers, SD-IoT switches integrated with an IoT gateway, and IoT devices. We then propose an algorithm for detecting and mitigating DDoS attacks using the proposed SD-IoT framework, and in the proposed algorithm, the cosine similarity of the vectors of the packet-in message rate at boundary SD-IoT switch ports is used to determine whether DDoS attacks occur in the IoT. Finally, experimental results show that the proposed algorithm has good performance, and the proposed framework adapts to strengthen the security of the IoT with heterogeneous and vulnerable devices.","['Computer crime', 'Computer architecture', 'Internet of Things', 'Control systems', 'Logic gates', 'Cloud computing']","['Software-defined Internet of Things (SD-IoT)', 'distributed denial of service (DDoS)', 'attack detection', 'attack mitigation', 'cosine similarity']"
"The health condition of a wheelset bearing, the key component of a railway bogie, has a considerable impact on the safety of a train. Traditional bearing fault diagnosis techniques generally extract signals manually and then diagnose the bearing health conditions through the classifier. However, high-speed trains (HSTs) are usually faced with variable loads, variable speeds, and strong environmental noise, which pose a huge challenge to the application of the traditional bearing fault diagnosis methods in wheelset bearing fault diagnosis. Therefore, this paper proposes a 1D residual block, and based on the block, a novel deeper 1D convolutional neural network (Der-1DCNN) is proposed. The framework includes the idea of residual learning and can effectively learn high-level and abstract features while effectively alleviating the problem of training difficulty and the performance degradation of a deeper network. Additionally, for the first time, we fully use the wide convolution kernel and dropout technology to improve the model's ability to learn low-frequency signal features related to the fault components and to enhance the network's generalization performance. By constructing a deep residual learning network, Der-1DCNN can adaptively learn the deep fault features of the original vibration signal. This method not only achieves very high diagnostic accuracy for the fault diagnosis task of wheelset bearings in HSTs under strong noise environment, but also its performance is quite superior when the train's working load changes without any domain adaptation algorithm processing. The proposed Der-1DCNN is evaluated on the dataset of the multi-operating conditions of the wheelset bearings of HSTs. Experiments show that this method shows a better diagnostic performance compared with the state-of-the-art deep learning methods of bearing fault diagnosis, which proves the method's effectiveness and superiority.","['Fault diagnosis', 'Feature extraction', 'Convolution', 'Training', 'Kernel', 'Vibrations', 'Safety']","['High-speed trains', 'wheelset bearings fault diagnosis', 'deep learning', 'one-dimensional residual block', 'wide convolutional kernel']"
"The advent of the Industry 4.0 initiative has made it so that manufacturing environments are becoming more and more dynamic, connected but also inherently more complex, with additional inter-dependencies, uncertainties and large volumes of data being generated. Recent advances in Industrial Artificial Intelligence have showcased the potential of this technology to assist manufacturers in tackling the challenges associated with this digital transformation of Cyber-Physical Systems, through its data-driven predictive analytics and capacity to assist decision-making in highly complex, non-linear and often multistage environments. However, the industrial adoption of such solutions is still relatively low beyond the experimental pilot stage, as real environments provide unique and difficult challenges for which organizations are still unprepared. The aim of this paper is thus two-fold. First, a systematic review of current Industrial Artificial Intelligence literature is presented, focusing on its application in real manufacturing environments to identify the main enabling technologies and core design principles. Then, a set of key challenges and opportunities to be addressed by future research efforts are formulated along with a conceptual framework to bridge the gap between research in this field and the manufacturing industry, with the goal of promoting industrial adoption through a successful transition towards a digitized and data-driven company-wide culture. This paper is among the first to provide a clear definition and holistic view of Industrial Artificial Intelligence in the Industry 4.0 landscape, identifying and analysing its fundamental building blocks and ongoing trends. Its findings are expected to assist and empower researchers and manufacturers alike to better understand the requirements and steps necessary for a successful transition into Industry 4.0 supported by AI, as well as the challenges that may arise during this process.","['Artificial intelligence', 'Industries', 'Robots', 'Systematics', 'Manufacturing', 'Decision making', 'Service robots']","['Artificial intelligence', 'Industry 4.0', 'digital transformation', 'guidelines', 'systematic review', 'framework', 'manufacturing']"
"Electric load forecasting has always been a key component of power grids. Many countries have opened up electricity markets and facilitated the participation of multiple agents, which create a competitive environment and reduce costs to consumers. In the electricity market, multi-step short-term load forecasting becomes increasingly significant for electricity market bidding and spot price calculation, but the performances of traditional algorithms are not robust and unacceptable enough. In recent years, the rise of deep learning gives us the opportunity to improve the accuracy of multi-step forecasting further. In this paper, we propose a novel model multi-scale convolutional neural network with time-cognition (TCMS-CNN). At first, a deep convolutional neural network model based on multi-scale convolutions (MS-CNN) extracts different level features that are fused into our network. In addition, we design an innovative time coding strategy called the periodic coding strengthening the ability of the sequential model for time cognition effectively. At last, we integrate MS-CNN and periodic coding into the proposed TCMS-CNN model with an end-to-end training and inference process. With ablation experiments, the MS-CNN and periodic coding methods had better performances obviously than the most popular methods at present. Specifically, for 48-step point load forecasting, the TCMS-CNN had been improved by 34.73%, 14.22%, and 19.05% on MAPE than the state-of-the-art methods recursive multi-step LSTM (RM-LSTM), direct multi-step MS-CNN (DM-MS-CNN), and the direct multi-step GCNN (DM-GCNN), respectively. For 48-step probabilistic load forecasting, the TCMS-CNN had been improved by 3.54% and 6.77% on average pinball score than the DM-MS-CNN and the DM-GCNN. These results show a great promising potential applied in practice.","['Load forecasting', 'Load modeling', 'Forecasting', 'Feature extraction', 'Predictive models', 'Training', 'Neural networks']","['Short-term load forecasting', 'probabilistic load forecasting', 'multi-step', 'multi-scale convolution', 'time cognition', 'deep learning']"
"The ultra-reliable low latency communications (uRLLC) in the fifth generation mobile communication system aims to support diverse emerging applications with strict requirements of latency and reliability. Mobile edge computing (MEC) is considered as a promising solution to reduce the latency of computation-intensive tasks leveraging powerful computing units at short distance. The state-of-art work on task offloading to MEC mainly focuses on the tradeoff between latency and energy consumption, rather than reliability. In this paper, the tradeoff between the latency and reliability in task offloading to MEC is studied. A framework is provided, where user equipment partitions a task into sub-tasks and offloads them to multiple nearby edge nodes (ENs) in sequence. In this framework, we formulate an optimization problem to jointly minimize the latency and offloading failure probability. Since the formulated problem is nonconvex, we design three algorithms based on heuristic search, reformulation linearization technique and semi-definite relaxation, respectively, and solve the problem through optimizing EN candidates selection, offloading ordering and task allocation. Compared with the previous work, the numerical simulation results show that the proposed algorithms strike a good balance between the latency and reliability in uRLLC. Among them, the Heuristic Algorithm achieves the best performance in terms of the latency and reliability with the minimal complexity.","['Task analysis', 'Reliability', 'Algorithm design and analysis', 'Mobile communication', 'Energy consumption', 'Cloud computing', 'Optimization']","['5G', 'ultra-reliable low latency communications', 'mobile edge computing', 'computation offloading']"
"When will automated vehicles come onto the market? This question has puzzled the automotive industry and society for years. The technology and its implementation have made rapid progress over the last decade, but the challenge of how to prove the safety of these systems has not yet been solved. Since a market launch without proof of safety would neither be accepted by society nor by legislators, much time and many resources have been invested into safety assessment in recent years in order to develop new approaches for an efficient assessment. This paper therefore provides an overview of various approaches, and gives a comprehensive survey of the so-called scenario-based approach. The scenario-based approach is a promising method, in which individual traffic situations are typically tested by means of virtual simulation. Since an infinite number of different scenarios can theoretically occur in real-world traffic, even the scenario-based approach leaves the question unanswered as to how to break these down into a finite set of scenarios, and find those which are representative in order to render testing more manageable. This paper provides a comprehensive literature review of related safety-assessment publications that deal precisely with this question. Therefore, this paper develops a novel taxonomy for the scenario-based approach, and classifies all literature sources. Based on this, the existing methods will be compared with each other and, as one conclusion, the alternative concept of formal verification will be combined with the scenario-based approach. Finally, future research priorities are derived.","['Safety', 'Testing', 'Bibliographies', 'Vehicles', 'Microscopy', 'Taxonomy', 'Automation']","['Automated vehicles', 'autonomous vehicles', 'data analysis', 'formal verification', 'intelligent vehicles', 'key performance indicators', 'simulation', 'vehicle safety']"
"Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading.","['Robot sensing systems', 'Intrusion detection', 'Monitoring', 'Aircraft', 'Machine learning']","['Intrusion detection', 'machine learning', 'autonomous vehicles']"
"This paper aims to explore and investigate the potential factors influencing students' behavioral intentions to use the e-learning system. This paper proposes an extended technology acceptance model (TAM) that has been tested and examined through the use of both innovation diffusion theory (IDT) and integrating TAM. This paper was conducted on 1286 students utilizing systems of e-learning in Malaysia. The findings were obtained via a quantitative research method. The findings illustrate that six perceptions of innovation characteristics, in particular, have impacts on students' e-learning system behavioral intention. The influences of the relative advantages, observability, trialability, perceived compatibility, complexity, and perceived enjoyment on the perceived ease of use is noteworthy. Moreover, the effects of the relative advantages, complexity, trialability, observability, perceived compatibility, and perceived enjoyment on the perceived usefulness have a strong impact. Therefore, the empirical results provide strong backing to the integrative approach between TAM and IDT. The findings suggest an extended model of TAM with IDT for the acceptance of the e-learning system used to improve the students' learning performance, which can help decision makers in higher education, universities, as well as colleges to evaluate, plan and execute the use of e-learning systems.","['Electronic learning', 'Technological innovation', 'Observability', 'Complexity theory', 'Learning systems', 'Training']","['Technology acceptance model (TAM)', 'innovation diffusion', 'theory (IDT)', 'E-learning system', 'structural equation modeling', 'system adoption', 'end-students’ perception']"
"In this paper, we provide the theoretical framework for the performance comparison of reconfigurable intelligent surfaces (RISs) and amplify-and-forward (AF) relaying wireless systems. In particular, after statistically characterizing the end-to-end (e2e) wireless channel coefficient of the RIS-assisted wireless system, in terms of probability density function (PDF) and cumulative density function (CDF), we extract novel closed-form expressions for the instantaneous and average e2e signal-to-noise ratio (SNR) for both the RIS-assisted and AF-relaying wireless systems. Building upon these expressions, we derive the diversity gain of the RIS-assisted wireless system as well as the outage probability (OP) and symbol error rate (SER) for a large variety of Gray-mapped modulation schemes of both systems under investigation. Additionally, the diversity order of the RIS-assisted wireless system is presented as well as the ergodic capacity (EC) of both the RIS-assisted and AF-relaying wireless systems. Likewise, high-SNR and high-number of metasurfaces (MS) approximations for the SER and EC for the RIS-assisted wireless system are reported. Finally, for the sake of completeness, the special case in which the RIS is equipped with only one MS is also investigated. For this case, the instantaneous and average e2e SNR are derived, as well as the OP, SER and EC. Our analysis is verified through respective Monte Carlo simulations, which reveal the accuracy of the presented theoretical framework. Moreover, our results highlight that, in general, RIS-assisted wireless systems outperform the corresponding AF-relaying ones in terms of average SNR, OP, SER and EC.","['Wireless communication', 'Signal to noise ratio', 'Closed-form solutions', 'Probability density function', 'Power system reliability', 'Probability', 'Error analysis']","['Amplify-and-forward', 'average signal-to-noise-ratio', 'beyond 5G systems', 'ergodic capacity', 'high-signal-to-noise-ratio approximation', 'meta-surfaces', 'multipath fading', 'outage probability', 'performance analysis', 'reconfigurable intelligent surfaces', 'symbol error rate', 'theoretical framework']"
"Topic extraction is an essential task in bibliometric data analysis, data mining and knowledge discovery, which seeks to identify significant topics from text collections. The conventional topic extraction schemes require human intervention and involve also comprehensive pre-processing tasks to represent text collections in an appropriate way. In this paper, we present a two-stage framework for topic extraction from scientific literature. The presented scheme employs a two-staged procedure, where word embedding schemes have been utilized in conjunction with cluster analysis. To extract significant topics from text collections, we propose an improved word embedding scheme, which incorporates word vectors obtained by word2vec, POS2vec, word-position2vec and LDA2vec schemes. In the clustering phase, an improved clustering ensemble framework, which incorporates conventional clustering methods (i.e., k-means, k-modes, k-means++, self-organizing maps and DIANA algorithm) by means of the iterative voting consensus, has been presented. In the empirical analysis, we analyze a corpus containing 160,424 abstracts of articles from various disciplines, including agricultural engineering, economics, engineering and computer science. In the experimental analysis, performance of the proposed scheme has been compared to conventional baseline clustering methods (such as, k-means, k-modes, and k-means++), LDA-based topic modelling and conventional word embedding schemes. The empirical analysis reveals that ensemble word embedding scheme yields better predictive performance compared to the baseline word vectors for topic extraction. Ensemble clustering framework outperforms the baseline clustering methods. The results obtained by the proposed framework show an improvement in Jaccard coefficient, Folkes & Mallows measure and F1 score.","['Task analysis', 'Clustering algorithms', 'Text categorization', 'Data analysis', 'Clustering methods', 'Text mining']","['topic extraction', 'machine learning', 'Cluster analysis', 'text mining']"
"The ever-increasing advancement in communication technologies of modern smart objects brings with it a newera of application development for Internet of Things (IoT)-based networks. In particular, owing to the contactless-ness nature and efficiency of the data retrieval of mobile smart objects, such as wearable equipment or tailored bio-sensors, several innovative types of healthcare systems with body sensor networks (BSN) have been proposed. In this paper, we introduce a secure IoT-based healthcare system, which operates through the BSN architecture. To simultaneously achieve system efficiency and robustness of transmission within public IoT-based communication networks, we utilize robust crypto-primitives to construct two communication mechanisms for ensuring transmission confidentiality and providing entity authentication among smart objects, the local processing unit and the backend BSN server. Moreover, we realize the implementation of the proposed healthcare system with the Raspberry PI platform to demonstrate the practicability and feasibility of the presented mechanisms.","['Smart devices', 'Authentication', 'Body sensor networks', 'Network security', 'Internet of things']","['Authentication', 'body sensor networks', 'internet of things (IoT)', 'security']"
"Drowsiness or fatigue is a major cause of road accidents and has significant implications for road safety. Several deadly accidents can be prevented if the drowsy drivers are warned in time. A variety of drowsiness detection methods exist that monitor the drivers' drowsiness state while driving and alarm the drivers if they are not concentrating on driving. The relevant features can be extracted from facial expressions such as yawning, eye closure, and head movements for inferring the level of drowsiness. The biological condition of the drivers' body, as well as vehicle behavior, is analyzed for driver drowsiness detection. This paper presents a comprehensive analysis of the existing methods of driver drowsiness detection and presents a detailed analysis of widely used classification techniques in this regard. First, in this paper, we classify the existing techniques into three categories: behavioral, vehicular, and physiological parameters-based techniques. Second, top supervised learning techniques used for drowsiness detection are reviewed. Third, the pros and cons and comparative study of the diverse method are discussed. In addition, the research frameworks are elaborated in diagrams for better understanding. In the end, overall research findings based on the extensive survey are concluded which will help young researchers for finding potential future work in the relevant field.","['Vehicles', 'Fatigue', 'Support vector machines', 'Mouth', 'Road accidents', 'Systematics']","['Digital image processing', 'driver drowsiness', 'sensors', 'fatigue detection', 'supervised learning', 'classification', 'support vector machine (SVM)']"
"With the rise of artificial intelligence (AI) and deep learning techniques, fake digital contents have proliferated in recent years. Fake footage, images, audios, and videos (known as deepfakes) can be a scary and dangerous phenomenon and can have the potential of altering the truth and eroding trust by giving false reality. Proof of authenticity (PoA) of digital media is critical to help eradicate the epidemic of forged content. Current solutions lack the ability to provide history tracking and provenance of digital media. In this paper, we provide a solution and a general framework using Ethereum smart contracts to trace and track the provenance and history of digital content to its original source even if the digital content is copied multiple times. The smart contract utilizes the hashes of the interplanetary file system (IPFS) used to store digital content and its metadata. Our solution focuses on video content, but the solution framework provided in this paper is generic enough and can be applied to any other form of digital content. Our solution relies on the principle that if the content can be credibly traced to a trusted or reputable source, the content can then be real and authentic. The full code of the smart contract has been made publicly available at Github.","['Blockchain', 'Smart contracts', 'History', 'Metadata', 'Artificial intelligence']","['AI', 'deepfake', 'blockchain', 'Ethereum', 'smart contracts']"
"The new development trends including Internet of Things (IoT), smart city, enterprises digital transformation and world’s digital economy are at the top of the tide. The continuous growth of data storage pressure drives the rapid development of the entire storage market on account of massive data generated. By providing data storage and management, cloud storage system becomes an indispensable part of the new era. Currently, the governments, enterprises and individual users are actively migrating their data to the cloud. Such a huge amount of data can create magnanimous wealth. However, this increases the possible risk, for instance, unauthorized access, data leakage, sensitive information disclosure and privacy disclosure. Although there are some studies on data security and privacy protection, there is still a lack of systematic surveys on the subject in cloud storage system. In this paper, we make a comprehensive review of the literatures on data security and privacy issues, data encryption technology, and applicable countermeasures in cloud storage system. Specifically, we first make an overview of cloud storage, including definition, classification, architecture and applications. Secondly, we give a detailed analysis on challenges and requirements of data security and privacy protection in cloud storage system. Thirdly, data encryption technologies and protection methods are summarized. Finally, we discuss several open research topics of data security for cloud storage.","['Cloud computing', 'Encryption', 'Data privacy', 'Secure storage', 'Memory']","['Cloud storage', 'data security', 'cryptography', 'access control', 'privacy protection']"
"In the last decades, fiber Bragg gratings (FBGs) have become increasingly attractive to medical applications due to their unique properties such as small size, biocompatibility, immunity to electromagnetic interferences, high sensitivity and multiplexing capability. FBGs have been employed in the development of surgical tools, assistive devices, wearables, and biosensors, showing great potentialities for medical uses. This paper reviews the FBG-based measuring systems, their principle of work, and their applications in medicine and healthcare. Particular attention is given to sensing solutions for biomechanics, minimally invasive surgery, physiological monitoring, and medical biosensing. Strengths, weaknesses, open challenges, and future trends are also discussed to highlight how FBGs can meet the demands of next-generation medical devices and healthcare system.","['Fiber gratings', 'Strain', 'Optical fiber sensors', 'Medical services', 'Temperature measurement']","['Biomechanics', 'biosensing', 'fiber Bragg grating sensors', 'minimally invasive surgery', 'physiological monitoring']"
"A number of impedance-based fault location algorithms have been developed for estimating the distance to faults in a transmission network. Each algorithm has specific input data requirements and makes certain assumptions that may or may not hold true in a particular fault location scenario. Without a detailed understanding of the principle of each fault-locating method, choosing the most suitable fault location algorithm can be a challenging task. This paper, therefore, presents the theory of one-ended (simple reactance, Takagi, modified Takagi, Eriksson, and Novosel et al.) and two-ended (synchronized, unsynchronized, and current-only) impedance-based fault location algorithms and demonstrates their application in locating real-world faults. The theory details the formulation and input data requirement of each fault-locating algorithm and evaluates the sensitivity of each to the following error sources: 1) load; 2) remote infeed; 3) fault resistance; 4) mutual coupling; 5) inaccurate line impedances; 6) DC offset and CT saturation; 7) three-terminal lines; and 8) tapped radial lines. From the theoretical analysis and field data testing, the following criteria are recommended for choosing the most suitable fault-locating algorithm: 1) data availability and 2) fault location application scenario. Another objective of this paper is to assess what additional information can be gleaned from waveforms recorded by intelligent electronic devices (IEDs) during a fault. Actual fault event data captured in utility networks is exploited to gain valuable feedback about the transmission network upstream from the IED device, and estimate the value of fault resistance.","['Fault location', 'Algorithm design and analysis', 'Resistance', 'Impedance', 'Synchronization', 'Mutual coupling', 'Fault currents', 'Estimation', 'Transmission lines']","['Fault location', 'impedance-measurement', 'intelligent electronic devices (IED)', 'power system faults', 'power system reliability', 'transmission line measurements']"
"The electrocardiogram (ECG) is an efficient and noninvasive indicator for arrhythmia detection and prevention. In real-world scenarios, ECG signals are prone to be contaminated with various noises, which may lead to wrong interpretation. Therefore, significant attention has been paid on denoising of ECG for accurate diagnosis and analysis. A denoising autoencoder (DAE) can be applied to reconstruct the clean data from its noisy version. In this paper, a DAE using the fully convolutional network (FCN) is proposed for ECG signal denoising. Meanwhile, the proposed FCN-based DAE can perform compression with regard to the DAE architecture. The proposed approach is applied to ECG signals from the MIT-BIH Arrhythmia database and the added noise signals are obtained from the MIT-BIH Noise Stress Test database. The denoising performance is evaluated using the root-mean-square error (RMSE), percentage-root-mean-square difference (PRD), and improvement in signal-to-noise ratio (SNR imp ). The results of the experiments conducted on noisy ECG signals of different levels of input SNR show that the FCN acquires better performance as compared to the deep fully connected neural network- and convolutional neural network-based denoising models. Moreover, the proposed FCN-based DAE reduces the size of the input ECG signals, where the compressed data is 32 times smaller than the original. The results of the study demonstrate the superiority of FCN in denoising, with lower RMSE and PRD, as well as higher SNR imp . According to the results, we believe that the proposed FCN-based DAE has a good application prospect in clinical practice.","['Electrocardiography', 'Noise reduction', 'Convolution', 'Decoding', 'Noise measurement', 'Databases', 'Signal to noise ratio']","['Electrocardiography', 'signal denoising', 'artificial neural networks', 'denoising autoencoders', 'fully convolutional network']"
"Optimal allocation of distributed generation units is essential to ensure power loss minimization, while meeting the real and reactive power demands in a distribution network. This paper proposes a solution to this non-convex, discrete problem by using the hybrid grey wolf optimizer, a new metaheuristic algorithm. This algorithm is applied to IEEE 33-, IEEE 69-, and Indian 85-bus radial distribution systems to minimize the power loss. The results show that there is a considerable reduction in the power loss and an enhancement of the voltage profile of the buses across the network. Comparisons show that the proposed method outperforms all other metaheuristic methods, and matches the best results by other methods, including exhaustive search, suggesting that the solution obtained is a global optimum. Furthermore, unlike for most other metaheuristic methods, this is achieved with no tuning of the algorithm on the part of the user, except for the specification of the population size.","['Xenon', 'Resource management', 'Reactive power', 'Distributed power generation', 'Hybrid power systems', 'Tuning', 'Particle swarm optimization']","['Distributed generation (DG)', 'optimal DG location', 'optimal DG size', 'loss minimization', 'radial distribution system', 'metaheuristic algorithm']"
"Blockchain is the promising technology of recent years, which has attracted remarkable attention in both academic studies and practical industrial applications. The smart contract is a programmable transaction that can perform a sophisticated task, execute automatically, and store on the blockchain. The smart contract is the key component of the blockchain, which has made blockchain a technology beyond the scope of the cryptocurrencies and applicable for a variety of applications such as healthcare, IoT, supply chain, digital identity, business process management, and more. Although in recent years the progress toward improving blockchain technology with the focus on the smart contract has been impressive, there is a lack of reviewing the smart contract topic. This paper systematically reviews the key concepts and proposes the direction of recent studies and developments regarding the smart contract. The research studies are presented in three main categories: 1) security methods and tools; 2) performance improvement approaches; and 3) decentralized applications based on smart contracts.","['Smart contracts', 'Blockchain', 'Peer-to-peer computing', 'Systematics', 'Bitcoin']","['Smart contract', 'blockchain', 'review', 'security', 'performance', 'application']"
"In recent years, computation offloading has become an effective way to overcome the constraints of mobile devices (MDs) by offloading delay-sensitive and computation-intensive mobile application tasks to remote cloud-based data centers. Smart cities can benefit from offloading to edge points in the framework of the so-called cyber-physical-social systems (CPSS), as for example in traffic violation tracking cameras. We assume that there are mobile edge computing networks (MECNs) in more than one region, and they consist of multiple access points, multi-edge servers, and N MDs, where each MD has M independent real-time massive tasks. The MDs can connect to a MECN through the access points or the mobile network. Each task be can processed locally by the MD itself or remotely. There are three offloading options: nearest edge server, adjacent edge server, and remote cloud. We propose a reinforcement-learning-based state-action-reward-state-action (RL-SARSA) algorithm to resolve the resource management problem in the edge server, and make the optimal offloading decision for minimizing system cost, including energy consumption and computing time delay. We call this method OD-SARSA (offloading decision-based SARSA). We compared our proposed method with reinforcement learning based Q learning (RL-QL), and it is concluded that the performance of the former is superior to that of the latter.",[],[]
"As an increasing attention towards sustainable development of energy and environment, the power electronics (PEs) are gaining more and more attraction on various energy systems. The insulated gate bipolar transistor (IGBT), as one of the PEs with numerous advantages and potentials for development of higher voltage and current ratings, has been used in a board range of applications. However, the continuing miniaturization and rapid increasing power ratings of IGBTs have remarkable high heat flux, which requires complex thermal management. In this paper, studies of the thermal management on IGBTs are generally reviewed including analyzing, comparing, and classifying the results originating from these researches. The thermal models to accurately calculate the dynamic heat dissipation are divided into analytical models, numerical models, and thermal network models, respectively. The thermal resistances of current IGBT modules are also studied. According to the current products on a number of IGBTs, we observe that the junction-to-case thermal resistance generally decreases inversely in terms of the total thermal power. In addition, the cooling solutions of IGBTs are reviewed and the performance of the various solutions are studied and compared. At last, we have proposed a quick and efficient evaluation judgment for the thermal management of the IGBTs depended on the requirements on the junction-to-case thermal resistance and equivalent heat transfer coefficient of the test samples.","['Insulated gate bipolar transistors', 'Thermal analysis', 'Thermal management', 'Thermal resistance', 'Thermal management of electronics', 'Heating systems', 'Stress']","['Power electronics', 'IGBT', 'thermal management', 'cooling', 'qualifications']"
"In the downlink transmission scenario, power allocation and beamforming design at the transmitter are essential when using multiple antenna arrays. This paper considers a multiple input–multiple output broadcast channel to maximize the weighted sum-rate under the total power constraint. The classical weighted minimum mean-square error (WMMSE) algorithm can obtain suboptimal solutions but involves high computational complexity. To reduce this complexity, we propose a fast beamforming design method using unsupervised learning, which trains the deep neural network (DNN) offline and provides real-time service online only with simple neural network operations. The training process is based on an end-to-end method without labeled samples avoiding the complicated process of obtaining labels. Moreover, we use the “APoZ”-based pruning algorithm to compress the network volume, which further reduces the computational complexity and volume of the DNN, making it more suitable for low computation-capacity devices. Finally, the experimental results demonstrate that the proposed method improves computational speed significantly with performance close to the WMMSE algorithm.","['Array signal processing', 'MIMO communication', 'Downlink', 'Neurons', 'Biological neural networks']","['MIMO', 'beamforming', 'deep learning', 'unsupervised learning', 'network pruning']"
"Research and development on the next generation wireless systems, namely 5G, has experienced explosive growth in recent years. In the physical layer, the massive multiple-input-multiple output (MIMO) technique and the use of high GHz frequency bands are two promising trends for adoption. Millimeter-wave (mmWave) bands, such as 28, 38, 64, and 71 GHz, which were previously considered not suitable for commercial cellular networks, will play an important role in 5G. Currently, most 5G research deals with the algorithms and implementations of modulation and coding schemes, new spatial signal processing technologies, new spectrum opportunities, channel modeling, 5G proof of concept systems, and other system-level enabling technologies. In this paper, we first investigate the contemporary wireless user equipment (UE) hardware design, and unveil the critical 5G UE hardware design constraints on circuits and systems. On top of the said investigation and design tradeoff analysis, a new, highly reconfigurable system architecture for 5G cellular user equipment, namely distributed phased arrays based MIMO (DPA-MIMO) is proposed. Finally, the link budget calculation and data throughput numerical results are presented for the evaluation of the proposed architecture.","['5G mobile communication', 'Wireless communication', 'MIMO', 'Batteries', 'Hardware', 'Radio frequency', 'Mobile handsets']","['5G', 'massive multiple-input-multiple-output (MIMO)', 'millimeter-wave (mmWave)', 'beamforming', 'distributed phased array', 'user equipment (UE)', 'hardware', 'system-on-chip (SoC)', 'spectral efficiency']"
"The intelligent transportation system (ITS) concept was introduced to increase road safety, manage traffic efficiently, and preserve our green environment. Nowadays, ITS applications are becoming more data-intensive and their data are described using the “5Vs of Big Data”. Thus, to fully utilize such data, big data analytics need to be applied. The Internet of vehicles (IoV) connects the ITS devices to cloud computing centres, where data processing is performed. However, transferring huge amount of data from geographically distributed devices creates network overhead and bottlenecks, and it consumes the network resources. In addition, following the centralized approach to process the ITS big data results in high latency which cannot be tolerated by the delay-sensitive ITS applications. Fog computing is considered a promising technology for real-time big data analytics. Basically, the fog technology complements the role of cloud computing and distributes the data processing at the edge of the network, which provides faster responses to ITS application queries and saves the network resources. However, implementing fog computing and the lambda architecture for real-time big data processing is challenging in the IoV dynamic environment. In this regard, a novel architecture for real-time ITS big data analytics in the IoV environment is proposed in this paper. The proposed architecture merges three dimensions including intelligent computing (i.e. cloud and fog computing) dimension, real-time big data analytics dimension, and IoV dimension. Moreover, this paper gives a comprehensive description of the IoV environment, the ITS big data characteristics, the lambda architecture for real-time big data analytics, several intelligent computing technologies. More importantly, this paper discusses the opportunities and challenges that face the implementation of fog computing and real-time big data analytics in the IoV environment. Finally, the critical issues and future research directions section discusses some issues that should be considered in order to efficiently implement the proposed architecture.","['Big Data', 'Real-time systems', 'Edge computing', 'Computer architecture', 'Transportation', 'Cloud computing']","['Vehicular and wireless technologies', 'intelligent transportation systems', 'data preprocessing', 'real time systems', 'ubiquitous computing']"
"In this paper, we propose a new chaos-based encryption scheme for medical images. It is based on a combination of chaos and DNA computing under the scenario of two encryption rounds, preceded by a key generation layer, and follows the permutation-substitution-diffusion structure. The SHA-256 hash function alongside the initial secret keys is employed to produce the secret keys of the chaotic systems. Each round of the proposed algorithm involves six steps, i.e., block-based permutation, pixel-based substitution, DNA encoding, bit-level substitution (i.e., DNA complementing), DNA decoding, and bit-level diffusion. A thorough search of the relevant literature yielded only this time the pixel-based substitution and the bit-level substitution are used in cascade for image encryption. The key-streams in the bit-level substitution are based on the logistic-Chebyshev map, while the sine-Chebyshev map allows producing the key-streams in the bit-level diffusion. The final encrypted image is obtained by repeating once the previous steps using new secret keys. Security analyses and computer simulations both confirm that the proposed scheme is robust enough against all kinds of attacks. Its low complexity indicates its high potential for real-time and secure image applications.","['DNA', 'Encryption', 'Biomedical imaging', 'Encoding', 'Chaos']","['Image encryption', 'medical images', 'permutation and diffusion', 'S-box', 'chaos', 'DNA encoding', 'SHA-256 hash function']"
"With ongoing large-scale smart energy metering deployments worldwide, disaggregation of a household's total energy consumption down to individual appliances using analytical tools, also known as non-intrusive appliance load monitoring (NALM), has generated increased research interest lately. NALM can deepen energy feedback, support appliance retrofit advice, and support home automation. However, despite the fact that NALM was proposed over 30 years ago, there are still many open challenges with respect to its practicality and effectiveness at low sampling rates. Indeed, the majority of NALM approaches, supervised or unsupervised, require training to build appliance models, and are sensitive to appliance changes in the house, thus requiring regular re-training. In this paper, we tackle this challenge by proposing an NALM approach that does not require any training. The main idea is to build upon the emerging field of graph signal processing to perform adaptive thresholding, signal clustering, and pattern matching. We determine the performance limits of our approach and demonstrate its usefulness in practice. Using two open access datasets-the US REDD data set with active power measurements downsampled to 1 min resolution and the UK REFIT data set with 8-s resolution, we demonstrate the effectiveness of the proposed method for typical smart meter sampling rate, with the state-of-the-art supervised and unsupervised NALM approaches as benchmarks.","['Home appliances', 'Training', 'Signal resolution', 'Energy consumption', 'Home automation', 'Load management', 'Adaptation models', 'Power system measurements']","['Non-intrusive appliance load monitoring', 'load disaggregation', 'graph signal processing']"
"Integration of the Internet into the entities of the different domains of human society (such as smart homes, health care, smart grids, manufacturing processes, product supply chains, and environmental monitoring) is emerging as a new paradigm called the Internet of Things (IoT). However, the ubiquitous and wide-range IoT networks make them prone to cyberattacks. One of the main types of attack is a denial of service (DoS), where the attacker floods the network with a large volume of data to prevent nodes from using the services. An intrusion detection mechanism is considered a chief source of protection for information and communications technology. However, conventional intrusion detection methods need to be modified and improved for application to the IoT owing to certain limitations, such as resource-constrained devices, the limited memory and battery capacity of nodes, and specific protocol stacks. In this paper, we develop a lightweight attack detection strategy utilizing a supervised machine learning-based support vector machine (SVM) to detect an adversary attempting to inject unnecessary data into the IoT network. The simulation results show that the proposed SVM-based classifier, aided by a combination of two or three incomplex features, can perform satisfactorily in terms of classification accuracy and detection time.","['Internet of Things', 'Intrusion detection', 'Feature extraction', 'Support vector machines', 'Protocols', 'Sensor phenomena and characterization']","['Intrusion detection system', 'anomaly detection', 'Internet of Things', 'support vector machine']"
"Nowadays, telemedicine is an emerging healthcare service where the healthcare professionals can diagnose, evaluate, and treat a patient using telecommunication technology. To diagnose and evaluate a patient, the healthcare professionals need to access the electronic medical record (EMR) of the patient, which might contain huge multimedia big data including X-rays, ultrasounds, CT scans, and MRI reports. For efficient access and supporting mobility for both the healthcare professionals as well as the patients, the EMR needs to be kept in big data storage in the healthcare cloud. In spite of the popularity of the healthcare cloud, it faces different security issues; for instance, data theft attacks are considered to be one of the most serious security breaches of healthcare data in the cloud. In this paper, the main focus has been given to secure healthcare private data in the cloud using a fog computing facility. To this end, a tri-party one-round authenticated key agreement protocol has been proposed based on the bilinear pairing cryptography that can generate a session key among the participants and communicate among them securely. Finally, the private healthcare data are accessed and stored securely by implementing a decoy technique.","['Cloud computing', 'Medical services', 'Edge computing', 'Big Data', 'Cryptography']","['Key management', 'security and privacy', 'medical big data', 'fog computing', 'pairing-based cryptography', 'decoy technique']"
"In the era of big data, recommender system (RS) has become an effective information filtering tool that alleviates information overload for Web users. Collaborative filtering (CF), as one of the most successful recommendation techniques, has been widely studied by various research institutions and industries and has been applied in practice. CF makes recommendations for the current active user using lots of users’ historical rating information without analyzing the content of the information resource. However, in recent years, data sparsity and high dimensionality brought by big data have negatively affected the efficiency of the traditional CF-based recommendation approaches. In CF, the context information, such as time information and trust relationships among the friends, is introduced into RS to construct a training model to further improve the recommendation accuracy and user’s satisfaction, and therefore, a variety of hybrid CF-based recommendation algorithms have emerged. In this paper, we mainly review and summarize the traditional CF-based approaches and techniques used in RS and study some recent hybrid CF-based recommendation approaches and techniques, including the latest hybrid memory-based and model-based CF recommendation algorithms. Finally, we discuss the potential impact that may improve the RS and future direction. In this paper, we aim at introducing the recent hybrid CF-based recommendation techniques fusing social networks to solve data sparsity and high dimensionality and provide a novel point of view to improve the performance of RS, thereby presenting a useful resource in the state-of-the-art research result for future researchers.","['Recommender systems', 'Collaboration', 'Social network services', 'Prediction algorithms', 'Big Data', 'Predictive models']","['Recommender systems', 'collaborative filtering', 'matrix factorization', 'singular value decomposition', 'trust-aware collaborative filtering', 'social networks']"
"There is an increasing interest and research effort focused on the analysis, design and implementation of distributed control systems for AC, DC and hybrid AC / DC microgrids. It is claimed that distributed controllers have several advantages over centralised control schemes, e.g., improved reliability, flexibility, controllability, black start operation, robustness to failure in the communication links, etc. In this work, an overview of the state-of-the-art of distributed cooperative control systems for isolated microgrids is presented. Protocols for cooperative control such as linear consensus, heterogeneous consensus and finite-time consensus are discussed and reviewed in this paper. Distributed cooperative algorithms for primary and secondary control systems, including (among others issues) virtual impedance, synthetic inertia, droop-free control, stability analysis, imbalance sharing, total harmonic distortion regulation, are also reviewed and discussed in this survey. Tertiary control systems, e.g., for economic dispatch of electric energy, based on cooperative control approaches, are also addressed in this work. This review also highlights existing issues, research challenges and future trends in distributed cooperative control of microgrids and their future applications.","['Decentralized control', 'Stability analysis', 'Topology', 'Power system stability', 'Microgrids', 'Asymptotic stability']","['AC-microgrid', 'consensus', 'DC-microgrid', 'distributed control', 'hierarchical control', 'hybrid-microgrid', 'microgrids']"
"In the last decade, Human Activity Recognition (HAR) has become a vibrant research area, especially due to the spread of electronic devices such as smartphones, smartwatches and video cameras present in our daily lives. In addition, the advance of deep learning and other machine learning algorithms has allowed researchers to use HAR in various domains including sports, health and well-being applications. For example, HAR is considered as one of the most promising assistive technology tools to support elderly's daily life by monitoring their cognitive and physical function through daily activities. This survey focuses on critical role of machine learning in developing HAR applications based on inertial sensors in conjunction with physiological and environmental sensors.","['Deep learning', 'Computational modeling', 'Activity recognition', 'Data models', 'Sensors', 'Biomedical monitoring', 'Smart phones']","['Human activity recognition (HAR)', 'deep learning (DL)', 'machine learning (ML)', 'available datasets', 'sensors', 'accelerometer']"
"Prognostics and systems health management (PHM) is an enabling discipline that uses sensors to assess the health of systems, diagnoses anomalous behavior, and predicts the remaining useful performance over the life of the asset. The advent of the Internet of Things (IoT) enables PHM to be applied to all types of assets across all sectors, thereby creating a paradigm shift that is opening up significant new business opportunities. This paper introduces the concepts of PHM and discusses the opportunities provided by the IoT. Developments are illustrated with examples of innovations from manufacturing, consumer products, and infrastructure. From this review, a number of challenges that result from the rapid adoption of IoT-based PHM are identified. These include appropriate analytics, security, IoT platforms, sensor energy harvesting, IoT business models, and licensing approaches.","['Prognostics and health management', 'Sensors', 'Internet of things', 'Maintenance engineering', 'Reliability', 'STEM', 'Degradation']","['Internet of things', 'maintenance', 'prognostics and systems health management', 'reliability', 'remaining useful life']"
"Cyber-physical-social system (CPSS) has drawn tremendous attention in industrial applications such as industrial Internet of Things (IIoT). As the fundamental component of IIoT, bearings play an increasingly important role in CPSS for IIoT. Better understanding of bearing working conditions and degradation patterns so as to more accurately predict the remaining useful life (RUL), becomes an urgent demand for industrial prognostics in IIoT. The data-driven approach has indicated good potential, but the prediction accuracy is still not satisfactory. This paper proposes a new method for the prediction of bearing RUL based on deep convolution neural network (CNN). A new feature extraction method is presented to obtain the eigenvector, named the spectrum-principal-energy-vector. The eigenvector is suitable for deep CNN. In the prediction phase, we propose a smoothing method to deal with the discontinuity problem found in the prediction results. To the best of our knowledge, we are the first to propose such a smoothing method for bearing RUL prediction. Experiments show that our method can significantly improve the prediction accuracy of bearing RUL.","['Vibrations', 'Feature extraction', 'Frequency-domain analysis', 'Neural networks', 'Predictive models', 'Convolution', 'Time-domain analysis']","['Cyber-physical-social system', 'industrial big data', 'deep learning', 'RUL prediction', 'deep convolution neural network']"
"In this paper, atom search optimization (ASO) algorithm and a novel chaotic version of it [chaotic ASO (ChASO)] are proposed to determine the optimal parameters of the fractional-order proportional+integral+derivative (FOPID) controller for dc motor speed control. The ASO algorithm is simple and easy to implement, which mathematically models and mimics the atomic motion model in nature, and is developed to address a diverse set of optimization problems. The proposed ChASO algorithm, on the other hand, is based on logistic map chaotic sequences, which makes the original algorithm be able to escape from local minima stagnation and improve its convergence rate and resulting precision. First, the proposed ChASO algorithm is applied to six unimodal and multimodal benchmark optimization problems and the results are compared with other algorithms. Second, the proposed ChASO-FOPID, ASO-FOPID, and ASO-PID controllers are compared with GWO-FOPID, GWO-PID, IWO-PID, and SFS-PID controllers using the integral of time multiplied absolute error (ITAE) objective function for a fair comparison. Comparisons were also made for the integral of time multiplied squared error (ITSE) and Zwe-Lee Gaing's (ZLG) objective function as the most commonly used objective functions in the literature. Transient response analysis, frequency response (Bode) analysis, and robustness analysis were all carried out. The simulation results are promising and validate the effectiveness of the proposed approaches. The numerical simulations of the proposed ChASO-FOPID and ASO-FOPID controllers for the dc motor speed control system demonstrated the superior performance of both the chaotic ASO and the original ASO, respectively.","['Optimization', 'Heuristic algorithms', 'Logistics', 'Tuning', 'Linear programming', 'DC motors', 'Velocity control']","['DC motor speed control', 'fractional order PID controller', 'chaotic atom search optimization algorithm', 'robustness analysis', 'transient response']"
"The achievable performance of subcarrier-index modulation (SIM) is analyzed in terms of its minimum Euclidean distance, constrained and unconstrained average mutual information, as well as its peak-to-average power ratio (PAPR). Our performance investigations identify the beneficial operating region of the SIM scheme over its conventional orthogonal frequency-division multiplexing (OFDM) counterpart, hence providing general design guidelines for the SIM parameters. More specifically, an SIM scheme is shown to be beneficial for the scenario of a relatively low transmission rate below 2 b/s/Hz. In addition, we demonstrate that the PAPR of the SIM scheme is comparable with that of its OFDM counterpart under the idealized simplifying assumption of having Gaussian input symbols.","['OFDM', 'Subcarrier indexes', 'Parallel processing', 'Peak to average power ratio', 'Capacity planning', 'Spatial modulation']","['Capacity', 'EXIT chart', 'index modulation', 'mutual information', 'OFDM', 'parallel combinatory', 'peak-to-average power ratio', 'spatial modulation', 'subcarrier-index modulation']"
"This paper provides an extensive review of the popular multi-objective optimization algorithm NSGA-II for selected combinatorial optimization problems viz. assignment problem, allocation problem, travelling salesman problem, vehicle routing problem, scheduling problem, and knapsack problem. It is identified that based on the manner in which NSGA-II has been implemented for solving the aforementioned group of problems, there can be three categories: Conventional NSGA-II, where the authors have implemented the basic version of NSGA-II, without making any changes in the operators; the second one is Modified NSGA-II, where the researchers have implemented NSGA-II after making some changes into it and finally, Hybrid NSGA-II variants, where the researchers have hybridized the conventional and modified NSGA-II with some other technique. The article analyses the modifications in NSGA-II and also discusses the various performance assessment techniques used by the researchers, i.e., test instances, performance metrics, statistical tests, case studies, benchmarking with other state-of-the-art algorithms. Additionally, the paper also provides a brief bibliometric analysis based on the work done in this study.","['Optimization', 'Statistics', 'Sociology', 'Sorting', 'Resource management', 'Linear programming', 'Genetic algorithms']","['NSGA-II', 'combinatorial optimization', 'multi-objective optimization', 'genetic algorithms']"
"Power electronic converter (PEC)-interfaced renewable energy generators (REGs) are increasingly being integrated to the power grid. With the high renewable power penetration levels, one of the key power system parameters, namely reactive power, is affected, provoking steady-state voltage and dynamic/transient stability issues. Therefore, it is imperative to maintain and manage adequate reactive power reserve to ensure a stable and reliable power grid. This paper presents a comprehensive literature review on the reactive power management in renewable rich power grids. Reactive power requirements stipulated in different grid codes for REGs are summarized to assess their adequacy for future network requirements. The PEC-interfaced REGs are discussed with a special emphasis on their reactive power compensation capability and control schemes. Along with REGs, conventional reactive power support devices (e.g., capacitor banks) and PEC-interfaced reactive power support devices (e.g., static synchronous compensators) play an indispensable role in the reactive power management of renewable rich power grids, and thus their reactive power control capabilities and limitations are thoroughly reviewed in this paper. Then, various reactive power control strategies are reviewed with a special emphasis on their advantages/disadvantages. Reactive power coordination between support devices and their optimal capacity are vital for an efficient and stable management of the power grid. Accordingly, the prominent reactive power coordination and optimization algorithms are critically examined and discussed in this paper. Finally, the key issues pertinent to the reactive power management in renewable rich power grids are enlisted with some important technical recommendations for the power industry, policymakers, and academic researchers.","['Reactive power', 'Power grids', 'Power system stability', 'Generators', 'Renewable energy sources', 'Wind power generation', 'Voltage control']","['Control strategies', 'grid codes', 'optimization algorithms', 'renewable energy generators (REGs)', 'reactive power', 'solar photovoltaic (PV)', 'wind generation']"
"Seismology is a data rich and data-driven science. Application of machine learning for gaining new insights from seismic data is a rapidly evolving sub-field of seismology. The availability of a large amount of seismic data and computational resources, together with the development of advanced techniques can foster more robust models and algorithms to process and analyze seismic signals. Known examples or labeled data sets, are the essential requisite for building supervised models. Seismology has labeled data, but the reliability of those labels is highly variable, and the lack of high-quality labeled data sets to serve as ground truth as well as the lack of standard benchmarks are obstacles to more rapid progress. In this paper we present a high-quality, large-scale, and global data set of local earthquake and non-earthquake signals recorded by seismic instruments. The data set in its current state contains two categories: (1) local earthquake waveforms (recorded at “local” distances within 350 km of earthquakes) and (2) seismic noise waveforms that are free of earthquake signals. Together these data comprise ~1.2 million time series or more than 19,000 hours of seismic signal recordings. Constructing such a large-scale database with reliable labels is a challenging task. Here, we present the properties of the data set, describe the data collection, quality control procedures, and processing steps we undertook to insure accurate labeling, and discuss potential applications. We hope that the scale and accuracy of STEAD presents new and unparalleled opportunities to researchers in the seismological community and beyond.","['Earthquakes', 'Instruments', 'Seismic waves', 'Seismic measurements', 'Seismology', 'Benchmark testing', 'Artificial intelligence']","['Earthquakes', 'seismic waveform data', 'machine learning', 'seismic measurements', 'artificial intelligence', 'benchmark testing']"
"Early detection of skin cancer, particularly melanoma, is crucial to enable advanced treatment. Due to the rapid growth in the number of skin cancers, there is a growing need of computerised analysis for skin lesions. The state-of-the-art public available datasets for skin lesions are often accompanied with a very limited amount of segmentation ground truth labeling. Also, the available segmentation datasets consist of noisy expert annotations reflecting the fact that precise annotations to represent the boundary of skin lesions are laborious and expensive. The lesion boundary segmentation is vital to locate the lesion accurately in dermoscopic images and lesion diagnosis of different skin lesion types. In this work, we propose the fully automated deep learning ensemble methods to achieve high sensitivity and high specificity in lesion boundary segmentation. We trained the ensemble methods based on Mask R-CNN and DeeplabV3+ methods on ISIC-2017 segmentation training set and evaluate the performance of the ensemble networks on ISIC-2017 testing set and PH2 dataset. Our results showed that the proposed ensemble methods segmented the skin lesions with Sensitivity of 89.93% and Specificity of 97.94% for the ISIC-2017 testing set. The proposed ensemble method Ensemble-A outperformed FrCN, FCNs, U-Net, and SegNet in Sensitivity by 4.4%, 8.8%, 22.7%, and 9.8% respectively. Furthermore, the proposed ensemble method Ensemble-S achieved a specificity score of 97.98% for clinically benign cases, 97.30% for the melanoma cases, and 98.58% for the seborrhoeic keratosis cases on ISIC-2017 testing set, exhibiting better performance than FrCN, FCNs, U-Net, and SegNet.","['Lesions', 'Skin', 'Image segmentation', 'Melanoma', 'Deep learning', 'Testing', 'Annotations']","['Skin cancer', 'skin lesion segmentation', 'ensemble segmentation methods', 'deep learning', 'melanoma', 'instance segmentation', 'semantic segmentation']"
"Urban air pollutant concentration prediction is dealing with a surge of massive environmental monitoring data and complex changes in air pollutants. This requires effective prediction methods to improve prediction accuracy and to prevent serious pollution incidents, thereby enhancing environmental management decision-making capacity. In this paper, a new pollutant concentration prediction method is proposed based on the vast amounts of environmental data and deep learning techniques. The proposed method integrates big data by using two kinds of deep networks. This method is based on the design that uses a convolutional neural network as the base layer, automatically extracting features of input data. A long short-term memory network is used for the output layer to consider the time dependence of pollutants. Our model consists of these two deep networks. With performance optimization, the model can predict future particulate matter (PM2.5) concentrations as a time series. Finally, the prediction results are compared with the results of numerical models. The applicability and advantages of the model are also analyzed. The experimental results show that it improves prediction performance compared with classic models.","['Feature extraction', 'Predictive models', 'Air pollution', 'Mathematical model', 'Atmospheric modeling', 'Data models', 'Data mining']","['Air pollution', 'machine learning', 'neural network', 'numerical analysis', 'prediction method']"
"In this paper, a review is presented for the research on eye gaze estimation techniques and applications, which has progressed in diverse ways over the past two decades. Several generic eye gaze use-cases are identified: desktop, TV, head-mounted, automotive, and handheld devices. Analysis of the literature leads to the identification of several platform specific factors that influence gaze tracking accuracy. A key outcome from this review is the realization of a need to develop standardized methodologies for the performance evaluation of gaze tracking systems and achieve consistency in their specification and comparative evaluation. To address this need, the concept of a methodological framework for practical evaluation of different gaze tracking systems is proposed.","['Gaze tracking', 'Estimation', 'Visualization', 'Performance evaluation', 'Computers', 'Calibration', 'Imaging']","['Eye gaze', 'gaze estimation', 'accuracy', 'error sources', 'performance evaluation', 'user platforms']"
"A building energy management system (BEMS) is a sophisticated method used for monitoring and controlling a building's energy requirements. A number of potential studies were conducted in nearly or net zero energy buildings (nZEBs) for the optimization of building energy consumption through efficient and sustainable ways. Moreover, policy makers are approving measures to improve building energy efficiency in order to foster sustainable energy usages. However, the intelligence of existing BEMSs or nZEBs is inadequate, because of the static set points for heating, cooling, and lighting, the complexity of large amounts of BEMS data, data loss, and network problems. To solve these issues, a BEMS or nZEB solution based on the Internet of energy (IoE) provides disruptive opportunities for revolutionizing sustainable building energy management. This paper presents a critical review of the potential of an IoE-based BEMS for enhancing the performance of future generation building energy utilization. The detailed studies of the IoE architecture, typical nZEB configuration, different generations of nZEB, and smart building energy systems for future BEMS are investigated. The operations, advantages, and limitations of the existing BEMSs or nZEBs are illustrated. A comprehensive review of the different types of IoE-based BEMS technologies, such as energy routers, storage systems and materials, renewable sources, and plug-and-play interfaces, is then presented. The rigorous review indicates that existing BEMSs require advanced controllers integrated with IoE-based technologies for sustainable building energy usage. The main objective of this review is to highlight several issues and challenges of the conventional controllers and IoE applications of BEMSs or nZEBs. Accordingly, the review provides several suggestions for the research and development of the advanced optimized controller and IoE of future BEMSs. All the highlighted insights and recommendations of this review will hopefully lead to increasing efforts toward the development of the future BEMS applications.","['Buildings', 'Energy consumption', 'Internet', 'Energy efficiency', 'Monitoring', 'Cooling']","['Internet of energy (IoE)', 'building energy management system', 'nearly or net zero energy building', 'sustainable energy']"
"This paper presents an efficient and secure chaotic S-Box based image encryption algorithm. Firstly, by cryptanalyzing a multiple chaotic S-Boxes based image encryption algorithm, we successfully cracked the cryptosystem by using chosen-plaintext attack (CPA). Secondly, we put forward a new image encryption scheme based on a novel compound chaotic map and single S-Box. In the new scheme, a novel discrete compound chaotic system, Logistic-Sine system (LSS), is proposed, which has wider chaotic range and better chaotic properties. And a new S-Box is constructed by using LSS, which has satisfactory cryptographic performance. Based on the new S-Box and the chaotic key stream, the new image encryption algorithm is designed, which consist of a round of permutation and two rounds of substitution process. The permutation and substitution key sequences are related to the plaintext image content, this strategy enables the cryptosystem to resist CPA. The simulation results and security analysis verified the effectiveness of the proposed image encryption scheme. Especially, the new scheme has obvious efficiency advantages, showing that it has better application potential in real-time image encryption.","['Encryption', 'Chaotic communication', 'Ciphers', 'Heuristic algorithms']","['Image encryption', 'chaos', 'S-box', 'Logistic-Sine system', 'substitution', 'chosen-plaintext attack']"
"The world is witnessing an unprecedented growth of cyber-physical systems (CPS), which are foreseen to revolutionize our world via creating new services and applications in a variety of sectors, such as environmental monitoring, mobile-health systems, intelligent transportation systems, and so on. The information and communication technology sector is experiencing a significant growth in data traffic, driven by the widespread usage of smartphones, tablets, and video streaming, along with the significant growth of sensors deployments that are anticipated in the near future. It is expected to outstandingly increase the growth rate of raw sensed data. In this paper, we present the CPS taxonomy via providing a broad overview of data collection, storage, access, processing, and analysis. Compared with other survey papers, this is the first panoramic survey on big data for CPS, where our objective is to provide a panoramic summary of different CPS aspects. Furthermore, CPS requires cybersecurity to protect them against malicious attacks and unauthorized intrusion, which become a challenge with the enormous amount of data that are continuously being generated in the network. Thus, we also provide an overview of the different security solutions proposed for CPS big data storage, access, and analytics. We also discuss big data meeting green challenges in the contexts of CPS.","['Big Data', 'Sensors', 'Cloud computing', 'Security', 'Green products', 'Cyber-physical systems', 'Tools']","['Cyber-physical systems (CPS)', 'Internet of Things (IoT)', 'context-awareness', 'social computing', 'cloud computing', 'big data', 'clustering', 'data mining', 'data analytics', 'machine learning', 'real-time analytics', 'space-time analytics', 'cybersecurity', 'green', 'energy', 'sustainability']"
"Intrusion detection system (IDS) provides an important basis for the network defense. Due to the development of the cloud computing and social network, massive amounts of data are generated, which inevitably brings much pressure to IDS. And therefore, it becomes crucial to efficiently divide the data into different classes over big data according to data features. Moreover, we can further determine whether one is normal behavior or not based on the classes information. Although the clustering approach based on K-means for IDS has been well studied, unfortunately directly using it in big data environment may suffer from inappropriateness. On the one hand, the efficiency of data clustering needs to be improved. On the other hand, differ from the classification, there is no unified evaluation indicator for clustering issue, and thus, it is necessary to study which indicator is more suitable for evaluating the clustering results of IDS. In this paper, we propose a clustering method for IDS based on Mini Batch K-means combined with principal component analysis. First, a preprocessing method is proposed to digitize the strings and then the data set is normalized so as to improve the clustering efficiency. Second, the principal component analysis method is used to reduce the dimension of the processed data set aiming to further improve the clustering efficiency, and then mini batch K-means method is used for data clustering. More specifically, we use K-means++ to initialize the centers of cluster in order to avoid the algorithm getting into the local optimum, in addition, we choose the Calsski Harabasz indicator so that the clustering result is more easily determined. Compared with the other methods, the experimental results and the time complexity analysis show that our proposed method is effective and efficient. Above all, our proposed clustering method can be used for IDS over big data environment.","['Principal component analysis', 'Clustering algorithms', 'Big Data', 'Clustering methods', 'Data mining', 'Intrusion detection', 'Classification algorithms']","['IDS', 'big data', 'clustering', 'principal component analysis', 'mini batch Kmeans']"
"Fault diagnosis of rotating machinery plays a significant role in the industrial production and engineering field. Owing to the drawbacks of traditional fault diagnosis methods, such as heavily dependence on human knowledge and professional experience, intelligent fault diagnosis based on deep learning (DL) has aroused the interest of researchers. DL achieves the desirable automatic feature learning and fault classification. Therefore, in this review, DL and DL-based intelligent fault diagnosis techniques are overviewed. DL-based fault diagnosis approaches for rotating machinery are summarized and discussed, primarily including bearing, gear/gearbox and pumps. Finally, with respect to modern intelligent fault diagnosis, the existing challenges and possible future research orientations are prospected and analyzed.","['Fault diagnosis', 'Artificial intelligence', 'Feature extraction', 'Neural networks', 'Pumps', 'Gears']","['Deep learning', 'deep neural network', 'intelligent fault diagnosis', 'rotating machinery']"
"In recent years, big data have become a hot research topic. The increasing amount of big data also increases the chance of breaching the privacy of individuals. Since big data require high computational power and large storage, distributed systems are used. As multiple parties are involved in these systems, the risk of privacy violation is increased. There have been a number of privacy-preserving mechanisms developed for privacy protection at different stages (e.g., data generation, data storage, and data processing) of a big data life cycle. The goal of this paper is to provide a comprehensive overview of the privacy preservation mechanisms in big data and present the challenges for existing mechanisms. In particular, in this paper, we illustrate the infrastructure of big data and the state-of-the-art privacy-preserving mechanisms in each stage of the big data life cycle. Furthermore, we discuss the challenges and future research directions related to privacy preservation in big data.","['Big data', 'Cloud computing', 'Data privacy', 'Memory management', 'Privacy']","['Big data', 'privacy', 'data auditing', 'big data storage', 'big data processing']"
"Air pollution has become an extremely serious problem, with particulate matter having a significantly greater impact on human health than other contaminants. The small diameter of fine particulate matter (PM2.5) allows it to penetrate deep into the alveoli as far as the bronchioles, interfering with a gas exchange within the lungs. Long-term exposure to particulate matter has been shown to cause the cardiovascular disease, respiratory disease, and increase the risk of lung cancers. Therefore, forecasting air quality has also become important to help guide individual actions. This paper aims to forecast air quality for up to 48 h using a combination of multiple neural networks, including an artificial neural network, a convolutional neural network, and a long-short-term memory to extract spatial-temporal relations. The proposed predictive model considers various meteorology data from the previous few hours as well as information related to the elevation space to extract terrain impact on air quality. The model includes trends from multiple locations, extracted from correlations between adjacent locations, and among similar locations in the temporal domain. Experiments employing Taiwan and Beijing data sets show that the proposed model achieves excellent performance and outperforms current state-of-the-art methods.","['Air quality', 'Atmospheric modeling', 'Predictive models', 'Neural networks', 'Wind forecasting', 'Lung', 'Data mining']","['Dynamic time warping(DTW)', 'convolutional neural network(CNN)', 'long-short-term memory(LSTM)', 'spatio-temporal analysis', 'big data', 'air quality forecast']"
"Internet of Things allow massive number of uniquely addressable “things” to communicate with each other and transfer data over existing internet or compatible network protocols. This paper proposes a new concept which tackles the issues for supporting control and monitoring activities at deployment sites and industrial automations, where intelligent things can monitor peripheral events, induce sensor data acquired from a variety of sources, use ad hoc, local, and distributed “machine intelligence” to determine appropriate course of actions, and then act to control or disseminate static or dynamic position aware robotic things in the physical world through a seamless manner by providing a means for utilizing them as Internet of robotic things (IoRT). Although progressive advancements can be seen in multi-robotic systems, robots are constantly getting enriched by easier developmental functionalities, such vertical robotic service centric silos are not enough for continuously and seamlessly supporting for which they are meant. In this paper, a novel concept-IoRT is presented that highlights architectural principles, vital characteristics, as well as research challenges. The aim of this paper is to provide a better understanding of the architectural assimilation of IoRT and identify important research directions on this term.","['Internet of things', 'Monitoring', 'Robot sensing systems', 'Intelligent systems', 'Automation']","['Internet of things', 'IoRT', 'robotics', 'cloud']"
"Grey wolf optimizer (GWO) is a very efficient metaheuristic inspired by the hierarchy of the Canis lupus wolves. It has been extensively employed to a variety of practical applications. Crow search algorithm (CSA) is a recently proposed metaheuristic algorithm, which mimics the intellectual conduct of crows. In this paper, a hybrid GWO with CSA, namely GWOCSA is proposed, which combines the strengths of both the algorithms effectively with the aim to generate promising candidate solutions in order to achieve global optima efficiently. In order to validate the competence of the proposed hybrid GWOCSA, a widely utilized set of 23 benchmark test functions having a wide range of dimensions and varied complexities is used in this paper. The results obtained by the proposed algorithm are compared to 10 other algorithms in this paper for verification. The statistical results demonstrate that the GWOCSA outperforms other algorithms, including the recent variants of GWO called, enhanced grey wolf optimizer (EGWO) and augmented grey wolf optimizer (AGWO) in terms of high local optima avoidance ability and fast convergence speed. Furthermore, in order to demonstrate the applicability of the proposed algorithm at solving complex real-world problems, the GWOCSA is also employed to solve the feature selection problem as well. The GWOCSA as a feature selection approach is tested on 21 widely employed data sets acquired from the University of California at Irvine repository. The experimental results are compared to the state-of-the-art feature selection techniques, including the native GWO, the EGWO, and the AGWO. The results reveal that the GWOCSA has comprehensive superiority in solving the feature selection problem, which proves the capability of the proposed algorithm in solving real-world complex problems.","['Optimization', 'Feature extraction', 'Heuristic algorithms', 'Prediction algorithms', 'Search problems', 'Genetic algorithms', 'Computer science']","['Grey wolf optimizer', 'crow search algorithm', 'hybrid algorithm', 'function optimization', 'feature selection']"
"A new method is presented to denoise 1-D experimental signals using wavelet transforms. Although the state-of-the-art wavelet denoising methods perform better than other denoising methods, they are not very effective for experimental signals. Unlike images and other signals, experimental signals in chemical and biophysical applications, for example, are less tolerant to signal distortion and under-denoising caused by the standard wavelet denoising methods. The new method: 1) provides a method to select the number of decomposition levels to denoise; 2) uses a new formula to calculate noise thresholds that does not require noise estimation; 3) uses separate noise thresholds for positive and negative wavelet coefficients; 4) applies denoising to the approximation component; and 5) allows the flexibility to adjust the noise thresholds. The new method is applied to continuous wave electron spin resonance spectra and it is found that it increases the signal-to-noise ratio (SNR) by more than 32 dB without distorting the signal, whereas standard denoising methods improve the SNR by less than 10 dB and with some distortion. In addition, its computation time is more than six times faster.","['Wavelet transforms', 'Noise measurement', 'Threshold current', 'Spectroscopy', 'Magnetic resonance', 'Noise reduction']","['Wavelet transform', 'wavelet denoising', 'noise thresholding', 'noise reduction', 'magnetic resonance spectroscopy']"
"Diabetic retinopathy (DR) is an important cause of blindness worldwide. However, DR is hard to be detected in the early stages, and the diagnostic procedure can be time-consuming even for the experienced experts. Therefore, a computer-aided diagnosis method based on deep learning algorithms is proposed to automatedly diagnose the referable diabetic retinopathy by classifying color retinal fundus photographs into two grades. In this paper, a novel convolutional neural network model with the Siamese-like architecture is trained with a transfer learning technique. Different from the previous works, the proposed model accepts binocular fundus images as inputs and learns their correlation to help to make a prediction. In the case with a training set of only 28 104 images and a test set of 7024 images, an area under the receiver operating curve of 0.951 is obtained by the proposed binocular model, which is 0.011 higher than that obtained by the existing monocular model. To further verify the effectiveness of the binocular design, a binocular model for five-class DR detection is also trained and evaluated on a 10% validation set. The result shows that it achieves a kappa score of 0.829 which is higher than that of the existing non-ensemble model.","['Diabetes', 'Retinopathy', 'Deep learning', 'Lesions', 'Convolutional neural networks', 'Blindness', 'Retina']","['Biomedical imaging processing', 'diabetic retinopathy', 'fundus photograph', 'convolutional neural network', 'deep learning', 'Siamese-like network']"
"The contribution of a plant is highly important for both human life and environment. Plants do suffer from diseases, like human beings and animals. There is the number of plant diseases that occur and affects the normal growth of a plant. These diseases affect complete plant including leaf, stem, fruit, root, and flower. Most of the time when the disease of a plant has not been taken care of, the plant dies or may cause leaves drop, flowers, and fruits drop. Appropriate diagnosis of such diseases is required for accurate identification and treatment of plant diseases. Plant pathology is the study of plant diseases, their causes, procedures for controlling and managing them. But, the existing method encompasses human involvement for classification and identification of diseases. This procedure is time-consuming and costly. Automatic segmentation of diseases from plant leaf images using soft computing approach can be reasonably useful than the existing one. In this paper, we have introduced a method named as bacterial foraging optimization based radial basis function neural network (BRBFNN) for identification and classification of plant leaf diseases automatically. For assigning optimal weight to radial basis function neural network we use bacterial foraging optimization that further increases the speed and accuracy of the network to identify and classify the regions infected of different diseases on the plant leafs. The region growing algorithm increases the efficiency of the network by searching and grouping of seed points having common attributes for feature extraction process. We worked on fungal diseases like common rust, cedar apple rust, late blight, leaf curl, leaf spot, and early blight. The proposed method attains higher accuracy in identification and classification of diseases.","['Diseases', 'Support vector machines', 'Microorganisms', 'Task analysis', 'Radial basis function networks', 'Optimization']","['Bacteria foraging algorithm', 'image segmentation', 'plant diseases', 'radial basis function neural network', 'soft computing']"
"Power system faults are significant problems in power transmission and distribution. Methods based on relay protection actions and electrical component actions have been put forward in recent years. However, they have deficiencies dealing with power system fault. In this paper, a method for data-based line trip fault prediction in power systems using long short-term memory (LSTM) networks and support vector machine (SVM) is proposed. The temporal features of multisourced data are captured with LSTM networks, which perform well in extracting the features of time series for a long-time span. The strong learning and mining ability of LSTM networks is suitable for a large quantity of time series in power transmission and distribution. SVM, with a strong generalization ability and robustness, is introduced for classification to get the final prediction results. Considering the overfitting problem in fault prediction, layer of dropout and batch normalization are added into the network. The complete network architecture is shown in this paper in detail. The parameters are adjusted to fit the specific situation of the actual power system. The data for experiments are obtained from the Wanjiang substation in the China Southern Power Grid. The real experiments prove the proposed method's improvements compared with current data mining methods. Concrete analyses of results are elaborated in this paper. A discussion of practical applications is presented to demonstrate the feasibility in real scenarios.","['Circuit faults', 'Support vector machines', 'Power system stability', 'Data mining', 'Protective relaying', 'Power system faults', 'Feature extraction']","['Data mining', 'power system faults', 'recurrent neural networks', 'support vector machines']"
"Cardiovascular disease is a substantial cause of mortality and morbidity in the world. In clinical data analytics, it is a great challenge to predict heart disease survivor. Data mining transforms huge amounts of raw data generated by the health industry into useful information that can help in making informed decisions. Various studies proved that significant features play a key role in improving performance of machine learning models. This study analyzes the heart failure survivors from the dataset of 299 patients admitted in hospital. The aim is to find significant features and effective data mining techniques that can boost the accuracy of cardiovascular patient’s survivor prediction. To predict patient’s survival, this study employs nine classification models: Decision Tree (DT), Adaptive boosting classifier (AdaBoost), Logistic Regression (LR), Stochastic Gradient classifier (SGD), Random Forest (RF), Gradient Boosting classifier (GBM), Extra Tree Classifier (ETC), Gaussian Naive Bayes classifier (G-NB) and Support Vector Machine (SVM). The imbalance class problem is handled by Synthetic Minority Oversampling Technique (SMOTE). Furthermore, machine learning models are trained on the highest ranked features selected by RF. The results are compared with those provided by machine learning algorithms using full set of features. Experimental results demonstrate that ETC outperforms other models and achieves 0.9262 accuracy value with SMOTE in prediction of heart patient’s survival.","['Heart', 'Data mining', 'Predictive models', 'Machine learning algorithms', 'Support vector machines', 'Medical diagnostic imaging', 'Boosting']","['Data mining', 'heart disease classification', 'machine learning', 'cardiovascular disease', 'feature selection', 'SMOTE']"
"Battery packs with a large number of battery cells are becoming more and more widely adopted in electronic systems, such as robotics, renewable energy systems, energy storage in smart grids, and electronic vehicles. Therefore, a well-designed battery pack is essential for battery applications. In the literature, the majority of research in battery pack design focuses on battery management system, safety circuit, and cell-balancing strategies. Recently, the reconfigurable battery pack design has gained increasing attentions as a promising solution to solve the problems existing in the conventional battery packs and associated battery management systems, such as low energy efficiency, short pack lifespan, safety issues, and low reliability. One of the most prominent features of reconfigurable battery packs is that the battery cell topology can be dynamically reconfigured in the real-time fashion based on the current condition (in terms of the state of charge and the state of health) of battery cells. So far, there are several reconfigurable battery schemes having been proposed and validated in the literature, all sharing the advantage of cell topology reconfiguration that ensures balanced cell states during charging and discharging, meanwhile providing strong fault tolerance ability. This survey is undertaken with the intent of identifying the state-of-the-art technologies of reconfigurable battery as well as providing review on related technologies and insight on future research in this emerging area.","['Energy storage', 'Battery management system', 'Safety', 'Battery cells', 'Reconfigurable batteries']","['Reconfigurable battery pack', 'energy storage system', 'SOC', 'battery management system']"
"Smart wearables collect and analyze data, and in some scenarios make a smart decision and provide a response to the user and are finding more and more applications in our daily life. In this paper, we comprehensively survey the most recent and important research works conducted in the area of wearable Internet of Things (IoT) and classify the wearables into four major clusters: (i) health, (ii) sports and daily activity, (iii) tracking and localization, and (iv) safety. The fundamental differences of the algorithms associated within each cluster are grouped and analyzed and the research challenges and open issues in each cluster are discussed. This survey reveals that although Cellular IoT (CIoT) has many advantages and can bring enormous applications to IoT wearables, it has been rarely studied by the researchers. This article also addresses the opportunities and challenges related to implementing CIoT-enabled wearables.","['Biomedical monitoring', 'Temperature sensors', 'Monitoring', 'Internet of Things', 'Wearable sensors', 'Temperature measurement']","['Smart wearables', 'Internet of Things', 'cellular IoT']"
"An important application in the growing field of unmanned aerial vehicles (UAVs) is in monitoring and inspection of high voltage power lines and electrical networks. The UAV-based monitoring method will save energy, simplify access to impassable or remote areas, reduce inspection cost, and automate the inspection process. However, the battery capacity of a medium scale drone limits their travel distance and mission duration. It is crucial to improve the energy feeding system of drones and overcome the battery capacity problem to foster the use of drones for routine monitoring operations. In this study, we focus on presenting wireless techniques available for drone mission duration improvement as well as discuss and practically examine the most feasible and reliable technique to charge UAV using power lines.","['Drones', 'Batteries', 'Laser beams', 'Monitoring', 'Wind', 'Wireless communication']","['Unmanned aerial vehicles', 'wireless charging', 'wireless energy transfer', 'inductive power transfer']"
"The Internet of Things (IoT) is rapidly becoming an integral part of our life and also multiple industries. We expect to see the number of IoT connected devices explosively grows and will reach hundreds of billions during the next few years. To support such a massive connectivity, various wireless technologies are investigated. In this survey, we provide a broad view of the existing wireless IoT connectivity technologies and discuss several new emerging technologies and solutions that can be effectively used to enable massive connectivity for IoT. In particular, we categorize the existing wireless IoT connectivity technologies based on coverage range and review diverse types of connectivity technologies with different specifications. We also point out key technical challenges of the existing connectivity technologies for enabling massive IoT connectivity. To address the challenges, we further review and discuss some examples of promising technologies such as compressive sensing (CS) random access, non-orthogonal multiple access (NOMA), and massive multiple input multiple output (mMIMO) based random access that could be employed in future standards for supporting IoT connectivity. Finally, a classification of IoT applications is considered in terms of various service requirements. For each group of classified applications, we outline its suitable IoT connectivity options.","['Wireless communication', 'Bluetooth', 'Internet of Things', 'Wireless sensor networks', 'NOMA', '5G mobile communication', 'OFDM']","['IoT connectivity technologies', '5G', 'massive MTC', 'massive connectivity', 'compressive sensing', 'NOMA', 'massive MIMO', 'machine learning', 'IoT applications']"
"Lithium-ion batteries (LIBs) are being intensively studied and universally used as power sources for electric vehicle applications. Despite the staggering growth in sales of LIBs worldwide, thermal safety issues still turn out to be the most intolerable pain point, and remain the focus of research for technological improvements. This paper presents a comprehensive overview on thermal safety issues of LIBs, in terms of thermal behavior and thermal runaway modeling and tests for battery cells, and safety management strategies for battery packs. Considering heat generation mechanism and thermal characteristics of LIBs, heat generation, dissipation and accumulation inside a cell are elaborated. The triggering factors leading to thermal runaway are also summarized. Finally, thermal runaway detection and prevention strategies for both cell- and pack-levels are introduced. Different engineering approaches from material refinement and additive adoption to thermal, electrical, and mechanical design are presented for thermal runaway prevention.","['Heating systems', 'Batteries', 'Mathematical model', 'Temperature measurement', 'Safety', 'Electrodes', 'Calorimetry']","['Electric vehicles', 'batteries', 'modeling', 'calorimetry', 'safety', 'thermal runaway', 'thermal management']"
"Automated digital contact tracing is effective and efficient, and one of the non-pharmaceutical complementary approaches to mitigate and manage epidemics like Coronavirus disease 2019 (COVID-19). Despite the advantages of digital contact tracing, it is not widely used in the western world, including the US and Europe, due to strict privacy regulations and patient rights. We categorized the current approaches for contact tracing, namely: mobile service-provider-application, mobile network operators’ call detail, citizen-application, and IoT-based. Current measures for infection control and tracing do not include animals and moving objects like cars despite evidence that these moving objects can be infection carriers. In this article, we designed and presented a novel privacy anonymous IoT model. We presented an RFID proof-of-concept for this model. Our model leverages blockchain’s trust-oriented decentralization for on-chain data logging and retrieval. Our model solution will allow moving objects to receive or send notifications when they are close to a flagged, probable, or confirmed diseased case, or flagged place or object. We implemented and presented three prototype blockchain smart contracts for our model. We then simulated contract deployments and execution of functions. We presented the cost differentials. Our simulation results show less than one-second deployment and call time for smart contracts, though, in real life, it can be up to 25 seconds on Ethereum public blockchain. Our simulation results also show that it costs an average of $1.95 to deploy our prototype smart contracts, and an average of $0.34 to call our functions. Our model will make it easy to identify clusters of infection contacts and help deliver a notification for mass isolation while preserving individual privacy. Furthermore, it can be used to understand better human connectivity, model similar other infection spread network, and develop public policies to control the spread of COVID-19 while preparing for future epidemics.","['Privacy', 'Wireless fidelity', 'Bluetooth', 'Diseases', 'Mobile handsets', 'Animals']","['Contact tracing', 'RFID', 'IoT', 'blockchain', 'hospitals', 'telemedicine', 'digital health', 'privacy', 'COVID-19']"
"Registration of multi-temporal remote sensing images has been widely applied in military and civilian fields, such as ground target identification, urban development assessment, and geographic change assessment. Ground surface change challenges feature point detection in amount and quality, which is a common dilemma faced by feature-based registration algorithms. Under severe appearance variation, detected feature points may contain a large proportion of outliers, whereas inliers may be inadequate and unevenly distributed. This paper presents a convolutional neural network (CNN) feature-based multitemporal remote sensing image registration method with two key contributions: (i) we use a CNN to generate robust multi-scale feature descriptors and (ii) we design a gradually increasing selection of inliers to improve the robustness of feature point registration. Extensive experiments on feature matching and image registration are performed over a multi-temporal satellite image data set and a multi-temporal unmanned aerial vehicle image dataset. Our method outperforms four state-of-the-art methods in most scenarios.","['Feature extraction', 'Image registration', 'Remote sensing', 'Robustness', 'Convolutional neural networks', 'Optimization', 'Indexes']","['Remote sensing', 'feature matching', 'image registration', 'convolutional feature']"
"Scientific advances build on reproducible researches which need publicly available benchmark data sets. The computer vision and speech recognition communities have led the way in establishing benchmark data sets. There are much less data sets available in mobile computing, especially for rich locomotion and transportation analytics. This paper presents a highly versatile and precisely annotated large-scale data set of smartphone sensor data for multimodal locomotion and transportation analytics of mobile users. The data set comprises seven months of measurements, collected from all sensors of four smartphones carried at typical body locations, including the images of a body-worn camera, while three participants used eight different modes of transportation in the south-east of the U.K., including in London. In total, 28 context labels were annotated, including transportation mode, participant's posture, inside/outside location, road conditions, traffic conditions, presence in tunnels, social interactions, and having meals. The total amount of collected data exceed 950 GB of sensor data, which corresponds to 2812 h of labeled data and 17 562 km of traveled distance. We present how we set up the data collection, including the equipment used and the experimental protocol. We discuss the data set, including the data curation process, the analysis of the annotations, and of the sensor data. We discuss the challenges encountered and present the lessons learned and some of the best practices we developed to ensure high quality data collection and annotation. We discuss the potential applications which can be developed using this large-scale data set. In particular, we present how a machine-learning system can use this data set to automatically recognize modes of transportations. Many other research questions related to transportation analytics, activity recognition, radio signal propagation and mobility modeling can be addressed through this data set. The full data set is being made available to the community, and a thorough preview is already published.","['Global Positioning System', 'Data collection', 'Automobiles', 'Cameras', 'Public transportation', 'Mobile handsets']","['Activity recognition', 'context awareness', 'camera', 'intelligent transportation systems', 'GPS', 'GSM', 'locomotion dataset', 'multimodal sensors', 'pattern analysis', 'sensor fusion', 'supervised learning', 'transportation dataset', 'Wi-Fi']"
"Sarcasm is a sophisticated form of irony widely used in social networks and microblogging websites. It is usually used to convey implicit information within the message a person transmits. Sarcasm might be used for different purposes, such as criticism or mockery. However, it is hard even for humans to recognize. Therefore, recognizing sarcastic statements can be very useful to improve automatic sentiment analysis of data collected from microblogging websites or social networks. Sentiment Analysis refers to the identification and aggregation of attitudes and opinions expressed by Internet users toward a specific topic. In this paper, we propose a pattern-based approach to detect sarcasm on Twitter. We propose four sets of features that cover the different types of sarcasm we defined. We use those to classify tweets as sarcastic and non-sarcastic. Our proposed approach reaches an accuracy of 83.1% with a precision equal to 91.1%. We also study the importance of each of the proposed sets of features and evaluate its added value to the classification. In particular, we emphasize the importance of pattern-based features for the detection of sarcastic statements.","['Sentiment analysis', 'Twitter', 'Machine learning', 'Feature extraction']","['Twitter', 'sentiment analysis', 'sarcasm detection', 'machine learning']"
"This paper describes work that has been done on design and development of a water quality monitoring system, with the objective of notifying the user of the real-time water quality parameters. The system is able to measure the physiochemical parameters of water quality, such as flow, temperature, pH, conductivity, and the oxidation reduction potential. These physiochemical parameters are used to detect water contaminants. The sensors, which are designed from first principles and implemented with signal conditioning circuits, are connected to a microcontroller-based measuring node, which processes and analyzes the data. In this design, ZigBee receiver and transmitter modules are used for communication between the measuring and notification nodes. The notification node presents the reading of the sensors and outputs an audio alert when water quality parameters reach unsafe levels. Various qualification tests are run to validate each aspect of the monitoring system. The sensors are shown to work within their intended accuracy ranges. The measurement node is able to transmit data by ZigBee to the notification node for audio and visual display. The results demonstrate that the system is capable of reading physiochemical parameters, and can successfully process, transmit, and display the readings.","['Pollution measurement', 'Water contamination', 'Flow control', 'ZigBee', 'Real-time systems', 'Wireless sensor networks', 'Conductivity measurement', 'pH measurement']","['Water quality monitoring', 'flow sensor', 'pH sensor', 'conductivity sensor', 'temperature sensor', 'ORP sensor', 'ZigBee', 'wireless sensor networks']"
"IoT devices have some special characteristics, such as mobility, limited performance, and distributed deployment, which makes it difficult for traditional centralized access control methods to support access control in current large-scale IoT environment. To address these challenges, this paper proposes an access control system in IoT named fabric-iot, which is based on Hyperledger Fabric blockchain framework and attributed based access control (ABAC). The system contains three kinds of smart contracts, which are Device Contract (DC), Policy Contract (PC), and Access Contract (AC). DC provides a method to store the URL of resource data produced by devices, and a method to query it. PC provides functions to manage ABAC policies for admin users. AC is the core program to implement an access control method for normal users. Combined with ABAC and blockchain technology, fabric-iot can provide decentralized, fine-grained and dynamic access control management in IoT. To verify the performance of this system, two groups of simulation experiments are designed. The results show that fabric-iot can maintain high throughput in large-scale request environment and reach consensus efficiently in a distributed system to ensure data consistency.","['Access control', 'Blockchain', 'Peer-to-peer computing', 'Fabrics', 'Distributed ledger', 'Smart contracts']","['Blockchain', 'IoT', 'ABAC', 'hyperledger fabric', 'distributed system']"
"In this paper, we consider the use of a team of multiple unmanned aerial vehicles (UAVs) to accomplish a search and rescue (SAR) mission in the minimum time possible while saving the maximum number of people. A novel technique for the SAR problem is proposed and referred to as the layered search and rescue (LSAR) algorithm. The novelty of LSAR involves simulating real disasters to distribute SAR tasks among UAVs. The performance of LSAR is compared, in terms of percentage of rescued survivors and rescue and execution times, with the max-sum, auction-based, and locust-inspired approaches for multi UAV task allocation (LIAM) and opportunistic task allocation (OTA) schemes. The simulation results show that the UAVs running the LSAR algorithm on average rescue approximately 74% of the survivors, which is 8% higher than the next best algorithm (LIAM). Moreover, this percentage increases with the number of UAVs, almost linearly with the least slope, which means more scalability and coverage is obtained in comparison to other algorithms. In addition, the empirical cumulative distribution function of LSAR results shows that the percentages of rescued survivors clustered around the [78%-100%] range under an exponential curve, meaning most results are above 50%. In comparison, all the other algorithms have almost equal distributions of their percentage of rescued survivor results. Furthermore, because the LSAR algorithm focuses on the center of the disaster, it finds more survivors and rescues them faster than the other algorithms, with an average of 55%~77%. Moreover, most registered times to rescue survivors by LSAR are bounded by a time of 04:50:02 with 95% confidence for a one-month mission time.","['Robots', 'Task analysis', 'Resource management', 'Search problems', 'Unmanned aerial vehicles', 'Approximation algorithms', 'Clustering algorithms']","['Autonomous agents', 'drones', 'search and rescue', 'unmanned aerial vehicles']"
"As the secondary widely used battery, lithium-ion batteries (LIBs) have become the core component of the energy supply for most devices. Accurately predicting the current cycle time of LIBs is of great importance to ensure the reliability and safety of the equipment. In this paper, considering the nonlinear and non-Gaussian capacity degradation characteristics of LIBs, a remaining useful life (RUL) prediction method based on the exponential model and the particle filter is proposed. The cycle life test data of LIBs published by prognostics center of excellence in national aeronautics and space administration were exponentially experiencing the rule of degradation. And then the extrapolation method was used to get the quantitative expression of the uncertainty of life expectancy of LIBs, i.e. the prediction mean and the probability distribution histogram. The prognostic horizon index and the new specific accuracy index were applied to evaluate the prediction performance. Moreover, the prediction error under different prediction starting points is given. Compared with other methods such as the auto-regressive integrated moving average model, the fusion nonlinear degradation autoregressive model and the regularized particle filter algorithm, the proposed algorithm has a better prediction performance. According to the accuracy index, the proposed prediction method has better prediction accuracy and convergence. The RUL prediction for LIBs can provide a better decision support for the maintenance and support systems to optimize maintenance strategies, and reduce maintenance costs.","['Prediction algorithms', 'Degradation', 'Predictive models', 'Mathematical model', 'Batteries', 'Particle filters', 'Analytical models']","['Lithium-ion batteries (LIBs)', 'exponential model', 'particle filter (PF)', 'remaining useful life (RUL) prediction']"
"Accurate and timely prediction of remaining useful life (RUL) of a machine enables the machine to have an appropriate operation and maintenance decision. Data-driven RUL prediction methods are more attractive to researchers because they can be deployed quicker and cheaper compared to other approaches. The existing deep neural network (DNN) models proposed for the applications of RUL prediction are mostly single-path and top-down propagation. In order to improve the prognostic accuracy of the network, this paper proposes a directed acyclic graph (DAG) network that combines long short term memory (LSTM) and a convolutional neural network (CNN) to predict the RUL. Different from the existing prediction models combined with CNN and LSTM, the method proposed in this paper combines CNN and LSTM organically instead of just using CNN for feature extraction. Moreover, when a single timestamp is used as an input, padding the signals in the same training batch would affect the prediction ability of the developed model. To overcome this drawback, the proposed method generates a short-term sequence by sliding the time window (TW) with one step size. In addition, based on the degradation mechanism, the piece-wise RUL function is used instead of the traditional linear function. In the experimental test, the turbofan engine degradation simulation dataset provided by NASA is used to validate the proposed RUL prediction model. By comparing with the existing methods using the same dataset, it can be concluded that the prediction method proposed in this paper has better prediction capability.","['Predictive models', 'Feature extraction', 'Degradation', 'Data models', 'Engines', 'Neural networks']","['Remaining useful life prediction', 'long-short-term memory network', 'convolutional neural networks', 'turbofan engine']"
"In order to improve the accuracy of emotional recognition by end-to-end automatic learning of emotional features in spatial and temporal dimensions of electroencephalogram (EEG), an EEG emotional feature learning and classification method using deep convolution neural network (CNN) was proposed based on temporal features, frequential features, and their combinations of EEG signals in DEAP dataset. The shallow machine learning models including bagging tree (BT), support vector machine (SVM), linear discriminant analysis (LDA), and Bayesian linear discriminant analysis (BLDA) models and deep CNN models were used to make emotional binary classification experiments on DEAP datasets in valence and arousal dimensions. The experimental results showed that the deep CNN models which require no feature engineering achieved the best recognition performance on temporal and frequency combined features in both valence and arousal dimensions, which is 3.58% higher than the performance of the best traditional BT classifier in valence dimension and 3.29% higher than that of BT classifier in arousal dimension.","['Electroencephalography', 'Feature extraction', 'Brain modeling', 'Emotion recognition', 'Frequency-domain analysis', 'Videos', 'Convolutional neural networks']","['EEG', 'emotion recognition', 'convolution neural network', 'combined features', 'deep learning']"
"Different automated decision support systems based on artificial neural network (ANN) have been widely proposed for the detection of heart disease in previous studies. However, most of these techniques focus on the preprocessing of features only. In this paper, we focus on both, i.e., refinement of features and elimination of the problems posed by the predictive model, i.e., the problems of underfitting and overfitting. By avoiding the model from overfitting and underfitting, it can show good performance on both the datasets, i.e., training data and testing data. Inappropriate network configuration and irrelevant features often result in overfitting the training data. To eliminate irrelevant features, we propose to use $\chi ^{2}$ statistical model while the optimally configured deep neural network (DNN) is searched by using exhaustive search strategy. The strength of the proposed hybrid model named $\chi ^{2}$ -DNN is evaluated by comparing its performance with conventional ANN and DNN models, another state of the art machine learning models and previously reported methods for heart disease prediction. The proposed model achieves the prediction accuracy of 93.33%. The obtained results are promising compared to the previously reported methods. The findings of the study suggest that the proposed diagnostic system can be used by physicians to accurately predict heart disease.","['Heart', 'Diseases', 'Neural networks', 'Training data', 'Neurons', 'Predictive models', 'Data models']","['Deep neural network', 'heart disease', 'hyperparameters optimization', 'overfitting', 'underfitting']"
"Bayesian optimisation is a statistical method that efficiently models and optimises expensive “black-box” functions. This review considers the application of Bayesian optimisation to experimental design, in comparison to existing Design of Experiments (DOE) methods. Solutions are surveyed for a range of core issues in experimental design including: the incorporation of prior knowledge, high dimensional optimisation, constraints, batch evaluation, multiple objectives, multi-fidelity data, and mixed variable types.","['Optimization', 'Adaptation models', 'Bayes methods', 'Metals', 'Gaussian processes', 'Computational modeling', 'Uncertainty']","['Bayesian methods', 'design for experiments', 'design optimization', 'machine learning algorithms']"
"With the development of network-enabled sensors and artificial intelligence algorithms, various human-centered smart systems are proposed to provide services with higher quality, such as smart healthcare, affective interaction, and autonomous driving. Considering cognitive computing is an indispensable technology to develop these smart systems, this paper proposes human-centered computing assisted by cognitive computing and cloud computing. First, we provide a comprehensive investigation of cognitive computing, including its evolution from knowledge discovery, cognitive science, and big data. Then, the system architecture of cognitive computing is proposed, which consists of three critical technologies, i.e., networking (e.g., Internet of Things), analytics (e.g., reinforcement learning and deep learning), and cloud computing. Finally, it describes the representative applications of human-centered cognitive computing, including robot technology, emotional communication system, and medical cognitive system.","['Cognitive systems', 'Big Data', 'Cognition', 'Cloud computing', 'Cognitive science', 'Cyberspace', 'Human computer interaction']","['Cognitive computing', 'big data analysis', 'Internet of Things', 'cloud computing']"
"Blockchain technology has a wide range of applications in the fields of finance, credit reporting and intellectual property, etc. As the core of blockchain, consensus algorithm affects the security and performance of blockchain system directly. In the past 10 years, there have been about 30 consensus algorithms such as Proof of Work (PoW), Proof of Stake (PoS), Delegated Proof of Stake (DPoS), Ripple Protocol Consensus Algorithm (RPCA) and AlgoRand. But their security, stability and operating efficiency still lag far behind our actual needs. This paper introduces the computing power competition of PoW into DPoS to design an improved consensus algorithm named Delegated Proof of Stake with Downgrade (DDPoS). Through the further modification, the impact of both computing resources and stakes on generating blocks is reduced to achieve higher efficiency, fairness, and decentralization in consensus process. Then a downgrade mechanism is proposed to quickly replace the malicious nodes to improve the security. The simulation experiments in blockchain system show that the proposed consensus algorithm is significantly more efficient than PoW and PoS, but slightly lower than DPoS. However, its degree of centralization remains far below that of DPoS. And through the downgrade mechanism, the proposed consensus algorithm can detect and downgrade the malicious nodes timely to ensure the security and good operation of system.","['Blockchain', 'Consensus algorithm', 'Peer-to-peer computing', 'Protocols', 'Contracts', 'Bitcoin']","['Blockchain', 'consensus algorithm', 'delegated proof of stake with downgrade', 'downgrade mechanism', 'efficiency', 'fairness', 'decentralization']"
"Medical expert systems are part of the portable and smart healthcare monitoring devices used in day-to-day life. Arrhythmic beat classification is mainly used in electrocardiogram (ECG) abnormality detection for identifying heart related problems. In this paper, ECG signal preprocessing and support vector machine-based arrhythmic beat classification are performed to categorize into normal and abnormal subjects. In ECG signal preprocessing, a delayed error normalized LMS adaptive filter is used to achieve high speed and low latency design with less computational elements. Since the signal processing technique is developed for remote healthcare systems, white noise removal is mainly focused. Discrete wavelet transform is applied on the preprocessed signal for HRV feature extraction and machine learning techniques are used for performing arrhythmic beat classification. In this paper, SVM classifier and other popular classifiers have been used on noise removed feature extracted signal for beat classification. Results indicate that the performance of SVM classifier is better than other machine learning-based classifiers.","['Electrocardiography', 'Feature extraction', 'Adaptive filters', 'Heart rate variability', 'IIR filters', 'Support vector machines']","['Adaptive filter', 'arrhythmic beat classification', 'ECG preprocessing', 'SVM classifier', 'machine learning']"
"The 2019 novel coronavirus (2019-nCoV) outbreak has been treated as a Public Health Emergency of International Concern by the World Health Organization. This work made an early prediction of the 2019-nCoV outbreak in China based on a simple mathematical model and limited epidemiological data. Combing characteristics of the historical epidemic, we found part of the released data is unreasonable. Through ruling out the unreasonable data, the model predictions exhibit that the number of the cumulative 2019-nCoV cases may reach 76,000 to 230,000, with a peak of the unrecovered infectives (22,000-74,000) occurring in late February to early March. After that, the infected cases will rapidly monotonically decrease until early May to late June, when the 2019-nCoV outbreak will fade out. Strong anti-epidemic may reduce the cumulative infected cases by 40%-49%. The improvement of medical care can also lead to about one-half transmission decrease and effectively shorten the duration of the 2019-nCoV.","['Mathematical model', 'Statistics', 'Predictive models', 'Viruses (medical)', 'Urban areas', 'Diseases', 'China']","['Epidemic transmission', 'infection rate', 'mathematical model', 'novel coronavirus', 'prediction', 'removal rate']"
"Emotion is intrinsic to humans and consequently, emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data on platforms such as Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential applications in health-care systems (as a tool for psychological analysis), education (understanding student frustration), and more. In Addition, ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user’s emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However, it is a difficult problem to solve because of several research challenges. In this paper, we discuss these challenges and shed light on recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC.","['Emotion recognition', 'Task analysis', 'Context modeling', 'Taxonomy', 'Natural language processing', 'Pragmatics']","['Emotion recognition', 'sentiment analysis', 'dialogue systems', 'natural language processing']"
"Electricity is the commonest commodity for most businesses in our world today. The use of electricity has been a breakthrough for the discovery of new technologies and has become the main driving force behind several innovations. With the introduction of smart grid systems, there have been improvements in how utility companies interact with their customers with regards to electricity use. However, since the readings are done via the Internet, there is the tendency for the data to be compromised when it gets into the hands of the wrong people. Moreover, customers mostly do not know why they pay huge amounts and which appliances use more electricity, since they are not privy to the readings. The sovereign blockchain technology, which provides transparency and provenance, is utilized in this paper to mitigate these above mentioned problems. A smart contract, which executes laid down procedures to provide a trust-based system between participants on the network is also implemented. Our system proves very efficient as the user can monitor how the electricity is used, and it also provides a platform where there is no manipulation from either party.","['Smart grids', 'Contracts', 'Companies', 'Public key', 'Monitoring']","['Sovereign blockchain', 'smart meter', 'smart grid network', 'electricity', 'event']"
"Mental stress has become a social issue and could become a cause of functional disability during routine work. In addition, chronic stress could implicate several psychophysiological disorders. For example, stress increases the likelihood of depression, stroke, heart attack, and cardiac arrest. The latest neuroscience reveals that the human brain is the primary target of mental stress, because the perception of the human brain determines a situation that is threatening and stressful. In this context, an objective measure for identifying the levels of stress while considering the human brain could considerably improve the associated harmful effects. Therefore, in this paper, a machine learning (ML) framework involving electroencephalogram (EEG) signal analysis of stressed participants is proposed. In the experimental setting, stress was induced by adopting a well-known experimental paradigm based on the montreal imaging stress task. The induction of stress was validated by the task performance and subjective feedback. The proposed ML framework involved EEG feature extraction, feature selection (receiver operating characteristic curve, t-test and the Bhattacharya distance), classification (logistic regression, support vector machine and naïve Bayes classifiers) and tenfold cross validation. The results showed that the proposed framework produced 94.6% accuracy for two-level identification of stress and 83.4% accuracy for multiple level identification. In conclusion, the proposed EEG-based ML framework has the potential to quantify stress objectively into multiple levels. The proposed method could help in developing a computer-aided diagnostic tool for stress detection.","['Stress', 'Electroencephalography', 'Feature extraction', 'Support vector machines', 'Cardiac arrest', 'Object recognition', 'Psychology']","['Absolute power', 'amplitude asymmetry', 'coherence', 'EEG', 'machine learning', 'mental stress levels', 'phase lag', 'relative power', 'support vector machine', 't-test']"
"Methods to overcome metal artifacts in computed tomography (CT) images have been researched and developed for nearly 40 years. When X-rays pass through a metal object, depending on its size and density, different physical effects will negatively affect the measurements, most notably beam hardening, scatter, noise, and the non-linear partial volume effect. These phenomena severely degrade image quality and hinder the diagnostic power and treatment outcomes in many clinical applications. In this paper, we first review the fundamental causes of metal artifacts, categorize metal object types, and present recent trends in the CT metal artifact reduction (MAR) literature. To improve image quality and recover information about underlying structures, many methods and correction algorithms have been proposed and tested. We comprehensively review and categorize these methods into six different classes of MAR: metal implant optimization, improvements to the data acquisition process, data correction based on physics models, modifications to the reconstruction algorithm (projection completion and iterative reconstruction), and image-based post-processing. The primary goals of this paper are to identify the strengths and limitations of individual MAR methods and overall classes, and establish a relationship between types of metal objects and the classes that most effectively overcome their artifacts. The main challenges for the field of MAR continue to be cases with large, dense metal implants, as well as cases with multiple metal objects in the field of view. Severe photon starvation is difficult to compensate for with only software corrections. Hence, the future of MAR seems to be headed toward a combined approach of improving the acquisition process with dual-energy CT, higher energy X-rays, or photon-counting detectors, along with advanced reconstruction approaches. Additional outlooks are addressed, including the need for a standardized evaluation system to compare MAR methods.","['Metal objects', 'Computed tomography', 'X-rays', 'Image quality', 'Image reconstruction']","['Biomedical imaging', 'computed tomography', 'radiation therapy', 'reconstruction algorithms', 'metal artifact reduction']"
"State-of-charge (SOC), which indicates the remaining capacity at the current cycle, is the key to the driving range prediction of electric vehicles and optimal charge control of rechargeable batteries. In this paper, we propose a combined convolutional neural network (CNN) - long short-term memory (LSTM) network to infer battery SOC from measurable data, such as current, voltage, and temperature. The proposed network shares the merits of both CNN and LSTM networks and can extract both spatial and temporal features from input data. The proposed network is trained using data collected from different discharge profiles, including a dynamic stress test, federal urban driving schedule, and US06 test. The performance of the proposed network is evaluated using data collected from a new combined dynamic loading profile in terms of estimation accuracy and robustness against the unknown initial state. The experimental results show that the proposed CNN-LSTM network well captures the nonlinear relationships between SOC and measurable variables and presents better tracking performance than the LSTM and CNN networks. In case of unknown initial SOCs, the proposed network fast converges to true SOC and, then, presents smooth and accurate results, with maximum mean average error under 1% and maximum root mean square error under 2%. Moreover, the proposed network well learns the influence of ambient temperature and can estimate battery SOC under varying temperatures with maximum mean average error under 1.5% and maximum root mean square error under 2%.","['Batteries', 'State of charge', 'Voltage measurement', 'Estimation', 'Temperature measurement', 'Current measurement', 'Battery charge measurement']","['State-of-charge estimation', 'long short-term memory', 'convolutional neural network', 'lithium-ion batteries']"
"With the exponential rise in the number of devices, the Internet of Things (IoT) is geared toward edge-centric computing to offer high bandwidth, low latency, and improved connectivity. In contrast, legacy cloud-centric platforms offer deteriorated bandwidth and connectivity that affect the quality of service. Edge-centric Internet of Things-based technologies, such as fog and mist computing, offer distributed and decentralized solutions to resolve the drawbacks of cloud-centric models. However, to foster distributed edge-centric models, a decentralized consensus system is necessary to incentivize all participants to share their edge resources. This paper is motivated by the shortage of comprehensive reviews on decentralized consensus systems for edge-centric Internet of Things that elucidates myriad of consensus facets, such as data structure, scalable consensus ledgers, and transaction models. Decentralized consensus systems adopt either blockchain or blockchainless directed acyclic graph technologies, which serve as immutable public ledgers for transactions. This paper scrutinizes the pros and cons of state-of-the-art decentralized consensus systems. With an extensive literature review and categorization based on existing decentralized consensus systems, we propose a thematic taxonomy. The pivotal features and characteristics associated with existing decentralized consensus systems are analyzed via a comprehensive qualitative investigation. The commonalities and variances among these systems are analyzed using key criteria derived from the presented literature. Finally, several open research issues on decentralized consensus for edge-centric IoT are presented, which should be highlighted regarding centralization risk and deficiencies in blockchain/blockchainless solutions.","['Cloud computing', 'Edge computing', 'Taxonomy', 'Data structures', 'Internet of Things', 'Electronic mail']","['Blockchain', 'decentralized consensus systems', 'directed acyclic graph', 'edge-centric Internet of Things']"
"In this paper, we propose an eight-port/four-resonator slot antenna array with a dual-polarized function for multiple-input-multiple-output (MIMO) 5G mobile terminals. The design is composed of four dual-polarized square-ring slot radiators fed by pairs of microstrip-line structures. The radiation elements are designed to operate at 3.6 GHz and are located on the corners of the smartphone PCB. The square-ring slot radiators provide good dual-polarization characteristic with similar performances in terms of fundamental radiation characteristics. In order to improve the isolation and also reduce the mutual coupling characteristic between the adjunct microstrip-line feeding ports of the dual-polarized radiators, a pair of circular-ring/open-ended parasitic structures is embedded across each square-ring slot radiator. The -10-dB impedance bandwidth of each antenna-element is 3.4-3.8 GHz. However, for -6-dB impedance bandwidth, this value is 600 MHz (3.3-3.9 GHz). The proposed MIMO antenna offers good S-parameters, high-gain radiation patterns, and sufficient total efficiencies, even though it is arranged on a high-loss FR-4 dielectric. The SAR function and the radiation characteristics of the proposed design in the vicinity of user-hand/user-head are studied. A prototype of the proposed smartphone antenna is fabricated, and good measurements are provided. The antenna provides good features with a potential application for use in the 5G mobile terminals.","['Slot antennas', 'Microstrip antennas', 'Antenna measurements', 'MIMO communication', 'Antenna radiation patterns', '5G mobile communication']","['5G', 'dual-polarized antenna', 'MIMO system', 'mobile terminal', 'ring slot antenna']"
"Traditional feature extraction methods are used to extract the features of signal to construct the fault feature matrix, which exists the complex structure, higher correlation, and redundancy. This will increase the complex fault classification and seriously affect the accuracy and efficiency of fault identification. In order to solve these problems, a new fault diagnosis (PABSFD) method based on the principal component analysis (PCA) and the broad learning system (BLS) is proposed for rotor system in this paper. In the proposed PABSFD method, the PCA with revealing the signal essence is used to reduce the dimension of the constructed feature matrix and decrease the linear feature correlation between data and eliminate the redundant attributes in order to obtain the low-dimensional feature matrix with retaining the essential features for the classification model. Then, the BLS with low time complexity and high classification accuracy is regarded as a classification model to realize the fault identification; it can efficiently accomplish the fault classification of rotor system. Finally, the actual vibration data of rotor system are selected to test and verify the effectiveness of the PABSFD method. The experimental results show that the PCA method can effectively eliminate the feature correlation and realize the dimension reduction of the feature matrix, the BLS can take on better adaptability, faster computation speed, and higher classification accuracy, and the PABSFD method can efficiently and accurately obtain the fault diagnosis results.","['Fault diagnosis', 'Principal component analysis', 'Feature extraction', 'Rotors', 'Dimensionality reduction', 'Covariance matrices', 'Correlation']","['Rotor system', 'fault diagnosis', 'principal component analysis (PCA)', 'broad learning system (BLS)', 'dimension reduction']"
"A systematic and comprehensive review of security and privacy-preserving challenges in e-health solutions indicates various privacy preserving approaches to ensure privacy and security of electronic health records (EHRs) in the cloud. This paper highlights the research challenges and directions concerning cyber security to build a comprehensive security model for EHR. We carry an intensive study in the IEEE, Science Direct, Google Scholar, PubMed, and ACM for papers on EHR approach published between 2000 and 2018 and summarized them in terms of the architecture types as well as evaluation strategies. We surveyed, investigated, and reviewed various aspects of several articles and identified the following tasks: 1) EHR security and privacy; 2) security and privacy requirements of e-health data in the cloud; 3) EHR cloud architecture, and; 4) diverse EHR cryptographic and non-cryptographic approaches. We also discuss some crucial issues and the ample opportunities for advanced research related to security and privacy of EHRs. Since big data provide a great mine of information and knowledge in e-Health applications, serious privacy and security challenges that require immediate attention exist. Studies must focus on efficient comprehensive security mechanisms for EHR and also explore techniques to maintain the integrity and confidentiality of patients' information.","['Security', 'Medical services', 'Data privacy', 'Privacy', 'Cloud computing', 'Servers', 'Electronic medical records']","['e-health', 'electronic health record', 'EHR cryptographic and non-cryptographic', 'security and privacy', 'systematic review']"
"The applications of compressive sensing (CS) in the field of information security have captured a great deal of researchers' attention in the past decade. To supply guidance for researchers from a comprehensive perspective, this paper, for the first time, reviews CS in information security field from two aspects: theoretical security and application security. Moreover, the CS applied in image cipher is one of the most widespread applications, as its characteristics of dimensional reduction and random projection can be utilized and integrated into image cryptosystems, which can achieve simultaneous compression and encryption of an image or multiple images. With respect to this application, the basic framework designs and the corresponding analyses are investigated. Specifically, the investigation proceeds from three aspects, namely, image ciphers based on chaos and CS, image ciphers based on optics and CS, and image ciphers based on chaos, optics, and CS. A total of six frameworks are put forward. Meanwhile, their analyses in terms of security, advantages, disadvantages, and so on are presented. At last, we attempt to indicate some other possible application research topics in future.","['Chaos theory', 'Information security', 'Compressed sensing', 'Ciphers', 'Optical fiber communication', 'Image processing', 'Computer security', 'Cryptography']","['Compressive sensing', 'theoretical security', 'application security', 'image cipher', 'chaos', 'optics']"
"Pervasive growth and usage of the Internet and mobile applications have expanded cyberspace. The cyberspace has become more vulnerable to automated and prolonged cyberattacks. Cyber security techniques provide enhancements in security measures to detect and react against cyberattacks. The previously used security systems are no longer sufficient because cybercriminals are smart enough to evade conventional security systems. Conventional security systems lack efficiency in detecting previously unseen and polymorphic security attacks. Machine learning (ML) techniques are playing a vital role in numerous applications of cyber security. However, despite the ongoing success, there are significant challenges in ensuring the trustworthiness of ML systems. There are incentivized malicious adversaries present in the cyberspace that are willing to game and exploit such ML vulnerabilities. This paper aims to provide a comprehensive overview of the challenges that ML techniques face in protecting cyberspace against attacks, by presenting a literature on ML techniques for cyber security including intrusion detection, spam detection, and malware detection on computer networks and mobile networks in the last decade. It also provides brief descriptions of each ML method, frequently used security datasets, essential ML tools, and evaluation metrics to evaluate a classification model. It finally discusses the challenges of using ML techniques in cyber security. This paper provides the latest extensive bibliography and the current trends of ML in cyber security.","['Computer crime', 'Machine learning', 'Internet', 'Deep learning', 'Market research', 'Malware', 'Intrusion detection']","['Cyber security', 'deep learning', 'intrusion detection', 'malware', 'machine learning', 'spam']"
"In this paper, online deep learning (DL)-based channel estimation algorithm for doubly selective fading channels is proposed by employing the deep neural network (DNN). With properly selected inputs, the DNN can not only exploit the features of channel variation from previous channel estimates but also extract additional features from pilots and received signals. Moreover, the DNN can take the advantages of the least squares estimation to further improve the performance of channel estimation. The DNN is first trained with simulated data in an off-line manner and then it could track the dynamic channel in an online manner. To reduce the performance degradation from random initialization, a pre-training approach is designed to refine the initial parameters of the DNN with several epochs of training. The proposed algorithm benefits from the excellent learning and generalization capability of DL and requires no prior knowledge about the channel statistics. Hence, it is more suitable for communication systems with modeling errors or non-stationary channels, such as high-mobility vehicular systems, underwater acoustic systems, and molecular communication systems. The numerical results show that the proposed DL-based algorithm outperforms the existing estimator in terms of both efficiency and robustness, especially when the channel statistics are time-varying.","['Channel estimation', 'Fading channels', 'OFDM', 'Indexes', 'Channel models', 'Training', 'Deep learning']","['Deep learning', 'neural networks', 'channel estimation', 'doubly selective channel', 'LS oriented input', 'pre-training']"
"Dempster-Shafer evidence theory is efficient to deal with uncertain information. One assumption of evidence theory is that the source of information should be independent when combined by Dempster's rule for evidence combination. However, the assumption does not coincide with the reality. A lot of works are done to solve the problem about the independence. The existing method based on the statistical parameter Pearson correlation coefficient discount is one of the feasible methods. However, the Pearson correlation coefficient is only used to characterize the linear correlation between the attributes of the normal distribution. In this paper, a new method is proposed, the Pearson correlation coefficient and Shearman correlation coefficient to generate the discounting factor. Taking the parametric statistic and nonparametric statistic into consideration, the proposed method is more efficient. The experiments on wine data set are illustrated to show the efficiency of our proposed method.","['Correlation', 'Magnesium', 'Gaussian distribution', 'Image color analysis', 'Manganese', 'Matrix converters', 'Parametric statistics']","['Dempster-Shafer theory', 'dependent evidence combination', 'Pearson coefficient', 'Shearman coefficient', 'total coefficient']"
"Fifth-generation (5G) telecommunication systems are expected to meet the world market demands of accessing and delivering services anywhere and anytime. The Non-Terrestrial Network (NTN) systems are able to satisfy the requests of anywhere and anytime connections by offering wide-area coverage and ensuring service availability, continuity, and scalability. In this work, we review the 3GPP NTN features and their potential for satisfying the user expectations in 5G & beyond networks. The state of the art, current 3GPP research activities, and open issues are summarized to highlight the importance of NTN over the wireless communication landscape. Future research directions are also identified to assess the role of NTN in 5G and beyond systems.","['5G mobile communication', 'Satellite broadcasting', 'Satellites', 'Earth', '3GPP', 'Planetary orbits']","['Non-terrestrial network', 'satellite communication', 'new radio', '5G system and beyond']"
"Applications of Blockchain (BC) technology and Cyber-Physical Systems (CPS) are increasing exponentially. However, framing resilient and correct smart contracts (SCs) for these smart application is a quite challenging task because of the complexity associated with them. SC is modernizing the traditional industrial, technical, and business processes. It is self-executable, self-verifiable, and embedded into the BC that eliminates the need for trusted third-party systems, which ultimately saves administration as well as service costs. It also improves system efficiency and reduces the associated security risks. However, SCs are well encouraging the new technological reforms in Industry 4.0, but still, various security and privacy challenges need to be addressed. In this paper, a survey on SC security vulnerabilities in the software code that can be easily hacked by a malicious user or may compromise the entire BC network is presented. As per the literature, the challenges related to SC security and privacy are not explored much by the authors around the world. From the existing proposals, it has been observed that designing a complex SCs cannot mitigate its privacy and security issues. So, this paper investigates various Artificial Intelligence (AI) techniques and tools for SC privacy protection. Then, open issues and challenges for AI-based SC are analyzed. Finally, a case study of retail marketing is presented, which uses AI and SC to preserve its security and privacy.","['Artificial intelligence', 'Privacy', 'Security', 'Smart contracts', 'Tools', 'Blockchain']","['Cyber-physical system', 'blockchain', 'smart contract', 'artificial intelligence', 'security', 'privacy']"
"Waveguide slot array antennas can have high gain, since the power distribution network (waveguide) has low loss, enabling a large aperture size. Rapid response to requirements for frequency, gain, and skew angle inspired a search for an alternative to conventional, commercial slot array acquisition. The solution to this requirement is high-resolution 3-D printing of modified slot arrays combined with metal plating. Modification of the structure included removal of wall material in regions where these openings would not cause radiation, opening the structure to enable metal plating while not affecting gain. A 3-D-printed slot array requires no further assembly, unlike conventional waveguide-based arrays that require soldering or brazing, block machining, or plate assembled, brazed structures. Stereolithography 3-D printing of plastic slot array antennas, modified to enable metal plating, has been used to produce a 30 dBi realized gain slot array at 21 GHz for under $1000 USD in a few weeks. Metal plated, 3-D printed plastic slot arrays are also very lightweight in comparison with conventional metal structures. Performance of 3-D printed, metal plated slot arrays has been shown to be identical to conventional metal structures at frequencies up to 22 GHz.","['Slat arrays', 'Waveguide arrays', 'Slot antennas', 'Power distribution', 'Antenna arrays', 'Three-dimensional printing', 'Metal structures']","['Slot arrays', 'waveguide arrays']"
"The security of image steganography is an important basis for evaluating steganography algorithms. Steganography has recently made great progress in the long-term confrontation with steganalysis. To improve the security of image steganography, steganography must have the ability to resist detection by steganalysis algorithms. Traditional embedding-based steganography embeds the secret information into the content of an image, which unavoidably leaves a trace of the modification that can be detected by increasingly advanced machine-learning-based steganalysis algorithms. The concept of steganography without embedding (SWE), which does not need to modify the data of the carrier image, appeared to overcome the detection of machine-learning-based steganalysis algorithms. In this paper, we propose a novel image SWE method based on deep convolutional generative adversarial networks. We map the secret information into a noise vector and use the trained generator neural network model to generate the carrier image based on the noise vector. No modification or embedding operations are required during the process of image generation, and the information contained in the image can be extracted successfully by another neural network, called the extractor, after training. The experimental results show that this method has the advantages of highly accurate information extraction and a strong ability to resist detection by state-of-the-art image steganalysis algorithms.","['Gallium nitride', 'Distortion', 'Brain modeling', 'Training', 'Digital images', 'Resists', 'Transform coding']","['Steganography', 'without embedding', 'coverless', 'generative adversarial networks']"
"Nowadays, a large amount of information has to be transmitted or processed. This implies high-power processing, large memory density, and increased energy consumption. In several applications, such as imaging, radar, speech recognition, and data acquisition, the signals involved can be considered sparse or compressive in some domain. The compressive sensing theory could be a proper candidate to deal with these constraints. It can be used to recover sparse or compressive signals with fewer measurements than the traditional methods. Two problems must be addressed by compressive sensing theory: design of the measurement matrix and development of an efficient sparse recovery algorithm. These algorithms are usually classified into three categories: convex relaxation, non-convex optimization techniques, and greedy algorithms. This paper intends to supply a comprehensive study and a state-of-the-art review of these algorithms to researchers who wish to develop and use them. Moreover, a wide range of compressive sensing theory applications is summarized and some open research challenges are presented.","['Matching pursuit algorithms', 'Compressed sensing', 'Sparse matrices', 'Signal processing algorithms', 'Estimation', 'Coherence', 'Sensors']","['Bayesian compressive sensing', 'compressive sensing', 'convex relaxation', 'greedy algorithms', 'sparse recovery algorithms', 'sparse signals']"
"In this study, a new technique is proposed to forecast short-term electrical load. Load forecasting is an integral part of power system planning and operation. Precise forecasting of load is essential for unit commitment, capacity planning, network augmentation and demand side management. Load forecasting can be generally categorized into three classes such as short-term, midterm and long-term. Short-term forecasting is usually done to predict load for next few hours to few weeks. In the literature, various methodologies such as regression analysis, machine learning approaches, deep learning methods and artificial intelligence systems have been used for short-term load forecasting. However, existing techniques may not always provide higher accuracy in short-term load forecasting. To overcome this challenge, a new approach is proposed in this paper for short-term load forecasting. The developed method is based on the integration of convolutional neural network (CNN) and long short-term memory (LSTM) network. The method is applied to Bangladesh power system to provide short-term forecasting of electrical load. Also, the effectiveness of the proposed technique is validated by comparing the forecasting errors with that of some existing approaches such as long short-term memory network, radial basis function network and extreme gradient boosting algorithm. It is found that the proposed strategy results in higher precision and accuracy in short-term load forecasting.","['Forecasting', 'Load forecasting', 'Computer architecture', 'Logic gates', 'Power systems', 'Load modeling', 'Time series analysis']","['Short-term load forecasting', 'convolutional neural network', 'long-short-term memory network', 'Bangladesh power system', 'evaluation metrics']"
"Blockchain is a revolutionary technology that is making a great impact on modern society due to its transparency, decentralization, and security properties. Blockchain gained considerable attention due to its very first application of Cryptocurrencies e.g., Bitcoin. In the near future, Blockchain technology is determined to transform the way we live, interact, and perform businesses. Recently, academics, industrialists, and researchers are aggressively investigating different aspects of Blockchain as an emerging technology. Unlike other Blockchain surveys focusing on either its applications, challenges, characteristics, or security, we present a comprehensive survey of Blockchain technology's evolution, architecture, development frameworks, and security issues. We also present a comparative analysis of frameworks, classification of consensus algorithms, and analysis of security risks & cryptographic primitives that have been used in the Blockchain so far. Finally, this paper elaborates on key future directions, novel use cases and open research challenges, which could be explored by researchers to make further advances in this field.","['Blockchain', 'Security', 'Cryptography', 'Smart contracts', 'Peer-to-peer computing', 'Consensus algorithm', 'Computer architecture']","['Evolution of blockchain', 'blockchain architecture', 'smart contracts', 'blockchain applications', 'development frameworks', 'blockchain security']"
"Having gained momentum from its promise of centralized control over distributed network architectures at bargain costs, software-defined Networking (SDN) is an ever-increasing topic of research. SDN offers a simplified means to dynamically control multiple simple switches via a single controller program, which contrasts with current network infrastructures where individual network operators manage network devices individually. Already, SDN has realized some extraordinary use cases outside of academia with companies, such as Google, AT&T, Microsoft, and many others. However, SDN still presents many research and operational challenges for government, industry, and campus networks. Because of these challenges, many SDN solutions have developed in an ad hoc manner that are not easily adopted by other organizations. Hence, this paper seeks to identify some of the many challenges where new and current researchers can still contribute to the advancement of SDN and further hasten its broadening adoption by network operators.","['Security', 'Government', 'Industries', 'Virtualization', 'Standards organizations', 'Centralized control']","['Software-defined networking (SDN)', 'network virtualization (NV)', 'network functions virtualization (NFV)', 'standards', 'SDN interfaces and APIs', 'data plane', 'middleboxes', 'SDN security', 'hybrid networks', 'software-defined exchange (SDX)', 'software-defined infrastructure (SDI)', 'software-defined wireless networks (SDWN)', 'Internet of Things (IoT)', 'information-centric networking (ICN)', 'cloud', 'software-defined RAN', '5G']"
"Recently, the advancement in communications, intelligent transportation systems, and computational systems has opened up new opportunities for intelligent traffic safety, comfort, and efficiency solutions. Artificial intelligence (AI) has been widely used to optimize traditional data-driven approaches in different areas of the scientific research. Vehicle-to-everything (V2X) system together with AI can acquire the information from diverse sources, can expand the driver's perception, and can predict to avoid potential accidents, thus enhancing the comfort, safety, and efficiency of the driving. This paper presents a comprehensive survey of the research works that have utilized AI to address various research challenges in V2X systems. We have summarized the contribution of these research works and categorized them according to the application domains. Finally, we present open problems and research challenges that need to be addressed for realizing the full potential of AI to advance V2X systems.","['Vehicle-to-everything', 'Particle swarm optimization', 'Long Term Evolution', 'Safety', 'Vehicular ad hoc networks', 'Autonomous vehicles']","['Artificial intelligence', 'machine learning', 'VANETs', 'V2X', 'predictions', 'platoon', 'VEC']"
"Augmented reality smart glasses (ARSG) are increasingly popular and have been identified as a vital technology supporting shop-floor operators in the smart factories of the future. By improving our knowledge of how to efficiently evaluate and select the ARSG for the shop-floor context, this paper aims to facilitate and accelerate the adoption of the ARSG by the manufacturing industry. The market for ARSG has exploded in recent years, and the large variety of products to select from makes it not only difficult but also time consuming to identify the best alternative. To address this problem, this paper presents an efficient step-by-step process for evaluating the ARSG, including concrete guidelines as to what parameters to consider and their recommended minimum values. Using the suggested evaluation process, manufacturing companies can quickly make optimal decisions about what products to implement on their shop floors. This paper demonstrates the evaluation process in practice, presenting a comprehensive review of currently available products along with a recommended best buy. This paper also identifies and discusses topics meriting research attention to ensure that the ARSG are successfully implemented on the industrial shop floor.","['Augmented reality', 'Glass', 'Production facilities', 'Guidelines', 'Companies', 'Optics']","['Augmented reality smart glasses', 'smart factory', 'augmented reality', 'industrial operator support']"
"Parkinson's Disease (PD) is a progressive neurodegenerative disease with multiple motor and non-motor characteristics. PD patients commonly face vocal impairments during the early stages of the disease. So, diagnosis systems based on vocal disorders are at the forefront on recent PD detection studies. Our study proposes two frameworks based on Convolutional Neural Networks to classify Parkinson's Disease (PD) using sets of vocal (speech) features. Although, both frameworks are employed for the combination of various feature sets, they have difference in terms of combining feature sets. While the first framework combines different feature sets before given to 9-layered CNN as inputs, whereas the second framework passes feature sets to the parallel input layers which are directly connected to convolution layers. Thus, deep features from each parallel branch are extracted simultaneously before combining in the merge layer. Proposed models are trained with dataset taken from UCI Machine Learning repository and their performances are validated with Leave-One-Person-Out Cross Validation (LOPO CV). Due to imbalanced class distribution in our data, F-Measure and Matthews Correlation Coefficient metrics are used for the assessment along with accuracy. Experimental results show that the second framework seems to be very promising, since it is able to learn deep features from each feature set via parallel convolution layers. Extracted deep features are not only successful at distinguishing PD patients from healthy individuals but also effective in boosting up the discriminative power of the classifiers.","['Feature extraction', 'Convolution', 'Deep learning', 'Support vector machines', 'Frequency measurement', ""Parkinson's disease""]","['Convolutional neural networks', 'deep learning', 'health informatics', 'Parkinson’s disease classification', 'vocal features']"
"Medical image analysis is currently experiencing a paradigm shift due to deep learning. This technology has recently attracted so much interest of the Medical Imaging Community that it led to a specialized conference in “Medical Imaging with Deep Learning” in the year 2018. This paper surveys the recent developments in this direction and provides a critical review of the related major aspects. We organize the reviewed literature according to the underlying pattern recognition tasks and further sub-categorize it following a taxonomy based on human anatomy. This paper does not assume prior knowledge of deep learning and makes a significant contribution in explaining the core deep learning concepts to the non-experts in the Medical Community. This paper provides a unique computer vision/machine learning perspective taken on the advances of deep learning in medical imaging. This enables us to single out “lack of appropriately annotated large-scale data sets” as the core challenge (among other challenges) in this research direction. We draw on the insights from the sister research fields of computer vision, pattern recognition, and machine learning, where the techniques of dealing with such challenges have already matured, to provide promising directions for the Medical Imaging Community to fully harness deep learning in the future.","['Biomedical imaging', 'Deep learning', 'Computational modeling', 'Task analysis', 'Computer vision', 'Data models']","['Deep learning', 'medical imaging', 'artificial neural networks', 'survey', 'tutorial', 'data sets']"
"Smartphones and smartwatches, which include powerful sensors, provide a readily available platform for implementing and deploying mobile motion-based behavioral biometrics. However, the few studies that utilize these commercial devices for motion-based biometrics are quite limited in terms of the sensors and physical activities that they evaluate. In many such studies, only the smartwatch accelerometer is utilized and only one physical activity, walking, is investigated. In this study we consider the accelerometer and gyroscope sensor on both the smartphone and smartwatch, and determine which combination of sensors performs best. Furthermore, eighteen diverse activities of daily living are evaluated for their biometric efficacy and, unlike most other studies, biometric identification is evaluated in addition to biometric authentication. The results presented in this article show that motion-based biometrics using smartphones and/or smartwatches yield good results, and that these results hold for the eighteen activities. This suggests that zero-effort continuous biometrics based on normal activities of daily living is feasible, and also demonstrates that certain easy-to-perform activities, such as clapping, may be a viable alternative (or supplement) to gait-based biometrics.","['Biometrics (access control)', 'Authentication', 'Accelerometers', 'Biological system modeling', 'Gyroscopes', 'Biosensors']","['Authentication', 'biometrics', 'data mining', 'gait recognition', 'identification', 'sensors', 'smartphone', 'smartwatch', 'ubiquitous computing']"
"Self-governing small regions of power systems, known as “microgrids”, are enabling the integration of small-scale renewable energy sources (RESs) while improving the reliability and energy efficiency of the electricity network. Microgrids can be primarily classified into three types based on their voltage characteristics and system architecture; 1) AC microgrids, 2) DC microgrids, and 3) Hybrid AC/DC microgrids. This paper presents a comprehensive review of stability, control, power management and fault ride-through (FRT) strategies for the AC, DC, and hybrid AC/DC microgrids. This paper also classifies microgrids in terms of their intended application and summarises the operation requirements stipulated in standards (e.g., IEEE Std. 1547-2018). The control strategies for each microgrid architecture are reviewed in terms of their operating principle and performance. In terms of the hybrid AC/DC microgrids, specific control aspects, such as mode transition and coordinated control between multiple interlinking converters (ILCs) and energy storage system (ESS) are analysed. A case study is also presented on the dynamic performance of a hybrid AC/DC microgrid under different control strategies and dynamic loads. Hybrid AC/DC microgrids shown to have more advantages in terms of economy and efficiency compared with the other microgrid architectures. This review shows that hierarchical control schemes, such as primary, secondary, and tertiary control are very popular among all three microgrid types. It is shown that the hybrid AC/DC microgrids require more complex control strategies for power management and control compared to AC or DC microgrids due to their dependency on the ILC controls and the operation mode of the hybrid AC/DC microgrid. Case study illustrated the significant effects of microgrid feeder characteristics on the dynamic performance of the hybrid AC/DC microgrid. It is also revealed that any transient conditions either in the AC or DC microgrids could propagate through the ILC affecting the entire microgrid dynamic performance. Additionally, the critical control issues and the future research challenges of microgrids are also discussed in this paper.","['Microgrids', 'Power system stability', 'Hybrid power systems', 'Voltage control', 'IEEE Standards', 'Reactive power', 'Stability criteria']","['Energy storage system (ESS)', 'hybrid AC/DC microgrid', 'IEEE Std. 1547-2018', 'interlinking converter (ILC)', 'microgrid stability', 'power management', 'renewable energy sources (RESs)']"
"As a major challenge and opportunity for traditional manufacturing, intelligent manufacturing is facing the needs of sustainable development in future. Sustainability assessment undoubtedly plays a pivotal role for future development of intelligent manufacturing. Aiming at this, the paper presents the digital twin driven information architecture of sustainability assessment oriented for dynamic evolution under the whole life cycle based on the classic digital twin mapping system. The sustainability assessment method segment of the architecture includes indicator system building, indicator value determination, indicator importance degree determination and intelligent manufacturing project assessing. A novel approach for treating the ambiguity of expert' judgment in indicator value determination by introducing trapezoidal fuzzy number into analytic hierarchy process is proposed, while the complexity of the influence relationship among the indicators is processed by the integration of complex networks modeling and PROMETHEE II for the indicator importance degree determination. A two-stage evidence combination model based on evidence theory is built for intelligent manufacturing project assessing lastly. The presented digital-twin-driven information architecture and the sustainability assessment method is tested and validated on a study of sustainability assessment of 8 intelligent manufacturing projects of an air conditioning enterprise. The results of the presented method were validated by comparing them with the results of the fuzzy and rough extension of the PROMETHEE II, TOPSIS and VIKOR methods, indicator importance degree determining method by entropy and indicator value determining method by accurate expert scoring.","['Sustainable development', 'Manufacturing', 'Production', 'Decision making', 'Physical layer', 'Technological innovation', 'Information architecture']","['Digital twin', 'sustainability', 'intelligent manufacturing', 'fuzzy number', 'analytic hierarchy process', 'complex networks', 'PROMETHEE II', 'evidence theory']"
"With the rapid evolution of network traffic diversity, the understanding of network traffic has become more pivotal and more formidable. Previously, traffic classification and intrusion detection require a burdensome analyzing of various traffic features and attack-related characteristics by experts, and even, private information might be required. However, due to the outdated features labeling and privacy protocols, the existing approaches may not fit with the characteristics of the changing network environment anymore. In this paper, we present a light-weight framework with the aid of deep learning for encrypted traffic classification and intrusion detection, termed as deep-full-range (DFR). Thanks to deep learning, DFR is able to learn from raw traffic without manual intervention and private information. In such a framework, our proposed algorithms are compared with other state-of-the-art methods using two public datasets. The experimental results show that our framework not only can outperform the state-of-the-art methods by averaging 13.49% on encrypted traffic classification’s F1 score and by averaging 12.15% on intrusion detection’s F1 score but also require much lesser storage resource requirement.","['Cryptography', 'Intrusion detection', 'Deep learning', 'Data preprocessing', 'Feature extraction', 'Privacy', 'Protocols']","['Encrypted traffic classification', 'network intrusion detection', 'deep learning', 'end-to-end']"
"A computer-aided diagnosis (CAD) system based on mammograms enables early breast cancer detection, diagnosis, and treatment. However, the accuracy of the existing CAD systems remains unsatisfactory. This paper explores a breast CAD method based on feature fusion with convolutional neural network (CNN) deep features. First, we propose a mass detection method based on CNN deep features and unsupervised extreme learning machine (ELM) clustering. Second, we build a feature set fusing deep features, morphological features, texture features, and density features. Third, an ELM classifier is developed using the fused feature set to classify benign and malignant breast masses. Extensive experiments demonstrate the accuracy and efficiency of our proposed mass detection and breast cancer classification method.","['Feature extraction', 'Mammography', 'Breast cancer', 'Breast tumors']","['Mass detection', 'computer-aided diagnosis', 'deep learning', 'fusion feature', 'extreme learning machine']"
"Identity-based cryptosystems mean that public keys can be directly derived from user identifiers, such as telephone numbers, email addresses, and social insurance number, and so on. So they can simplify key management procedures of certificate-based public key infrastructures and can be used to realize authentication in blockchain. Linearly homomorphic signature schemes allow to perform linear computations on authenticated data. And the correctness of the computation can be publicly verified. Although a series of homomorphic signature schemes have been designed recently, there are few homomorphic signature schemes designed in identity-based cryptography. In this paper, we construct a new ID-based linear homomorphic signature scheme, which avoids the shortcomings of the use of public-key certificates. The scheme is proved secure against existential forgery on adaptively chosen message and ID attack under the random oracle model. The ID-based linearly homomorphic signature schemes can be applied in e-business and cloud computing. Finally, we show how to apply it to realize authentication in blockchain.",[],[]
"Facial expression recognition (FER) is a significant task for the machines to understand the emotional changes in human beings. However, accurate hand-crafted features that are highly related to changes in expression are difficult to extract because of the influences of individual difference and variations in emotional intensity. Therefore, features that can accurately describe the changes in facial expressions are urgently required. Method: A weighted mixture deep neural network (WMDNN) is proposed to automatically extract the features that are effective for FER tasks. Several pre-processing approaches, such as face detection, rotation rectification, and data augmentation, are implemented to restrict the regions for FER. Two channels of facial images, including facial grayscale images and their corresponding local binary pattern (LBP) facial images, are processed by WMDNN. Expression-related features of facial grayscale images are extracted by fine-tuning a partial VGG16 network, the parameters of which are initialized using VGG16 model trained on ImageNet database. Features of LBP facial images are extracted by a shallow convolutional neural network (CNN) built based on DeepID. The outputs of both channels are fused in a weighted manner. The result of final recognition is calculated using softmax classification. Results: Experimental results indicate that the proposed algorithm can recognize six basic facial expressions (happiness, sadness, anger, disgust, fear, and surprise) with high accuracy. The average recognition accuracies for benchmarking data sets “CK+,”“JAFFE,”and “Oulu-CASIA”are 0.970, 0.922, and 0.923, respectively. Conclusions: The proposed FER method outperforms the state-of-the-art FER methods based on the hand-crafted features or deep networks using one channel. Compared with the deep networks that use multiple channels, our proposed network can achieve comparable performance with easier procedures. Fine-tuning is effective to FER tasks with a well pre-trained model if sufficient samples cannot be collected.","['Feature extraction', 'Face recognition', 'Image recognition', 'Face detection', 'Neural networks', 'Machine learning']","['Facial expression recognition', 'double channel facial images', 'deep neural network', 'weighted mixture', 'softmax classification']"
"To explore human emotions, in this paper, we design and build a multi-modal physiological emotion database, which collects four modal physiological signals, i.e., electroencephalogram (EEG), galvanic skin response, respiration, and electrocardiogram (ECG). To alleviate the influence of culture dependent elicitation materials and evoke desired human emotions, we specifically collect an emotion elicitation material database selected from more than 1500 video clips. By the considerable amount of strict man-made labeling, we elaborately choose 28 videos as standardized elicitation samples, which are assessed by psychological methods. The physiological signals of participants were synchronously recorded when they watched these standardized video clips that described six discrete emotions and neutral emotion. With three types of classification protocols, different feature extraction methods and classifiers (support vector machine and k-NearestNeighbor) were used to recognize the physiological responses of different emotions, which presented the baseline results. Simultaneously, we present a novel attention-long short-term memory (A-LSTM), which strengthens the effectiveness of useful sequences to extract more discriminative features. In addition, correlations between the EEG signals and the participants' ratings are investigated. The database has been made publicly available to encourage other researchers to use it to evaluate their own emotion estimation methods.","['Electroencephalography', 'Brain modeling', 'Physiology', 'Databases', 'Emotion recognition', 'Support vector machines', 'Feature extraction']","['Discrete emotion recognition', 'physiological signals', 'EEG', 'affective computing', 'machine learning', 'video-induced emotion', 'LSTM']"
"Chest X-ray film is the most widely used and common method of clinical examination for pulmonary nodules. However, the number of radiologists obviously cannot keep up with this outburst due to the sharp increase in the number of pulmonary diseases, which increases the rate of missed diagnosis and misdiagnosis. The method based on deep learning is the most appropriate way to deal with such problems so far. The main research in this paper was using inception-v3 transfer learning model to classify pulmonary images, and finally to get a practical and feasible computer-aided diagnostic model. The computer-aided diagnostic model could improve the accuracy and rapidity of doctors in the diagnosis of thoracic diseases. In this experiment, we augmented the data of pulmonary images, then used the fine-tuned Inception-v3 model based on transfer learning to extract features automatically, and used different classifiers (Softmax, Logistic, SVM) to classify the pulmonary images. Finally, it was compared with various models based on the original Deep Convolution Neural Network (DCNN) model. The experiment proved that the experiment based on transfer learning was meaningful for pulmonary image classification. The highest sensitivity and specificity are 95.41% and 80.09% respectively in the experiment, and the better pulmonary image classification performance was obtained than other methods.","['Feature extraction', 'Diseases', 'Medical diagnostic imaging', 'Image classification', 'Computational modeling', 'Convolutional neural networks']","['Pulmonary image', 'data augmentation', 'deep convolutional neural network', 'transfer learning', 'inception-v3']"
"A tri-polarized 12-antenna array working in the 3.5-GHz band (3.4-3.6 GHz) for future 5G (the fifth generation mobile communication) multiple-input multiple-output (MIMO) operations in the smartphone is presented. In order to reduce the mutual couplings and simplify the design process, orthogonal polarization technique is utilized. By combining a quarter mode substrate integrated wave-guide antenna and two open-end slots, a compact 3-antenna tri-polarization block operating in the 3.5-GHz band is achieved within a small volume of 17 × 17 × 6 mm 3 . Thanks to the orthogonal polarization features, the three antennas within the block are able to have good impedance matchings and low mutual couplings between antennas. By integrating four such tri-polarization blocks, a 12-antenna MIMO array is then designed for smartphone applications. It is also due to the tri-polarization feature, the proposed array could attain acceptable isolations and low correlations between antennas with only two additional decoupling structures. The proposed array is fabricated and tested, good antenna performances, such as return loss better than 10 dB, isolation higher than 12.5 dB, and antenna efficiencies higher than 50%, are obtained. The channel capacity of the 12-antenna array is calculated to be about 57 bps/Hz in a 12 × 12 MIMO system with 20-dB signal-to-noise ratio, which indicates the proposed array using tri-polarization technique is a good choice for future 5G terminals.","['Antenna arrays', 'MIMO', '5G mobile communication', 'Slot antennas', 'Substrates', 'Impedance matching']","['Smartphone antennas', 'MIMO antenna array', '5G communication', 'orthogonal polarization']"
"In distributed peer-to-peer (P2P) applications, peers self-organize and cooperate to effectively complete certain tasks such as forwarding files, delivering messages, or uploading data. Nevertheless, users are selfish in nature and they may refuse to cooperate due to their concerns on energy and bandwidth consumption. Thus each user should receive a satisfying reward to compensate its resource consumption for cooperation. However, suitable incentive mechanisms that can meet the diverse requirements of users in dynamic and distributed P2P environments are still missing. On the other hand, we observe that Blockchain is a decentralized secure digital ledger of economic transactions that can be programmed to record not just financial transactions and Blockchain-based cryptocurrencies get more and more market capitalization. Therefore in this paper, we propose a Blockchain based truthful incentive mechanism for distributed P2P applications that applies a cryptocurrency such as Bitcoin to incentivize users for cooperation. In this mechanism, users who help with a successful delivery get rewarded. As users and miners in the Blockchain P2P system may exhibit selfish actions or collude with each other, we propose a secure validation method and a pricing strategy, and integrate them into our incentive mechanism. Through a game theoretical analysis and evaluation study, we demonstrate the effectiveness and security strength of our proposed incentive mechanism.","['Pricing', 'Incentive schemes', 'Bitcoin', 'Data communication']","['Incentive mechanism', 'P2P applications', 'data transmissions', 'Bitcoin System', 'collusion attacks', 'pricing strategy']"
"Increasing use of renewable energy sources, liberalized energy markets and most importantly, the integrations of various monitoring, measuring and communication infrastructures into modern power system network offer the opportunity to build a resilient and efficient grid. However, it also brings about various threats of instabilities and security concerns in form of cyberattack, voltage instability, power quality (PQ) disturbance among others to the complex network. The need for efficient methodologies for quicker identification and detection of these problems have always been a priority to energy stakeholders over the years. In recent times, machine learning techniques (MLTs) have proven to be effective in numerous applications including power system studies. In the literature, various MLTs such as artificial neural networks (ANN), Decision Tree (DT), support vector machines (SVM) have been proposed, resulting in effective decision making and control actions in the secured and stable operations of the power system. Given this growing trend, this paper presents a comprehensive review on the most recent studies whereby MLTs were developed for power system security and stability especially in cyberattack detections, PQ disturbance studies and dynamic security assessment studies. The aim is to highlight the methodologies, achievements and more importantly the limitations in the classifier(s) design, dataset and test systems employed in the reviewed publications. A brief review of reinforcement learning (RL) and deep reinforcement learning (DRL) approaches to transient stability assessment is also presented. Finally, we highlighted some challenges and directions for future studies.","['Power system stability', 'Power system security', 'Stability criteria', 'Machine learning', 'Power quality']","['Classifiers', 'cyberattacks', 'deep reinforcement learning', 'intruder detection system', 'machine learning techniques', 'power quality disturbance', 'power system', 'reinforcement learning', 'test systems', 'transient stability assessment', 'voltage stability']"
"Plug-in hybrid electric vehicles (PHEVs) have emerged as an important tool in reducing greenhouse gas emissions, due to their lower dependency on fossil fuel. Since, for cost efficiency, PHEVs have a limited battery capacity, they must be recharged often and especially after trips. Thus, efficient battery charging plays an important role on the success of PHEVs commercial adoption. This paper surveys the state-of-the-art of existing PHEV battery charging schemes. We classify these schemes into four classes, namely, uncontrolled, indirectly controlled, smart, and bidirectional charging, and review various existing techniques within each class. For uncontrolled charging, existing studies focus on evaluating the impact of adding variable charging load on the smart grid. Various indirectly controlled charging schemes have been proposed to control energy prices, in order to indirectly influence the charging operations. Smart charging schemes can directly control a rich set of charging parameters to achieve various performance objectives, such as minimizing power loss, maximizing operator's profit, ensuring fairness, and so on. Finally, bidirectional charging allows a PHEV to discharge energy into smart grid, such that the vehicle can act as a mobile energy source to further stabilize the grid, which is partially supplied by intermittent renewable energy sources. This survey provides a comprehensive one-stop introductory reference to quickly learn about the key features and technical challenges, addressed by existing PHEV battery charging schemes in smart grid.","['Electric vehicles', 'Batteries', 'Smart grids', 'Plug-in hybrid electric vehicles', 'Global warming', 'Environmental factors', 'Fossill fuels', 'Discharges (electric)', 'Emissions', 'Greenhouse effect']","['Plug-in hybrid electric vehicles', 'uncontrolled charging', 'indirectly-controlled charging', 'smart charging', 'bidirectional charging', 'smart grid']"
"Cognitive radio technology is an important branch in the field of wireless communication, and automatic identification is a major part of cognitive radio technology. Convolutional neural network (CNN) is an advanced neural network, which is the forefront of application in the digital image recognition area. In this paper, we explore CNN in an automatic system to recognize the cognitive radio waveforms. Excitedly, it is a more effective model with high ratio of successful recognition (RSR) under high power background noise. The system can identify eight kinds of signals, including binary phase shift keying (Barker codes modulation) linear frequency modulation, Costas codes, Frank code, and polytime codes (T1, T2, T3, and T4). The recognition part includes a CNN classifier. First, we determine the appropriate architecture to make CNN effective for proposed system. Specifically, we focus on how many convolutional layers are needed, what appropriate number of hidden units is, and what the best pooling strategy is. Second, we research how to obtain the image features into CNN that based on Choi-Williams time-frequency distribution. Finally, by means of the simulations, the results of classification are demonstrated. Simulation results show the overall RSR is 93.7% when the signal-to-noise ratio is -2dB.","['Time-frequency analysis', 'Signal to noise ratio', 'Feature extraction', 'Convolution', 'Neural networks', 'Cognitive radio', 'Image recognition']","['Cognitive radio', 'radar countermeasures', 'waveform recognition', 'time-frequency distribution', 'convolutional neural network']"
"Remaining useful life (RUL) prediction of lithium-ion batteries can reduce the risk of battery failure by predicting the end of life. In this paper, we propose novel RUL prediction techniques based on long short-term memory (LSTM). To estimate RUL even in the presence of capacity regeneration phenomenon, we consider multiple measurable data from battery management system such as voltage, current and temperature charging profiles whose patterns vary as aging. Unlike the traditional LSTM prediction that matches input layer with output layer as one-to-one structure, we leverage many-to-one structure to be flexible for various input types and to substantially reduce the number of parameters for better generalization. Using the NASA lithium-ion battery datasets, we verify the accuracy of the proposed LSTM-based RUL prediction. The experimental results show that the proposed single-channel LSTM model improves the mean absolute percentage error (MAPE) by 39.2% compared to the baseline LSTM model. Furthermore, the proposed multi-channel LSTM model significantly improves the MAPE, e.g., by 63.7% compared to the baseline; the proposed model achieves 0.47-1.88% of MAPE while the state-of-the-art baseline LSTM shows 0.6-6.45% of MAPE.","['Batteries', 'Degradation', 'Logic gates', 'Battery charge measurement', 'Electrodes', 'Aging', 'NASA']","['Lithium-ion battery', 'long short-term memory', 'remaining useful life', 'capacity estimation']"
"With the fast expansion of renewable energy system installed capacity in recent years, the availability, stability, and quality of smart grids have become increasingly important. The renewable energy output forecasting applications have also been developing rapidly in recent years, and such techniques have particularly been applied in the fields of wind and solar photovoltaic (PV). In the case of solar PV output forecasting, many applications have been performed with machine learning and hybrid techniques. In this paper, we propose a high-precision deep neural network model named PVPNet to forecast PV system output power. The methodology behind the proposed model is based on deep neural networks, and the model is able to generate a 24-h probabilistic and deterministic forecasting of PV power output based on meteorological information, such as temperature, solar radiation, and historical PV system output data. The forecasting accuracy of PVPNet is determined by the mean absolute error (MAE) and root mean square error (RMSE) values. The results from the experiments show that the MAE and RMSE of the proposed algorithm are 109.4845 and 163.1513, respectively. The results prove that the prediction accuracy of the PVPNet outperforms other benchmark models, and the algorithm also effectively predicts complex time series with a high degree of volatility and irregularity.","['Forecasting', 'Predictive models', 'Power generation', 'Weather forecasting', 'Data models', 'Numerical models']","['Deep neural network', 'photovoltaic output power forecasting', 'photovoltaic system', 'renewable energy sources']"
"Photovoltaic embedded generation in low-voltage ac networks is quite popular; however, despite its benefits, there are some problems especially when photovoltaic (PV) penetration exceeds certain thresholds. Among others, voltage violation is of prime importance. Our review of the literature focused on PV penetration limits due to voltage violations in low-voltage (LV) networks. The review revealed that voltage violations can occur at a penetration level as low as 2.5% when a large distributed generator (DG) is installed at a single point. Alternatively, a LV network can host a large number of photovoltaic distributed generators (PVDGs), with a penetration level up to 110% if evenly distributed over shorter lengths. However, an LV network has no rules of thumb for safe penetration limits. Penetration-level calculations have been found that they used numerous approaches, which we have analyzed and discussed to adopt a more rational and unified approach. Our literature review revealed that, in LVs, a very high penetration level can be achieved as compared with medium-voltage (MV) networks. However, MV voltage-level control problems impose a limit for PV hosting in LV networks. There is a need to evolve strategies for robust voltage control at the MV level and to develop certain rules of thumb for PV penetration limits in LV networks independent of the MV level, to increase the PV hosting capacity.",[],[]
"Batteries are gaining entry into every home and office for they are widely used because of their variant benefits. However, these batteries are prone to failure caused by charge imbalance in the batteries connected in either series or parallel, which can sometimes be catastrophic and hence they require to be properly monitored in a real-time manner. There exist many battery balancing schemes which are broadly grouped into either passive or active schemes. All these schemes have their own advantages and disadvantages, and hence it is upon the user to decide on which scheme will best work for them. However, research has proven that the hybrid scheme will be the best as it couples the benefits of all schemes. This study will review the various battery cell balancing methodologies and evaluate their relationship with battery performance. At present there are a few studies tackling the mechanical vibration of battery balancing performance. This study shows that battery balancing performance during long-term should be evaluated from various temperature and vibration frequencies.","['Batteries', 'Heating systems', 'Resistance', 'Vibrations', 'Temperature measurement', 'Temperature', 'Integrated circuit modeling']","['Battery cell balancing', 'electric vehicles', 'hybrid schemes', 'and performance optimization']"
"Nowadays, heart disease is the leading cause of death worldwide. Predicting heart disease is a complex task since it requires experience along with advanced knowledge. Internet of Things (IoT) technology has lately been adopted in healthcare systems to collect sensor values for heart disease diagnosis and prediction. Many researchers have focused on the diagnosis of heart disease, yet the accuracy of the diagnosis results is low. To address this issue, an IoT framework is proposed to evaluate heart disease more accurately using a Modified Deep Convolutional Neural Network (MDCNN). The smartwatch and heart monitor device that is attached to the patient monitors the blood pressure and electrocardiogram (ECG). The MDCNN is utilized for classifying the received sensor data into normal and abnormal. The performance of the system is analyzed by comparing the proposed MDCNN with existing deep learning neural networks and logistic regression. The results demonstrate that the proposed MDCNN based heart disease prediction system performs better than other methods. The proposed method shows that for the maximum number of records, the MDCNN achieves an accuracy of 98.2 which is better than existing classifiers.","['Heart', 'Diseases', 'Biomedical monitoring', 'Cloud computing', 'Monitoring', 'Electrocardiography']","['AEHO', 'cuttlefish algorithm', 'MDCNN', 'IoT', 'Cleveland dataset', 'sensors', 'wearable device', 'CAGR', 'electrocardiogram', 'LSTM', 'CNN']"
"We propose automatic contrast-limited adaptive histogram equalization (CLAHE) for image contrast enhancement. We automatically set the clip point for CLAHE based on textureness of a block. Also, we introduce dual gamma correction into CLAHE to achieve contrast enhancement while preserving naturalness. First, we redistribute the histogram of the block in CLAHE based on the dynamic range of each block. Second, we perform dual gamma correction to enhance the luminance, especially in dark regions while reducing over-enhancement artifacts. Since automatic CLAHE adaptively enhances contrast in each block while boosting luminance, it is very effective in enhancing dark images and daylight ones with strong dark shadows. Moreover, automatic CLAHE is computationally efficient, i.e., more than 35 frames/s at 1024 × 682 resolution, due to the independent block processing for contrast enhancement. Experimental results demonstrate that automatic CLAHE with dual gamma correction achieves good performance in contrast enhancement and outperforms state-of-the-art methods in terms of visual quality and quantitative measures.","['Histograms', 'Dynamic range', 'Image enhancement', 'Interpolation', 'Visualization', 'Image segmentation', 'Transfer functions']","['CLAHE', 'luminance enhancement', 'contrast enhancement', 'gamma correction', 'dark image', 'over-enhancement']"
"Narrow body and wide body aircraft are responsible for more than 75% of aviation greenhouse gas (GHG) emission and aviation, itself, was responsible for about 2.5% of all GHG emissions in the United States in 2018. This situation becomes worse when considering a 4-5% annual growth in air travel. Electrified aircraft is clearly a promising solution to combat the GHG challenge; thus, the trend is to eliminate all but electrical forms of energy in aircraft power distribution systems. However, electrification adds tremendously to the complexity of aircraft electric power systems (EPS), which is dramatically changing in our journey from conventional aircraft to more electric aircraft (MEA) and all electric aircraft (AEA). In this article, we provide an in-depth discussion on MEA/AEA EPS: electric propulsion, distributed propulsion systems (DPS), EPS voltage levels, power supplies, and EPS architectures are discussed. Publications on power flow (PF) analysis and management of EPS are reviewed, and an initial schematic of a potential aircraft EPS with electric propulsion is proposed. In this regard, we also briefly review the components required for MEA/AEA EPS, including power electronics (PE) converters, electric machines, electrochemical energy units, circuit breakers (CBs), and wiring harness. A comprehensive review of each of the components mentioned above or other topics except for those related to steady state power flow in MEA/AEA EPS is out of this article's scope and should be found somewhere else. At the close of the paper, some challenges in the path towards AEA are presented. Unless the discussed challenges are satisfactorily addressed and solved, arriving at an AEA that can properly operate over commercial missions will not be possible.","['Aircraft', 'Aircraft propulsion', 'Aerospace electronics', 'Power systems', 'Circuit breakers', 'Atmospheric modeling']","['Aircraft electrification', 'all electric aircraft (AEA)', 'electric power system (EPS)', 'more electric aircraft (MEA)', 'power distribution system', 'steady state power flow analysis']"
"Healthcare data management has been gaining a lot of attention in recent years because of its high potential to provide more accurate and cost-efficient patient care. The traditional client-server and cloud-based healthcare data management systems suffer from the issues of single point of failure, data privacy, centralized data stewardship, and system vulnerability. The replication mechanism, and privacy and security features of blockchain have a promising future in the healthcare domain as they can solve some of the inherent issues of the health management system. However, most of the recent research works on blockchain in the healthcare domain have primarily focused on the permission-less Bitcoin network that suffers from drawbacks such as high energy consumption, limited scalability, and low transaction throughput. Consequently, there is a need for a scalable, fault-tolerant, secure, traceable and private blockchain to suit the requirements of the healthcare domain. We propose a lightweight blockchain architecture for the healthcare data management that reduces the computational and communication overhead compared to the Bitcoin network by dividing the network participants into clusters and maintaining one copy of the ledger per cluster. Our architecture introduces the use of canal, that allows secure and confidential transactions within a group of network participants. Furthermore, we propose a solution to avoid forking which is prevalent in the Bitcoin network. We demonstrate the effectiveness of our proposed architecture in providing security and privacy compared to the Bitcoin network by analyzing different threats and attacks. We also discuss how our proposed architecture addresses the identified threats. Our experimental results demonstrate that our proposed architecture generates 11 times lower network traffic compared to the Bitcoin network as the number of blocks increases. Our ledger update is 1.13 times faster. Our architecture shows a speedup of 67% in ledger update and 10 times lower network traffic when the number of nodes increases.","['Blockchain', 'Computer architecture', 'Medical diagnostic imaging', 'Hospitals', 'Bitcoin', 'Servers']","['Blockchain', 'consensus', 'decentralization', 'health information management', 'privacy', 'scalability']"
"Computed tomography (CT) is a popular medical imaging modality and enjoys wide clinical applications. At the same time, the X-ray radiation dose associated with CT scannings raises a public concern due to its potential risks to the patients. Over the past years, major efforts have been dedicated to the development of low-dose CT (LDCT) methods. However, the radiation dose reduction compromises the signal-to-noise ratio, leading to strong noise and artifacts that down-grade the CT image quality. In this paper, we propose a novel 3-D noise reduction method, called structurally sensitive multi-scale generative adversarial net, to improve the LDCT image quality. Specifically, we incorporate 3-D volumetric information to improve the image quality. Also, different loss functions for training denoising models are investigated. Experiments show that the proposed method can effectively preserve the structural and textural information in reference to the normal-dose CT images and significantly suppress noise and artifacts. Qualitative visual assessments by three experienced radiologists demonstrate that the proposed method retrieves more information and outperforms competing methods.","['Three-dimensional displays', 'Computed tomography', 'Noise reduction', 'Generators', 'Image quality', 'Loss measurement', 'Noise measurement']","['Machine leaning', 'low dose CT', 'image denoising', 'deep learning', 'loss function']"
"In this paper, we propose a home energy management system that employs load shifting strategy of demand side management to optimize the energy consumption patterns of a smart home. It aims to manage the load demand in an efficient way to minimize electricity cost and peak to average ratio while maintaining user comfort through coordination among home appliances. In order to meet the load demand of electricity consumers, we schedule the load in day-ahead and real-time basis. We propose a fitness criterion for proposed hybrid technique, which helps in balancing the load during ON-peak and OFF-peak hours. Moreover, for realtime rescheduling, we present the concept of coordination among home appliances. This helps the scheduler to optimally decide the ON/OFF status of appliances in order to reduce the waiting time of appliance. For this purpose, we formulate our real-time rescheduling problem as knapsack problem and solve it through dynamic programming. This paper also evaluates the behavior of the proposed technique for three pricing schemes including: time of use, real-time pricing, and critical peak pricing. Simulation results illustrate the significance of the proposed optimization technique with 95% confidence interval.","['Home appliances', 'Optimization', 'Real-time systems', 'Peak to average power ratio', 'Microorganisms', 'Schedules', 'Energy management']","['Smart homes', 'home automation', 'energy', 'multi-objective optimization', 'embedded systems', 'day-ahead and real-time scheduling', 'bacterial foraging optimization', 'genetic algorithm', 'coordination', 'hybrid technique']"
"Wireless sensor networks (WSNs) distribute hundreds to thousands of inexpensive microsensor nodes in their regions, and these nodes are important parts of Internet of Things (IoT). In WSN-assisted IoT, the nodes are resource constrained in many ways, such as storage resources, computing resources, energy resources, and so on. Robust routing protocols are required to maintain a long network lifetime and achieve higher energy utilization. In this paper, we propose a new energy-efficient centroid-based routing protocol (EECRP) for WSN-assisted IoT to improve the performance of the network. The proposed EECRP includes three key parts: a new distributed cluster formation technique that enables the self-organization of local nodes, a new series of algorithms for adapting clusters and rotating the cluster head based on the centroid position to evenly distribute the energy load among all sensor nodes, and a new mechanism to reduce the energy consumption for long-distance communications. In particular, the residual energy of nodes is considered in EECRP for calculating the centroid's position. Our simulation results indicate that EECRP performs better than LEACH, LEACH-C, and GEEC. In addition, EECRP is suitable for networks that require a long lifetime and whose base station (BS) is located in the network.","['Energy consumption', 'Wireless sensor networks', 'Routing protocols', 'Clustering algorithms', 'Energy resources', 'Heuristic algorithms']","['Internet of Things', 'wireless sensor networks', 'energy management', 'cluster']"
"Deep neural networks have demonstrated their effectiveness in most machine learning tasks, with intrusion detection included. Unfortunately, recent research found that deep neural networks are vulnerable to adversarial examples in the image classification domain, i.e., they leave some opportunities for an attacker to fool the networks into misclassification by introducing imperceptible changes to the original pixels in an image. The vulnerability raises some concerns in applying deep neural networks in security-critical areas, such as intrusion detection. In this paper, we investigate the performances of the state-of-the-art attack algorithms against deep learning-based intrusion detection on the NSL-KDD data set. The vulnerabilities of neural networks employed by the intrusion detection systems are experimentally validated. The roles of individual features in generating adversarial examples are explored. Based on our findings, the feasibility and applicability of the attack methodologies are discussed.","['Machine learning', 'Neural networks', 'Intrusion detection', 'Feature extraction', 'Perturbation methods', 'Measurement', 'Task analysis']","['Intrusion detection', 'neural networks', 'classification algorithms', 'data security']"
"Power grids are transforming into flexible, smart, and cooperative systems with greater dissemination of distributed energy resources, advanced metering infrastructure, and advanced communication technologies. Short-term electric load forecasting for individual residential customers plays a progressively crucial role in the operation and planning of future grids. Compared to the aggregated electrical load at the community level, the prediction of individual household electric loads is legitimately challenging because of the high uncertainty and volatility involved. Results from previous studies show that prediction using machine learning and deep learning models is far from accurate, and there is still room for improvement. We herein propose a deep learning framework based on a combination of a convolutional neural network (CNN) and long short-term memory (LSTM). The proposed hybrid CNN-LSTM model uses CNN layers for feature extraction from the input data with LSTM layers for sequence learning. The performance of our developed framework is comprehensively compared to state-of-the-art systems currently in use for short-term individual household electric load forecasting. The proposed model achieved significantly better results compared to other competing techniques. We evaluated our proposed model with the recently explored LSTM-based deep learning model on a publicly available electrical load data of individual household customers from the Smart Grid Smart City (SGSC) project. We obtained an average mean absolute percentage error (MAPE) of 40.38% for individual household electric load forecasts in comparison with the LSTM-based model that obtained an average MAPE of 44.06%. Furthermore, we evaluated the effectiveness of the proposed model on different time horizons (up to 3 h ahead). Compared to the recently developed LSTM-based model tested on the same dataset, we obtained 4.01%, 4.76%, and 5.98% improvement for one, two, and six look-forward time steps, respectively (with 2 lookback time steps). Additionally, we have performed clustering analysis based on the power consumption behavior of the energy users, which indicate that prediction accuracy could be improved by grouping and training the representative model using large amount of data. The results indicated that the proposed model outperforms the LSTM-based model for both 1 h ahead and 3 h ahead in forecasting individual household electric loads.","['Load modeling', 'Predictive models', 'Load forecasting', 'Forecasting', 'Machine learning', 'Data models', 'Energy consumption']","['CNN', 'deep learning framework', 'energy consumption', 'energy consumption forecasting', 'individual household', 'LSTM']"
"This paper explores the feasibility of social cooperation between prosumers within an energy network in establishing their sustainable participation in peer-to-peer (P2P) energy trading. In particular, a canonical coalition game (CCG) is utilized to propose a P2P energy trading scheme, in which a set of participating prosumers form a coalition group to trade their energy, if there is any, with one another. By exploring the concept of the core of the designed CCG framework, the mid-market rate is utilized as a pricing mechanism of the proposed P2P trading to confirm the stability of the coalition as well as to guarantee the benefit to the prosumers for forming the social coalition. This paper further introduces the motivational psychology models that are relevant to the proposed P2P scheme and it is shown that the outcomes of the proposed P2P energy trading scheme satisfy the discussed models. Consequently, it is proven that the proposed scheme is consumer-centric and has the potential to corroborate sustainable prosumer participation in P2P energy trading. Finally, some numerical examples are provided to demonstrate the beneficial properties of the proposed scheme.","['Microgrids', 'Peer-to-peer computing', 'Games', 'Biological system modeling', 'Power system stability', 'Australia', 'Psychology']","['Peer-to-peer trading', 'social cooperation', 'game theory', 'consumer-centric', 'motivational psychology']"
"Recent advances in hardware and telecommunications have enabled the development of low cost mobile devices equipped with a variety of sensors. As a result, new functionalities, empowered by emerging mobile platforms, allow millions of applications to take advantage of vast amounts of data. Following this trend, mobile health applications collect users health-related information to help them better comprehend their health status and to promote their overall wellbeing. Nevertheless, health-related information is by nature and by law deemed sensitive and, therefore, its adequate protection is of substantial importance. In this paper we provide an in-depth security and privacy analysis of some of the most popular freeware mobile health applications. We have performed both static and dynamic analysis of selected mobile health applications, along with tailored testing of each application's functionalities. Long term analyses of the life cycle of the reviewed apps and our general data protection regulation compliance auditing procedure are unique features of the present paper. Our findings reveal that the majority of the analyzed applications do not follow well-known practices and guidelines, not even legal restrictions imposed by contemporary data protection regulations, thus jeopardizing the privacy of millions of users.","['Security', 'Privacy', 'Mobile communication', 'Data protection', 'Law']","['Communication system security', 'mobile security', 'application security', 'data privacy']"
"Narrowband Internet of Things (NB-IoT) is a new narrow-band radio technology introduced in the Third Generation Partnership Project release 13 to the 5th generation evolution for providing low-power wide-area IoT. In NB-IoT systems, repeating transmission data or control signals has been considered as a promising approach for enhancing coverage. Considering the new feature of repetition, link adaptation for NB-IoT systems needs to be performed in 2-D, i.e., the modulation and coding scheme (MCS) and the repetition number. Therefore, existing link adaptation schemes without consideration of the repetition number are no longer applicable. In this paper, a novel uplink link adaptation scheme with the repetition number determination is proposed, which is composed of the inner loop link adaptation and the outer loop link adaptation, to guarantee transmission reliability and improve throughput of NB-IoT systems. In particular, the inner loop link adaptation is designed to cope with block error ratio variation by periodically adjusting the repetition number. The outer loop link adaptation coordinates the MCS level selection and the repetition number determination. Besides, key technologies of uplink scheduling, such as power control and transmission gap, are analyzed, and a simple single-tone scheduling scheme is proposed. Link-level simulations are performed to validate the performance of the proposed uplink link adaptation scheme. The results show that our proposed uplink link adaptation scheme for NB-IoT systems outperforms the repetition-dominated method and the straightforward method, particularly for good channel conditions and larger packet sizes. Specifically, it can save more than 14% of the active time and resource consumption compared with the repetition-dominated method and save more than 46% of the active time and resource consumption compared with the straightforward method.","['Uplink', 'Long Term Evolution', 'Narrowband', 'Downlink', 'Internet of Things', 'Wireless communication', '3GPP']","['Narrowband Internet of Things (NB-IoT)', 'coverage enhancement', 'low complexity', 'link adaptation']"
"In this paper, we propose a deep Recurrent Neural Networks (RNNs) based on Gated Recurrent Unit (GRU) in a bidirectional manner (BGRU) for human identification from electrocardiogram (ECG) based biometrics, a classification task which aims to identify a subject from a given time-series sequential data. Despite having a major issue in traditional RNN networks which they learn representations from previous time sequences, bidirectional is designed to learn the representations from future time steps which enables for better understanding of context, and eliminate ambiguity. Moreover, GRU cell in RNNs deploys an update gate and a reset gate in a hidden state layer which is computationally efficient than a usual LSTM network due to the reduction of gates. The experimental results suggest that our proposed BGRU model, the combination of RNN with GRU cell unit in bidirectional manner, achieved a high classification accuracy of 98.55%. Various neural network architectures with different parameters are also evaluated for different approaches, including one-dimensional Convolutional Neural Network (1D-CNN), and traditional RNNs with LSTM and GRU for non-fiducial approach. The proposed models were evaluated with two publicly available datasets: ECG-ID Database (ECGID) and MIT-BIH Arrhythmia Database (MITDB). This paper is expected to demonstrate the feasibility and effectiveness of applying various deep learning approaches to biometric identification and also evaluate the effect of network performance on classification accuracy according to the changes in percentage of training dataset.","['Logic gates', 'Electrocardiography', 'Recurrent neural networks', 'Biological system modeling', 'Feature extraction', 'Heart']","['1D-convolutional neural networks', 'bidriectional recurrent neural networks', 'biometrics classification', 'ECG signals', 'gated recurrent unit', 'user identification', 'signal processing']"
"Supervised intrusion detection system is a system that has the capability of learning from examples about the previous attacks to detect new attacks. Using artificial neural network (ANN)-based intrusion detection is promising for reducing the number of false negative or false positives, because ANN has the capability of learning from actual examples. In this paper, a developed learning model for fast learning network (FLN) based on particle swarm optimization (PSO) has been proposed and named as PSO-FLN. The model has been applied to the problem of intrusion detection and validated based on the famous dataset KDD99. Our developed model has been compared against a wide range of meta-heuristic algorithms for training extreme learning machine and FLN classifier. PSO-FLN has outperformed other learning approaches in the testing accuracy of the learning.","['Intrusion detection', 'Training', 'Computer hacking', 'Artificial intelligence', 'Artificial neural networks']","['Fast learning network', 'KDD Cup 99', 'intrusion detection system', 'particle swarm optimization']"
"Android applications are developing rapidly across the mobile ecosystem, but Android malware is also emerging in an endless stream. Many researchers have studied the problem of Android malware detection and have put forward theories and methods from different perspectives. Existing research suggests that machine learning is an effective and promising way to detect Android malware. Notwithstanding, there exist reviews that have surveyed different issues related to Android malware detection based on machine learning. We believe our work complements the previous reviews by surveying a wider range of aspects of the topic. This paper presents a comprehensive survey of Android malware detection approaches based on machine learning. We briefly introduce some background on Android applications, including the Android system architecture, security mechanisms, and classification of Android malware. Then, taking machine learning as the focus, we analyze and summarize the research status from key perspectives such as sample acquisition, data preprocessing, feature selection, machine learning models, algorithms, and the evaluation of detection effectiveness. Finally, we assess the future prospects for research into Android malware detection based on machine learning. This review will help academics gain a full picture of Android malware detection based on machine learning. It could then serve as a basis for subsequent researchers to start new work and help to guide research in the field more generally.","['Malware', 'Machine learning', 'Security', 'Feature extraction', 'Libraries', 'Kernel', 'Java']","['Android security', 'malware detection', 'machine learning', 'feature extraction', 'classifier evaluation']"
"Blockchain technology has been developed for more than ten years and has become a trend in various industries. As the oil and gas industry is gradually shifting toward intelligence and digitalization, many large oil and gas companies were working on blockchain technology in the past two years because of it can significantly improve the management level, efficiency, and data security of the oil and gas industry. This paper aims to let more people in the oil and gas industry understand the blockchain and lead more thinking about how to apply the blockchain technology. To the best of our knowledge, this is one of the earliest papers on the review of the blockchain system in the oil and gas industry. This paper first presents the relevant theories and core technologies of the blockchain, and then describes how the blockchain is applied to the oil and gas industry from four aspects: trading, management and decision making, supervision, and cyber security. Finally, the application status, the understanding level of the blockchain in the oil and gas industry, opportunities, challenges, and risks and development trends are analyzed. The main conclusions are as follows: 1) at present, Europe and Asia have the fastest pace of developing the application of blockchain in the oil and gas industry, but there are still few oil and gas blockchain projects in operation or testing worldwide; 2) nowadays, the understanding of blockchain in the oil and gas industry is not sufficiently enough, the application is still in the experimental stage, and the investment is not enough; and (3) blockchain can bring many opportunities to the oil and gas industry, such as reducing transaction costs and improving transparency and efficiency. However, since it is still in the early stage of the application, there are still many challenges, primarily technological, and regulatory and system transformation. The development of blockchains in the oil and gas industry will move toward hybrid blockchain architecture, multi-technology combination, cross-chain, hybrid consensus mechanisms, and more interdisciplinary professionals.","['Blockchain', 'Oils', 'Natural gas industry', 'Peer-to-peer computing', 'Natural gas', 'Security', 'Distributed databases']","['Blockchain', 'oil and gas industry', 'smart contract', 'oil and gas trade', 'track equipment', 'supervision']"
"Beyond energy, the growing number of defects in physical substrates is becoming another major constraint that affects the design of computing devices and systems. As the underlying semiconductor technologies are getting less and less reliable, the probability that some components of computing devices fail also increases, preventing designers from realizing the full potential benefits of on-chip exascale integration derived from near atomic scale feature dimensions. As the quest for performance confronts permanent and transient faults, device variation, and thermal issues, major breakthroughs in computing efficiency are expected to benefit from unconventional and new models of computation, such as brain-inspired computing. The challenge is then to find not only high-performance and energy-efficient, but also fault-tolerant computing solutions. Neural computing principles remain elusive, yet as source of a promising fault-tolerant computing paradigm. In the quest to fault tolerance can be translated into scalable and reliable computing systems, hardware design itself and/or to use circuits even with faults has further motivated research on neural networks, which are potentially capable of absorbing some degrees of vulnerability based on their natural properties. This paper presents a survey on fault tolerance in neural networks manly focusing on well-established passive techniques to exploit and improve, by design, such potential but limited intrinsic property in neural models, particularly for feedforward neural networks. First, fundamental concepts and background on fault tolerance are introduced. Then, we review fault types, models, and measures used to evaluate performance and provide a taxonomy of the main techniques to enhance the intrinsic properties of some neural models, based on the principles and mechanisms that they exploit to achieve fault tolerance passively. For completeness, we briefly review some representative works on active fault tolerance in neural networks. We present some key challenges that remain to be overcome and conclude with an outlook for this field.","['Fault tolerance', 'Fault tolerant systems', 'Circuit faults', 'Biological neural networks', 'Computational modeling', 'Transient analysis']","['Fault tolerance', 'neural networks', 'redundancy', 'fault masking', 'fault models', 'taxonomy']"
"Nowadays, there is an ever-increasing migration of people to urban areas. Health care service is one of the most challenging aspects that is greatly affected by the vast influx of people to city centers. Consequently, cities around the world are investing heavily in digital transformation in an effort to provide healthier ecosystems for people. In such a transformation, millions of homes are being equipped with smart devices (e.g., smart meters, sensors, and so on), which generate massive volumes of fine-grained and indexical data that can be analyzed to support smart city services. In this paper, we propose a model that utilizes smart home big data as a means of learning and discovering human activity patterns for health care applications. We propose the use of frequent pattern mining, cluster analysis, and prediction to measure and analyze energy usage changes sparked by occupants' behavior. Since people's habits are mostly identified by everyday routines, discovering these routines allows us to recognize anomalous activities that may indicate people's difficulties in taking care for themselves, such as not preparing food or not using a shower/bath. This paper addresses the need to analyze temporal energy consumption patterns at the appliance level, which is directly related to human activities. For the evaluation of the proposed mechanism, this paper uses the U.K. Domestic Appliance Level Electricity data set-time series data of power consumption collected from 2012 to 2015 with the time resolution of 6 s for five houses with 109 appliances from Southern England. The data from smart meters are recursively mined in the quantum/data slice of 24 h, and the results are maintained across successive mining exercises. The results of identifying human activity patterns from appliance usage are presented in detail in this paper along with the accuracy of shortand long-term predictions.","['Home appliances', 'Smart meters', 'Medical services', 'Data mining', 'Smart homes', 'Monitoring', 'Urban areas']","['Big data', 'smart cities', 'smart homes', 'health care applications', 'behavioral analytics', 'frequent pattern', 'cluster analysis', 'incremental data-mining', 'association rules', 'prediction']"
"In the present scenario, an energy efficiency has become a matter of prime importance for wireless networks. To meet the demands of an increased capacity, an improved data rate, and a better quality of the service of the next-generation networks, there is a need to adopt energy-efficient architectures. Along with these requirements, it is also our social responsibility to reduce the carbon footprint by reducing the power consumption in a wireless network. Hence, a green communication is an urgent need. In this paper, we have surveyed various techniques for the power optimization of the upcoming 5G networks. The primary focus is on the use of relays and small cells to improve the energy efficiency of the network. We have discussed the various scenarios of relaying for the next-generation networks. Along with this, the importance of simultaneous wireless power and information transfer, massive multiple input multiple output, and millimeter waves has been analyzed for 5G networks.","['Energy efficiency', 'Green communication', 'Microcell networks', 'Relays', 'Wireless networks', 'Power demand', 'Quality of service', '5G mobile communication']","['5G', 'C-RAN', 'Energy Efficiency', 'Green Communication', 'Relay', 'Small Cells', 'SWIPT']"
"The Internet of Things (IoT) depicts a bright future, where any devices having sensorial and computing capabilities can interact with each other. Among all existing technologies, the techniques for the fifth generation (5G) systems are the main driving force for the actualization of IoT concept. However, due to the heterogeneous environment in 5G networks and the broadcast nature of radio propagation, the security assurance against eavesdropping is a vital yet challenging task. In this paper, we focus on the transmission design for secure relay communications in IoT networks, where the communication is exposed to eavesdroppers with unknown number and locations. The randomize-and-forward relay strategy specially designed for secure multi-hop communications is employed in our transmission protocol. First, we consider a single-antenna scenario, where all the devices in the network are equipped with the single antenna. We derive the expression for the secrecy outage probability of the two-hop transmission. Following this, a secrecy-rate-maximization problem subject to a secrecy-outage-probability constraint is formulated. The optimal power allocation and codeword rate design are obtained. Furthermore, we generalize the above analyses to a more generic scenario, where the relay and eavesdroppers are equipped with multiple antennas. Numerical results show that the proper use of relay transmission can enhance the secrecy throughput and extend the secure coverage range.","['Radio propagation', 'Internet of things', '5G mobile communication', 'Antenna measurements', 'Sensors', 'Security', 'Resource management']","['Internet of Things (IoT)', 'physical layer security', 'relay transmission', 'resource allocation', 'stochastic geometry']"
"Epilepsy detection from electrical characteristics of EEG signals obtained from the brain of undergone subject is a challenge task for both research and neurologist due to the non-stationary and chaotic nature of EEG signals. As epileptic EEG signals contain huge fluctuating information about the functional behavior of the brain, it is hard to distinguish the fundamental dynamic, complex network of EEG signals without considering the strength among the nodes as they are connected with each other on the basis of these strengths. The prior research on natural visibility graph did not consider this issue in epileptic seizure, although it is a very important key point to have representative information from the signals. Hence, this paper aims to introduce a new idea for epilepsy detection using complex network statistical properties by measuring different strengths of the edges in natural visibility graph theory, which is considered as weight. Thus, the proposed method is named “weighted visibility graph”. In this proposed method, first, the epileptic EEG signals are transformed into complex network and then two important statistical properties of a network such as modularity and average weighted degree used for extracting the imperative characteristics from a network of EEG signals. After that, the extracted features are evaluated by two modern machine-learning classifiers such as, support vector machine with a different kernel function and k-nearest neighbor. The experimental results demonstrate that the combined effect of both features is valuable for network metrics to characterize the EEG time series signals in case of weighted complex network generating up to 100% classification accuracy.","['Epilepsy', 'Electroencephalography', 'Complex networks', 'Feature extraction', 'Support vector machines', 'Electric variables', 'Weight measurement']","['Average weighted degree', 'complex network', 'EEG', 'Epilepsy', 'KNN', 'modularity', 'SVM', 'visibility graph', 'weighted visibility graph']"
"In the era of big data, with the increasing number of audit data features, human-centered smart intrusion detection system performance is decreasing in training time and classification accuracy, and many support vector machine (SVM)-based intrusion detection algorithms have been widely used to identify an intrusion quickly and accurately. This paper proposes the FWP-SVM-genetic algorithm (GA) (feature selection, weight, and parameter optimization of support vector machine based on the genetic algorithm) based on the characteristics of the GA and the SVM algorithm. The algorithm first optimizes the crossover probability and mutation probability of GA according to the population evolution algebra and fitness value; then, it subsequently uses a feature selection method based on the genetic algorithm with an innovation in the fitness function that decreases the SVM error rate and increases the true positive rate. Finally, according to the optimal feature subset, the feature weights and parameters of SVM are simultaneously optimized. The simulation results show that the algorithm accelerates the algorithm convergence, increases the true positive rate, decreases the error rate, and shortens the classification time. Compared with other SVM-based intrusion detection algorithms, the detection rate is higher and the false positive and false negative rates are lower.","['Support vector machines', 'Sociology', 'Statistics', 'Feature extraction', 'Genetic algorithms', 'Intrusion detection', 'Biological cells']","['Genetic algorithm', 'intrusion detection', 'support vector machine']"
"The Internet of Things (IoT) has lately developed into an innovation for developing smart environments. Security and privacy are viewed as main problems in any technology's dependence on the IoT model. Privacy and security issues arise due to the different possible attacks caused by intruders. Thus, there is an essential need to develop an intrusion detection system for attack and anomaly identification in the IoT system. In this work, we have proposed a deep learning-based method Deep Belief Network (DBN) algorithm model for the intrusion detection system. Regarding the attacks and anomaly detection, the CICIDS 2017 dataset is utilized for the performance analysis of the present IDS model. The proposed method produced better results in all the parameters in relation to accuracy, recall, precision, F1-score, and detection rate. The proposed method has achieved 99.37% accuracy for normal class, 97.93% for Botnet class, 97.71% for Brute Force class, 96.67% for Dos/DDoS class, 96.37% for Infiltration class, 97.71% for Ports can class and 98.37% for Web attack, and these results were compared with various classifiers as shown in the results.","['Intrusion detection', 'Data models', 'Mathematical model', 'Training', 'Anomaly detection', 'Internet of Things']","['IoT', 'deep learning', 'anomaly detection', 'intrusion detection', 'DBN']"
"Differential permittivity sensors based on a pair of uncoupled microstrip lines, each one loaded with an open complementary split ring resonator (OCSRR), are proposed in this paper. The sensing principle is based on the measurement of the cross-mode insertion loss, very sensitive to asymmetric loading. Thus, by loading one of the OCSRRs with the reference sample, and the other one with the sample under test (SUT), the difference in the complex permittivity between both samples generates an asymmetry that gives rise to mode conversion. From the measurement of the cross-mode transmission coefficient, the dielectric properties of the SUT can be determined, provided those of the reference sample are well known. It is shown that by adding fluidic channels on top of the OCSRRs, the proposed sensor is useful for the measurement of the complex dielectric constant of liquids, and experimental results in mixtures of ethanol and deionized (DI) water and methanol in DI water, as a function of the ethanol/methanol content, are provided. Due to the high sensitivity of the proposed differential sensor to detect small perturbations (asymmetries), the structure is also of interest for the accurate measurement of solute concentrations in liquid solutions. In this paper, the structure is applied to monitor sodium content in aqueous solutions, and it is found that sodium concentrations as small as 0.25 g/L can be resolved.","['Sensors', 'Liquids', 'Dielectric measurement', 'Transmission line measurements', 'Resonators', 'Dielectrics', 'Permittivity']","['Microwave sensors', 'dielectric characterization', 'permittivity sensors', 'differential sensors', 'split ring resonators', 'microstrip technology']"
"Diabetic retinopathy (DR) is a major reason for the increased visual loss globally, and it became an important cause of visual impairment among people in 25-74 years of age. The DR significantly affects the economic status in society, particularly in healthcare systems. When timely treatment is provided to the DR patients, approximately 90% of patients can be saved from visual loss. Therefore, it becomes highly essential to classify the stages and severity of DR for the recommendation of required treatments. In this view, this paper introduces a new automated Hyperparameter Tuning Inception-v4 (HPTI-v4) model for the detection and classification of DR from color fundus images. At the preprocessing stage, the contrast level of the fundus image will be improved by the use of contrast limited adaptive histogram equalization (CLAHE) model. Then, the segmentation of the preprocessed image takes place utilizing a histogram-based segmentation model. Afterward, the HPTI-v4 model is applied to extract the required features from the segmented image and it subsequently undergoes classification by the use of a multilayer perceptron (MLP). A series of experiments take place on MESSIDOR (Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology) DR dataset to guarantee the goodness of the HPTI-v4 approach and the obtained results clearly exhibited the supremacy of the HPTI-v4 model over the compared methods in a significant way.","['Image segmentation', 'Diabetes', 'Tuning', 'Histograms', 'Feature extraction', 'Biomedical imaging', 'Deep learning']","['Diabetic retinopathy', 'image classification', 'hyperparameter', 'deep learning']"
"Conventional sensing methodologies for smart home are known to be labor-intensive and complicated for practical deployment. Thus, researchers are resorting to alternative sensing mechanisms. Wi-Fi is one of the key technologies that enable connectivity for smart home services. Apart from its primary use for communication, Wi-Fi signal has now been widely leveraged for various sensing tasks, such as gesture recognition and fall detection, due to its sensitivity to environmental dynamics. Building smart home based on Wi-Fi sensing is cost-effective, non-invasive, and enjoys convenient deployment. In this paper, we survey the recent advances in the smart home systems based on the Wi-Fi sensing, mainly in such areas as health monitoring, gesture recognition, contextual information acquisition, and authentication.","['Wireless fidelity', 'Smart homes', 'Monitoring', 'Intelligent sensors', 'Gesture recognition', 'Task analysis']","['IoT', 'smart home', 'WiFi sensing']"
"For fifth-generation wireless communication systems, network slicing has emerged as a key concept to meet the diverse requirements of various use cases. By slicing an infrastructure network into multiple dedicated logical networks, wireless networks can support a wide range of services. However, how to fast deploy the end-to-end slices is the main issue in a multi-domain wireless network infrastructure. In this paper, a mathematical model is used to construct network slice requests and map them to the infrastructure network. The mapping process consists of two steps: the placement of virtual network functions and the selection of link paths chaining them. To efficiently utilize the limited physical resources, we pay attention to the service-oriented deployment by offering different deployment policies for three typical slices: eMBB slices, mMTC slices, and uRLLC slices. Furthermore, we adopt complex network theory to obtain the topological information of slices and infrastructure network. With the topological information, we define a node importance metric to rank the nodes in node mapping. To evaluate the performance of deployment policy we proposed, extensive simulations have been conducted. The results have shown that our algorithm performed better in terms of resource efficiency and acceptance ratio. In addition, the average execute time of our algorithm is in a linear growth with the increase of infrastructure network size.","['Mathematical model', 'Network slicing', '5G mobile communication', 'Wireless networks', 'Heuristic algorithms', 'Complex networks']","['5G', 'network slicing', 'complex network theory', 'service-oriented deployment', 'end-to-end slices']"
"A terminal sliding mode control (SMC) method based on nonlinear disturbance observer is investigated to realize the speed and the current tracking control for the permanent magnet synchronous motor (PMSM) drive system in this paper. The proposed method adopts the speed-current single-loop control structure instead of the traditional cascade control in the vector control of the PMSM. First, considering the nonlinear and the coupling characteristic, a single-loop terminal sliding mode controller is designed for PMSM drive system through feedback linearization technology. This method can make the motor speed and current reach the reference value in finite time, which can realize the fast transient response. Although the SMC is less sensitive to parameter uncertainties and external disturbance, it may produce a large switching gain, which may cause the undesired chattering. Meanwhile, the SMC cannot keep the property of invariance in the presence of unmatched uncertainties. Then, a nonlinear disturbance observer is proposed to the estimate the lump disturbance, which is used in the feed-forward compensation control. Thus, a composite control scheme is developed for the PMSM drive system. The results show that the motor control system based on the proposed method has good speed and current tracking performance and strong robustness.","['Sliding mode control', 'Disturbance observers', 'Drives', 'Uncertainty', 'Robustness', 'Torque']","['PMSM drive', 'terminal sliding mode control', 'feedback linearization', 'nonlinear disturbance observer']"
"Multi-access edge computing (MEC) has recently been proposed to aid mobile end devices in providing compute- and data-intensive services with low latency. Growing service demands by the end devices may overwhelm MEC installations, while cost constraints limit the increases of the installed MEC computing and data storage capacities. At the same time, the ever increasing computation capabilities and storage capacities of mobile end devices are valuable resources that can be utilized to enhance the MEC. This article comprehensively surveys the topic area of device-enhanced MEC, i.e., mechanisms that jointly utilize the resources of the community of end devices and the installed MEC to provide services to end devices. We classify the device-enhanced MEC mechanisms into mechanisms for computation offloading and mechanisms for caching. We further subclassify the offloading and caching mechanisms according to the targeted performance goals, which include throughput maximization, latency minimization, energy conservation, utility maximization, and enhanced security. We identify the main limitations of the existing device-enhanced MEC mechanisms and outline future research directions.","['Device-to-device communication', 'Edge computing', 'Servers', 'Cloud computing', 'Wireless communication', 'Security', 'Communication system security']","['Caching', 'computation offloading', 'device-to-device (D2D) communication', 'mobile edge computing (MEC)']"
"To address the vast variety of user requirements, applications, and channel conditions, flexibility support is strongly highlighted for 5G radio access technologies (RATs). For this purpose, usage of multiple orthogonal frequency division multiplexing (OFDM) numerologies, i.e., different parameterization of OFDM-based subframes, within the same frame has been proposed in the third-generation partnership project discussions for 5G new radio. This concept will likely meet the current expectations in multiple service requirements to some extent. However, since the quantity of wireless devices, applications, and heterogeneity of user requirements will keep increasing toward the next decade, the sufficiency of the aforementioned flexibility consideration remains quite disputable for future services. Therefore, novel RATs facilitating much more flexibility are needed to address various technical challenges, e.g., power efficiency, massive connectivity, latency, spectral efficiency, robustness against channel dispersions, and so on. In this paper, we discuss the potential directions to achieve further flexibility in RATs beyond 5G, such as future releases of 5G and 6G. In this context, a framework for developing flexible waveform, numerology, and frame design strategies is proposed along with sample methods. We also discuss their potential role to handle various upper-level system issues, including the ones in orthogonal and nonorthogonal multiple accessing schemes and cellular networks. By doing so, we aim to contribute to the future vision of designing flexible RATs and to point out the possible research gaps in the related fields.","['Radio access technologies', 'OFDM', '5G mobile communication', 'Signal to noise ratio', 'Interference']","['5G', '6G', 'FBMC', 'multi-access communications', 'numerology', 'OFDM', 'radio access networks', 'waveform', 'wireless communications']"
"Mobile edge computing is a new cloud computing paradigm, which makes use of small-sized edge clouds to provide real-time services to users. These mobile edge-clouds (MECs) are located in close proximity to users, thus enabling users to seamlessly access applications running on MECs. Due to the co-existence of the core (centralized) cloud, users, and one or multiple layers of MECs, an important problem is to decide where (on which computational entity) to place different components of an application. This problem, known as the application or workload placement problem, is notoriously hard, and therefore, heuristic algorithms without performance guarantees are generally employed in common practice, which may unknowingly suffer from poor performance as compared with the optimal solution. In this paper, we address the application placement problem and focus on developing algorithms with provable performance bounds. We model the user application as an application graph and the physical computing system as a physical graph, with resource demands/availabilities annotated on these graphs. We first consider the placement of a linear application graph and propose an algorithm for finding its optimal solution. Using this result, we then generalize the formulation and obtain online approximation algorithms with polynomial-logarithmic (poly-log) competitive ratio for tree application graph placement. We jointly consider node and link assignment, and incorporate multiple types of computational resources at nodes.","['Cloud computing', 'Approximation algorithms', 'Databases', 'Mobile communication', 'Mobile handsets', 'Face recognition', 'Streaming media']","['Cloud computing', 'graph mapping', 'mobile edge-cloud (MEC)', 'online approximation algorithm', 'optimization theory']"
"As a crime of employing technical means to steal sensitive information of users, phishing is currently a critical threat facing the Internet, and losses due to phishing are growing steadily. Feature engineering is important in phishing website detection solutions, but the accuracy of detection critically depends on prior knowledge of features. Moreover, although features extracted from different dimensions are more comprehensive, a drawback is that extracting these features requires a large amount of time. To address these limitations, we propose a multidimensional feature phishing detection approach based on a fast detection method by using deep learning. In the first step, character sequence features of the given URL are extracted and used for quick classification by deep learning, and this step does not require third-party assistance or any prior knowledge about phishing. In the second step, we combine URL statistical features, webpage code features, webpage text features, and the quick classification result of deep learning into multidimensional features. The approach can reduce the detection time for setting a threshold. Testing on a dataset containing millions of phishing URLs and legitimate URLs, the accuracy reaches 98.99%, and the false positive rate is only 0.59%. By reasonably adjusting the threshold, the experimental results show that the detection efficiency can be improved.","['Phishing', 'Feature extraction', 'Uniform resource locators', 'Deep learning', 'Blacklisting', 'Internet']","['Phishing website detection', 'convolutional neural network', 'long short-term memory network', 'semantic feature', 'machine learning']"
"The usage and adoption of electric vehicles (EVs) have increased rapidly in the 21st century due to the shifting of the global energy demand away from fossil fuels. The market penetration of EVs brings new challenges to the usual operations of the power system. Uncontrolled EV charging impacts the local distribution grid in terms of its voltage profile, power loss, grid unbalance, and reduction of transformer life, as well as harmonic distortion. Multiple research studies have addressed these problems by proposing various EV charging control methods. This manuscript comprehensively reviews EV control charging strategies using real-world data. This review classifies the EV control charging strategies into scheduling, clustering, and forecasting strategies. The models of EV control charging strategies are highlighted to compare and evaluate the techniques used in EV charging, enabling the identification of the advantages and disadvantages of the different methods applied. A summary of the methods and techniques for these EV charging strategies is presented based on machine learning and probabilities approaches. This research paper indicates many factors and challenges in the development of EV charging control in next-generation smart grid applications and provides potential recommendations. A report on the guidelines for future studies on this research topic is provided to enhance the comparability of the various results and findings. Accordingly, all the highlighted insights of this paper serve to further the increasing effort towards the development of advanced EV charging methods and demand-side management (DSM) for future smart grid applications.","['Electric vehicle charging', 'Forecasting', 'Power system stability', 'Batteries', 'Stability analysis', 'Data models', 'Power grids']","['Electric vehicle charging', 'scheduling', 'clustering', 'forecasting', 'probabilities', 'machine learning']"
"In this paper, a forecasting algorithm is proposed to predict photovoltaic (PV) power generation using a long short term memory (LSTM) neural network (NN). A synthetic weather forecast is created for the targeted PV plant location by integrating the statistical knowledge of historical solar irradiance data with the publicly available type of sky forecast of the host city. To achieve this, a K-means algorithm is used to classify the historical irradiance data into dynamic type of sky groups that vary from hour to hour in the same season. In other words, the types of sky are defined for each hour uniquely using different levels of irradiance based on the hour of the day and the season. This can mitigate the performance limitations of using fixed type of sky categories by translating them into dynamic and numerical irradiance forecast using historical irradiance data. The proposed synthetic weather forecast is proved to embed the statistical features of the historical weather data, which results in a significant improvement in the forecasting accuracy. The performance of the proposed model is investigated using different intraday horizon lengths in different seasons. It is shown that using the synthetic irradiance forecast can achieve up to 33% improvement in accuracy in comparison to that when an hourly categorical type of sky forecast is used, and up to 44.6% in comparison to that when a daily type of sky forecast is used. This highlights the significance of utilizing the proposed synthetic forecast, and promote a more efficient utilization of the publicly available type of sky forecast to achieve a more reliable PV generation prediction. Moreover, the superiority of the LSTM NN with the proposed features is verified by investigating other machine learning engines, namely the recurrent neural network (RNN), the generalized regression neural network (GRNN) and the extreme learning machine (ELM).","['Weather forecasting', 'Forecasting', 'Predictive models', 'Time series analysis', 'Artificial neural networks']","['PV power forecasting', 'machine learning', 'LSTM', 'neural network', 'deep learning', 'synthetic weather forecast']"
"This paper sets up a framework for designing a massive multiple-input multiple-output (MIMO) testbed by investigating hardware (HW) and system-level requirements, such as processing complexity, duplexing mode, and frame structure. Taking these into account, a generic system and processing partitioning is proposed, which allows flexible scaling and processing distribution onto a multitude of physically separated devices. Based on the given HW constraints such as maximum number of links and maximum throughput for peer-to-peer interconnections combined with processing capabilities, the framework allows to evaluate modular HW components. To verify our design approach, we present the Lund University Massive MIMO testbed, which constitutes the first reconfigurable real-time HW platform for prototyping massive MIMO. Utilizing up to 100 base station antennas and more than 50 field programmable gate array, up to 12 user equipment are served on the same time/frequency resource using an LTE-like orthogonal frequency division multiplexing time-division duplex-based transmission scheme. Proof-of-concept tests with this system show that massive MIMO can simultaneously serve a multitude of users in a static indoor and static outdoor environment utilizing the same time/frequency resource.","['MIMO', 'Hardware', 'OFDM', 'Real-time systems', 'Calibration', 'Antennas', 'Channel estimation']","['5G', 'system design', 'testbed', 'outdoor measurement', 'indoor measurement', 'software-defined radio', 'TDD']"
"Cooperative Intelligent Transportation Systems, mainly represented by vehicular ad hoc networks (VANETs), are among the key components contributing to the Smart City and Smart World paradigms. Based on the continuous exchange of both periodic and event triggered messages, smart vehicles can enhance road safety, while also providing support for comfort applications. In addition to the different communication protocols, securing such communications and establishing a certain trustiness among vehicles are among the main challenges to address, since the presence of dishonest peers can lead to unwanted situations. To this end, existing security solutions are typically divided into two main categories, cryptography and trust, where trust appeared as a complement to cryptography on some specific adversary models and environments where the latter was not enough to mitigate all possible attacks. In this paper, we provide an adversary-oriented survey of the existing trust models for VANETs. We also show when trust is preferable to cryptography, and the opposite. In addition, we show how trust models are usually evaluated in VANET contexts, and finally, we point out some critical scenarios that existing trust models cannot handle, together with some possible solutions.","['Cryptography', 'Vehicular ad hoc networks', 'Vehicles', 'Privacy', 'Biological system modeling', 'Safety']","['VANETs', 'trust management', 'attacker models']"
"Recent deep learning based image editing methods have achieved promising results for removing object in an image but fail to generate plausible results for removing large objects of complex nature, especially in facial images. The objective of this work is to remove mask objects in facial images. This problem is challenging because (1) most of the time facial masks cover quite a large region of face that even extends beyond the actual face boundary below chin, and (2) facial image pairs with and without mask object do not exist for training. We break the problem into two stages: mask object detection and image completion of the removed mask region. The first stage of our model automatically produces binary segmentation for the mask region. Then, the second stage removes the mask and synthesizes the affected region with fine details while retaining the global coherency of face structure. For this, we have employed a GAN-based network using two discriminators where one discriminator helps learn the global structure of the face and then another discriminator comes in to focus learning on the deep missing region. To train our model in a supervised manner, we create a paired synthetic dataset using publicly available CelebA dataset and evaluated on real world images collected from the Internet. Our model outperforms others representative state-of-the-art approaches both qualitatively and quantitatively.","['Face', 'Gallium nitride', 'Object detection', 'Glass', 'Image edge detection', 'Deep learning', 'Training']","['Generative adversarial network', 'object removal', 'image editing']"
"Multilevel thresholding has got more attention in recent years with various successful applications. However, the implementation becomes more and more complex and time-consuming when the number of thresholds is high, and color images which contain more information are even worse. Therefore, this paper proposes an alternative hybrid algorithm for color image segmentation, the advantages of which lie in extracting the best features from the high performance of two algorithms and overcoming the limitations of each algorithm to some extent. Two techniques, Otsu's method, and Kapur's entropy, are used as fitness function to determine the segmentation threshold values. Harris hawks optimization (HHO) is a novel and general-purpose algorithm, and the hybridization of HHO is fulfilled by adding another powerful algorithm-differential evolution (DE), which is known as HHO-DE. More specifically, the whole population is divided into two equal subpopulations which will be assigned to HHO and DE algorithms, respectively. Then both algorithms operate in parallel to update the positions of each subpopulation during the iterative process. In order to fully demonstrate the superior performance of HHO-DE, the proposed method is compared with the seven state-of-the-art algorithms by an array of experiments on ten benchmark images. Meanwhile, five measures, including the average fitness values, standard deviation (STD), peak signal to noise ratio (PSNR), structure similarity index (SSIM), and feature similarity index (FSIM), are used to evaluate the performance of each algorithm. In addition, Wilcoxon's rank sum test for statistical analysis and the comparison with the super-pixel method are also conducted to verify the superiority of HHO-DE. The experimental results reveal that the proposed method significantly outperforms other algorithms. Hence, the HHO-DE algorithm is a remarkable and promising tool for multilevel thresholding color image segmentation.","['Image segmentation', 'Entropy', 'Color', 'Optimization', 'Feature extraction', 'Heuristic algorithms', 'Sociology']","['Image segmentation', 'hybrid algorithm', 'Harris hawks optimization', 'differential evolution', 'Kapur’s entropy', 'Otsu’s method']"
"The very last wireless network technology, created to increase the speed and the connections responsiveness, the Fifth-Generation Network (5G) can transmit a great volume of data. It uses wireless broadband connections to support specific end-users and businesses services. It is specifically useful for the Internet of Vehicles (IoV), guaranteeing fast connections and security. The 5G network technology can be used to support Vehicle-to-Everything (V2X) communications and applications on autonomous vehicles. It can enable information exchanges between vehicles and other infrastructures and people. It can also provide a more comfortable and safer environment and accurate traffic knowledge. The traffic ?ow can be improved, reducing pollution and accident rates. The cellular network can be associated with V2X as a communicating base to offer enhanced road safety and autonomous driving, and also to offer the IoV connections. This survey presents the 5G technology evolution, standards, and infrastructure associated with V2X ecosystem by IoV. In other words, it presents the IoV supported by 5G V2X communications, considering its architecture, applications and also the V2X features and protocols, as well as the modes, the evaluation and the technological support in such combination. The contribution of this paper is a systematized study about the interaction among these three contents: IoV, 5G, and V2X. Eighty four works were selected to present concepts, standards and to identify the ways to overcome challenges. This survey aims to guide the development of new 5G-V2X services and technologies dedicated to vehicle communications, and also to indicate future directions.","['5G mobile communication', 'Vehicle-to-everything', 'Sensors', 'Wireless communication', 'Autonomous vehicles', 'Cellular networks']","['IoV', 'connected vehicles', '5G networks', 'V2X communications']"
"In this paper, a random frequency diverse array-based directional modulation with artificial noise (RFDA-DM-AN) scheme is proposed to enhance physical layer security of wireless communications. Specifically, we first design the RFDA-DM-AN scheme by randomly allocating frequencies to transmit antennas, thereby achieving 2-D (i.e., angle and range) secure transmissions, and outperforming the state-of-the-art 1-D (i.e., angle) phase array (PA)-based DM scheme. Then we derive the closed-form expression of a lower bound on the ergodic secrecy capacity (ESC) of our RFDA-DM-AN scheme. Based on the theoretical lower bound derived, we further optimize the transmission power allocation between the useful signal and artificial noise (AN) in order to improve the ESC. Simulation results show that: (1) our RFDA-DM-AN scheme achieves a higher secrecy capacity than that of the PA-based DM scheme; (2) the lower bound derived is shown to approach the ESC as the number of transmit antennas N increases and precisely matches the ESC when N is sufficiently large; and (3) the proposed optimum power allocation achieves the highest ESC of all power allocations schemes in the RFDA-DM-AN.","['Radio spectrum management', 'Frequency diversity', 'Transmitting antennas', 'Network security', 'Physical layer', 'Resource management', 'Antenna arrays', 'Noise measurement', 'Power system reliability']","['Physical layer security', 'directional modulation', 'frequency diverse array', 'power allocation']"
"We propose a cognitive healthcare framework that adopts the Internet of Things (IoT)-cloud technologies. This framework uses smart sensors for communications and deep learning for intelligent decision-making within the smart city perspective. The cognitive and smart framework monitors patients' state in real time and provides accurate, timely, and high-quality healthcare services at low cost. To assess the feasibility of the proposed framework, we present the experimental results of an EEG pathology classification technique that uses deep learning. We employ a range of healthcare smart sensors, including an EEG smart sensor, to record and monitor multimodal healthcare data continuously. The EEG signals from patients are transmitted via smart IoT devices to the cloud, where they are processed and sent to a cognitive module. The system determines the state of the patient by monitoring sensor readings, such as facial expressions, speech, EEG, movements, and gestures. The real-time decision, based on which the future course of action is taken, is made by the cognitive module. When information is transmitted to the deep learning module, the EEG signals are classified as pathologic or normal. The patient state monitoring and the EEG processing results are shared with healthcare providers, who can then assess the patient's condition and provide emergency help if the patient is in a critical state. The proposed deep learning model achieves better accuracy than the state-of-the-art systems.","['Medical services', 'Electroencephalography', 'Monitoring', 'Smart cities', 'Pathology', 'Deep learning', 'Real-time systems']","['Cognitive', 'IoT-cloud', 'deep learning', 'smart healthcare', 'EEG']"
"The concept of smart home is widely favored, as it enhances the lifestyle of the residents involving multiple disciplines, i.e., lighting, security, and much more. As the smart home networks continue to grow in size and complexity, it is essential to address a handful among the myriads of challenges related to data loss due to the interference and efficient energy management. In this paper, we propose a smart home control system using a coordinator-based ZigBee networking. The working of the proposed system is three fold: smart interference control system controls the interference caused due to the co-existence of IEEE 802.11x-based wireless local area networks and wireless sensor networks; smart energy control system is developed to integrate sunlight with light source and optimizes the energy consumption of the household appliances by controlling the unnecessary energy demands; and smart management control system to efficiently control the operating time of the electronic appliances. The performance of the proposed smart home is testified through computer simulation. Simulation results show that the proposed smart home system is less affected by the interference and efficient in reducing the energy consumption of the appliances used in a smart home.","['Smart homes', 'Home automation', 'Energy management', 'Internet of things', 'ZigBee', 'Interference', 'Wireless LAN', 'IEEE 802.11x Standard']","['ZigBee', 'interference', 'IEEE 80211x', 'WLAN', 'smart home']"
"The long short-term memory (LSTM) model is one of the most commonly used vehicle trajectory predicting models. In this paper, we study two problems of the existing LSTM models for long-term trajectory prediction in dense traffic. First, the existing LSTM models cannot simultaneously describe the spatial interactions between different vehicles and the temporal relations between the trajectory time series. Thus, the existing models cannot accurately estimate the influence of the interactions in dense traffic. Second, the basic LSTM models often suffer from vanishing gradient problem and are, thus, hard to train for long time series. These two problems sometimes lead to large prediction errors in vehicle trajectory predicting. In this paper, we proposed a spatio-temporal LSTM-based trajectory prediction model (ST-LSTM) which includes two modifications. We embed spatial interactions into LSTM models to implicitly measure the interactions between neighboring vehicles. We also introduce shortcut connections between the inputs and the outputs of two consecutive LSTM layers to handle gradient vanishment. The proposed new model is evaluated on the I-80 and US-101 datasets. Results show that our new model has a higher trajectory predicting accuracy than one state-of-the-art model [maneuver-LSTM (M-LSTM)].","['Trajectory', 'Predictive models', 'Hidden Markov models', 'Time series analysis', 'Training', 'Brakes', 'Roads']","['Trajectory prediction', 'vehicle interactions', 'shortcut connection', 'long short-term memory (LSTM)']"
"In this paper, we strive to construct an efficient multi-hop network based on the sub-GHz low-power wide-area technology. Specifically, we investigate the combination of LoRa, a physical-layer standard that can provide several-kilometer outdoor coverage, and concurrent transmission (CT), a recently proposed multi-hop protocol that can significantly improve the network efficiency. The main contributions of this paper are threefold. 1) Since the CT enhances the network efficiency by allowing synchronized packet collisions, the performance of the physical-layer receiver under such packet collisions needs to be carefully examined to ensure the network reliability. We first extensively evaluate the LoRa receiver performance under CT to verify that LoRa is compatible to CT. Specifically, we find that, due to the time-domain and frequency-domain energy spreading effect, LoRa is robust to the packet collisions resulting from CT. 2) We further find the receiver performance under CT can be further improved by introducing timing offsets between the relaying packets. In view of this, we propose a timing delay insertion method, the offset-CT method, that adds random timing delay before the packets while preventing the timing offset from diverging over the multi-hop network. 3) We conduct proof-of-concept experiments to demonstrate the feasibility of CT-based LoRa multi-hop network and the performance improvement brought by the proposed offset-CT method.","['Receivers', 'Spread spectrum communication', 'Standards', 'Frequency shift keying', 'Timing', 'Protocols', 'Chirp']","['LoRa', 'concurrent transmission', 'multi-hop networks', 'mesh networks', 'communication networks', 'relay networks', 'ad hoc networks']"
"Non-orthogonal multiple access (NOMA) has been shown in the literature to have a better performance than OMA in terms of sum channel capacity; however, the capacity superiority of NOMA over OMA has been only proved for single antenna systems, and the proof for the capacity superiority of multiple-input multiple-output NOMA (MIMO-NOMA) over conventional MIMO-OMA has not been available yet. In this paper, we will provide our proof to demonstrate that the MIMO-NOMA is strictly better than MIMO-OMA in terms of sum channel capacity (except for the case where only one user is being communicated to), i.e., for any rate pair achieved by MIMO-OMA, there is a power split for which MIMO-NOMA can achieve rate pairs that are strictly larger. Based on this result, we prove that the MIMO-NOMA can also achieve a larger sum ergodic capacity than MIMO-OMA. Our analytical results are verified by simulations.","['NOMA', 'Performance evaluation', 'MIMO', 'Channel capacity', 'Analytical models']","['NOMA', 'OMA', 'MIMO', 'multiple access', 'capacity']"
"There is an immense need of a proof of delivery (PoD) of today's digital media and content, especially those that are subject to payment. Current PoD systems are mostly centralized and heavily dependent on a trusted third party (TTP) especially for payment. Such existing PoD systems often lack security, transparency, and visibility, and are not highly credible, as the TTP can be subject to failure, manipulation, corruption, compromise, and hacking. In this paper, we propose a decentralized PoD solution for PoD of digital assets. Our solution leverages key features of blockchain and Ethereum smart contracts to provide immutable and tamper-proof logs, accountability, and traceability. Ethereum smart contracts are used to orchestrate and govern all interactions and transactions including automatic payments in Ether cryptocurrency between customers, digital-content provider, and the file server hosting the digital content. All entities are incentivized to act honestly, and our solution has a mechanism to handle dispute if arisen among participants. The solution has an off-chain secure download phase involving the file server and customers. Moreover, our solution leverages the benefits of interplanetary file system to store the agreed upon terms and conditions between the smart contract actors. A security analysis of our proposed system has been provided. The full code of the smart contract has been publicly made available on Github.","['Servers', 'Media', 'Videos']","['Blockchain', 'Ethereum', 'smart contracts', 'proof of delivery', 'digital content']"
"In the past few years, the implementation of blockchain technology for various applications has been widely discussed in the research community and the industry. There are sufficient number of articles that discuss the possibility of applying blockchain technology in various areas, such as, healthcare, IoT, and business. However, in this article, we present a comparative analysis of core blockchain architecture, its fundamental concepts, and its applications in three major areas: the Internet-of-Things (IoT), healthcare, business and vehicular industry. For each area, we discuss in detail, challenges and solutions that have been proposed from the research community and industry. This research studies also presented the complete ecosystem of blockchain of all the papers we reviewed and summarized. Moreover, analysis is performed of various blockchain platforms, their consensus models, and applications. Finally, we discuss key aspects that are required for the widespread future adoption of blockchain technology in these major areas.","['Medical services', 'Industries', 'Ecosystems', 'Organizations']","['Blockchain', 'IoT blockchain', 'healthcare blockchain', 'permissioned blockchain', 'business blockchain']"
"Multilevel inverters are a new family of converters for dc-ac conversion for the medium and high voltage and power applications. In this paper, two new topologies for the staircase output voltage generations have been proposed with a lesser number of switch requirement. The first topology requires three dc voltage sources and ten switches to synthesize 15 levels across the load. The extension of the first topology has been proposed as the second topology, which consists of four dc voltage sources and 12 switches to achieve 25 levels at the output. Both topologies, apart from having lesser switch count, exhibit the merits in terms of reduced voltage stresses across the switches. In addition, a detailed comparative study of both topologies has been presented in this paper to demonstrate the features of the proposed topologies. Several experimental results have been included in this paper to validate the performances of the proposed topologies with different loading condition and dynamic changes in load and modulation indexes.","['Topology', 'Inverters', 'Switching converters', 'DC-AC power converters', 'Power electronics']","['Asymmetric', 'hybrid inverter', 'inverter topology', 'multilevel inverter', 'MLI', 'nearest level control', 'power electronics', 'single-phase inverter', 'reduce switch count']"
"Non-orthogonal multiple access (NOMA) is envisioned as a key technology to enhance the spectrum efficiency for 5G cellular networks. Meanwhile, ambient backscatter communication is a promising solution to the Internet of Things (IoT), due to its high spectrum efficiency and power efficiency. In this paper, we are interested in a symbiotic system of cellular and IoT networks and propose a backscatter-NOMA system, which incorporates a downlink NOMA system with a backscatter device (BD). In the proposed system, the base station (BS) transmits information to two cellular users according to the NOMA protocol, while a BD transmits its information over the BS signals to one cellular user using the passive radio technology. In particular, if the BS only serves the cellular user that decodes BD information, the backscatter-NOMA system turns into a symbiotic radio (SR) system. We derive the expressions of the outage probabilities and the ergodic rates and analyze the corresponding diversity orders and slopes for both backscatter-NOMA and SR systems. Finally, we provide the numerical results to verify the theoretical analysis and demonstrate the interrelationship between the cellular networks and the IoT networks.","['NOMA', 'Probability', 'Power system reliability', 'Backscatter', 'Signal to noise ratio', 'Interference', 'Symbiosis']","['Non-orthogonal multiple access (NOMA)', 'Internet-of-Things (IoT)', 'ambient backscatter communication (AmBC)', 'symbiotic radio (SR)', 'outage probability', 'ergodic rate']"
"Nowadays, coronavirus (COVID-19) is getting international attention due it considered as a life-threatened epidemic disease that hard to control the spread of infection around the world. Machine learning (ML) is one of intelligent technique that able to automatically predict the event with reasonable accuracy based on the experience and learning process. In the meantime, a rapid number of ML models have been proposed for predicate the cases of COVID-19. Thus, there is need for an evaluation and benchmarking of COVID-19 ML models which considered the main challenge of this study. Furthermore, there is no single study have addressed the problem of evaluation and benchmarking of COVID diagnosis models. However, this study proposed an intelligent methodology is to help the health organisations in the selection COVID-19 diagnosis system. The benchmarking and evaluation of diagnostic models for COVID-19 is not a trivial process. There are multiple criteria requires to evaluate and some of the criteria are conflicting with each other. Our study is formulated as a decision matrix (DM) that embedded mix of ten evaluation criteria and twelve diagnostic models for COVID-19. The multi-criteria decision-making (MCDM) method is employed to evaluate and benchmarking the different diagnostic models for COVID19 with respect to the evaluation criteria. An integrated MCDM method are proposed where TOPSIS applied for the benchmarking and ranking purpose while Entropy used to calculate the weights of criteria. The study results revealed that the benchmarking and selection problems associated with COVID19 diagnosis models can be effectively solved using the integration of Entropy and TOPSIS. The SVM (linear) classifier is selected as the best diagnosis model for COVID19 with the closeness coefficient value of 0.9899 for our case study data. Furthermore, the proposed methodology has solved the significant variance for each criterion in terms of ideal best and worst best value, beside issue when specific diagnosis models have same ideal best value.","['Benchmark testing', 'Medical diagnostic imaging', 'Reliability', 'Diagnostic radiography', 'Tools', 'COVID-19']","['COVID19 diagnostic', 'machine learning', 'benchmarking methodology', 'chest X-rays images', 'entropy', 'TOPSIS', 'multi-criteria decision-making']"
"The utilization of renewable energy sources (RESs) has become significant throughout the world, especially over the last two decades. Although high-level RESs penetration reduces negative environmental impact compared to conventional fossil fuel-based energy generation, control issues become more complex as the system inertia is significantly decreased due to the absence of conventional synchronous generators. Some other technical issues, high uncertainties, low fault ride through capability, high fault current, low generation reserve, and low power quality, arise due to RESs integration. Renewable energy like solar and wind are highly uncertain due to the intermittent nature of wind and sunlight. Cutting edge technologies including different control strategies, optimization techniques, energy storage devices, and fault current limiters are employed to handle those issues. This paper summarizes several challenges in the integration process of high-level RESs to the existing grid. The respective solutions to each challenge are presented and discussed. A comprehensive list of challenges and solutions, for both wind and solar energy integration cases, are well documented. Finally, the future recommendations are provided to solve the several problems of renewable energy integration which could be key research areas for the industry personnel and researchers.","['Renewable energy sources', 'Wind power generation', 'Frequency control', 'Synchronous generators', 'Uncertainty', 'Wind turbines']","['Renewable energy resources', 'solar and wind energy conversion', 'virtual inertia', 'fault ride through capability', 'fault current limiter', 'control of converter']"
"With the increasing demands on quality healthcare and the raising cost of care, pervasive healthcare is considered as a technological solutions to address the global health issues. In particular, the recent advances in Internet of Things have led to the development of Internet of Medical Things (IoMT). Although such low cost and pervasive sensing devices could potentially transform the current reactive care to preventative care, the security and privacy issues of such sensing system are often overlooked. As the medical devices capture and process very sensitive personal health data, the devices and their associated communications have to be very secured to protect the user's privacy. However, the miniaturized IoMT devices have very limited computation power and fairly limited security schemes can be implemented in such devices. In addition, with the widespread use of IoMT devices, managing and ensuring the security of IoMT systems are very challenging and which are the major issues hindering the adoption of IoMT for clinical applications. In this paper, the security and privacy challenges, requirements, threats, and future research directions in the domain of IoMT are reviewed providing a general overview of the state-of-the-art approaches.","['Medical services', 'Security', 'Privacy', 'Servers', 'Sensors', 'Medical devices', 'Routing protocols']","['Security', 'privacy', 'Internet of Medical Things', 'IoMT', 'mIoT', 'healthcare systems', 'survey']"
"Estimation of absolute temperature distributions is crucial for many thermal processes in the nonlinear distributed parameter systems, such as predicting the curing temperature distribution of the chip, the temperature distribution of the catalytic rod, and so on. In this work, a spatiotemporal model based on the Karhunen-Loève (KL) decomposition, the multilayer perceptron (MLP), and the long short-term memory (LSTM) network, named KL-MLP-LSTM, is developed for estimating temperature distributions with a three-step procedure. Firstly, the infinite-dimensional model is transformed into a finite-dimensional model, where the KL decomposition method is used for dimension reduction and spatial basis functions extraction. Secondly, a novel MLP-LSTM hybrid time series model is constructed to deal with the two inherently coupled nonlinearities. Finally, the spatiotemporal temperature distribution model can be reconstructed through spatiotemporal synthesis. The effectiveness of the proposed model is validated by the data from a snap curing oven thermal process. Satisfactory agreement between the results of the current model and the other well-established model shows that the KL-MLP-LSTM model is reliable for estimating the temperature distributions during the thermal process.","['Spatiotemporal phenomena', 'Mathematical model', 'Temperature distribution', 'Curing', 'Analytical models', 'Time series analysis', 'Data models']","['Spatiotemporal modeling', 'nonlinear distributed thermal processes', 'Karhunen-Loève decomposition', 'multilayer perceptron', 'long short-term memory']"
"This paper presents an optimised bidirectional Vehicle-to-Grid (V2G) operation, based on a fleet of Electric Vehicles (EVs) connected to a distributed power system, through a network of charging stations. The system is able to perform day-ahead scheduling of EV charging/discharging to reduce EV ownership charging cost through participating in frequency and voltage regulation services. The proposed system is able to respond to real-time EV usage data and identify the required changes that must be made to the day-ahead energy prediction, further optimising the use of EVs to support both voltage and frequency regulation. An optimisation strategy is established for V2G scheduling, addressing the initial battery State Of Charge (SOC), EV plug-in time, regulation prices, desired EV departure time, battery degradation cost and vehicle charging requirements. The effectiveness of the proposed system is demonstrated using a standardized IEEE 33-node distribution network integrating five EV charging stations. Two case studies have been undertaken to verify the contribution of this advanced energy supervision approach. Comprehensive simulation results clearly show an opportunity to provide frequency and voltage support while concurrently reducing EV charging costs, through the integration of V2G technology, especially during on-peak periods when the need for active and reactive power is high.","['Vehicle-to-grid', 'Regulation', 'Batteries', 'State of charge', 'Voltage control', 'Reactive power']","['Electric vehicle', 'vehicle-to-grid', 'battery degradation performance', 'frequency regulation service', 'voltage regulation service', 'charging cost', 'day-ahead scheduling', 'smart-grid']"
"Recently, the Internet of Things (IoT) concept has attracted a lot of attention due to its capability to translate our physical world into a digital cyber world with meaningful information. The IoT devices are smaller in size, sheer in number, contain less memory, use less energy, and have more computational capabilities. These scarce resources for IoT devices are powered by small operating systems (OSs) that are specially designed to support the IoT devices' diverse applications and operational requirements. These IoT OSs are responsible for managing the constrained resources of IoT devices efficiently and in a timely manner. In this paper, discussions on IoT devices and OS resource management are provided. In detail, the resource management mechanisms of the state-of-the-art IoT OSs, such as Contiki, TinyOS, and FreeRTOS, are investigated. The different dimensions of their resource management approaches (including process management, memory management, energy management, communication management, and file management) are studied, and their advantages and limitations are highlighted.","['Resource management', 'Protocols', 'Memory management', 'Sensors', 'Security', 'Energy efficiency', 'Internet of Things']","['Internet of Things', 'operating systems', 'resource management', 'Contiki', 'TinyOS', 'FreeRTOS']"
,"['Smart grids', 'Electric vehicle charging', 'Mathematical model', 'Batteries', 'Schedules']","['Electric vehicles', 'smart grids', 'blockchain technology', 'adaptive charging scheme']"
"The selection of variational mode decomposition (VMD) parameters usually adopts the empirical method, trial-and-error method, or single-objective optimization method. The above-mentioned method cannot achieve the global optimal effect. Therefore, a multi-objective particle swarm optimization (MOPSO) algorithm is proposed to optimize the parameters of VMD, and it is applied to the composite fault diagnosis of the gearbox. The specific steps are: first, symbol dynamic entropy (SDE) can effectively remove background noise, and use state mode probability and state transition to preserve fault information. Power spectral entropy (PSE) reflects the complexity of signal frequency composition. Therefore, the SDE and PSE are selected as fitness functions and then the Pareto frontier optimal solution set is obtained by the MOPSO algorithm. Finally, the optimal combination of VMD parameters (k, a) is obtained by normalization. The improved VMD is used to analyze the simulation signal and gearbox fault signal. The effectiveness of the proposed method is verified by comparing with the ensemble empirical mode decomposition (EEMD).","['Optimization', 'Fault diagnosis', 'Particle swarm optimization', 'Bandwidth', 'Entropy', 'Indexes', 'Convergence']","['Variational mode decomposition', 'multi-objective particle swarm', 'symbol dynamic entropy', 'power spectral entropy', 'fault diagnosis of the gearbox']"
"Predicting crop yield based on the environmental, soil, water and crop parameters has been a potential research topic. Deep-learning-based models are broadly used to extract significant crop features for prediction. Though these methods could resolve the yield prediction problem there exist the following inadequacies: Unable to create a direct non-linear or linear mapping between the raw data and crop yield values; and the performance of those models highly relies on the quality of the extracted features. Deep reinforcement learning provides direction and motivation for the aforementioned shortcomings. Combining the intelligence of reinforcement learning and deep learning, deep reinforcement learning builds a complete crop yield prediction framework that can map the raw data to the crop prediction values. The proposed work constructs a Deep Recurrent Q-Network model which is a Recurrent Neural Network deep learning algorithm over the Q-Learning reinforcement learning algorithm to forecast the crop yield. The sequentially stacked layers of Recurrent Neural network is fed by the data parameters. The Q- learning network constructs a crop yield prediction environment based on the input parameters. A linear layer maps the Recurrent Neural Network output values to the Q-values. The reinforcement learning agent incorporates a combination of parametric features with the threshold that assist in predicting crop yield. Finally, the agent receives an aggregate score for the actions performed by minimizing the error and maximizing the forecast accuracy. The proposed model efficiently predicts the crop yield outperforming existing models by preserving the original data distribution with an accuracy of 93.7%.","['Agriculture', 'Reinforcement learning', 'Predictive models', 'Deep learning', 'Machine learning algorithms', 'Feature extraction', 'Data models']","['Crop yield prediction', 'deep recurrent Q-network', 'deep reinforcement learning', 'intelligent agrarian application']"
"Vehicular networks are facing the challenges to support ubiquitous connections and high quality of service for numerous vehicles. To address these issues, mobile edge computing (MEC) is explored as a promising technology in vehicular networks by employing computing resources at the edge of vehicular wireless access networks. In this paper, we study the efficient task offloading schemes in vehicular edge computing networks. The vehicles perform the offloading time selection, communication, and computing resource allocations optimally, the mobility of vehicles and the maximum latency of tasks are considered. To minimize the system costs, including the costs of the required communication and computing resources, we first analyze the offloading schemes in the independent MEC servers scenario. The offloading tasks are processed by the MEC servers deployed at the access point (AP) independently. A mobility-aware task offloading scheme is proposed. Then, in the cooperative MEC servers scenario, the MEC servers can further offload the collected overloading tasks to the adjacent servers at the next AP on the vehicles’ moving direction. A location-based offloading scheme is proposed. In both scenarios, the tradeoffs between the task completed latency and the required communication and computation resources are mainly considered. Numerical results show that our proposed schemes can reduce the system costs efficiently, while the latency constraints are satisfied.","['Task analysis', 'Servers', 'Edge computing', 'Resource management', 'Computational modeling', '5G mobile communication', 'Roads']","['Vehicular network', 'edge computing', 'resource allocation', 'offloading', 'mobility']"
"A decision map contains complete and clear information about the image to be fused, and detecting the decision map is crucial to various image fusion issues, especially multi-focus image fusion. Nevertheless, in an attempt to obtain an approving image fusion effect, it is necessary and always difficult to obtain a decision map. In this paper, we address this problem with a novel image segmentation-based multi-focus image fusion algorithm, in which the task of detecting the decision map is treated as image segmentation between the focused and defocused regions in the source images. The proposed method achieves segmentation through a multi-scale convolutional neural network, which performs a multi-scale analysis on each input image to derive the respective feature maps on the region boundaries between the focused and defocused regions. The feature maps are then inter-fused to produce a fused feature map. Afterward, the fused map is post-processed using initial segmentation, morphological operation, and watershed to obtain the segmentation map/decision map. We illustrate that the decision map gained from the multi-scale convolutional neural network is trustworthy and that it can lead to high-quality fusion results. Experimental results evidently validate that the proposed algorithm can achieve an optimum fusion performance in light of both qualitative and quantitative evaluations.","['Image fusion', 'Image segmentation', 'Neural networks', 'Convolution', 'Transforms', 'Algorithm design and analysis', 'Morphological operations']","['Convolutional neural network', 'multi-focus image', 'decision map', 'image fusion']"
"Automatic assessing the location and extent of liver and liver tumor is critical for radiologists, diagnosis and the clinical process. In recent years, a large number of variants of U-Net based on Multi-scale feature fusion are proposed to improve the segmentation performance for medical image segmentation. Unlike the previous works which extract the context information of medical image via applying the multi-scale feature fusion, we propose a novel network named Multi-scale Attention Net (MA-Net) by introducing self-attention mechanism into our method to adaptively integrate local features with their global dependencies. The MA-Net can capture rich contextual dependencies based on the attention mechanism. We design two blocks: Position-wise Attention Block (PAB) and Multi-scale Fusion Attention Block (MFAB). The PAB is used to model the feature interdependencies in spatial dimensions, which capture the spatial dependencies between pixels in a global view. In addition, the MFAB is to capture the channel dependencies between any feature map by multi-scale semantic feature fusion. We evaluate our method on the dataset of MICCAI 2017 LiTS Challenge. The proposed method achieves better performance than other state-of-the-art methods. The Dice values of liver and tumors segmentation are 0.960 ± 0.03 and 0.749 ± 0.08 respectively.","['Image segmentation', 'Liver', 'Tumors', 'Semantics', 'Biomedical imaging', 'Feature extraction', 'Two dimensional displays']","['CT', 'liver tumor segmentation', 'deep learning', 'attention mechanism', 'context information']"
"As the number of inverters increases in the power grid, the stability of grid-tied inverters becomes an important concern for the power industry. In particular, a weak grid can lead to voltage fluctuations at the inverter terminals and consequently cause inverter instability. In this paper, impacts of circuit and control parameters on the stability of voltage source inverters are studied using a small-signal state-space model in the synchronously rotating dq-frame of reference. The full-order state-space model developed in this paper is directly extracted from the pulsewidth modulation switching pattern and enables the stability analysis of concurrent variations in the three-phase circuit and control parameters. This paper demonstrates that the full-order model of a grid-tied active (P) and reactive (Q) power (PQ)-controlled voltage source inverter (VSI) can be significantly reduced to a second-order model, preserving the overall system stability in the case of grid impedance variations. This paper also shows that a decrease in the grid inductance does not necessarily improve the stability of grid-tied VSIs. The system stability is a function of both the grid R/X ratio and grid inductance. Despite the grid-side inductor of the LCL filter is in series with the grid impedance, they have different impacts on the stability of a grid-tied PQ-controlled VSI, i.e., an increase in the filter inductance may improve the system stability in a weak grid. These findings are verified through simulated and experimentally obtained data.","['Power system stability', 'Circuit stability', 'Inverters', 'Stability criteria', 'State-space methods', 'Inductance']","['Grid-tied voltage-source inverter', 'weak grids', 'microgrids', 'active (P) and reactive (Q) power (PQ)-controlled inverters', 'stability analysis', 'reduced-order model']"
"This paper presents the design and the realization of broadband circularly polarized (CP) Fabry-Perot resonant antenna using a single superstrate for the fifth-generation (5G) wireless multiple-input-multiple-output (MIMO) applications. The antenna consists of a corner cut patch with a diagonal slot and a superstrate. The individual resonances of the corner cut patch and patch with diagonal slot are overlapped to improve the intrinsic narrow impedance and axial ratio (AR) bandwidths of the single-fed patch antennas. A half-wavelength spaced superstrate having a half-wavelength thickness is employed as a partially reflecting surface (PRS) for high gain and wide AR as well as impedance bandwidths. The design procedure and mechanisms of the PRS are discussed in detail through the equivalent circuit and ray tracing analysis. Simulated and measured results show that the proposed antennas have a wide operational bandwidth of 25-33 GHz (27.6%) for |S 11 | <; -10 dB with a stable gain achieving a maximum value of 14.1 dBiC and a wide 3-dB AR bandwidth ranging from 26-31.3 GHz (17%). This operational bandwidth of the antenna covers the proposed entire global 5G millimeter wave (mmWave) spectrum (26-29.5 GHz). Moreover, a 2 × 2 MIMO antenna is designed using the proposed antenna in such a way that the polarization diversity of the adjacent radiator is exploited, resulting in high isolation between antenna elements and low-envelope correlation coefficient, which makes it a suitable candidate for future 5G MIMO applications.","['5G mobile communication', 'MIMO communication', 'Broadband antennas', 'Bandwidth', 'Cavity resonators', 'Resonant frequency']","['Fifth-generation (5G)', 'millimeter wave', 'MIMO antenna', 'Fabry-Perot resonant antenna']"
"Any implant or prosthesis replacing a function or functions of an organ or group of organs should be biologically and sensorily integrated with the human body in order to increase their acceptance with their user. If this replacement is for a human hand, which is an important interface between humans and their environment, the acceptance issue and developing sensory-motor embodiment will be more challenging. Despite progress in prosthesis technologies, 50-60% of hand amputees wear a prosthetic device. One primary reason for the rejection of the prosthetic hands is that there is no or negligibly small feedback or tactile sensation from the hand to the user, making the hands less functional. In fact, the loss of a hand means interrupting the closed-loop sensory feedback between the brain (motor control) and the hand (sensory feedback through the nerves). The lack of feedback requires significant cognitive efforts from the user in order to do basic gestures and daily activities. To this aim, recently, there has been significant development in the provision of sensory feedback from transradial prosthetic hands, to enable the user take part in the control loop and improve user embodiment. Sensory feedback to the hand users can be provided via invasive and non-invasive methods. The latter includes the use of temperature, vibration, mechanical pressure and skin stretching, electrotactile stimulation, phantom limb stimulation, audio feedback, and augmented reality. This paper provides a comprehensive review of the non-invasive methods, performs their critical evaluation, and presents challenges and opportunities associated with the non-invasive sensory feedback methods.","['Prosthetic hand', 'Vibrations', 'Skin', 'Sensors', 'Surgery', 'Implants']","['Sensory feedback', 'prosthetics', 'non-invasive', 'electrotactile stimulation', 'mechanotactile stimulation', 'vibrotactile stimulation']"
"Underwater images play a key role in ocean exploration but often suffer from severe quality degradation due to light absorption and scattering in water medium. Although major breakthroughs have been made recently in the general area of image enhancement and restoration, the applicability of new methods for improving the quality of underwater images has not specifically been captured. In this paper, we review the image enhancement and restoration methods that tackle typical underwater image impairments, including some extreme degradations and distortions. First, we introduce the key causes of quality reduction in underwater images, in terms of the underwater image formation model (IFM). Then, we review underwater restoration methods, considering both the IFM-free and the IFM-based approaches. Next, we present an experimental-based comparative evaluation of the state-of-the-art IFM-free and IFM-based methods, considering also the prior-based parameter estimation algorithms of the IFM-based methods, using both subjective and objective analyses (the used code is freely available at https://github.com/wangyanckxx/Single-Underwater-Image-Enhancement-and-Color-Restoration). Starting from this paper, we pinpoint the key shortcomings of existing methods, drawing recommendations for future research in this area. Our review of underwater image enhancement and restoration provides researchers with the necessary background to appreciate challenges and opportunities in this important field.","['Image enhancement', 'Image color analysis', 'Image restoration', 'Scattering', 'Cameras', 'Histograms']","['Underwater image formation model', 'single underwater image enhancement', 'single underwater image restoration', 'background light estimation', 'transmission map estimation']"
"The intensive research in the fifth generation (5G) technology is a clear indication of technological revolution to meet the ever-increasing demand and needs for high speed communication as well as Internet of Thing (IoT) based applications. The timely upgradation in 5G technology standards is released by third generation partnership project (3GPP) which enables the researchers to refine the research objectives and contribute towards the development. The 5G technology will be supported by not only smartphones but also different IoT devices to provide different services like smart building, smart city, and many more which will require a 5G antenna with low latency, low path loss, and stable radiation pattern. This paper provides a comprehensive study of different antenna designs considering various 5G antenna design aspects like compactness, efficiency, isolation, etc. This review paper elaborates the state-of-the-art research on the different types of antennas with their performance enhancement techniques for 5G technology in recent years. Also, this paper precisely covers 5G specifications and categorization of antennas followed by a comparative analysis of different antenna designs. Till now, many 5G antenna designs have been proposed by the different researchers, but an exhaustive review of different types of 5G antenna with their performance enhancement method is not yet done. So, in this paper, we have attempted to explore the different types of 5G antenna designs, their performance enhancement techniques, comparison, and future breakthroughs in a holistic way.","['5G mobile communication', 'Broadband antennas', 'MIMO communication', 'Quality of service', 'Internet of Things', 'Dipole antennas']","['SISO', 'MIMO', 'wideband', 'multiband', '5G communication', 'metamaterial', 'corrugations', 'dielectric lens', 'defected ground structure (DGS)', 'antipodal Vivaldi antenna (AVA)', 'multi-element antenna', 'monopole', 'dipole', 'magneto-electric(ME) dipole', 'loop', 'fractal', 'inverted F antenna (IFA)', 'planar inverted F antenna (PIFA)']"
"Recently, the popularity of the Internet of Things (IoT) has led to a rapid development and significant advancement of ubiquitous applications seamlessly integrated within our daily life. Owing to the accompanying growth of the importance of privacy, a great deal of attention has focused on the issues of secure management and robust access control of IoT devices. In this paper, we propose the design of a blockchain connected gateway which adaptively and securely maintains user privacy preferences for IoT devices in the blockchain network. Individual privacy leakage can be prevented because the gateway effectively protects users' sensitive data from being accessed without their consent. A robust digital signature mechanism is proposed for the purposes of authentication and secure management of privacy preferences. Furthermore, we adopt the blockchain network as the underlying architecture of data processing and maintenance to resolve privacy disputes.","['Logic gates', 'Privacy', 'Contracts', 'Data privacy', 'Security', 'Biomedical monitoring', 'Object recognition']","['Blockchain', 'bluetooth low energy', 'Internet of Things (IoT)', 'security', 'privacy']"
"Heart failure is considered one of the leading cause of death around the world. The diagnosis of heart failure is a challenging task especially in under-developed and developing countries where there is a paucity of human experts and equipments. Hence, different researchers have developed different intelligent systems for automated detection of heart failure. However, most of these methods are facing the problem of overfitting i.e. the recently proposed methods improved heart failure detection accuracy on testing data while compromising heart failure detection accuracy on training data. Consequently, the constructed models overfit to the testing data. In order, to come up with an intelligent system that would show good performance on both training and testing data, in this paper we develop a novel diagnostic system. The proposed diagnostic system uses random search algorithm (RSA) for features selection and random forest model for heart failure prediction. The proposed diagnostic system is optimized using grid search algorithm. Two types of experiments are performed to evaluate the precision of the proposed method. In the first experiment, only random forest model is developed while in the second experiment the proposed RSA based random forest model is developed. Experiments are performed using an online heart failure database namely Cleveland dataset. The proposed method is efficient and less complex than conventional random forest model as it produces 3.3% higher accuracy than conventional random forest model while using only 7 features. Moreover, the proposed method shows better performance than five other state of the art machine learning models. In addition, the proposed method achieved classification accuracy of 93.33% while improving the training accuracy as well. Finally, the proposed method shows better performance than eleven recently proposed methods for heart failure detection.","['Heart', 'Diseases', 'Solid modeling', 'Feature extraction', 'Prediction algorithms']","['Heart failure', 'hyperparameters optimization', 'feature selection', 'random search algorithm', 'grid search algorithm']"
"Complicated weather conditions lead to intermittent, random and volatility in photovoltaic (PV) systems, which makes PV predictions difficult. A recurrent neural network (RNN) is considered to be an effective tool for time-series data prediction. However, when the weather changes intensely, the long-term sequence of multivariate may cause gradient vanishing (exploding) during the training of RNN, leading the prediction results to local optimum. Long short-term memory (LSTM) network is the deep structure of RNN. Due to its special hidden layer unit structure, it can preserve the trend information contained in the long-term sequence, which is allowed to solve the problems of RNN and improve performance. An LSTM-based approach is applied for short-term predictions in this study based on a timescale that encompasses global horizontal irradiance (GHI) one hour in advance and one day in advance. Inaccurate forecasts usually occur on cloudy days, and the results of ANN and SVR in the literature prove this. To improve prediction accuracy on cloudy days, the clearness-index was introduced as an input data for the LSTM model and to classify the type of weather by k-means during the data processing, where cloudy days are classified as the cloudy and the mixed(partially cloudy). NN models are established to compare the accuracy of different approaches and the cross-regional study is to prove whether the method can be generalizable. From the results of hourly forecast, the R 2 coefficient of LSTM on cloudy days and mixed days is exceeding 0.9, while the R 2 of RNN is only 0.70 and 0.79 in Atlanta and Hawaii. From the results of daily forecast, All R 2 on cloudy days is about 0.85. However, the LSTM is still very effective in improving of RNN and more accurate than other models.","['Clouds', 'Forecasting', 'Weather forecasting', 'Predictive models', 'Power generation', 'Artificial neural networks']","['LSTM', 'forecasting short-term solar irradiance', 'complicated weather', 'comparative research']"
"Automatic image detection of colonic polyps is still an unsolved problem due to the large variation of polyps in terms of shape, texture, size, and color, and the existence of various polyp-like mimics during colonoscopy. In this paper, we apply a recent region-based convolutional neural network (CNN) approach for the automatic detection of polyps in the images and videos obtained from colonoscopy examinations. We use a deep-CNN model (Inception Resnet) as a transfer learning scheme in the detection system. To overcome the polyp detection obstacles and the small number of polyp images, we examine image augmentation strategies for training deep networks. We further propose two efficient post-learning methods, such as automatic false positive learning and offline learning, both of which can be incorporated with the region-based detection system for reliable polyp detection. Using the large size of colonoscopy databases, experimental results demonstrate that the suggested detection systems show better performance than other systems in the literature. Furthermore, we show improved detection performance using the proposed post-learning schemes for colonoscopy videos.","['Training', 'Colonoscopy', 'Videos', 'Detectors', 'Image color analysis', 'Proposals', 'Feature extraction']","['Colonoscopy', 'convolutional neural network', 'image augmentation', 'polyp detection', 'region proposal network', 'transfer learning']"
"In this paper, we study fingerprinting-based indoor localization in commodity 5-GHz WiFi networks. We first theoretically and experimentally validate three hypotheses on the channel state information (CSI) data of 5-GHz OFDM channels. We then propose a system termed BiLoc, which uses bi-modality deep learning for localization in the indoor environment using off-the-shelf WiFi devices. We develop a deep learning-based algorithm to exploit bi-modal data, i.e., estimated angle of arrivings and average amplitudes (which are calibrated CSI data using several proposed techniques), for both the off-line and online stages of indoor fingerprinting. The proposed BiLoc system is implemented using commodity WiFi devices. Its superior performance is validated with extensive experiments under three typical indoor environments and through comparison with three benchmark schemes.","['Antennas', 'Wireless fidelity', 'OFDM', 'Feature extraction', 'Data mining', 'Machine learning', 'Antenna measurements']","['Indoor localization', 'fingerprinting', 'deep learning', '5GHz commodity WiFi', 'channel state information', 'bi-modality fingerprinting']"
"Search and rescue (SAR) operations can take significant advantage from supporting autonomous or teleoperated robots and multi-robot systems. These can aid in mapping and situational assessment, monitoring and surveillance, establishing communication networks, or searching for victims. This paper provides a review of multi-robot systems supporting SAR operations, with system-level considerations and focusing on the algorithmic perspectives for multi-robot coordination and perception. This is, to the best of our knowledge, the first survey paper to cover (i) heterogeneous SAR robots in different environments, (ii) active perception in multi-robot systems, while (iii) giving two complementary points of view from the multi-agent perception and control perspectives. We also discuss the most significant open research questions: shared autonomy, sim-to-real transferability of existing methods, awareness of victims' conditions, coordination and interoperability in heterogeneous multi-robot systems, and active perception. The different topics in the survey are put in the context of the different challenges and constraints that various types of robots (ground, aerial, surface, or underwater) encounter in different SAR environments (maritime, urban, wilderness, or other post-disaster scenarios). The objective of this survey is to serve as an entry point to the various aspects of multi-robot SAR systems to researchers in both the machine learning and control fields by giving a global overview of the main approaches being taken in the SAR robotics area.","['Robot kinematics', 'Multi-robot systems', 'Collaboration', 'Robot sensing systems', 'Planning']","['Robotics', 'search and rescue (SAR)', 'multi-robot systems (MRS)', 'machine learning (ML)', 'deep learning (DL)', 'active perception', 'active vision', 'multi-agent perception', 'autonomous robots']"
"Intelligent compound fault diagnosis of rotating machinery plays a crucial role for the security, high-efficiency, and reliability of modern manufacture machines, but identifying and decoupling the compound fault are still a great challenge. The traditional compound fault diagnosis methods focus on either bearing or gear fault diagnosis, where the compound fault is always regarded as an independent fault pattern in the process of fault diagnosis, and the relationship between the single fault and compound fault is not considered completely. To solve such a problem, a novel method called deep decoupling convolutional neural network is proposed for intelligent compound fault diagnosis. First, one-dimensional deep convolutional neural network is employed as the feature learning model, which can effectively learn the discriminative features from raw vibration signals. Second, multi-stack capsules are designed as the decoupling classifier to accurately identify and decouple the compound fault. Finally, the routing by agreement algorithm and the margin loss cost function are utilized to train and optimize the proposed model. The proposed method is validated by gearbox fault tests, and the experimental results demonstrate that the proposed method can effectively identify and decouple the compound fault.","['Fault diagnosis', 'Compounds', 'Convolutional neural networks', 'Gears', 'Vibrations', 'Feature extraction']","['Compound fault decoupling', 'deep decoupling convolutional neural network (DDCNN)', 'intelligent fault diagnosis', 'rotating machinery', 'decoupling classifier']"
"The growing development of IoT (Internet of Things) devices creates a large attack surface for cybercriminals to conduct potentially more destructive cyberattacks; as a result, the security industry has seen an exponential increase in cyber-attacks. Many of these attacks have effectively accomplished their malicious goals because intruders conduct cyber-attacks using novel and innovative techniques. An anomaly-based IDS (Intrusion Detection System) uses machine learning techniques to detect and classify attacks in IoT networks. In the presence of unpredictable network technologies and various intrusion methods, traditional machine learning techniques appear inefficient. In many research areas, deep learning methods have shown their ability to identify anomalies accurately. Convolutional neural networks are an excellent alternative for anomaly detection and classification due to their ability to automatically categorize main characteristics in input data and their effectiveness in performing faster computations. In this paper, we design and develop a novel anomaly-based intrusion detection model for IoT networks. First, a convolutional neural network model is used to create a multiclass classification model. The proposed model is then implemented using convolutional neural networks in 1D, 2D, and 3D. The proposed convolutional neural network model is validated using the BoT-IoT, IoT Network Intrusion, MQTT-IoT-IDS2020, and IoT-23 intrusion detection datasets. Transfer learning is used to implement binary and multiclass classification using a convolutional neural network multiclass pre-trained model. Our proposed binary and multiclass classification models have achieved high accuracy, precision, recall, and F1 score compared to existing deep learning implementations.","['Internet of Things', 'Deep learning', 'Security', 'Intrusion detection', 'Convolutional neural networks', 'Computational modeling', 'Neural networks']","['Internet of Things', 'anomaly detection', 'IoT intrusion detection', 'machine learning', 'deep learning', 'transfer learning', 'network security', 'convolutional neural network']"
"In recent years, there has been a paradigm shift in Internet of Things (IoT) from centralized cloud computing to edge computing (or fog computing). Developments in ICT have resulted in the significant increment of communication and computation capabilities of embedded devices and this will continue to increase in coming years. However, existing paradigms do not utilize low-level devices for any decision-making process. In fact, gateway devices are also utilized mostly for communication interoperability and some low-level processing. In this paper, we have proposed a new computing paradigm, named Edge Mesh, which distributes the decision-making tasks among edge devices within the network instead of sending all the data to a centralized server. All the computation tasks and data are shared using a mesh network of edge devices and routers. Edge Mesh provides many benefits, including distributed processing, low latency, fault tolerance, better scalability, better security, and privacy. These benefits are useful for critical applications, which require higher reliability, real-time processing, mobility support, and context awareness. We first give an overview of existing computing paradigms to establish the motivation behind Edge Mesh. Then, we describe in detail about the Edge Mesh computing paradigm, including the proposed software framework, research challenges, and benefits of Edge Mesh. We have also described the task management framework and done a preliminary study on task allocation problem in Edge Mesh. Different application scenarios, including smart home, intelligent transportation system, and healthcare, are presented to illustrate the significance of Edge Mesh computing paradigm.","['Cloud computing', 'Edge computing', 'Servers', 'Resource management', 'Security', 'Decision making', 'Sensors']","['Edge devices', 'Internet of Things', 'distributed intelligence', 'distributed computing', 'mesh network']"
"Uncertainty quantification plays a critical role in the process of decision making and optimization in many fields of science and engineering. The field has gained an overwhelming attention among researchers in recent years resulting in an arsenal of different methods. Probabilistic forecasting and in particular prediction intervals (PIs) are one of the techniques most widely used in the literature for uncertainty quantification. Researchers have reported studies of uncertainty quantification in critical applications such as medical diagnostics, bioinformatics, renewable energies, and power grids. The purpose of this survey paper is to comprehensively study neural network-based methods for construction of prediction intervals. It will cover how PIs are constructed, optimized, and applied for decision-making in presence of uncertainties. Also, different criteria for unbiased PI evaluation are investigated. The paper also provides some guidelines for further research in the field of neural network-based uncertainty quantification.","['Uncertainty', 'Probability density function', 'Artificial neural networks', 'Probabilistic logic', 'Forecasting', 'Upper bound']","['Prediction interval', 'uncertainty quantification', 'heteroscedastic uncertainty', 'neural network', 'forecast', 'time series data', 'regression', 'probability']"
"In recent years, the haze has caused serious troubles to people's lives, with the continuous increase of PM2.5 emissions. The accurate prediction of PM2.5 is very crucial for policy makers to make predictive measures. Due to the nonlinearity of the PM2.5 time series, it is difficult to predict accurately. Despite some studies about PM2.5 being proposed, the problem of the LSTM (long short-term memory) gradient disappearance and random selection of wavelet orders and layers isn't still solved. In this study, a novel model based on WT (wavelet transform)-SAE (stacked autoencoder)-LSTM is proposed. Firstly, six study sites from China are taken as examples and WT is used to decompose PM2.5 time series into several low-and high- frequency components based on different samples. Secondly, the decomposed components are predicted based on SAE-LSTM. Finally, the predicted results are reconstructed in view of all low-and high-frequency components and the predicted results are obtained. The results imply that: (1) the forecasting performance of SAE-LSTM is better than that of other models (e.g., BP (back propagation)) used for comparison; (2) for six different PM 2.5 samples, four orders five layers, five orders six layers, five orders seven layers, three orders six layers, five orders seven layers, and five orders six layers are the most appropriate. The conclusion that such a novel model may help to enhance the accuracy of PM 2.5 prediction can be drawn.","['Predictive models', 'Forecasting', 'Wavelet transforms', 'Logic gates', 'Neural networks', 'Atmospheric modeling']","['PM 2.5 time series', 'wavelet transform', 'stacked autoencoder', 'long short-term memory', 'prediction']"
"Blockchain technology is found to have its applicability in almost every domain because of its advantages such as crypto-security, transparency, immutability, decentralized data network. In present times, a smart healthcare system with a blockchain data network and healthcare 4.0 processes provides transparency, easy and faster accessibility, security, efficiency, etc. Healthcare 4.0 trends include industry 4.0 processes such as the internet of things (IoT), industrial IoT (IIoT), cognitive computing, artificial intelligence, cloud computing, fog computing, edge computing, etc. The goal of this work is to design a smart healthcare system and it is found to be possible through integration and interoperability of Blockchain 3.0 and Healthcare 4.0 in consideration with healthcare ground-realities. Here, healthcare 4.0 processes used for data accessibility are targeted to be validated through statistical simulation-optimization methods and algorithms. The blockchain is implemented in the Ethereum network, and with associated programming languages, tools, and techniques such as solidity, web3.js, Athena, etc. Further, this work prepares a comparative and comprehensive survey of state-of-the-art blockchain-based smart healthcare systems. The comprehensive survey includes methodology, applications, requirements, outcomes, future directions, etc. A list of groups, organizations, and enterprises are prepared that are working in electronic health records (EHR), electronic medical records (EMR) or electronic personal records (EPR) mainly, and a comparative analysis is drawn concerning adopting the blockchain technology in their processes. This work has explored optimization algorithms applicable to Healthcare 4.0 trends and improves the performance of blockchain-based decentralized applications for the smart healthcare system. Further, smart contracts and their designs are prepared for the proposed system to expedite the trust-building and payment systems. This work has considered simulation and implementation to validate the proposed approach. Simulation results show that the Gas value required (indicating block size and expenditure) lies within current Etherum network Gas limits. The proposed system is active because block utilization lies above 80%. Automated smart contract execution is below 20 seconds. A good number (average 3 per simulation time) is generated in the network that indicates a health competition. Although there is error observed in simulation and implementation that lies between 0.55% and 4.24%, these errors are not affecting overall system performance because simulated and actual (taken in state-of-the-art) data variations are negligible.","['Medical services', 'Blockchain', 'Smart contracts', 'Market research', 'Industries', 'Cloud computing']","['Block', 'blockchain 3.0', 'healthcare 4.0', 'Industrial IoT (IIoT)', 'Industry 4.0', 'Internet of Things (IoT)', 'mining optimization', 'smart solution', 'transaction']"
"Recently, software defined networks (SDNs) and cloud computing have been widely adopted by researchers and industry. However, widespread acceptance of these novel networking paradigms has been hampered by the security threats. Advances in the processing technologies have helped attackers in increasing the attacks too, for instance, the development of Denial of Service (DoS) attacks to distributed DoS (DDoS) attacks which are seldom identified by conventional firewalls. In this paper, we present the state of art of the DDoS attacks in SDN and cloud computing scenarios. Especially, we focus on the analysis of SDN and cloud computing architecture. Besides, we also overview the research works and open problems in identifying and tackling the DDoS attacks.","['Cloud computing', 'Computer crime', 'Software defined networking', 'IP networks', 'Organizations', 'Floods']","['Software defined network', 'cloud computing', 'distributed denial of service attacks (DDoS)', 'DDoS attack and detection', 'experimental setup', 'survey']"
"Cyber-Physical System (CPS) is a new kind of digital technology that increases its attention across academia, government, and industry sectors and covers a wide range of applications like agriculture, energy, medical, transportation, etc. The traditional power systems with physical equipment as a core element are more integrated with information and communication technology, which evolves into the Cyber-Physical Power System (CPPS). The CPPS consists of a physical system tightly integrated with cyber systems (control, computing, and communication functions) and allows the two-way flows of electricity and information for enabling smart grid technologies. Even though the digital technologies monitoring and controlling the electric power grid more efficiently and reliably, the power grid is vulnerable to cybersecurity risk and involves the complex interdependency between cyber and physical systems. Analyzing and resolving the problems in CPPS needs the modelling methods and systematic investigation of a complex interaction between cyber and physical systems. The conventional way of modelling, simulation, and analysis involves the separation of physical domain and cyber domain, which is not suitable for the modern CPPS. Therefore, an integrated framework needed to analyze the practical scenario of the unification of physical and cyber systems. A comprehensive review of different modelling, simulation, and analysis methods and different types of cyber-attacks, cybersecurity measures for modern CPPS is explored in this paper. A review of different types of cyber-attack detection and mitigation control schemes for the practical power system is presented in this paper. The status of the research in CPPS around the world and a new path for recommendations and research directions for the researchers working in the CPPS are finally presented.","['Power system stability', 'Analytical models', 'Monitoring', 'Computer security', 'Power grids', 'Control systems']","['Cyber-physical power system (CPPS)', 'CPPS modelling', 'CPPS simulation', 'cyber-physical social system (CPSS)', 'cyber attack', 'cyber security', 'smart grid']"
"Indoor localization has received wide attention recently due to the potential use of wide range of intelligent services. This paper presents a deep learning-based approach for indoor localization by utilizing transmission channel quality metrics, including received signal strength (RSS) and channel state information (CSI). We partition a rectangular room plane into two-dimensional blocks. Each block is regarded as a class, and we formulate the localization as a classification problem. Using RSS and CSI, we develop four deep neural networks implemented with multi-layer perceptron (MLP) and one-dimensional convolutional neural network (1D-CNN) to estimate the location of a subject in a room. The experimental results indicate that the 1D-CNN using CSI information achieves excellent localization performance with much lower network complexity.","['Fingerprint recognition', 'Receivers', 'Neural networks', 'Radio transmitters', 'Feature extraction', 'Wireless fidelity', 'Complexity theory']","['Indoor localization', 'deep learning', 'convolutional neural network (CNN)', 'received signal strength (RSS)', 'channel state information (CSI)']"
"Recently, researchers found that the intended generalizability of (deep) face recognition systems increases their vulnerability against attacks. In particular, the attacks based on morphed face images pose a severe security risk to face recognition systems. In the last few years, the topic of (face) image morphing and automated morphing attack detection has sparked the interest of several research laboratories working in the field of biometrics and many different approaches have been published. In this paper, a conceptual categorization and metrics for an evaluation of such methods are presented, followed by a comprehensive survey of relevant publications. In addition, technical considerations and tradeoffs of the surveyed methods are discussed along with open issues and challenges in the field.","['Face', 'Face recognition', 'Active shape model', 'Security', 'Measurement', 'Neural networks']","['Biometrics', 'face morphing attack', 'face recognition', 'image morphing', 'morphing attack detection']"
"Heart disease, one of the major causes of mortality worldwide, can be mitigated by early heart disease diagnosis. A clinical decision support system (CDSS) can be used to diagnose the subjects' heart disease status earlier. This study proposes an effective heart disease prediction model (HDPM) for a CDSS which consists of Density-Based Spatial Clustering of Applications with Noise (DBSCAN) to detect and eliminate the outliers, a hybrid Synthetic Minority Over-sampling Technique-Edited Nearest Neighbor (SMOTE-ENN) to balance the training data distribution and XGBoost to predict heart disease. Two publicly available datasets (Statlog and Cleveland) were used to build the model and compare the results with those of other models (naive bayes (NB), logistic regression (LR), multilayer perceptron (MLP), support vector machine (SVM), decision tree (DT), and random forest (RF)) and of previous study results. The results revealed that the proposed model outperformed other models and previous study results by achieving accuracies of 95.90% and 98.40% for Statlog and Cleveland datasets, respectively. In addition, we designed and developed the prototype of the Heart Disease CDSS (HDCDSS) to help doctors/clinicians diagnose the patients'/subjects' heart disease status based on their current condition. Therefore, early treatment could be conducted to prevent the deaths caused by late heart disease diagnosis.","['Heart', 'Diseases', 'Predictive models', 'Support vector machines', 'Data models', 'Radio frequency', 'Machine learning']","['Heart disease', 'disease prediction model', 'clinical decision support system', 'outlier data', 'imbalanced data', 'machine learning']"
"Computer-aided detection, localization, and segmentation methods can help improve colonoscopy procedures. Even though many methods have been built to tackle automatic detection and segmentation of polyps, benchmarking of state-of-the-art methods still remains an open problem. This is due to the increasing number of researched computer vision methods that can be applied to polyp datasets. Benchmarking of novel methods can provide a direction to the development of automated polyp detection and segmentation tasks. Furthermore, it ensures that the produced results in the community are reproducible and provide a fair comparison of developed methods. In this paper, we benchmark several recent state-of-the-art methods using Kvasir-SEG, an open-access dataset of colonoscopy images for polyp detection, localization, and segmentation evaluating both method accuracy and speed. Whilst, most methods in literature have competitive performance over accuracy, we show that the proposed ColonSegNet achieved a better trade-off between an average precision of 0.8000 and mean IoU of 0.8100, and the fastest speed of 180 frames per second for the detection and localization task. Likewise, the proposed ColonSegNet achieved a competitive dice coefficient of 0.8206 and the best average speed of 182.38 frames per second for the segmentation task. Our comprehensive comparison with various state-of-the-art methods reveals the importance of benchmarking the deep learning methods for automated real-time polyp identification and delineations that can potentially transform current clinical practices and minimise miss-detection rates.","['Colonoscopy', 'Image segmentation', 'Benchmark testing', 'Real-time systems', 'Cancer', 'Videos', 'Biomedical imaging']","['Medical image segmentation', 'ColonSegNet', 'colonoscopy', 'polyps', 'deep learning', 'detection', 'localization', 'benchmarking', 'Kvasir-SEG']"
"The explosive growth of massive data generation from Internet of Things in industrial, agricultural and scientific communities has led to a rapid increase for data analytics in cloud data centers. The ubiquitous and pervasive demand for near-data processing urges the edge computing paradigm in recent years. Edge computing is promising for less network backbone bandwidth usage and thus less data center side processing pressure, as well as enhanced service responsiveness and data privacy protection. Computation offloading plays a crucial role in edge computing in terms of network packets transmission and system responsiveness through dynamic task partitioning between cloud data centers and edge servers and edge devices. In this paper a thorough literature review is conducted to reveal the state-of-the-art of computation offloading in edge computing. Various aspects of computation offloading, including energy consumption minimization, Quality of Services guarantee, and Quality of Experiences enhancement are surveyed. Moreover, resource scheduling approaches, gaming and tradeoffing among system performance and overheads for computation offloading decision making are also reviewed.","['Cloud computing', 'Edge computing', 'Computational modeling', 'Data centers', 'Internet of Things', 'Task analysis', 'Computer architecture']","['Edge computing', 'computation offloading', 'task partitioning', 'game theory', 'edge-cloud collaboration']"
"The essence of blockchain smart contracts lies in the execution of business logic code in a decentralized architecture in which the execution outcomes are trusted and agreed upon by all the executing nodes. Despite the decentralized and trustless architectures of the blockchain systems, smart contracts on their own cannot access data from the external world. Instead, smart contracts interact with off-chain external data sources, called oracles, whose primary job is to collect and provide data feeds and input to smart contracts. However, there is always risk of oracles providing corrupt, malicious, or inaccurate data. In this paper, we analyze and present the notion of trust in the oracles used in blockchain ecosystems. We analyze and compare trust-enabling features of the leading blockchain oracle approaches, techniques, and platforms. Moreover, we discuss open research challenges that should be addressed to ensure secure and trustworthy blockchain oracles.","['Blockchain', 'Smart contracts', 'Peer-to-peer computing', 'Feeds', 'Data models', 'Reliability', 'Ecosystems']","['Blockchain', 'data attestation', 'decentralization', 'oracles', 'smart contract', 'trust']"
"Fog computing (FC) is an emerging distributed computing platform aimed at bringing computation close to its data sources, which can reduce the latency and cost of delivering data to a remote cloud. This feature and related advantages are desirable for many Internet-of-Things applications, especially latency sensitive and mission intensive services. With comparisons to other computing technologies, the definition and architecture of FC are presented in this paper. The framework of resource allocation for latency reduction combined with reliability, fault tolerance, privacy, and underlying optimization problems are also discussed. We then investigate an application scenario and conduct resource optimization by formulating the optimization problem and solving it via a genetic algorithm. The resulting analysis generates some important insights on the scalability of the FC systems.","['Cloud computing', 'Computer architecture', 'Edge computing', 'Optimization', 'Logic gates', 'Big Data']","['Fog computing', 'genetic algorithms', 'Internet of Things', 'optimization']"
"Blockchain, a form of distributed ledger technology has attracted the interests of stakeholders across several sectors including healthcare. Its' potential in the multi-stakeholder operated sector like health has been responsible for several investments, studies, and implementations. Electronic Health Records (EHR) systems traditionally used for the exchange of health information amongst healthcare stakeholders have been criticised for centralising power, failures and attack-points with exchange data custodians. EHRs have struggled in the face of multi-stakeholder and system requirements while adhering to security, privacy, ethical and other regulatory constraints. Blockchain is promising amongst others to address the many EHR challenges, primarily trustless and secure exchange of health information amongst stakeholders. Many blockchain-in-healthcare frameworks have been proposed; some prototyped and/or implemented. This study leveraged the PRISMA framework to systematically search and evaluate the different models proposed; prototyped and/or implemented. The bibliometric and functional distribution of all 143 articles from this study were presented. This study evaluated 61 articles that discussed either prototypes or pilot or implementations. The technical and architectural analysis of these 61 articles for privacy, security, cost, and performance were detailed. Blockchain was found to solve the trust, security and privacy constraints of traditional EHRs often at significant performance, storage and cost trade-offs.","['Blockchain', 'Medical services', 'Systematics', 'Market research', 'Bitcoin']","['Bioinformatics', 'blockchain', 'DLT', 'distributed ledger technology', 'distributed computing', 'distributed databases', 'health information management', 'health information exchange', 'hospitals', 'pharmaceutical technology', 'telemedicine', 'digital health', 'eHealth', 'mHealth']"
"Demand side management (DSM) will play a significant role in the future smart grid by managing loads in a smart way. DSM programs, realized via home energy management systems for smart cities, provide many benefits; consumers enjoy electricity price savings and utility operates at reduced peak demand. In this paper, evolutionary algorithms-based (binary particle swarm optimization, genetic algorithm, and cuckoo search) DSM model for scheduling the appliances of residential users is presented. The model is simulated in time of use pricing environment for three cases: 1) traditional homes; 2) smart homes; and 3) smart homes with renewable energy sources. Simulation results show that the proposed model optimally schedules the appliances resulting in electricity bill and peaks reductions.","['Home appliances', 'Pricing', 'Scheduling', 'Renewable energy sources', 'Smart grids', 'Schedules']","['Appliance scheduling', 'binary particle swarm optimization', 'genetic algorithm', 'cuckoo search algorithm', 'energy management system', 'electricity pricing', 'smart grid']"
"This paper presents a metasurface-based single-layer low-profile circularly polarized (CP) antenna with the wideband operation and its multiple-input multiple-output (MIMO) configuration for fifth-generation (5G) communication systems. The antenna consists of a truncated corner patch and a metasurface (MS) of a 2 × 2 periodic square metallic plates. The distinguishing feature of this design is that all the radiating elements (radiator and MS) are printed on the single-layer of the dielectric substrate, which ensures the low-profile and low-cost features of the antenna while maintaining high gain and wideband characteristics. The wideband CP radiations are realized by exploiting surface-waves along the MS and its radiation mechanism is explained in detail. The single-layer antenna geometry has an overall compact size of 1.0λ 0 × 1.0λ 0 × 0.04λ 0 . Simulated and measured results show that the single-layer metasurface antenna has a wide 10 dB impedance bandwidth of 23.4 % (24.5 - 31 GHz) (23.4 %) and overlapping 3-dB axial ratio bandwidth of 16.8 % (25 - 29.6 GHz). The antenna also offers stable radiation patterns with a high radiation efficiency (>95%) and a flat gain of 11 dBic. Moreover, a 4-port (2 × 2) MIMO antenna is designed using the proposed design by placing each element perpendicular to each other. Without a dedicated decoupling structure, the MIMO antenna shows an excellent diversity performance in terms of isolation between antenna elements, envelope correlation coefficient, and channel capacity loss. Most importantly, the operational bandwidth of the antenna covers the millimeter-wave (mm-wave) band (25 - 29.5 GHz) assigned for 5G communication. These features of the proposed antenna system make it a suitable candidate for 5G smart devices and sensors.","['5G mobile communication', 'MIMO communication', 'Wideband', 'Broadband antennas', 'Millimeter wave communication']","['28 GHz', 'metasurface antenna', 'fifth-generation (5G)', 'millimeter-wave systems', 'MIMO', 'circular polarization']"
"The micro air vehicle link (MAVLink in short) is a communication protocol for unmanned systems (e.g., drones and robots). It specifies a comprehensive set of messages exchanged between unmanned systems and ground stations. This protocol is used in major autopilot systems, mainly ArduPilot and PX4, and provides powerful features not only for monitoring and controlling unmanned systems missions but also for their integration into the Internet. However, there is no technical survey and/or tutorial in the literature that presents these features or explains how to make use of them. Most of the references are online tutorials and basic technical reports, and none of them presents comprehensive and systematic coverage of the protocol. In this paper, we address this gap, and we propose an overview of the MAVLink protocol, the difference between its versions, and it is potential in enabling Internet connectivity to unmanned systems. We also discuss the security aspects of the MAVLink. To the best of our knowledge, this is the first technical survey and tutorial on the MAVLink protocol, which represents an important reference for unmanned systems users and developers.","['Protocols', 'Tutorials', 'Drones', 'Reliability', 'Payloads', 'Robots']","['MAVLink', 'ArduPilot', 'PX4', 'Unmanned Aerial Vehicles (UAVs)', 'Ground Control Stations (GCSs)']"
"Recent advancements in human-computer interaction research have led to the possibility of emotional communication via brain-computer interface systems for patients with neuropsychiatric disorders or disabilities. In this paper, we efficiently recognize emotional states by analyzing the features of electroencephalography (EEG) signals, which are generated from EEG sensors that noninvasively measure the electrical activity of neurons inside the human brain, and select the optimal combination of these features for recognition. In this paper, the scalp EEG data of 21 healthy subjects (12-14 years old) were recorded using a 14-channel EEG machine while the subjects watched images with four types of emotional stimuli (happy, calm, sad, or scared). After preprocessing, the Hjorth parameters (activity, mobility, and complexity) were used to measure the signal activity of the time series data. We selected the optimal EEG features using a balanced one-way ANOVA after calculating the Hjorth parameters for different frequency ranges. Features selected by this statistical method outperformed univariate and multivariate features. The optimal features were further processed for emotion classification using support vector machine, k-nearest neighbor, linear discriminant analysis, Naive Bayes, random forest, deep learning, and four ensembles methods (bagging, boosting, stacking, and voting). The results show that the proposed method substantially improves the emotion recognition rate with respect to the commonly used spectral power band method.","['Electroencephalography', 'Feature extraction', 'Emotion recognition', 'Electrodes', 'Sensors', 'Support vector machines', 'Medical services']","['EEG pattern recognition', 'Hjorth parameter', 'EEG feature extraction', 'EEG emotion recognition']"
"Due to a battery constraint in wireless sensor networks (WSNs), prolonging their lifetime is important. Energy-efficient routing techniques for WSNs play a great role in doing so. In this paper, we articulate this problem and classify current routing protocols for WSNs into two categories according to their orientation toward either homogeneous or heterogeneous WSNs. They are further classified into static and mobile ones. We give an overview of these protocols in each category by summarizing their characteristics, limitations, and applications. Finally, some open issues in energy-efficient routing protocol design for WSNs are indicated.","['Wireless sensor networks', 'Energy efficiency', 'Routing protocols', 'Mobile communication', 'Batteries', 'Design methodology']","['Wireless sensor networks (WSNs)', 'energy-efficient routing protocol', 'internet of things']"
"A vision of the future Internet is introduced in such a fashion that various computing devices are connected together to form a network called Internet of Things (IoT). This network will generate massive data that may be leveraged for entertainment, security, and most importantly user trust. Yet, trust is an imperative obstruction that may hinder the IoT growth and even delay the substantial squeeze of a number of applications. In this survey, an extensive analysis of trust management techniques along with their pros and cons is presented in a different context. In comparison with other surveys, the goal is to provide a systematic description of the most relevant trust management techniques to help researchers understand that how various systems fit together to bring preferred functionalities without examining different standards. Besides, the lessons learned are presented, and the views are argued regarding the primary goal trust which is likely to play in the future Internet.","['Servers', 'Internet of Things', 'Protocols', 'Authentication']","['Internet of Things', 'trust management techniques', 'trust contributions', 'trust limitations']"
"The ever increasing trend of renewable energy sources (RES) into the power system has increased the uncertainty in the operation and control of power system. The vulnerability of RES towards the unforeseeable variation of meteorological conditions demands additional resources to support. In such instance, energy storage systems (ESS) are inevitable as they are one among the various resources to support RES penetration. However, ESS has limited ability to fulfil all the requirements of a certain application. So, hybridization of multiple ESS to form a composite ESS is a potential solution. While integrating these different ESS, their power sharing control plays a crucial role to exploit the complementary characteristics of each other. Therefore, this article attempts to bring the numerous control strategies proposed in the literature at one place. Various control techniques implemented for HESS are critically reviewed and the notable observations are tabulated for better insights. Furthermore, the control techniques are classified into broad categories and they are briefly discussed with their limitations. From the carried-out analysis, the challenges faced towards the implementation of HESS for standalone and grid connected microgrid systems are presented. Finally, the future directions are laid out for the researchers to carry out the research and implementation of HESS technologies. Overall, this article would serve as a thorough guide on various control techniques implemented for HESS including their features, limitations and real-time applications.","['Batteries', 'Topology', 'Hybrid power systems', 'Renewable energy sources', 'Microgrids']","['Hybrid energy storage system', 'microgrid', 'intelligent control', 'renewable energy', 'energy management', 'power electronics']"
"The IoT has applications in many areas such as manufacturing, healthcare, and agriculture, to name a few. Recently, wearable devices have become popular with wide applications in the health monitoring system which has stimulated the growth of the Internet of Medical Things (IoMT). The IoMT has an important role to play in reducing the mortality rate by the early detection of disease. The prediction of heart disease is a key issue in the analysis of clinical dataset. The aim of the proposed investigation is to identify the key characteristics of heart disease prediction using machine learning techniques. Many studies have focused on heart disease diagnosis, but the accuracy of the findings is low. Therefore, to improve prediction accuracy, an IoMT framework for the diagnosis of heart disease using modified salp swarm optimization (MSSO) and an adaptive neuro-fuzzy inference system (ANFIS) is proposed. The proposed MSSO-ANFIS improves the search capability using the Levy flight algorithm. The regular learning process in ANFIS is dependent on gradient-based learning and has a tendency to become trapped in local minima. The learning parameters are optimized utilizing MSSO to provide better results for ANFIS. The following information is taken from medical records to predict the risk of heart disease: blood pressure (BP), age, sex, chest pain, cholesterol, blood sugar, etc. The heart condition is identified by classifying the received sensor data using MSSO-ANFIS. A simulation and analysis is conducted to show that MSSA-ANFIS works well in relation to disease prediction. The results of the simulation demonstrate that the MSSO-ANFIS prediction model achieves better accuracy than the other approaches. The proposed MSSO-ANFIS prediction model obtains an accuracy of 99.45 with a precision of 96.54, which is higher than the other approaches.","['Heart', 'Diseases', 'Biomedical monitoring', 'Predictive models', 'Monitoring', 'Medical diagnostic imaging']","['Internet of Things', 'heart disease', 'LCSA', 'ANFIS', 'MSSO', 'Internet of Medical Things']"
"In the digital healthcare era, it is of the utmost importance to harness medical information scattered across healthcare institutions to support in-depth data analysis and achieve personalized healthcare. However, the cyberinfrastructure boundaries of healthcare organizations and privacy leakage threats place obstacles on the sharing of medical records. Blockchain, as a public ledger characterized by its transparency, tamper-evidence, trustlessness, and decentralization, can help build a secure medical data exchange network. This paper surveys the state-of-the-art schemes on secure and privacy-preserving medical data sharing of the past decade with a focus on blockchain-based approaches. We classify them into permissionless blockchain-based approaches and permissioned blockchain-based approaches and analyze their advantages and disadvantages. We also discuss potential research topics on blockchain-based medical data sharing.","['Medical services', 'Cloud computing', 'Blockchain', 'Biomedical imaging', 'Data privacy', 'Cryptography']","['Access control', 'blockchain', 'encryption', 'medical data', 'privacy', 'security']"
"Due to the sheer global energy crisis, concerns about fuel exhaustion, electricity shortages, and global warming are becoming increasingly severe. Solar and wind energy, which are clean and renewable, provide solutions to these problems through distributed generators. Microgrids, as an essential interface to connect the power produced by renewable energy resources-based distributed generators to the power system, have become a research hotspot. Modern research in the field of microgrids has focused on the integration of microgrid technology at the load level. Due to the complexity of protection and control of multiple interconnected distributed generators, the traditional power grids are now outmoded. Microgrids are feasible alternatives to the conventional grid since they provide an integrating platform for micro-resources-based distributed generators, storage equipment, loads, and voltage source converters at the user end, all within a compact footprint. A microgrid can be architected to function either in grid-connected or standalone mode, depending upon the generation, integration potential to the main grid, and consumers’ requirements. The amalgamation of distributed energy resources-based microgrids to the conventional power system is giving rise to a new power framework. Nevertheless, the grids’ control, protection, operational stability, and reliability are major concerns. There has yet to be an effective real-time implementation and commercialization of micro-grids. This review article summarizes various concerns associated with microgrids’ technical and economic aspects and challenges, power flow controllers, microgrids’ role in smart grid development, main flaws, and future perspectives.","['Microgrids', 'Power system stability', 'Power harmonic filters', 'Harmonic analysis', 'Energy storage', 'Renewable energy sources', 'Power quality', 'Global warming']","['Distributed energy resources (DERs)', 'distributed generation (DG)', 'electrical energy storage devices (EESDs)', 'frequency control', 'micro-resources', 'microgrids (MGs)', 'microgrid control', 'power quality', 'power system stability', 'PQ~droop', 'renewable energy resources (RERs)', 'smart grid (SG)']"
"A smart contract is an agreement between two or more parties, which is executed by the computer code. The code does the execution without giving either party the ability to back out, so it ensures the trustless execution. The smart contract is one of the most important features in blockchain applications, which implements trusted transactions without third parties. However, with the rapid development, blockchain smart contracts have also exposed many security problems, and some attacks caused by contract vulnerabilities have led to terrible losses. In order to better deal with such dilemma, making a comprehensive survey about the security verification of blockchain smart contracts from major scientific databases is quite indispensable. Even though the significance of studying security verification of blockchain smart contracts is evident, it is really fresh yet. The major contributions of our survey work come from three aspects. First, after retrieving all-sided research studies, we select 53 most related papers to show the state-of-the art of this topic, where 20 papers focus on dealing with security assurance of blockchain smart contracts, and 33 papers focus on the correctness verification of blockchain smart contracts. Second, we propose a taxonomy toward the topic of security verification of blockchain smart contracts and discuss the pros and cons of each category of related studies. Third, through in-depth analysis of these studies, we come to know that the correctness verification of smart contracts based on the formal method has already become the more significant and more effective method to validate whether a smart contract is credible and accurate. So, we further present representative studies of formal verification of smart contracts in detail to demonstrate that using a formal method to validate blockchain smart contracts must have a promising and meritorious future.","['Smart contracts', 'Blockchain', 'Security', 'Law', 'Reliability', 'Taxonomy']","['Blockchain', 'formal method', 'security verification', 'smart contract', 'survey']"
"This paper presents a comparison of the expected lifetime for Internet of Things (IoT) devices operating in several wireless networks: the IEEE 802.15.4/e, Bluetooth low energy (BLE), the IEEE 802.11 power saving mode, the IEEE 802.11ah, and in new emerging long-range technologies, such as LoRa and SIGFOX. To compare all technologies on an equal basis, we have developed an analyzer that computes the energy consumption for a given protocol based on the power required in a given state (Sleep, Idle, Tx, and Rx) and the duration of each state. We consider the case of an energy constrained node that uploads data to a sink, analyzing the physical (PHY) layer under medium access control (MAC) constraints, and assuming IPv6 traffic whenever possible. This paper considers the energy spent in retransmissions due to corrupted frames and collisions as well as the impact of imperfect clocks. The comparison shows that the BLE offers the best lifetime for all traffic intensities in its capacity range. LoRa achieves long lifetimes behind 802.15.4 and BLE for ultra low traffic intensity; SIGFOX only matches LoRa for very small data sizes. Moreover, considering the energy consumption due to retransmissions of lost data packets only decreases the lifetimes without changing their relative ranking. We believe that these comparisons will give all users of IoT technologies indications about the technology that best fits their needs from the energy consumption point of view. Our analyzer will also help IoT network designers to select the right MAC parameters to optimize the energy consumption for a given application.","['Energy consumption', 'IEEE 802.15 Standard', 'Wireless networks', 'Hardware', 'Internet of Things', 'Media Access Protocol']","['Internet of Things (IoT)', 'wireless sensor networks', '6LoWPAN', '802.15.4e', 'TSCH', '802.11ah', 'Bluetooth low energy', 'LoRa', 'SIGFOX', 'energy consumption model', 'clock drift']"
"While customers rivet their eyes on Wi-Fi 6, in the bowels of the IEEE 802.11 Working Group that creates Wi-Fi standards, the next generation Wi-Fi is being developed. At the very first sight, the new IEEE 802.11be amendment to the Wi-Fi standard is nothing but scaled 11ax with doubled bandwidth and the increased number of spatial streams, which together provide data rates as high as 40 Gbps. A bit deeper dive into the 802.11 activities reveals that 11be will support real-time applications. In reality, 11be introduces many more revolutionary changes to Wi-Fi, which will form a basement for further Wi-Fi evolution. Although by now (May 2020), the development process is at the very early phase without any draft specification, the analysis of the discussion in the 802.11 Working Group gives insights into the main innovations of 11be. In addition to the ones above, they include native multi-link operation, channel sounding optimization that opens the door for massive MIMO, advanced PHY and MAC techniques, the cooperation of various access points. The paper analyzes hundreds of features proposed for the new technology, focusing on the open problems that can be solved by the researchers who want to contribute to the development of 802.11be.","['Wireless fidelity', 'IEEE 802.11 Standard', 'MIMO communication', 'Throughput', 'Media Access Protocol', 'OFDM']","['802.11be', 'extremely high throughput', '4096 QAM', '320 MHz', 'MU-MIMO', 'time-sensitive networking', 'multi-link operation', 'implicit sounding', 'distributed MU-MIMO']"
"Electricity is of great significance for national economic, social, and technological activities, such as material production, healthcare, and education. The nationwide electricity demand has grown rapidly over the past few decades. Therefore, efficient electricity demand estimation and management are required for better strategies planning, energy utilization, waste management, improving revenue, and maintenance of power systems. In this paper, we propose an empirical mode decomposition (EMD)-based deep learning approach which combines the EMD method with the long short-term memory network model to estimate electricity demand for the given season, day, and time interval of a day. For this purpose, the EMD algorithm decomposes a load time series signal into several intrinsic mode functions (IMFs) and residual. Then, a LSTM model is trained separately for each of the extracted IMFs and residual. Finally, the prediction results of all IMFs are combined by summation to determine an aggregated output for electricity demand. To demonstrate the applicability of the proposed approach, it is applied to electricity consumption data of city Chandigarh. Furthermore, the performance of the proposed approach is evaluated by comparing the prediction results with recurrent neural network (RNN), LSTM, and EMD-based RNN (EMD+RNN) models.","['Predictive models', 'Demand forecasting', 'Time series analysis', 'Machine learning', 'Recurrent neural networks', 'Load modeling', 'Support vector machines']","['Deep learning', 'electricity demand prediction', 'empirical mode decomposition', 'energy analytic', 'long short term memory network']"
"Condition monitoring and incipient fault diagnosis of rolling bearing is of great importance to detect failures and ensure reliable operations in rotating machinery. In this paper, a new multi-speed fault diagnostic approach is presented by using self-adaptive wavelet transform components generated from bearing vibration signals. The proposed approach is capable of discriminating signatures from four conditions of rolling bearing, i.e., normal bearing and three different types of defected bearings on outer race, inner race, and roller separately. Particle swarm optimization and Broyden-Fletche-Goldfarb-Shanno-based quasi-Newton minimization algorithms are applied to seek optimal parameters of Impulse Modeling-based continuous wavelet transform model. Then, a 3-D feature space of the statistical parameters and a nearest neighbor classifier are, respectively, applied for fault signature extraction and fault classification. Effectiveness of this approach is then evaluated, and the results have achieved an overall accuracy of 100%. Moreover, the generated discriminatory fault signatures are suitable for multi-speed fault data sets. This technique will be further implemented and tested in a real industrial environment.","['Rolling bearings', 'Vibrations', 'Continuous wavelet transforms', 'Optimization', 'Wavelet analysis']","['Fault diagnosis', 'vibration measurement', 'continuous wavelet transforms', 'roller bearing', 'particle swarm optimization', 'quasi-newton minimization', 'fault signatures']"
"This paper reviews the modeling of high-temperature superconductors (HTS) using the finiteelement method (FEM) based on the H-formulation of Maxwell's equations. This formulation has become the most popular numerical modeling method for simulating the electromagnetic behavior of HTS, especially thanks to the easiness of implementation in the commercial finite-element program COMSOL Multiphysics. Numerous studies prove that the H-formulation is able to simulate a wide scope of HTS topologies, from simple geometries such as HTS tapes and coils, to more complex HTS devices, up to large superconducting magnets. In this paper, we review the basics of the H-formulation, its evolution from 2D to 3D, its application for calculating critical currents and AC losses as well as magnetization of HTS bulks and tape stacks. We also review the use of the H-formulation for large-scale HTS applications, its use to solve multi-physics problems involving electromagnetic-thermal and electromagnetic-mechanical couplings, and its application to study the dynamic resistance of superconductors and flux pumps.","['High-temperature superconductors', 'Finite element analysis', 'Mathematical model', 'Electromagnetics', 'Superconducting magnets', 'Three-dimensional displays']","['Review', 'H -formulation', 'high temperature superconductor (HTS)', 'finite-element method (FEM)']"
"Road pavement cracks detection has been a hot research topic for quite a long time due to the practical importance of crack detection for road maintenance and traffic safety. Many methods have been proposed to solve this problem. This paper reviews the three major types of methods used in road cracks detection: image processing, machine learning and 3D imaging based methods. Image processing algorithms mainly include threshold segmentation, edge detection and region growing methods, which are used to process images and identify crack features. Crack detection based traditional machine learning methods such as neural network and support vector machine still relies on hand-crafted features using image processing techniques. Deep learning methods have fundamentally changed the way of crack detection and greatly improved the detection performance. In this work, we review and compare the deep learning neural networks proposed in crack detection in three ways, classification based, object detection based and segmentation based. We also cover the performance evaluation metrics and the performance of these methods on commonly-used benchmark datasets. With the maturity of 3D technology, crack detection using 3D data is a new line of research and application. We compare the three types of 3D data representations and study the corresponding performance of the deep neural networks for 3D object detection. Traditional and deep learning based crack detection methods using 3D data are also reviewed in detail.","['Roads', 'Image segmentation', 'Image edge detection', 'Three-dimensional displays', 'Deep learning']","['Crack detection', 'image processing', 'deep learning', '3D imaging']"
"Nowadays billions of smart devices or things are present in Internet of Things (IoT) environments, such as homes, hospitals, factories, and vehicles, all around the world. As a result, the number of interconnected devices is continuously and rapidly growing. These devices communicate with each other and with other services using various communication protocols for the transportation of sensor or event data. These protocols enable applications to collect, store, process, describe, and analyze data to solve a variety of problems. IoT also aims to provide secure, bi-directional communication between interconnected devices, such as sensors, actuators, microcontrollers or smart appliances, and corresponding cloud services. In this paper we analyze the growth of M2M protocol research (MQTT, AMQP, and CoAP) over the past 20 years, and show how the growth in MQTT research stands out from the rest. We also gather relevant application areas of MQTT, as the most widespread M2M/IoT protocol, by performing a detailed literature search in major digital research archives. Our quantitative evaluation presents some of the important MQTT-related studies published in the past five years, which we compare to discuss the main features, advantages, and limitations of the MQTT protocol. We also propose a taxonomy to compare the properties and features of various MQTT implementations, i.e. brokers and libraries currently available in the public domain to help researchers and end-users to efficiently choose a broker or client library based on their requirements. Finally, we discuss the relevant findings of our comparison and highlight open issues that need further research and attention.","['Protocols', 'Internet of Things', 'Machine-to-machine communications', 'Reliability', 'Quality of service', 'Cloud computing', 'ISO Standards']","['IoT', 'IoT protocols', 'MQTT', 'MQTT brokers', 'survey']"
"Deep neural networks (DNNs) have shown prominent performance in the field of object detection. However, DNNs usually run on powerful devices with high computational ability and sufficient memory, which have greatly limited their deployment for constrained environments such as embedded devices. YOLO is one of the state-of-the-art DNN-based object detection approaches with good performance both on speed and accuracy and Tiny-YOLO-V3 is its latest variant with a small model that can run on embedded devices. In this paper, Tinier-YOLO, which is originated from Tiny-YOLO-V3, is proposed to further shrink the model size while achieving improved detection accuracy and real-time performance. In Tinier-YOLO, the fire module in SqueezeNet is appointed by investigating the number of fire modules as well as their positions in the model in order to reduce the number of model parameters and then reduce the model size. For further improving the proposed Tinier-YOLO in terms of detection accuracy and real-time performance, the connectivity style between fire modules in Tinier-YOLO differs from SqueezeNet in that dense connection is introduced and fine designed to strengthen the feature propagation and ensure the maximum information flow in the network. The object detection performance is enhanced in Tinier-YOLO by using the passthrough layer that merges feature maps from the front layers to get fine-grained features, which can counter the negative effect of reducing the model size. The resulting Tinier-YOLO yields a model size of 8.9MB (almost 4× smaller than Tiny-YOLO-V3) while achieving 25 FPS real-time performance on Jetson TX1 and an mAP of 65.7% on PASCAL VOC and 34.0% on COCO. Tinier-YOLO alse posses comparable results in mAP and faster runtime speed with smaller model size and BFLOP/s value compared with other lightweight models like SqueezeNet SSD and MobileNet SSD.","['Object detection', 'Real-time systems', 'Feature extraction', 'Detectors', 'Convolution', 'Performance evaluation', 'Computational modeling']","['Constrained environments', 'dense connection', 'fire modules', 'passthrough layer', 'YOLO']"
"Many countries are challenged by the medical resources required for COVID-19 detection which necessitates the development of a low-cost, rapid tool to detect and diagnose the virus effectively for a large numbers of tests. Although a chest X-Ray scan is a useful candidate tool the images generated by the scans must be analyzed accurately and quickly if large numbers of tests are to be processed. COVID-19 causes bilateral pulmonary parenchymal ground-glass and consolidative pulmonary opacities, sometimes with a rounded morphology and a peripheral lung distribution. In this work, we aim to extract rapidly from chest X-Ray images the similar small regions that may contain the identifying features of COVID-19. This paper therefore proposes a hybrid COVID-19 detection model based on an improved marine predators algorithm (IMPA) for X-Ray image segmentation. The ranking-based diversity reduction (RDR) strategy is used to enhance the performance of the IMPA to reach better solutions in fewer iterations. RDR works on finding the particles that couldn't find better solutions within a consecutive number of iterations, and then moving those particles towards the best solutions so far. The performance of IMPA has been validated on nine chest X-Ray images with threshold levels between 10 and 100 and compared with five state-of-art algorithms: equilibrium optimizer (EO), whale optimization algorithm (WOA), sine cosine algorithm (SCA), Harris-hawks algorithm (HHA), and salp swarm algorithms (SSA). The experimental results demonstrate that the proposed hybrid model outperforms all other algorithms for a range of metrics. In addition, the performance of our proposed model was convergent on all numbers of thresholds level in the Structured Similarity Index Metric (SSIM) and Universal Quality Index (UQI) metrics.","['Image segmentation', 'COVID-19', 'Entropy', 'Clustering algorithms', 'X-ray imaging', 'Feature extraction', 'Measurement']","['COVID-19 detection', 'marine predators algorithm', 'ranking-based reduction diversity', 'Kapur’s entropy', 'image segmentation']"
"This paper proposes a new chaotic image encryption scheme, which employs Josephus traversing and mixed chaotic map. The scheme consists of three processes: key stream generation process; three-round scrambling process; and one-round diffusion process. The proposed mathematical model is applied for the key stream generator in the first process. The initial values and parameters are sensitive to both the secret keys in the new scheme and plain images. The second process employs the Josephus traversing in scrambling; then the rows and columns of pixels are exchanged. The third process can modify the pixel gray-level values and crack the strong correlations between adjacent pixels simultaneously. The initial conditions for chaotic systems are derived using external secret keys by applying some algebraic transformations to the key. Security analysis indicates that the new scheme is effective, which can resist common attacks.","['Encryption', 'Chaos', 'Logistics', 'Mathematical model', 'Diffusion processes']","['Gray-scale', 'image analysis', 'cryptography', 'encryption', 'diffusion processes', 'chaos']"
"Currently, Internet of Things (IoT) and blockchain technologies are experiencing exponential growth in academia and industry. Generally, IoT is a centralized system whose security and performance mainly rely on centralized servers. Therefore, users have to trust the centralized servers; in addition, it is difficult to coordinate external computing resources to improve the performance of IoT. Fortunately, the blockchain may provide this decentralization, high credibility and high security. Consequently, blockchain-based IoT may become a reasonable choice for the design of a decentralized IoT system. In this paper, we propose a novel blockchain-based threshold IoT service system: BeeKeeper. In the BeeKeeper system, servers can process a user's data by performing homomorphic computations on the data without learning anything from them. Furthermore, any node can become a leader's server if the node and the leader desire so. In this way, BeeKeeper's performance can continually increase by attracting external computing resources to join in it. Moreover, malicious nodes can be scrutinized. In addition, BeeKeeper is fault tolerant since a user's BeeKeeper protocol may work smoothly as long as a threshold number of its servers are active and honest. Finally, we deploy BeeKeeper on the Ethereum blockchain and give the corresponding performance evaluation. In our experiments, servers can generate their response with about 107 ms. Moreover, the performance of BeeKeeper mainly depends on the blockchain platform. For instance, the response time is about 22.5 s since the block interval of Ethereum blockchain is about 15 s. In fact, if we use some other blockchain with short block interval, the response time may be obviously short.","['Servers', 'Cryptography', 'Performance evaluation', 'Contracts', 'Protocols', 'Internet of Things']","['IoT', 'blockchain', 'secret sharing', 'secure multi-party computing']"
"Automated modulation classification plays a very important part in cognitive radio networks. Deep learning is also a powerful tool that we could not overlook its potential in addressing signal modulation recognition problem. In our last work, we propose a new data conversion algorithm in order to gain a better classification accuracy of communication signal modulation, but we still believe that the convolution neural network (CNN) can work better. However, its application to signal modulation recognition is often hampered by insufficient data and overfitting. Here, we propose a smart approach to programmatic data augmentation method by using the auxiliary classifier generative adversarial networks (ACGANs). The famous CNN model, AlexNet, has been utilized to be the classifier and ACGAN to be the generator, which will enlarge our data set. In order to alleviate the common issues in the traditional generative adversarial nets training, such as discriminator overfitting, generator disconverge, and mode collapse, we apply several training tricks in our training. With the result on original data set as our baseline, we will evaluate our result on enlarged data set to validate the ACGAN’s performance. The result shows that we can gain 0.1~6% increase in the classification accuracy in the ACGAN-based data set.","['Constellation diagram', 'Training', 'Gallium nitride', 'Phase shift keying', 'Image color analysis', 'Signal to noise ratio']","['Cognitive radio', 'modulation recognition', 'pattern recognition', 'classification algorithms', 'deep learning', 'convolutional networks', 'generative adversarial net']"
"Virtual inertia control is considered as an important part of microgrids with high renewable penetration. Virtual inertia emulation based on the derivative of frequency is one of the effective methods for improving system inertia and maintaining frequency stability. However, in this method, the ability to provide virtual damping is usually neglected in its design, and hence, its performance might be insufficient in the system with low damping. Confronted with this issue, this paper proposes a novel design and analysis of virtual inertia control to imitate damping and inertia properties simultaneously to the microgrid, enhancing frequency performance and stability. The proposed virtual inertia control uses the derivative technique to calculate the derivative of frequency for virtual inertia emulation. Trajectory sensitivities have been performed to analyze the dynamic impacts of the virtual inertia and virtual damping variables over the system performance. Time-domain simulations are also presented to evaluate the efficiency of the virtual damping and virtual inertia in enhancing system frequency stability. Finally, the efficiency and robustness of the proposed control technique are compared with the conventional inertia control under a wide range of system operation, including the decrease in system damping and inertia and high integrations of load variation and renewable energy.","['Damping', 'Microgrids', 'Frequency control', 'Power system stability', 'Stability analysis', 'Synchronous generators', 'Power system dynamics']","['Frequency stability', 'isolated microgrid', 'virtual inertia regulation', 'virtual synchronous machine']"
"In recent years, the IoT concept is more and more powerful, having set the goal of integrating billions of devices to the Internet. Thus, from this perspective, the interest allocated to low-power wireless networks of sensors is higher than ever. In this paper, the SigFox scalability is analyzed from the IoT concept point of view. In the scientific research, there are a series of papers which tackle the SigFox issues, oftentimes at a comparative study level, without evaluating the performance level of the communication protocol. This paper comes to fill this gap by creating a realistic SigFox communication model. Moreover, a developed and tested generator of SigFox traffic has been implemented, using SDRs. This allows the possibility of evaluating the performance level of WSN networks, of a large-scale high-density-type. Both of the suggested instruments represent the novelty of this paper. The obtained results show that the maximum number of sensors that can transmit data at the same time, using the proposed scenarios, is of approximately 100, in order to obtain a high level of performance when the number of available channels is 360. If we are to increase the number of sensors, an avalanche effect ensues which triggers the sharp decrease of the performance of the SigFox network. At the end of this work, a series of solutions are being suggested with the main purpose of increasing the performance level of large-scale, high-density SigFox networks.","['Logic gates', 'Sensors', 'Scalability', 'Europe', 'Wireless sensor networks', 'Internet of Things', 'Modulation']","['Internet of Things', 'scalability', 'wireless sensor networks']"
"Deep learning methods, such as convolution neural networks (CNNs), have achieved remarkable success in computer vision tasks. Hence, an increasing trend in using deep learning for electroencephalograph (EEG) analysis is evident. Extracting relevant information from CNN features is one of the key reasons behind the success of the CNN-based deep learning models. Some CNN models use convolutional features from different CNN layers with good effect. However, extraction and fusion of multilevel convolutional features remain unexplored for EEG applications. Moreover, cognitive computing and artificial intelligence experience increasing applications in all fields. Cognitive process is based on understanding human brain cognition through signals, such as EEG. Hence, deep learning can aid in developing cognitive systems and related applications by improving EEG decoding. The classification and recognition of EEG have consistently been challenging due to its characteristics of dynamic time series data and low signal-to-noise ratio. However, the information hidden in different convolution layers can aid in improving feature discrimination capability. In this paper, we use the EEG motor imagery data to uncover the benefits of extracting and fusing multilevel convolutional features from different CNN layers, which are abstract representations of the input at various levels. Our proposed CNN model can learn robust spectral and temporal features from the raw EEG data. We demonstrate that such multilevel feature fusion outperforms the models that use features only from the last layer. Our results are better than the state of the art for EEG decoding and classification.","['Electroencephalography', 'Feature extraction', 'Brain modeling', 'Deep learning', 'Convolution', 'Task analysis', 'Data mining']","['EEG motor imagery classification', 'deep learning', 'convolution neural network', 'multilevel feature fusion']"
"Internet of Medical Things (IoMT) is the collection of medical devices and related applications which link the healthcare IT systems through online computer networks. In the field of diagnosis, medical image classification plays an important role in prediction and early diagnosis of critical diseases. Medical images form an indispensable part of a patient's health record which can be applied to control, handle and treat the diseases. But, classification of images is a challenging task in computer-based diagnostics. In this research article, we have introduced a improved classifier i.e., Optimal Deep Learning (DL) for classification of lung cancer, brain image, and Alzheimer's disease. The researchers proposed the Optimal Feature Selection based Medical Image Classification using DL model by incorporating preprocessing, feature selection and classification. The main goal of the paper is to derive an optimal feature selection model for effective medical image classification. To enhance the performance of the DL classifier, Opposition-based Crow Search (OCS) algorithm is proposed. The OCS algorithm picks the optimal features from pre-processed images, here Multi-texture, grey level features were selected for the analysis. Finally, the optimal features improved the classification result and increased the accuracy, specificity and sensitivity in the diagnosis of medical images. The proposed results were implemented in MATLAB and compared with existing feature selection models and other classification approaches. The proposed model achieved the maximum performance in terms of accuracy, sensitivity and specificity being 95.22%, 86.45 % and 100% for the applied set of images.","['Medical diagnostic imaging', 'Feature extraction', 'Deep learning', 'Solid modeling', 'Cancer']","['IoMT', 'classification', 'deep learning', 'medical image', 'features', 'Crow search algorithm', 'optimization']"
"Video and images acquired by a visual system are seriously degraded under hazy and foggy weather, which will affect the detection, tracking, and recognition of targets. Thus, restoring the true scene from such a foggy video or image is of significance. The main goal of this paper was to summarize current video and image defogging algorithms. We first presented a review of the detection and classification method of a foggy image. Then, we summarized existing image defogging algorithms, including image restoration algorithms, image contrast enhancement algorithms, and fusion-based defogging algorithms. We also presented current video defogging algorithms. We summarized objective image quality assessment methods that have been widely used for the comparison of different defogging algorithms, followed by an experimental comparison of various classical image defogging algorithms. Finally, we presented the problems of video and image defogging which need to be further studied. The code of all algorithms will be available at <;uri xlink:href=""http://www.yongxu.org/lunwen.html"" xlink:type=""simple"">http://www.yongxu.org/lunwen.html<;/uri>.","['Classification algorithms', 'Visual systems', 'Image restoration', 'Meteorology', 'Feature extraction', 'Image classification', 'Defogging']","['Foggy image classification', 'image defogging', 'video defogging', 'image quality assessment']"
"Melanoma is a type of skin cancer with a high mortality rate. The different types of skin lesions result in an inaccurate diagnosis due to their high similarity. Accurate classification of the skin lesions in their early stages enables dermatologists to treat the patients and save their lives. This paper proposes a model for a highly accurate classification of skin lesions. The proposed model utilized the transfer learning and pre-trained model with GoogleNet. The model parameters are used as initial values, and then these parameters will be modified through training. The latest well-known public challenge dataset, ISIC 2019, is used to test the ability of the proposed model to classify different kinds of skin lesions. The proposed model successfully classified the eight different classes of skin lesions, namely, melanoma, melanocytic nevus, basal cell carcinoma, actinic keratosis, benign keratosis, dermatofibroma, vascular lesion, and Squamous cell carcinoma. The achieved classification accuracy, sensitivity, specificity, and precision percentages are 94.92%, 79.8%, 97%, and 80.36%, respectively. The proposed model can detect images that do not belong to any one of the eight classes where these images are classified as unknown images.","['Lesions', 'Skin', 'Melanoma', 'Computer architecture', 'Support vector machines', 'Feature extraction']","['Melanoma classification', 'skin lesions', 'convolution neural network', 'GoogleNet', 'ISIC 2019', 'bootstrap multiclass SVM', 'transfer learning']"
"The Internet of Things (IoT) is an emerging classical model, envisioned as a system of billions of small interconnected devices for posing the state-of-the-art findings to real-world glitches. Over the last decade, there has been an increasing research concentration in the IoT as an essential design of the constant convergence between human behaviors and their images on Information Technology. With the development of technologies, the IoT drives the deployment of across-the-board and self-organizing wireless networks. The IoT model is progressing toward the notion of a cyber-physical world, where things can be originated, driven, intermixed, and modernized to facilitate the emergence of any feasible association. This paper provides a summary of the existing IoT research that underlines enabling technologies, such as fog computing, wireless sensor networks, data mining, context awareness, real-time analytics, virtual reality, and cellular communications. Also, we present the lessons learned after acquiring a thorough representation of the subject. Thus, by identifying numerous open research challenges, it is presumed to drag more consideration into this novel paradigm.","['Smart cities', 'Wireless sensor networks', 'Internet of Things', 'Sensors', 'Edge computing', 'Data mining']","['Internet of Things', 'fog computing', 'wireless sensor networks', 'smart cities', 'cellular IoT', 'real-time analytics']"
"Emerging technologies rapidly change the essential qualities of modern societies in terms of smart environments. To utilize the surrounding environment data, tiny sensing devices and smart gateways are highly involved. It has been used to collect and analyze the real-time data remotely in all Industrial Internet of Things (IIoT). Since the IIoT environment gathers and transmits the data over insecure public networks, a promising solution known as authentication and key agreement (AKA) is preferred to prevent illegal access. In the medical industry, the Internet of Medical Things (IoM) has become an expert application system. It is used to gather and analyze the physiological parameters of patients. To practically examine the medical sensor-nodes, which are imbedded in the patient's body. It would in turn sense the patient medical information using smart portable devices. Since the patient information is so sensitive to reveal other than a medical professional, the security protection and privacy of medical data are becoming a challenging issue of the IoM. Thus, an anonymity-based user authentication protocol is preferred to resolve the privacy preservation issues in the IoM. In this paper, a Secure and Anonymous Biometric Based User Authentication Scheme (SAB-UAS) is proposed to ensure secure communication in healthcare applications. This paper also proves that an adversary cannot impersonate as a legitimate user to illegally access or revoke the smart handheld card. A formal analysis based on the random-oracle model and resource analysis is provided to show security and resource efficiencies in medical application systems. In addition, the proposed scheme takes a part of the performance analysis to show that it has high-security features to build smart healthcare application systems in the IoM. To this end, experimental analysis has been conducted for the analysis of network parameters using NS3 simulator. The collected results have shown superiority in terms of the packet delivery ratio, end-to-end delay, throughput rates, and routing overhead for the proposed SAB-UAS in comparison to other existing protocols.","['Authentication', 'Sensors', 'Wireless sensor networks', 'Password', 'Analytical models', 'Protocols']","['Authentication and key agreement', 'internet of medical things', 'security protection and privacy user authentication', 'random-oracle model and resource analysis', 'e-healthcare application', 'biometrics']"
"The Internet of Things (IoT) has been widely used because of its high efficiency and real-time collaboration. A wireless sensor network is the core technology to support the operation of the IoT, and the security problem is becoming more and more serious. Aiming at the problem that the existing malicious node detection methods in wireless sensor networks cannot be guaranteed by fairness and traceability of detection process, we present a blockchain trust model (BTM) for malicious node detection in wireless sensor networks. First, it gives the whole framework of the trust model. Then, it constructs the blockchain data structure which is used to detect malicious nodes. Finally, it realizes the detection of malicious nodes in 3D space by using the blockchain smart contract and the WSNs' quadrilateral measurement localization method, and the voting consensus results are recorded in the blockchain distributed. The simulation results show that the model can effectively detect malicious nodes in WSNs, and it can also ensure the traceability of the detection process.","['Wireless sensor networks', 'Blockchain', 'Smart contracts', 'Peer-to-peer computing', 'Intelligent sensors', 'Monitoring']","['Wireless sensor networks', 'blockchain', 'smart contract', 'malicious nodes', 'vote']"
"Wireless sensor networks (WSNs) have gained wide attention from researchers in the last few years because it has a vital role in countless applications. The main function of WSN is to process extracted data and to transmit it to remote locations. A large number of sensor nodes are deployed in the monitoring area. Therefore, deploying the minimum number of nodes that maintain full coverage and connectivity is of immense importance for research. Hence, coverage and connectivity issues, besides maximizing the network lifetime, represented the main concern to be considered in this paper. The key point of this paper is to classify different coverage techniques in WSNs into three main parts: coverage based on classical deployment techniques, coverage based on meta-heuristic techniques, and coverage based on self-scheduling techniques. Moreover, multiple comparisons among these techniques are provided considering their advantages and disadvantages. Additionally, performance metrics that must be considered in WSNs and comparison among different WSNs simulators are provided. Finally, open research issues, as well as recommendations for researchers, are discussed.","['Wireless sensor networks', 'Sensors', 'Monitoring', 'Mathematical model', 'Routing', 'Data mining', 'Measurement']","['Coverage', 'connectivity', 'deployment techniques', 'power consumption', 'wireless sensor network (WSN)']"
"Blockchain technology becomes increasingly popular. It also attracts scams, for example, a Ponzi scheme, a classic fraud, has been found making a notable amount of money on Blockchain, which has a very negative impact. To help to deal with this issue and to provide reusable research data sets for future research, this paper collects real-world samples and proposes an approach to detect Ponzi schemes implemented as smart contracts (i.e., smart Ponzi schemes) on the blockchain. First, 200 smart Ponzi schemes are obtained by manually checking more than 3,000 open source smart contracts on the Ethereum platform. Then, two kinds of features are extracted from the transaction history and operation codes of the smart contracts. Finally, a classification model is presented to detect smart Ponzi schemes. The extensive experiments show that the proposed model performs better than many traditional classification models and can achieve high accuracy for practical use. By using the proposed approach, we estimate that there are more than 500 smart Ponzi schemes running on Ethereum. Based on these results, we propose to build a uniform platform to evaluate and monitor every created smart contract for early warning of scams.","['Smart contracts', 'Blockchain', 'Feature extraction', 'Internet', 'High level languages', 'History']","['Blockchain', 'smart contract', 'Ponzi Schemes', 'ethereum', 'data mining']"
"Now-a-days image processing placed an important role for recognizing various diseases such as breast, lung, and brain tumors in earlier stage for giving the appropriate treatment. Presently, most cancer diagnosis worked according to the visual examination process with effectively. Human visual reviewing of infinitesimal biopsy pictures is exceptionally tedious, subjective, and conflicting due to between and intra-onlooker varieties. In this manner, the malignancy and it’s compose will be distinguished in a beginning time for finish treatment and fix. This brain tumor classification system using machine learning-based back propagation neural networks (MLBPNN) causes pathologists to enhance the exactness and proficiency in location of threat and to limit the entomb onlooker variety. Moreover, the technique may assist doctors with analyzing the picture cell by utilizing order and bunching calculations by recoloring qualities of the phones. The different picture preparing steps required for disease location from biopsy pictures incorporate procurement, upgrade, and division; include extraction, picture portrayal, characterization, and basic leadership. In this paper, MLBPNN is analyzed with the help of infra-red sensor imaging technology. Then, the computational multifaceted nature of neural distinguishing proof incredibly diminished when the entire framework is deteriorated into a few subsystems. The features are extracted using fractal dimension algorithm and then the most significant features are selected using multi fractal detection technique to reduce the complexity. This imaging sensor is integrated via wireless infrared imaging sensor which is produced to transmit the tumor warm data to a specialist clinician to screen the wellbeing condition and for helpful control of ultrasound measurements level, especially if there should arise an occurrence of elderly patients living in remote zones.","['Tumors', 'Magnetic resonance imaging', 'Feature extraction', 'Fractals', 'Biological neural networks', 'Image segmentation']","['Wireless infrared imaging sensor', 'infra-red sensor', 'principal component analysis gray level covariance matrix', 'machine learning based neural networks']"
"Falls are abnormal activity events that occur infrequently; however, they are serious health problems among elderly individuals. With the advancements of technologies, falls have been widely studied by scientific researchers to minimize serious consequences and negative impacts. Fall detection and fall prevention are two strategies to tackle fall issues with a variety of sensing techniques and classifier models. Currently, many reviews on fall-related technologies have been presented and analyzed; however, most of them give surveys on the subfield of fall-related systems, while others are not extensive and comprehensive reviews. In fact, the latest researches have a new trend of fusion-based methods to improve the performance of the fall-related systems based on a combination of different sensors or classifier models. Adaptive threshold and radio frequency-based systems are also researched and proposed recently, which are seldom mentioned in other reviews. Therefore, a global taxonomy for current fall-related studies from four aspects, including current literature reviews, fall detection, and prevention systems based on different sensor apparatus and analytic algorithm, low power techniques, and sensor placements for fall-related systems are conducted in this paper. Several research challenges and issues in the fall-related field are also discussed and analyzed. The objective of this review paper is to conclude and provide a good position of current fall-related studies to inspire researchers in this field.","['Sensor systems', 'Taxonomy', 'Senior citizens', 'Bibliographies', 'Systematics', 'Aging']","['Adaptive algorithm', 'classification algorithms', 'fall detection', 'fall prevention', 'low power techniques', 'sensing techniques']"
"With a wide scope to explore and harness the oceanic sources of interest, the field of underwater wireless sensor networks (UWSNs) is attracting a growing interest of researchers. Owing to the real-time remote data monitoring requirements, underwater acoustic sensor networks (UASNs) emerged as a preferred network to a great extent. In UASN, the limited availability and non-rechargeability of energy resources along with the relative inaccessibility of deployed sensor nodes for energy replenishments necessitated the evolution of several energy optimization techniques. Clustering is one such technique that increases system scalability and reduces energy consumption. Besides clustering, coverage and connectivity are two significant properties that decide the proper detection and communication of events of interest in UWSN due to unstable underwater environment. Underwater communication is also possible with non-acoustic communication techniques like radio frequency, magnetic induction, and underwater free-space optics. In this paper, we surveyed clustering, coverage, and connectivity issues of UASN and qualitatively compared their performance. Particularly, the impact of these non-conventional communication techniques on clustering, coverage, and connectivity aspects is demonstrated. Additionally, we highlighted some key open issues related to the UWSN. This paper provides a broad view of existing algorithms of clustering, coverage, and connectivity based on acoustic communication. It also provides a useful guidance to the researchers in UWSN from various other communication techniques' perspective.","['Wireless sensor networks', 'Radio frequency', 'Clustering algorithms', 'Wireless communication', 'Underwater acoustics', 'Monitoring', 'Magnetoacoustic effects']","['Clustering', 'connectivity', 'coverage', 'RF', 'MI', 'UWFSO', 'acoustic', 'underwater wireless sensor networks']"
"Healthcare supply chains are complex structures spanning across multiple organizational and geographical boundaries, providing critical backbone to services vital for everyday life. The inherent complexity of such systems can introduce impurities including inaccurate information, lack of transparency and limited data provenance. Counterfeit drugs is one consequence of such limitations within existing supply chains which not only has serious adverse impact on human health but also causes severe economic loss to the healthcare industry. Consequently, existing studies have emphasized the need for a robust, end-to-end track and trace system for pharmaceutical supply chains. Therein, an end-to-end product tracking system across the pharmaceutical supply chain is paramount to ensuring product safety and eliminating counterfeits. Most existing track and trace systems are centralized leading to data privacy, transparency and authenticity issues in healthcare supply chains. In this article, we present an Ethereum blockchain-based approach leveraging smart contracts and decentralized off-chain storage for efficient product traceability in the healthcare supply chain. The smart contract guarantees data provenance, eliminates the need for intermediaries and provides a secure, immutable history of transactions to all stakeholders. We present the system architecture and detailed algorithms that govern the working principles of our proposed solution. We perform testing and validation, and present cost and security analysis of the system to evaluate its effectiveness to enhance traceability within pharmaceutical supply chains.","['Drugs', 'Supply chains', 'Medical services', 'Blockchain', 'Stakeholders', 'Smart contracts', 'Industries']","['Blockchain', 'drug counterfeiting', 'traceability', 'healthcare', 'supply chain', 'trust', 'security']"
"Images captured under poor illumination conditions often exhibit characteristics such as low brightness, low contrast, a narrow gray range, and color distortion, as well as considerable noise, which seriously affect the subjective visual effect on human eyes and greatly limit the performance of various machine vision systems. The role of low-light image enhancement is to improve the visual effect of such images for the benefit of subsequent processing. This paper reviews the main techniques of low-light image enhancement developed over the past decades. First, we present a new classification of these algorithms, dividing them into seven categories: gray transformation methods, histogram equalization methods, Retinex methods, frequency-domain methods, image fusion methods, defogging model methods and machine learning methods. Then, all the categories of methods, including subcategories, are introduced in accordance with their principles and characteristics. In addition, various quality evaluation methods for enhanced images are detailed, and comparisons of different algorithms are discussed. Finally, the current research progress is summarized, and future research directions are suggested.","['Image enhancement', 'Image color analysis', 'Brightness', 'Color', 'Lighting', 'Visual effects', 'Machine learning algorithms']","['Review', 'survey', 'low-light image enhancement', 'Retinex method', 'image enhancement', 'quality evaluation']"
"An intrusion detection system (IDS) is an important protection instrument for detecting complex network attacks. Various machine learning (ML) or deep learning (DL) algorithms have been proposed for implementing anomaly-based IDS (AIDS). Our review of the AIDS literature identifies some issues in related work, including the randomness of the selected algorithms, parameters, and testing criteria, the application of old datasets, or shallow analyses and validation of the results. This paper comprehensively reviews previous studies on AIDS by using a set of criteria with different datasets and types of attacks to set benchmarking outcomes that can reveal the suitable AIDS algorithms, parameters, and testing criteria. Specifically, this paper applies 10 popular supervised and unsupervised ML algorithms for identifying effective and efficient ML-AIDS of networks and computers. These supervised ML algorithms include the artificial neural network (ANN), decision tree (DT), k-nearest neighbor (k-NN), naive Bayes (NB), random forest (RF), support vector machine (SVM), and convolutional neural network (CNN) algorithms, whereas the unsupervised ML algorithms include the expectation-maximization (EM), k-means, and self-organizing maps (SOM) algorithms. Several models of these algorithms are introduced, and the turning and training parameters of each algorithm are examined to achieve an optimal classifier evaluation. Unlike previous studies, this study evaluates the performance of AIDS by measuring the true positive and negative rates, accuracy, precision, recall, and F-Score of 31 ML-AIDS models. The training and testing time for ML-AIDS models are also considered in measuring their performance efficiency given that time complexity is an important factor in AIDSs. The ML-AIDS models are tested by using a recent and highly unbalanced multiclass CICIDS2017 dataset that involves real-world network attacks. In general, the k-NN-AIDS, DT-AIDS, and NB-AIDS models obtain the best results and show a greater capability in detecting web attacks compared with other models that demonstrate irregular and inferior results.","['Classification algorithms', 'Feature extraction', 'Training', 'Benchmark testing', 'Support vector machines', 'Self-organizing feature maps', 'Radio frequency']","['Cyberattacks', 'intrusion detection system', 'machine learning', 'supervised and unsupervised learning']"
"Feature selection (FS) is one of the important tasks of data preprocessing in data analytics. The data with a large number of features will affect the computational complexity, increase a huge amount of resource usage and time consumption for data analytics. The objective of this study is to analyze relevant and significant features of huge network traffic to be used to improve the accuracy of traffic anomaly detection and to decrease its execution time. Information Gain is the most feature selection technique used in Intrusion Detection System (IDS) research. This study uses Information Gain, ranking and grouping the features according to the minimum weight values to select relevant and significant features, and then implements Random Forest (RF), Bayes Net (BN), Random Tree (RT), Naive Bayes (NB) and J48 classifier algorithms in experiments on CICIDS-2017 dataset. The experiment results show that the number of relevant and significant features yielded by Information Gain affects significantly the improvement of detection accuracy and execution time. Specifically, the Random Forest algorithm has the highest accuracy of 99.86% using the relevant selected features of 22, whereas the J48 classifier algorithm provides an accuracy of 99.87% using 52 relevant selected features with longer execution time.","['Feature extraction', 'Classification algorithms', 'Anomaly detection', 'Information filters', 'Support vector machines', 'Filtering algorithms']","['Feature selection', 'anomaly detection', 'information gain', 'CICIDS-2017 dataset', 'classifier algorithm']"
"The IoT (Internet of Things) connect systems, applications, data storage, and services that may be a new gateway for cyber-attacks as they continuously offer services in the organization. Currently, software piracy and malware attacks are high risks to compromise the security of IoT. These threats may steal important information that causes economic and reputational damages. In this paper, we have proposed a combined deep learning approach to detect the pirated software and malware-infected files across the IoT network. The TensorFlow deep neural network is proposed to identify pirated software using source code plagiarism. The tokenization and weighting feature methods are used to filter the noisy data and further, to zoom the importance of each token in terms of source code plagiarism. Then, the deep learning approach is used to detect source code plagiarism. The dataset is collected from Google Code Jam (GCJ) to investigate software piracy. Apart from this, the deep convolutional neural network is used to detect malicious infections in IoT network through color image visualization. The malware samples are obtained from Maling dataset for experimentation. The experimental results indicate that the classification performance of the proposed solution to measure the cybersecurity threats in IoT are better than the state of the art methods.","['Malware', 'Feature extraction', 'Plagiarism', 'Computer crime', 'Internet of Things', 'Computer languages']","['Internet of Things', 'data mining', 'cyber security', 'software piracy', 'malware detection']"
"One of the major research topics in unmanned aerial vehicle (UAV) collaborative control systems is the problem of multi-UAV target assignment and path planning (MUTAPP). It is a complicated optimization problem in which target assignment and path planning are solved separately. However, recalculation of the optimal results is too slow for real-time operations in dynamic environments because of the large number of calculations required. In this paper, we propose an artificial intelligence method named simultaneous target assignment and path planning (STAPP) based on a multi-agent deep deterministic policy gradient (MADDPG) algorithm, which is a type of multi-agent reinforcement learning algorithm. In STAPP, the MUTAPP problem is first constructed as a multi-agent system. Then, the MADDPG framework is used to train the system to solve target assignment and path planning simultaneously according to a corresponding reward structure. The proposed system can deal with dynamic environments effectively as its execution only requires the locations of the UAVs, targets, and threat areas. Real-time performance can be guaranteed as the neural network used in the system is simple. In addition, we develop a technique to improve the training effect and use experiments to demonstrate the effectiveness of our method.","['Path planning', 'Heuristic algorithms', 'Optimization', 'Training', 'Reinforcement learning', 'Task analysis', 'Unmanned aerial vehicles']","['Multi-UAV', 'target assignment and path planning', 'multi-agent reinforcement learning', 'MADDPG', 'dynamic environments']"
"Hurricanes regularly cause widespread and prolonged power outages along the U.S. coastline. These power outages have significant impacts on other infrastructure dependent on electric power and on the population living in the impacted area. Efficient and effective emergency response planning within power utilities, other utilities dependent on electric power, private companies, and local, state, and federal government agencies benefit from accurate estimates of the extent and spatial distribution of power outages in advance of an approaching hurricane. A number of models have been developed for predicting power outages in advance of a hurricane, but these have been specific to a given utility service area, limiting their use to support wider emergency response planning. In this paper, we describe the development of a hurricane power outage prediction model applicable along the full U.S. coastline using only publicly available data, we demonstrate the use of the model for Hurricane Sandy, and we use the model to estimate what the impacts of a number of historic storms, including Typhoon Haiyan, would be on current U.S. energy infrastructure.","['Storms', 'Hurricanes', 'Predictive models', 'Contingency planning', 'Emergency services', 'Power outages', 'Power system restoration']","['Hurricane', 'storm response planning', 'outage prediction', 'outage model']"
"One of the most common types of human malignancies is skin cancer, which is chiefly diagnosed visually, initiating with a clinical screening followed by dermoscopic analysis, histopathological assessment, and a biopsy. Due to the fine-grained differences in the appearance of skin lesions, automated classification is quite challenging through images. To attain highly segregated and potentially general tasks against the finely grained object categorized, deep convolutional neural networks (CNNs) are used. In this paper, we propose a new prediction model that classifies skin lesions into benign or malignant lesions based on a novel regularizer technique. Hence, this is a binary classifier that discriminates between benign or malignant lesions. The proposed model achieved an average accuracy of 97.49%, which in turns showed its superiority over other state-of-the-art methods. The performance of CNN in terms of AUC-ROC with an embedded novel regularizer is tested on multiple use cases. The area under the curve (AUC) achieved for nevus against melanoma lesion, seborrheic keratosis versus basal cell carcinoma lesion, seborrheic keratosis versus melanoma lesion, solar lentigo versus melanoma lesion is 0.77, 0.93, 0.85, and 0.86, respectively. Our results showed that the proposed learning model outperformed the existing algorithm and can be used to assist medical practitioners in classifying various skin lesions.","['Melanoma', 'Skin', 'Lesions', 'Feature extraction', 'Convolution']","['Convolutional neural network', 'skin lesion', 'novel regularizer', 'AUC-ROC']"
"Battery State-of-Health (SOH) estimation is of utmost importance for the performance and cost-effectiveness of electric vehicles. Incremental capacity analysis (ICA) has been ubiquitously used for battery SOH estimation. However, challenges remain with regard to the characteristic parameter selection, estimation viability and feasibility for practical implementation. In this paper, a novel ICA-based method for battery SOH estimation is proposed, with the goals to identify the most effective characteristic parameters of IC curves, optimize the SOH model parameters for better prediction accuracy and enhance its applicability in realistic battery management systems. To this end, the IC curve is first derived and filtered using the wavelet filtering, with the peak value and position extracted as health factors (HFs). Then, the correlations between SOH and HFs are explored through the grey correlation analysis. The SOH model is further established based on the Gaussian process regression (GPR), in which the optimal hyper parameters are calculated through the conjugate gradient method and the multi-island genetic algorithm (MIGA). The effects of different HFs and kernel functions are also analyzed. The effectiveness of the proposed MIGA-GPR SOH model is validated by experimentation.","['Estimation', 'Degradation', 'Wavelet transforms', 'Integrated circuits', 'Gaussian processes']","['Batteries', 'incremental capacity analysis', 'state of health', 'Gaussian process regression', 'multi-island genetic algorithm']"
"Energy storage systems are playing an increasingly important role in a variety of applications, such as electric vehicles or grid-connected systems. In this context, supercapacitors (SCs) are gaining ground due to their high power density, good performance, and long maintenance-free lifetime. For this reason, SCs are a hot research topic, and several papers are being published on material engineering, performance characterization, modeling. and post-mortem analysis. A compilation of the most important millstones on this topic is essential to keep researchers on related fields updated about new potentials of this technology. This review paper covers recent research aspects and applications of SCs, highlighting the relationship between material properties and electrical characteristics. It begins with an explanation of the energy storage mechanisms and materials used by SCs. Based on these materials, the SCs are classified, their key features are summarized, and their electrochemical characteristics are related to electrical performance. Given the high interest in system modeling and a large number of papers published on this topic, modeling techniques are classified, explained, and compared, addressing their strengths and weaknesses, and the experimental techniques used to measure the modeled properties are described. Finally, SCs are successfully used in the market sectors, as well as their growth expectations are analyzed. The analysis presented herein gives the account of the expansion that the SC market is currently undergoing and identifies the most promising research trends on this field.","['Electrodes', 'Supercapacitors', 'Market research', 'Electrolytes', 'Batteries']","['Electrical performance', 'electrochemistry', 'energy storage', 'experimental characterization', 'modeling', 'supercapacitor']"
"In the telecom sector, a huge volume of data is being generated on a daily basis due to a vast client base. Decision makers and business analysts emphasized that attaining new customers is costlier than retaining the existing ones. Business analysts and customer relationship management (CRM) analyzers need to know the reasons for churn customers, as well as, behavior patterns from the existing churn customers’ data. This paper proposes a churn prediction model that uses classification, as well as, clustering techniques to identify the churn customers and provides the factors behind the churning of customers in the telecom sector. Feature selection is performed by using information gain and correlation attribute ranking filter. The proposed model first classifies churn customers data using classification algorithms, in which the Random Forest (RF) algorithm performed well with 88.63% correctly classified instances. Creating effective retention policies is an essential task of the CRM to prevent churners. After classification, the proposed model segments the churning customer’s data by categorizing the churn customers in groups using cosine similarity to provide group-based retention offers. This paper also identified churn factors that are essential in determining the root causes of churn. By knowing the significant churn factors from customers’ data, CRM can improve productivity, recommend relevant promotions to the group of likely churn customers based on similar behavior patterns, and excessively improve marketing campaigns of the company. The proposed churn prediction model is evaluated using metrics, such as accuracy, precision, recall, f-measure, and receiving operating characteristics (ROC) area. The results reveal that our proposed churn prediction model produced better churn classification using the RF algorithm and customer profiling using k-means clustering. Furthermore, it also provides factors behind the churning of churn customers through the rules generated by using the attribute-selected classifier algorithm.","['Telecommunications', 'Companies', 'Predictive models', 'Customer relationship management', 'Data mining', 'Decision trees', 'Classification algorithms']","['Churn prediction', 'retention', 'telecom', 'CRM', 'machine learning']"
"Breast cancer (BC) is one of the primary causes of cancer death among women. Early detection of BC allows patients to receive appropriate treatment, thus increasing the possibility of survival. In this work, a new deep-learning (DL) model based on the transfer-learning (TL) technique is developed to efficiently assist in the automatic detection and diagnosis of the BC suspected area based on two techniques namely 80-20 and cross-validation. DL architectures are modeled to be problem-specific. TL uses the knowledge gained during solving one problem in another relevant problem. In the proposed model, the features are extracted from the mammographic image analysis- society (MIAS) dataset using a pre-trained convolutional neural network (CNN) architecture such as Inception V3, ResNet50, Visual Geometry Group networks (VGG)-19, VGG-16, and Inception-V2 ResNet. Six evaluation metrics for evaluating the performance of the proposed model in terms of accuracy, sensitivity, specificity, precision, F-score, and area under the ROC curve (AUC) has been chosen. Experimental results show that the TL of the VGG16 model is powerful for BC diagnosis by classifying the mammogram breast images with overall accuracy, sensitivity, specificity, precision, F-score, and AUC of 98.96%, 97.83%, 99.13%, 97.35%, 97.66%, and 0.995, respectively for 80-20 method and 98.87%, 97.27%, 98.2%, 98.84%, 98.04%, and 0.993 for 10-fold cross-validation method.","['Feature extraction', 'Breast', 'Sensitivity', 'Image segmentation', 'Histograms', 'Training', 'Residual neural networks']","['Breast cancer', 'machine learning', 'deep-learning', 'transfer learning', 'image classification', 'convolutional neural networks']"
"This paper presents a literature review on pattern recognition of electromyography (EMG) signals and its applications. The EMG technology is introduced and the most relevant aspects for the design of an EMG-based system are highlighted, including signal acquisition and filtering. EMG-based systems have been used with relative success to control upper- and lower-limb prostheses, electronic devices and machines, and for monitoring human behavior. Nevertheless, the existing systems are still inadequate and are often abandoned by their users, prompting for further research. Besides controlling prostheses, EMG technology is also beneficial for the development of machine learning-based devices that can capture the intention of able-bodied users by detecting their gestures, opening the way for new human-machine interaction (HMI) modalities. This paper also reviews the current feature extraction techniques, including signal processing and data dimensionality reduction. Novel classification methods and approaches for detecting non-trained gestures are discussed. Finally, current applications are reviewed, through the comparison of different EMG systems and discussion of their advantages and drawbacks.","['Electrodes', 'Electromyography', 'Muscles', 'Sensors', 'Pattern recognition', 'Electric potential', 'Band-pass filters']","['EMG', 'human-machine interaction', 'pattern classification', 'regression']"
"In open and dynamic multiagent systems (MASs), agents often need to rely on resources or services provided by other agents to accomplish their goals. During this process, agents are exposed to the risk of being exploited by others. These risks, if not mitigated, can cause serious breakdowns in the operation of MASs and threaten their long-term wellbeing. To protect agents from the uncertainty in the behavior of their interaction partners, the age-old mechanism of trust between human beings is re-contexted into MASs. The basic idea is to let agents self-police the MAS by rating each other on the basis of their observed behavior and basing future interaction decisions on such information. Over the past decade, a large number of trust management models were proposed. However, there is a lack of research effort in several key areas, which are critical to the success of trust management in MASs where human beings and agents coexist. The purpose of this paper is to give an overview of existing research in trust management in MASs. We analyze existing trust models from a game theoretic perspective to highlight the special implications of including human beings in an MAS, and propose a possible research agenda to advance the state of the art in this field.","['Game theory', 'Decision making', 'Uncertainty', 'Analytical models', 'Context awareness', 'Multi-agent systems', 'Computational modeling', 'Trust management']","['Game theory', 'multi-agent systems', 'reputation', 'trust']"
"New advances in electronic commerce systems and communication technologies have made the credit card the potentially most popular method of payment for both regular and online purchases; thus, there is significantly increased fraud associated with such transactions. Fraudulent credit card transactions cost firms and consumers large financial losses every year, and fraudsters continuously attempt to find new technologies and methods for committing fraudulent transactions. The detection of fraudulent transactions has become a significant factor affecting the greater utilization of electronic payment. Thus, there is a need for efficient and effective approaches for detecting fraud in credit card transactions. This paper proposes an intelligent approach for detecting fraud in credit card transactions using an optimized light gradient boosting machine (OLightGBM). In the proposed approach, a Bayesian-based hyperparameter optimization algorithm is intelligently integrated to tune the parameters of a light gradient boosting machine (LightGBM). To demonstrate the effectiveness of our proposed OLightGBM for detecting fraud in credit card transactions, experiments were performed using two real-world public credit card transaction data sets consisting of fraudulent transactions and legitimate ones. Based on a comparison with other approaches using the two data sets, the proposed approach outperformed the other approaches and achieved the highest performance in terms of accuracy (98.40%), Area under receiver operating characteristic curve (AUC) (92.88%), Precision (97.34%) and F1-score (56.95%).","['Credit cards', 'Machine learning algorithms', 'Feature extraction', 'Boosting', 'Bayes methods']","['Credit card fraud', 'electronic commerce', 'machine learning', 'optimization methods']"
"In the early months of the COVID-19 pandemic with no designated cure or vaccine, the only way to break the infection chain is self-isolation and maintaining the physical distancing. In this article, we present a potential application of the Internet of Things (IoT) in healthcare and physical distance monitoring for pandemic situations. The proposed framework consists of three parts: a lightweight and low-cost IoT node, a smartphone application (app), and fog-based Machine Learning (ML) tools for data analysis and diagnosis. The IoT node tracks health parameters, including body temperature, cough rate, respiratory rate, and blood oxygen saturation, then updates the smartphone app to display the user health conditions. The app notifies the user to maintain a physical distance of 2 m (or 6 ft), which is a key factor in controlling virus spread. In addition, a Fuzzy Mamdani system (running at the fog server) considers the environmental risk and user health conditions to predict the risk of spreading infection in real time. The environmental risk conveys from the virtual zone concept and provides updated information for different places. Two scenarios are considered for the communication between the IoT node and fog server, 4G/5G/WiFi, or LoRa, which can be selected based on environmental constraints. The required energy usage and bandwidth (BW) are compared for various event scenarios. The COVID-SAFE framework can assist in minimizing the coronavirus exposure risk.","['COVID-19', 'Servers', 'Internet of Things', 'Bluetooth', 'Temperature sensors']","['IoT', 'health monitoring', 'smart healthcare', 'pandemic', 'COVID-19']"
"The wind power generation is a rapidly growing grid integrated renewable energy (RE) technology with an installed capacity of 539.291 GW. The capability of the wind energy conversion system (WECS) to remain integrated into the utility network in the case of low voltage events is called low-voltage ride-through (LVRT) capability. This paper offers a comprehensive overview of improvement techniques of the LVRT capability in WECS to increase the wind energy penetration level in the utility grid. Exhibited portrait manifests a broad spectrum of 1) wind turbines, 2) electrical generators used for wind power applications, 3) international grid codes applicable for grid integration of WECS, 4) LVRT fundamentals in WECS, 5) wind turbines LVRT methods by doubly fed induction generator (DFIG), 6) wind turbines LVRT methods by permanent magnet synchronous generators (PMSG), and 7) LVRT methods of wind turbines using squirrel cage induction generator (SCIG). This ready-reckoner paper critically reviews and classifies more than 190 research papers on LVRT issues, practices, and available technologies for grid integration in wind energy systems, and it aims to be a quick reference for the researchers, designers, manufacturers, and engineers working in the same field.","['Wind power generation', 'Wind turbines', 'Wind energy', 'Doubly fed induction generators', 'Mathematical model', 'Low voltage']","['DFIG', 'grid codes', 'LVRT', 'PMSG', 'SCIG', 'wind energy conversion system']"
"This paper presents an automatic content-based image retrieval (CBIR) system for brain tumors on T1-weighted contrast-enhanced magnetic resonance images (CE-MRI). The key challenge in CBIR systems for MR images is the semantic gap between the low-level visual information captured by the MRI machine and the high-level information perceived by the human evaluator. The traditional feature extraction methods focus only on low-level or high-level features and use some handcrafted features to reduce this gap. It is necessary to design a feature extraction framework to reduce this gap without using handcrafted features by encoding/combining low-level and high-level features. Deep learning is very powerful for feature representation that can depict low-level and high-level information completely and embed the phase of feature extraction in self-learning. Therefore, we propose a deep convolutional neural network VGG19-based novel feature extraction framework and apply closed-form metric learning to measure the similarity between the query image and database images. Furthermore, we adopt transfer learning and propose a block-wise fine-tuning strategy to enhance the retrieval performance. The extensive experiments are performed on a publicly available CE-MRI dataset that consists of three types of brain tumors (i.e., glioma, meningioma, and pituitary tumor) collected from 233 patients with a total of 3064 images across the axial, coronal, and sagittal views. Our method is more generic, as we do not use any handcrafted features; it requires minimal preprocessing, tested as robust on fivefold cross-validation, can achieve a fivefold mean average precision of 96.13%, and outperforms the state-of-the-art CBIR systems on the CE-MRI dataset.","['Feature extraction', 'Tumors', 'Deep learning', 'Biomedical imaging', 'Task analysis', 'Shape', 'Measurement']","['Brain tumor retrieval', 'block-wise fine-tuning', 'closed-form metric learning', 'convolutional neural networks', 'feature extraction', 'transfer learning']"
"To improve the recognition model accuracy of crop disease leaves and locating diseased leaves, this paper proposes an improved Faster RCNN to detect healthy tomato leaves and four diseases: powdery mildew, blight, leaf mold fungus and ToMV. First, we use a depth residual network to replace VGG16 for image feature extraction so we can obtain deeper disease features. Second, the k-means clustering algorithm is used to cluster the bounding boxes. We improve the anchoring according to the clustering results. The improved anchor frame tends toward the real bounding box of the dataset. Finally, we carry out a k-means experiment with three kinds of different feature extraction networks. The experimental results show that the improved method for crop leaf disease detection had 2.71% higher recognition accuracy and a faster detection speed than the original Faster RCNN.","['Diseases', 'Feature extraction', 'Agriculture', 'Object detection', 'Clustering algorithms']","['Faster RCNN', 'disease recognition', 'deep residual network', 'K-means clustering', 'disease diagnosis']"
"An adaptive fuzzy logic (FL)-based new maximum power point (MPP) tracking (MPPT) methodology for controlling photovoltaic (PV) systems is proposed, designed, and implemented in this paper. The existing methods for implementing FL-based MPPTs lack for adaptivity with the operating point, which varies in wide range in practical PV systems with operating irradiance and ambient temperature. The new proposed adaptive FL-based MPPT (AFL-MPPT) algorithm is simple, accurate, and provides faster convergence to optimal operating point. The effectiveness and feasibility verifications of the proposed AFL-MPPT methodology are validated with considering various operating conditions at slow and fast change of solar radiation. In addition, the simplified implementation of the proposed algorithm is carried out using C-block in PSIM software environment, wherein the proposed algorithm and system are simulated. Additionally, experimental results are performed using a floating-point digital signal processing (DSP) controller (TMS320F28335) for verifying the feasibility of the proposed AFL-MPPT methodology. The results of simulations and experimental prototypes show great consistency and prove the capability of the new AFL-MPPT methodology to extract MPPT rapidly and precisely. The new proposed AFL-MPPT method achieves accurate output power of the PV system with smooth and low ripple. In addition, the new proposed AFL-MPPT method benefits fast dynamics and it reaches steady state within 0.01 s.","['Fuzzy logic', 'Maximum power point trackers', 'Mathematical model', 'Photovoltaic systems', 'Control systems', 'Design methodology']","['DSP controller', 'energy efficiency', 'fuzzy logic (FL)', 'MPPT', 'photovoltaic systems']"
"Real-time scene parsing through object detection running on an embedded device is very challenging, due to limited memory and computing power of embedded devices. To deal with these challenges, we redesign a lightweight network without notably reducing detection accuracy. Based on the Darknet-53, we use depth separable convolutions and pointwise group convolutions to reduce the parameter size of the network. A feature extraction backbone network with a parameter size of only 16 percent of darknet-53 is constructed. Meanwhile, in order to compensate for the degradation of accuracy, we have added a Multi-Scale Feature Pyramid Network based on a simple U-shaped structure to improve the performance of multi-scale object detection, which called it Mini-YOLOv3. It has smaller model size and fewer trainable parameters and floating point operations (FLOPs) in comparison of YOLOv3. We evaluate Mini-YOLOv3 on MS-COCO benchmark dataset; The parameter size of Mini-YOLOv3 is only 23% of YOLOv3 and achieves comparable detection accuracy as YOLOv3 but only requires 1/2 detect time, Specifically, Mini-YOLOv3 achieves mAP-50 of 52.1 at speed of 67 fps.","['Feature extraction', 'Object detection', 'Real-time systems', 'Detectors', 'Performance evaluation', 'Standards', 'Computational modeling']","['Real-time object detector', 'embedded applications', 'convolutional neural network (CNN)', 'YOLOv3']"
"Software-defined networking (SDN) is a novel network paradigm that enables flexible management for networks. As the network size increases, the single centralized controller cannot meet the increasing demand for flow processing. Thus, the promising solution for SDN with large-scale networks is the multi-controller. In this paper, we present a compressive survey for multi-controller research in SDN. First, we introduce the overview of multi-controller, including the origin of multi-controller and its challenges. Then, we classify multi-controller research into four aspects (scalability, consistency, reliability, and load balancing) depending on the process of implementing the multi-controller. Finally, we propose some relevant research issues to deal with in the future and conclude the multi-controller research.","['Switches', 'Scalability', 'Reliability', 'Process control', 'Routing', 'Load management']","['Software-defined networking', 'multi-controller', 'scalability', 'consistency', 'reliability', 'load balancing']"
"The use of unmanned aerial vehicles (UAVs) has been considered to be an efficient platform for monitoring critical infrastructures spanning over geographical areas. UAVs have also demonstrated exceptional feasibility when collecting data due to the wide wireless sensor networks in which they operate. Based on environmental information such as prohibited airspace, geo-locational conditions, flight risk, and sensor deployment statistics, we developed an optimal flight path planning mechanism by using multiobjective bio-inspired algorithms. In this paper, we first acquire data sensing points from the entire sensor field, in which UAV communicates with sensors to obtain sensor data, then we determine the best flight path between neighboring acquisition points. Using the proposed joint genetic algorithm and ant colony optimization from possible UAV flight paths, an optimal one is selected in accordance with sensing, energy, time, and risk utilities. The simulation results show that our method can obtain dynamic environmental adaptivity and high utility in various practical situations.","['Sensors', 'Path planning', 'Unmanned aerial vehicles', 'Three-dimensional displays', 'Genetic algorithms', 'Topology', 'Energy consumption']","['Bio-inspired algorithms', 'multi-objectives', 'optimal path', 'sensor networks', 'unmanned aerial vehicle']"
"Recent advancements in the Internet of Health Things (IoHT) have ushered in the wide adoption of IoT devices in our daily health management. For IoHT data to be acceptable by stakeholders, applications that incorporate the IoHT must have a provision for data provenance, in addition to the accuracy, security, integrity, and quality of data. To protect the privacy and security of IoHT data, federated learning (FL) and differential privacy (DP) have been proposed, where private IoHT data can be trained at the owner’s premises. Recent advancements in hardware GPUs even allow the FL process within smartphone or edge devices having the IoHT attached to their edge nodes. Although some of the privacy concerns of IoHT data are addressed by FL, fully decentralized FL is still a challenge due to the lack of training capability at all federated nodes, the scarcity of high-quality training datasets, the provenance of training data, and the authentication required for each FL node. In this paper, we present a lightweight hybrid FL framework in which blockchain smart contracts manage the edge training plan, trust management, and authentication of participating federated nodes, the distribution of global or locally trained models, the reputation of edge nodes and their uploaded datasets or models. The framework also supports the full encryption of a dataset, the model training, and the inferencing process. Each federated edge node performs additive encryption, while the blockchain uses multiplicative encryption to aggregate the updated model parameters. To support the full privacy and anonymization of the IoHT data, the framework supports lightweight DP. This framework was tested with several deep learning applications designed for clinical trials with COVID-19 patients. We present here the detailed design, implementation, and test results, which demonstrate strong potential for wider adoption of IoHT-based health management in a secure way.","['Data models', 'Training', 'Data privacy', 'Security', 'Blockchain', 'Deep learning', 'Computational modeling']","['Blockchain', 'Internet of Health Things', 'homomorphic encryption', 'federated learning', 'provenance']"
"The smart grid (SG) paradigm is the next technological leap of the conventional electrical grid, contributing to the protection of the physical environment and providing multiple advantages such as increased reliability, better service quality, and the efficient utilization of the existing infrastructure and the renewable energy resources. However, despite the fact that it brings beneficial environmental, economic, and social changes, the existence of such a system possesses important security and privacy challenges, since it includes a combination of heterogeneous, co-existing smart, and legacy technologies. Based on the rapid evolution of the cyber-physical systems (CPS), both academia and industry have developed appropriate measures for enhancing the security surface of the SG paradigm using, for example, integrating efficient, lightweight encryption and authorization mechanisms. Nevertheless, these mechanisms may not prevent various security threats, such as denial of service (DoS) attacks that target on the availability of the underlying systems. An efficient countermeasure against several cyberattacks is the intrusion detection and prevention system (IDPS). In this paper, we examine the contribution of the IDPSs in the SG paradigm, providing an analysis of 37 cases. More detailed, these systems can be considered as a secondary defense mechanism, which enhances the cryptographic processes, by timely detecting or/and preventing potential security violations. For instance, if a cyberattack bypasses the essential encryption and authorization mechanisms, then the IDPS systems can act as a secondary protection service, informing the system operator for the presence of the specific attack or enabling appropriate preventive countermeasures. The cases we study focused on the advanced metering infrastructure (AMI), supervisory control and data acquisition (SCADA) systems, substations, and synchrophasors. Based on our comparative analysis, the limitations and the shortcomings of the current IDPS systems are identified, whereas appropriate recommendations are provided for future research efforts.","['Computer crime', 'Substations', 'Smart grids', 'Intrusion detection', 'Encryption', 'Smart meters']","['Advanced metering infrastructure', 'cyberattacks', 'intrusion detection system', 'intrusion prevention system', 'SCADA', 'security', 'smart grid', 'substation', 'synchrophasor']"
"In every aspect of human life, sound plays an important role. From personal security to critical surveillance, sound is a key element to develop the automated systems for these fields. Few systems are already in the market, but their efficiency is a point of concern for their implementation in real-life scenarios. The learning capabilities of the deep learning architectures can be used to develop the sound classification systems to overcome efficiency issues of the traditional systems. Our aim, in this paper, is to use the deep learning networks for classifying the environmental sounds based on the generated spectrograms of these sounds. We used the spectrogram images of environmental sounds to train the convolutional neural network (CNN) and the tensor deep stacking network (TDSN). We used two datasets for our experiment: ESC-10 and ESC-50. Both systems were trained on these datasets, and the achieved accuracy was 77% and 49% in CNN and 56% in TDSN trained on the ESC-10. From this experiment, it is concluded that the proposed approach for sound classification using the spectrogram images of sounds can be efficiently used to develop the sound classification and recognition systems.","['Spectrogram', 'Stacking', 'Convolutional neural networks', 'Deep learning', 'Feature extraction', 'Computer architecture']","['Deep learning', 'convolutional neural network', 'tensor deep stacking networks', 'spectrograms']"
"Direction of arrival (DOA) estimation from the perspective of sparse signal representation has attracted tremendous attention in past years, where the underlying spatial sparsity reconstruction problem is linked to the compressive sensing (CS) framework. Although this is an area with ongoing intensive research and new methods and results are reported regularly, it is time to have a review about the basic approaches and methods for CS-based DOA estimation, in particular for the underdetermined case. We start from the basic time-domain CS-based formulation for narrowband arrays and then move to the case for recently developed methods for sparse arrays based on the co-array concept. After introducing two specifically designed structures (the two-level nested array and the co-prime array) for optimizing the virtual sensors corresponding to the difference co-array, this CS-based DOA estimation approach is extended to the wideband case by employing the group sparsity concept, where a much larger physical aperture can be achieved by allowing a larger unit inter-element spacing and therefore leading to further improved performance. Finally, a specifically designed uniform linear array structure with associated CS-based underdetermined DOA estimation is presented to exploit the difference co-array concept in the spatio-spectral domain, leading to a significant increase in degrees of freedom. Representative simulation results for typical narrowband and wideband scenarios are provided to demonstrate their performance.","['Direction-of-arrival estimation', 'Estimation', 'Sensor arrays', 'Wideband', 'Narrowband', 'Signal reconstruction']","['Compressive sensing', 'direction of arrival estimation', 'underdetermined', 'difference co-array', 'sparse array structures']"
"Due to the significant properties of unpredictability, ergodicity, and initial state sensitivity, chaotic system is widely used as a useful tool in image encryption. In this paper, we propose a 2-dimensional logistic-modulated-sine-coupling-logistic chaotic map (LSMCL), where we use the logistic map to modulate Sine map and couple the result of modulation and Sine map together. In terms of chaotic trajectory, Lyapunov exponent, and Kolmogorov entropy, comparing with other existing chaotic maps, we can observe that LSMCL has better chaotic performance. Furthermore, we propose an LSMCL-based image encryption algorithm with two rounds of permutation and diffusion operation. First, we provide a secret key generation procedure to generate the initial values and do permutation operation with the chaotic matrix by LSMCL. Furthermore, in diffusion procedure, we use two different chaotic matrices generated by LSMCL to change the pixel values in row and column. Finally, we provide some theoretical analyses and simulations to confirm the security and the validity of the proposed algorithm.","['Chaotic communication', 'Logistics', 'Encryption', 'Two dimensional displays', 'Trajectory', 'Modulation']","['Coupling', 'logistic map', 'modulation', 'Sine map', 'hyper-chaotic system']"
"Brain-computer interface provides a new communication bridge between the human mind and devices, depending largely on the accurate classification and identification of non-invasive EEG signals. Recently, the deep learning approaches have been widely used in many fields to extract features and classify various types of data successfully. However, the deep learning approach requires massive data to train its neural networks, and the amount of data impacts greatly on the quality of the classifiers. This paper proposes a novel approach that combines deep learning and data augmentation for EEG classification. We applied the empirical mode decomposition on the EEG frames and mixed their intrinsic mode functions to create new artificial EEG frames, followed by transforming all EEG data into tensors as inputs of the neural network by complex Morlet wavelets. We proposed two neural networks-convolutional neural network and wavelet neural network-to train the weights and classify two classes of motor imagery signals. The wavelet neural network is a new type of neural network using wavelets to replace the convolutional layers. The experimental results show that the artificial EEG frames substantially improve the training of neural networks, and both two networks yield relatively higher classification accuracies compared to prevailing approaches. Meanwhile, we also verified the performance of our new proposed wavelet neural network model in the classification of steady-state visual evoked potentials.","['Electroencephalography', 'Brain modeling', 'Deep learning', 'Training', 'Feature extraction', 'Biological neural networks']","['Motor imagery classification', 'deep learning', 'convolutional neural network', 'wavelet neural network', 'empirical mode decomposition', 'artificial EEG frames']"
"Tomato leaf disease seriously affects the yield of tomato. It is extremely vital for agricultural economy to identify agricultural diseases. The traditional data augmentation methods, such as rotation, flip and translation, are severely limited, which cannot achieve good generalization results. To improve the recognition accuracy of tomato leaf diseases, a new method of data augmentation by generative adversarial networks (GANs) is proposed for leaf disease recognition in this work. Generated images augmented by deep convolutional generative adversarial networks (DCGAN) and original images as the input of GoogLeNet, this model can achieve a top-1 average identification accuracy of 94.33%. By adjusting the hyper-parameters, modifying the architecture of the convolutional neural networks, and selecting different generative adversarial networks, an improved model for training and testing 5 classes of tomato leaf images was obtained. Meanwhile, images generated by DCGAN not only enlarge the size of the data set, but also have the characteristics of diversity, which makes the model have a good generalization effect. We have also visually confirmed that the images generated by DCGAN have much better quality and are more convincing through the t-Distributed Stochastic Neighbor Embedding (t-SNE) and Visual Turing Test. Experiments with tomato leaf disease identification show that DCGAN can generate data that approximate to real images, which can be used to (1) provide a larger data set for the training of large neural networks, and improve the performance of the recognition model through highly discriminating image generation technology; (2) reduce the cost of data collection; (3) enhance the diversity of data and the generalization ability of the recognition models.","['Diseases', 'Training', 'Generative adversarial networks', 'Gallium nitride', 'Data models', 'Image recognition', 'Neural networks']","['Tomato leaf disease', 'data augmentation', 'generative adversarial networks', 'generalization', 'recognition accuracy']"
"Epilepsy is a health problem that seriously affects the quality of humans for many years. Therefore, it is important to accurately analyze and recognize epilepsy based on EEG signals, and for a long time, researchers have attempted to extract new features from the signals for epilepsy recognition. However, it is very difficult to select useful features from a large number of them in this diagnostic application. As the development of artificial intelligence progresses, unsupervised feature learning based on the deep learning model can obtain features that can better describe identified objects from unlabeled data. In this paper, the deep convolution network and autoencoders-based model, named as AE-CDNN, is constructed in order to perform unsupervised feature learning from EEG in epilepsy. We extract features by AE-CDNN model and classify the features based on two public EEG data sets. Experimental results showed that the classification results of features obtained by AE-CDNN are more optimal than features obtained by principal component analysis and sparse random projection. Using several common classifiers to classify features obtained by AE-CDNN model results in high accuracy and not inferior to the research results from most recent studies. The results also showed that the features of AE-CDNN model are clear, effective, and easy to learn. These features can speed up the convergence and reduce the training times of classifiers. Therefore, the AE-CDNN model can be effectively applied to feature extraction of EEG in epilepsy.","['Electroencephalography', 'Feature extraction', 'Brain modeling', 'Convolution', 'Epilepsy', 'Training', 'Deconvolution']","['EEG', 'unsupervised learning', 'feature extraction', 'CNN', 'epileptic seizure']"
"Alzheimer's disease (AD) is an irreversible progressive neurodegenerative disorder. Mild cognitive impairment (MCI) is the prodromal state of AD, which is further classified into a progressive state (i.e., pMCI) and a stable state (i.e., sMCI). With the development of deep learning, the convolutional neural networks (CNNs) have made great progress in image recognition using magnetic resonance imaging (MRI) and positron emission tomography (PET) for AD diagnosis. However, due to the limited availability of these imaging data, it is still challenging to effectively use CNNs for AD diagnosis. Toward this end, we design a novel deep learning framework. Specifically, the virtues of 3D-CNN and fully stacked bidirectional long short-term memory (FSBi-LSTM) are exploited in our framework. First, we design a 3D-CNN architecture to derive deep feature representation from both MRI and PET. Then, we apply FSBi-LSTM on the hidden spatial information from deep feature maps to further improve its performance. Finally, we validate our method on the AD neuroimaging initiative (ADNI) dataset. Our method achieves average accuracies of 94.82%, 86.36%, and 65.35% for differentiating AD from normal control (NC), pMCI from NC, and sMCI from NC, respectively, and outperforms the related algorithms in the literature.","['Magnetic resonance imaging', 'Three-dimensional displays', 'Feature extraction', 'Kernel', 'Deep learning', 'Diseases', 'Two dimensional displays']","['Alzheimer’s disease', '3D-CNN', 'FSBi-LSTM', 'multi-modal fusion']"
"Physical unclonable functions (PUFs) are increasingly used for authentication and identification applications as well as the cryptographic key generation. An important feature of a PUF is the reliance on minute random variations in the fabricated hardware to derive a trusted random key. Currently, most PUF designs focus on exploiting process variations intrinsic to the CMOS technology. In recent years, progress in emerging nanoelectronic devices has demonstrated an increase in variation as a consequence of scaling down to the nanoregion. To date, emerging PUFs with nanotechnology have not been fully established, but they are expected to emerge. Initial research in this area aims to provide security primitives for emerging integrated circuits with nanotechnology. In this paper, we review emerging nanotechnology-based PUFs.","['Nanotechnology', 'Cloning', 'Physical unclonable functions', 'Nanoscale devices', 'Object recognition', 'CMOS integrated circuits', 'Computer security', 'Private key cryptography', 'Cryptography']","['Physical unclonable functions', 'hardware security', 'nanoelectronic devices', 'nanotechnology', 'reconfigurable PUF', 'strong PUF']"
"In this paper, we present a deep learning based method for blind hyperspectral unmixing in the form of a neural network autoencoder. We show that the linear mixture model implicitly puts certain architectural constraints on the network, and it effectively performs blind hyperspectral unmixing. Several different architectural configurations of both shallow and deep encoders are evaluated. Also, deep encoders are tested using different activation functions. Furthermore, we investigate the performance of the method using three different objective functions. The proposed method is compared to other benchmark methods using real data and previously established ground truths of several common data sets. Experiments show that the proposed method compares favorably to other commonly used hyperspectral unmixing methods and exhibits robustness to noise. This is especially true when using spectral angle distance as the network's objective function. Finally, results indicate that a deeper and a more sophisticated encoder does not necessarily give better results.","['Linear programming', 'Decoding', 'Hyperspectral imaging', 'Machine learning', 'Neural networks', 'Spatial resolution']","['Hyperspectral unmixing', 'autoencoder', 'deep learning', 'neural network', 'spectral angle distance', 'endmember extraction']"
"Considering a future scenario in which a driverless Electric Vehicle (EV) needs an automatic charging system without human intervention. In this regard, there is a requirement for a fully automatable, fast, safe, cost-effective, and reliable charging infrastructure that provides a profitable business model and fast adoption in the electrified transportation systems. These qualities can be comprehended through wireless charging systems. Wireless Power Transfer (WPT) is a futuristic technology with the advantage of flexibility, convenience, safety, and the capability of becoming fully automated. In WPT methods resonant inductive wireless charging has to gain more attention compared to other wireless power transfer methods due to high efficiency and easy maintenance. This literature presents a review of the status of Resonant Inductive Wireless Power Transfer Charging technology also highlighting the present status and its future of the wireless EV market. First, the paper delivers a brief history throw lights on wireless charging methods, highlighting the pros and cons. Then, the paper aids a comparative review of different type’s inductive pads, rails, and compensations technologies done so far. The static and dynamic charging techniques and their characteristics are also illustrated. The role and importance of power electronics and converter types used in various applications are discussed. The batteries and their management systems as well as various problems involved in WPT are also addressed. Different trades like cyber security economic effects, health and safety, foreign object detection, and the effect and impact on the distribution grid are explored. Prospects and challenges involved in wireless charging systems are also highlighting in this work. We believe that this work could help further the research and development of WPT systems.","['Inductive charging', 'Batteries', 'Wireless communication', 'Vehicle dynamics', 'History', 'Wireless power transfer', 'Receivers']","['Electric vehicle charging', 'wireless power transfer', 'inductive wireless charging', 'magnetic resonance charging', 'compensator networks']"
"We consider the problem of spectrum sharing in a cognitive radio system consisting of a primary user and a secondary user. The primary user and the secondary user work in a non-cooperative manner. Specifically, the primary user is assumed to update its transmitted power based on a pre-defined power control policy. The secondary user does not have any knowledge about the primary user's transmit power, or its power control strategy. The objective of this paper is to develop a learning-based power control method for the secondary user in order to share the common spectrum with the primary user. To assist the secondary user, a set of sensor nodes are spatially deployed to collect the received signal strength information at different locations in the wireless environment. We develop a deep reinforcement learning-based method, which the secondary user can use to intelligently adjust its transmit power such that after a few rounds of interaction with the primary user, both users can transmit their own data successfully with required qualities of service. Our experimental results show that the secondary user can interact with the primary user efficiently to reach a goal state (defined as a state in which both users can successfully transmit their data) from any initial states within a few number of steps.","['Power control', 'Interference', 'Receivers', 'Cognitive radio', 'Signal to noise ratio', 'Machine learning', 'Quality of service']","['Spectrum sharing', 'power control', 'cognitive radio', 'deep reinforcement learning']"
"Prognostics and health management is a promising methodology to cope with the risks of failure in advance and has been implemented in many well-known applications including battery systems. Since the estimation of battery capacity is critical for safe operation and decision making, battery capacity should be estimated precisely. In this regard, we leverage measurable data such as voltage, current, and temperature profiles from the battery management system whose patterns vary in cycles as aging. Based on these data, the relationship between capacity and charging profiles is learned by neural networks. Specifically, to estimate the state of health accurately we apply feedforward neural network, convolutional neural network, and long short-term memory. Our results show that the proposed multi-channel technique based on voltage, current, and temperature profiles outperforms the conventional method that uses only voltage profile by up to 25%-58% in terms of mean absolute percentage error.","['Estimation', 'Aging', 'Lithium-ion batteries', 'Battery charge measurement', 'Temperature measurement', 'Temperature distribution']","['Lithium-ion battery', 'neural network', 'remaining useful life', 'capacity estimation', 'state of health']"
"The future wireless networks promise to provide ubiquitous connectivity to a multitude of devices with diversified traffic patterns wherever and whenever needed. For the sake of boosting resilience against faults, natural disasters, and unexpected traffic, the unmanned aerial vehicle (UAV)-assisted wireless communication systems can provide a unique opportunity to cater for such demands in a timely fashion without relying on the overly engineered cellular network. However, for UAV-assisted communication, issues of capacity, coverage, and energy efficiency are considered of paramount importance. The case of non-orthogonal multiple access (NOMA) is investigated for aerial base station (BS). NOMA's viability is established by formulating the sum-rate problem constituting a function of power allocation and UAV altitude. The optimization problem is constrained to meet individual user-rates arisen by orthogonal multiple access (OMA) bringing it at par with NOMA. The relationship between energy efficiency and altitude of a UAV inspires the solution to the aforementioned problem considering two cases, namely, altitude fixed NOMA and altitude optimized NOMA. The latter allows exploiting the extra degrees of freedom of UAV-BS mobility to enhance the spectral efficiency and the energy efficiency. Hence, it saves joules in the operational cost of the UAV. Finally, a constrained coverage expansion methodology, facilitated by NOMA user rate gain is also proposed. Results are presented for various environment settings to conclude NOMA manifesting better performance in terms of sum-rate, coverage, and energy efficiency.","['NOMA', 'Unmanned aerial vehicles', 'Energy consumption', 'Propagation losses', 'Channel models', 'Wireless networks']","['Non-orthogonal multiple access (NOMA)', 'orthogonal multiple access (OMA)', 'unmanned aerial vehicle (UAV)', 'sum-rate maximization', 'coverage maximization', 'aerial cells', 'energy efficiency']"
"This paper investigates the secrecy performance of a two-user downlink non-orthogonal multiple access systems. Both single-input and single-output and multiple-input and single-output systems with different transmit antenna selection (TAS) strategies are considered. Depending on whether the base station has the global channel state information of both the main and wiretap channels, the exact closed-form expressions for the secrecy outage probability (SOP) with suboptimal antenna selection and optimal antenna selection schemes are obtained and compared with the traditional space-time transmission scheme. To obtain further insights, the asymptotic analysis of the SOP in high average channel power gains regime is presented and it is found that the secrecy diversity order for all the TAS schemes with fixed power allocation is zero. Furthermore, an effective power allocation scheme is proposed to obtain the non-zero diversity order with all the TAS schemes. Monte Carlo simulations are performed to verify the proposed analytical results.","['NOMA', 'Resource management', 'Transmitting antennas', 'Base stations', 'MISO', 'Signal to noise ratio']","['Non-orthogonal multiple access', 'physical layer security', 'transmit antenna selection', 'secrecy outage probability']"
"Owing to the explosive expansion of wireless communication and networking technologies, cost-effective unmanned aerial vehicles (UAVs) have recently emerged and soon they will occupy the major part of our sky. UAVs can be exploited to efficiently accomplish complex missions when cooperatively organized as an ad hoc network, thus creating the well-known flying ad hoc networks (FANETs). The establishment of such networks is not feasible without deploying an efficient networking model allowing a reliable exchange of information between UAVs. FANET inherits common features and characteristics from mobile ad hoc networks (MANETs) and their sub-classes, such as vehicular ad hoc networks (VANETs) and wireless sensor networks (WSNs). Unfortunately, UAVs are often deployed in the sky adopting a mobility model dictated by the nature of missions that they are expected to handle, and therefore, differentiate themselves from any traditional networks. Moreover, several flying constraints and the highly dynamic topology of FANETs make the design of routing protocols a complicated task. In this paper, a comprehensive survey is presented covering the architecture, the constraints, the mobility models, the routing techniques, and the simulation tools dedicated to FANETs. A classification, descriptions, and comparative studies of an important number of existing routing protocols dedicated to FANETs are detailed. Furthermore, the paper depicts future challenge perspectives, helping scientific researchers to discover some themes that have been addressed only ostensibly in the literature and need more investigation. The novelty of this survey is its uniqueness to provide a complete analysis of the major FANET routing protocols and to critically compare them according to different constraints based on crucial parameters, thus better presenting the state of the art of this specific area of research.","['Routing protocols', 'Ad hoc networks', 'Routing', 'Wireless sensor networks', 'Wireless communication', 'Unmanned aerial vehicles', 'Organizations']","['UAV', 'FANET', 'mobility', 'simulation', 'routing protocols']"
"The research area of ambient assisted living has led to the development of activity recognition systems (ARS) based on human activity recognition (HAR). These systems improve the quality of life and the health care of the elderly and dependent people. However, before making them available to end users, it is necessary to evaluate their performance in recognizing activities of daily living, using data set benchmarks in experimental scenarios. For that reason, the scientific community has developed and provided a huge amount of data sets for HAR. Therefore, identifying which ones to use in the evaluation process and which techniques are the most appropriate for prediction of HAR in a specific context is not a trivial task and is key to further progress in this area of research. This work presents a systematic review of the literature of the sensor-based data sets used to evaluate ARS. On the one hand, an analysis of different variables taken from indexed publications related to this field was performed. The sources of information are journals, proceedings, and books located in specialized databases. The analyzed variables characterize publications by year, database, type, quartile, country of origin, and destination, using scientometrics, which allowed identification of the data set most used by researchers. On the other hand, the descriptive and functional variables were analyzed for each of the identified data sets: occupation, annotation, approach, segmentation, representation, feature selection, balancing and addition of instances, and classifier used for recognition. This paper provides an analysis of the sensor-based data sets used in HAR to date, identifying the most appropriate dataset to evaluate ARS and the classification techniques that generate better results.","['Intelligent sensors', 'Feature extraction', 'Benchmark testing', 'Activity recognition', 'Monitoring', 'Object recognition']","['Ambient assisted living–AAL', 'human activity recognition–HAR', 'activities of daily living–ADL', 'activity recognition systems–ARS', 'dataset']"
"Smart contracts are programs that reside within decentralized blockchains and are executed pursuant to triggered instructions. A smart contract acts in a similar way to a traditional agreement but negates the necessity for the involvement of a third party. Smart contracts are capable of initiating their commands automatically, thus eliminating the involvement of a regulatory body. As a consequence of blockchain's immutable feature, smart contracts are developed in a manner that is distinct from traditional software. Once deployed to the blockchain, a smart contract cannot be modified or updated for security patches, thus encouraging developers to implement strong security strategies before deployment in order to avoid potential exploitation at a later time. However, the most recent dreadful attacks and the multifarious existing vulnerabilities which result as a consequence of the absence of security patches have challenged the sustainability of this technology. Attacks such as the Decentralized Autonomous Organization (DAO) attack and the Parity Wallet hack have cost millions of dollars simply as a consequence of naïve bugs in the smart contract code. In this paper, we classify blockchain exploitation techniques into 4 categories based on the attack rationale; attacking consensus protocols, bugs in the smart contract, malware running in the operating system, and fraudulent users. We then focus on smart contract vulnerabilities, analyzing the 7 most important attack techniques to determine the real impact on smart contract technology. We reveal that even adopting the 10 most widely used tools to detect smart contract vulnerabilities, these still contain known vulnerabilities, providing a dangerously false sense of security. We conclude the paper with a discussion about recommendations and future research lines to progress towards a secure smart contract solution.","['Smart contracts', 'Blockchain', 'Bitcoin', 'Computer bugs']","['Smart contracts', 'attack techniques', 'DApp', 'Ethereum', 'vulnerability']"
"Nowadays, motor imagery (MI) electroencephalogram (EEG) signal classification has become a hotspot in the research field of brain computer interface (BCI). More recently, deep learning has emerged as a promising technique to automatically extract features of raw MI EEG signals and then classify them. However, deep learning-based methods still face two challenging problems in practical MI EEG signal classification applications: (1) Generally, training a deep learning model successfully needs a large amount of labeled data. However, most of the EEG signal data is unlabeled and it is quite difficult or even impossible for human experts to label all the signal samples manually. (2) It is extremely time-consuming and computationally expensive to train a deep learning model from scratch. To cope with these two challenges, a deep transfer convolutional neural network (CNN) framework based on VGG-16 is proposed for EEG signal classification. The proposed framework consists of a VGG-16 CNN model pre-trained on the ImageNet and a target CNN model which shares the same structure with VGG-16 except for the softmax output layer. The parameters of the pre-trained VGG-16 CNN model are directly transferred to the target CNN model used for MI EEG signal classification. Then, front-layers parameters in the target model are frozen, while later-layers parameters are fine-tuned by the target MI dataset. The target dataset is composed of time-frequency spectrum images of EEG signals. The performance of the proposed framework is verified on the public benchmark dataset 2b from the BCI competition IV. The experimental results show that the proposed framework improves the accuracy and efficiency performance of EEG signal classification compared with traditional methods, including support vector machine (SVM), artificial neural network (ANN), and standard CNN.","['Electroencephalography', 'Feature extraction', 'Brain modeling', 'Task analysis', 'Computational modeling', 'Time-frequency analysis', 'Deep learning']","['Motor imagery (MI)', 'electroencephalogram (EEG)', 'signal classification', 'short time Fourier transform (STFT)', 'VGG-16', 'transfer learning']"
"Mobile cellular networks have become both the generators and carriers of massive data. Big data analytics can improve the performance of mobile cellular networks and maximize the revenue of operators. In this paper, we introduce a unified data model based on the random matrix theory and machine learning. Then, we present an architectural framework for applying the big data analytics in the mobile cellular networks. Moreover, we describe several illustrative examples, including big signaling data, big traffic data, big location data, big radio waveforms data, and big heterogeneous data, in mobile cellular networks. Finally, we discuss a number of open research challenges of the big data analytics in the mobile cellular networks.","['Cellular networks', 'Mobile communication', 'Big data', 'Data analytics', 'Random matrix theory', 'Machine learning']","['Big data analytics', 'mobile cellular networks']"
"Electronic medical records can help people prevent diseases, improve cure rates, provide a significant basis for medical institutions and pharmaceutical companies, and provide legal evidence for medical negligence and medical disputes. However, the integrity and security problems of electronic medical data still intractable. In this paper, based on the ciphertext policy attribute-based encryption system and IPFS storage environment, combined with blockchain technology, we constructed an attribute-based encryption scheme for secure storage and efficient sharing of electronic medical records in IPFS storage environment. Our scheme is based on ciphertext policy attribute encryption, which effectively controls the access of electronic medical data without affecting efficient retrieval. Meanwhile, we store the encrypted electronic medical data in the decentralized InterPlanetary File System (IPFS), which not only ensures the security of the storage platform but also solves the problem of the single point of failure. Besides, we leverage the non-tamperable and traceable nature of blockchain technology to achieve secure storage and search for medical data. The security proof shows that our scheme achieves selective security for the choose keyword attacks. Performance analysis and real data set simulation experiments shows that our scheme is efficient and feasible.","['Servers', 'Medical diagnostic imaging', 'Cloud computing', 'Encryption', 'Blockchain', 'Electronic medical records']","['Access control', 'attribute-based encryption', 'blockchain', 'electronic medical records', 'InterPlanetary File System (IPFS)']"
"In the age of industry 4.0, deep learning has attracted increasing interest for various research applications. In recent years, deep learning models have been extensively implemented in machinery fault detection and diagnosis (FDD) systems. The deep architecture's automated feature learning process offers great potential to solve problems with traditional fault detection and diagnosis (TFDD) systems. TFDD relies on manual feature selection, which requires prior knowledge of the data and is time intensive. However, the high performance of deep learning comes with challenges and costs. This paper presents a review of deep learning challenges related to machinery fault detection and diagnosis systems. The potential for future work on deep learning implementation in FDD systems is briefly discussed.","['Deep learning', 'Fault detection', 'Machinery', 'Computational modeling', 'Feature extraction', 'Training', 'Vibrations']","['Deep learning', 'fault detection and diagnosis', 'current challenges', 'future developments']"
"A smart home network will support various smart devices and applications, e.g., home automation devices, E-health devices, regular computing devices, and so on. Most devices in a smart home access the Internet through a home gateway (HGW). In this paper, we propose a software-definednetwork (SDN)-HGW framework to better manage distributed smart home networks and support the SDN controller of the core network. The SDN controller enables efficient network quality-of-service management based on real-time traffic monitoring and resource allocation of the core network. However, it cannot provide network management in distributed smart homes. Our proposed SDN-HGW extends the control to the access network, i.e., a smart home network, for better end-to-end network management. Specifically, the proposed SDN-HGW can achieve distributed application awareness by classifying data traffic in a smart home network. Most existing traffic classification solutions, e.g., deep packet inspection, cannot provide real-time application awareness for encrypted data traffic. To tackle those issues, we develop encrypted data classifiers (denoted as DataNets) based on three deep learning schemes, i.e., multilayer perceptron, stacked autoencoder, and convolutional neural networks, using an open data set that has over 200 000 encrypted data samples from 15 applications. A data preprocessing scheme is proposed to process raw data packets and the tested data set so that DataNet can be created. The experimental results show that the developed DataNets can be applied to enable distributed application-aware SDN-HGW in future smart home networks.","['Smart homes', 'Cryptography', 'Machine learning', 'Quality of service', 'Logic gates', 'Smart devices']","['Encrypted traffic classification', 'home gateway', 'distributed network management', 'deep learning', 'SDN']"
"Financial news has been proven to be a crucial factor which causes fluctuations in stock prices. However, previous studies heavily relied on analyzing shallow features and ignored the structural relation among words in a sentence. Several sentiment analysis studies have tried to point out the relationship between investors' reaction and news events. However, the sentiment dataset was usually constructed from the lingual dataset which is unrelated to the financial sector and led to poor performance. This paper proposes a novel framework to predict the directions of stock prices by using both financial news and sentiment dictionary. The original contributions of this paper include the proposal of a novel two-stream gated recurrent unit network and Stock2Vec-a sentiment word embedding trained on financial news dataset and Harvard IV-4. Two main experiments are conducted: the first experiment predicts S&P 500 index stock price directions using the historical S&P 500 prices and the articles crawled from Reuters and Bloomberg, and the second experiment forecasts the price trends of VN-index using VietStock news and stock prices from cophieu68. Results show that: 1) two-stream GRU outperforms state-of-the-art models; 2) Stock2Vec is more efficient in dealing with financial datasets; and 3) applying the model, a simulation scenario proves that our model is effective for the stock sector.","['Dictionaries', 'Sentiment analysis', 'Market research', 'Feature extraction', 'Machine learning', 'Internet']","['Deep learning', 'natural language processing', 'stock trends', 'sentiment analysis']"
"In this paper, a new dense dielectric (DD) patch array antenna prototype operating at 28 GHz for future fifth generation (5G) cellular networks is presented. This array antenna is proposed and designed with a standard printed circuit board process to be suitable for integration with radio frequency/microwave circuitry. The proposed structure employs four circular-shaped DD patch radiator antenna elements fed by a 1-to-4 Wilkinson power divider. To improve the array radiation characteristics, a ground structure based on a compact uniplanar electromagnetic bandgap unit cell has been used. The DD patch shows better radiation and total efficiencies compared with the metallic patch radiator. For further gain improvement, a dielectric layer of a superstrate is applied above the array antenna. The measured impedance bandwidth of the proposed array antenna ranges from 27 to beyond 32 GHz for a reflection coefficient (S11) of less than -10 dB. The proposed design exhibits stable radiation patterns over the whole frequency band of interest, with a total realized gain more than 16 dBi. Due to the remarkable performance of the proposed array, it can be considered as a good candidate for 5G communication applications.","['Dielectrics', 'Microwave antenna arrays', 'Antenna arrays', 'Antenna measurements', 'Prototypes', 'Radiators', 'Mobile communication', 'Electromagnetic band gap', 'Cellular networks', 'Patch antennas']","['Dense dielectric (DD) patch', 'superstrate', 'Wilkinson power divider', 'fifth generation (5G) wireless communications', 'printed circuit board (PCB)', 'electromagnetic bandgap (EBG)']"
"With the emergence of industry 4.0, the oil and gas (O&G) industry is now considering a range of digital technologies to enhance productivity, efficiency, and safety of their operations while minimizing capital and operating costs, health and environment risks, and variability in the O&G project life cycles. The deployment of emerging technologies allows O&G companies to construct digital twins (DT) of their assets. Considering DT adoption, the O&G industry is still at an early stage with implementations limited to isolated and selective applications instead of industry-wide implementation, limiting the benefits from DT implementation. To gain the full potential of DT and related technological adoption, a comprehensive understanding of DT technology, the current status of O&G-related DT research activities, and the opportunities and challenges associated with the deployment of DT in the O&G industry are of paramount importance. In order to develop this understanding, this paper presents a literature review of DT within the context of the O&G industry. The paper follows a systematic approach to select articles for the literature review. First, a keywords-based publication search was performed on the scientific databases such as Elsevier, IEEE Xplore, OnePetro, Scopus, and Springer. The filtered articles were then analyzed using online text analytic software (Voyant Tools) followed by a manual review of the abstract, introduction and conclusion sections to select the most relevant articles for our study. These articles and the industrial publications cited by them were thoroughly reviewed to present a comprehensive overview of DT technology and to identify current research status, opportunities and challenges of DT deployment in the O&G industry. From this literature review, it was found that asset integrity monitoring, project planning, and life cycle management are the key application areas of digital twin in the O&G industry while cyber security, lack of standardization, and uncertainty in scope and focus are the key challenges of DT deployment in the O&G industry. When considering the geographical distribution for the DT related research in the O&G industry, the United States (US) is the leading country, followed by Norway, United Kingdom (UK), Canada, China, Italy, Netherland, Brazil, Germany, and Saudi Arabia. The overall publication rate was less than ten articles (approximately) per year until 2017, and a significant increase occurred in 2018 and 2019. The number of journal publications was noticeably lower than the number of conference publications, and the majority of the publications presented theoretical concepts rather than the industrial implementations. Both these observations suggest that the DT implementation in the O&G industry is still at an early stage.","['Industries', 'Digital twin', 'Data models', 'Bibliographies', 'Oils', 'Market research', 'Companies']","['Digitalization', 'digital twin (DT)', 'industry 4.0', 'extended reality', 'industrial Internet of Things (IIoT)', 'oil and gas']"
"Recently, smart cities, smart homes, and smart medical systems have challenged the functionality and connectivity of the large-scale Internet of Things (IoT) devices. Thus, with the idea of offloading intensive computing tasks from them to edge nodes (ENs), edge computing emerged to supplement these limited devices. Benefit from this advantage, IoT devices can save more energy and still maintain the quality of the services they should provide. However, computational offload decisions involve federation and complex resource management and should be determined in the real-time face to dynamic workloads and radio environments. Therefore, in this work, we use multiple deep reinforcement learning (DRL) agents deployed on multiple edge nodes to indicate the decisions of the IoT devices. On the other hand, with the aim of making DRL-based decisions feasible and further reducing the transmission costs between the IoT devices and edge nodes, federated learning (FL) is used to train DRL agents in a distributed fashion. The experimental results demonstrate the effectiveness of the decision scheme and federated learning in the dynamic IoT system.","['Task analysis', 'Computational modeling', 'Edge computing', 'Delays', 'Optimization', 'Internet of Things', 'Resource management']","['Federated learning', 'computation offloading', 'IoT', 'edge computing']"
"Today, conventional power systems are evolving to smart grids, which encompass clusters of AC/DC microgrids, interfaced through power electronics converters. In such systems, increasing penetration of the power electronics-based distributed generations, energy storages, and modern loads provide a great opportunity for power quality control. In this paper, an overview of the power quality control of smart hybrid AC/DC microgrids is presented. Different types of power quality issues are studied first, with consideration of real-world hybrid microgrid examples, including data centers, electric railway systems, and electric vehicles charging stations. It shows that compared to traditional centralized power quality compensations, smart interfacing power converters from distributed generations, energy storages, and loads, and the AC and DC subgrids interfacing converters are promising candidates for power quality control. To realize the smart interfacing converters’ power quality control, both primary converters control and secondary system coordination are required. In this paper, a thorough review of the primary control of interfacing converters to integrate the power quality compensation are presented, with a focus on the hybrid AC/DC microgrid harmonics compensation and unbalance compensation. For multiple interfacing converters, the secondary control with system-level coordination and optimization for harmonics and unbalance compensation (considering both unbalance and harmonics in single-phase and three-phase systems) are also presented. Challenges like low switching frequency of interfacing converters, parallel interfacing converters operation, and interfacing converters communications are discussed, and typical solutions for primary and secondary controls to deal with them are presented. The paper also includes rich case study results.","['Power quality', 'Microgrids', 'Power harmonic filters', 'Harmonic analysis', 'Hybrid power systems', 'Data centers']","['Harmonic compensation', 'hybrid AC/DC microgrid', 'interfacing power electronics converters', 'power quality', 'primary and secondary control', 'smart converters', 'smart grids', 'unbalance compensation']"
"This paper presents a chaotic encryption-based blind digital image watermarking technique applicable to both grayscale and color images. Discrete cosine transform (DCT) is used before embedding the watermark in the host image. The host image is divided into 8 × 8 nonoverlapping blocks prior to DCT application, and the watermark bit is embedded by modifying difference between DCT coefficients of adjacent blocks. Arnold transform is used in addition to chaotic encryption to add double-layer security to the watermark. Three different variants of the proposed algorithm have been tested and analyzed. The simulation results show that the proposed scheme is robust to most of the image processing operations like joint picture expert group compression, sharpening, cropping, and median filtering. To validate the efficiency of the proposed technique, the simulation results are compared with certain state-of-art techniques. The comparison results illustrate that the proposed scheme performs better in terms of robustness, security, and imperceptivity. Given the merits of the proposed scheme, it can be used in applications like e-healthcare and telemedicine to robustly hide electronic health records in medical images.","['Watermarking', 'Robustness', 'Discrete cosine transforms', 'Encryption', 'Payloads']","['Electronic healthcare', 'Arnold transform', 'blind watermarking', 'chaos', 'DCT', 'encryption', 'robustness']"
"The commercial fifth-generation (5G) wireless communications networks have already been deployed with the aim of providing high data rates. However, the rapid growth in the number of smart devices and the emergence of the Internet of Everything (IoE) applications, which require an ultra-reliable and low-latency communication, will result in a substantial burden on the 5G wireless networks. As such, the data rate that could be supplied by 5G networks will unlikely sustain the enormous ongoing data traffic explosion. This has motivated research into continuing to advance the existing wireless networks toward the future generation of cellular systems, known as sixth generation (6G). Therefore, it is essential to provide a prospective vision of the 6G and the key enabling technologies for realizing future networks. To this end, this paper presents a comprehensive review/survey of the future evolution of 6G networks. Specifically, the objective of the paper is to provide a comprehensive review/survey about the key enabling technologies for 6G networks, which include a discussion about the main operation principles of each technology, envisioned potential applications, current state-of-the-art research, and the related technical challenges. Overall, this paper provides useful information for industries and academic researchers and discusses the potentials for opening up new research directions.","['6G mobile communication', '5G mobile communication', 'Wireless communication', 'Long Term Evolution', 'Broadband communication', 'Multiaccess communication', 'Reliability']","['6G', 'intelligent reflecting surfaces', 'orthogonal multiple access', 'NOMA', 'rate-splitting multiple access', 'spatial modulation', 'cell-free massive MIMO', 'mmWave', 'terahertz (THz)', 'holographic radio', 'full duplex', 'energy harvesting', 'backscatter', 'edge computing', 'optical wireless communications', 'blockchain', 'artificial intelligence', 'machine learning']"
"Model predictive control (MPC) has become one of the well-established modern control methods for three-phase inverters with an output LC filter, where a high-quality voltage with low total harmonic distortion (THD) is needed. Although it is an intuitive controller, easy to understand and implement, it has the significant disadvantage of requiring a large number of online calculations for solving the optimization problem. On the other hand, the application of model-free approaches such as those based on artificial neural networks approaches is currently growing rapidly in the area of power electronics and drives. This paper presents a new control scheme for a two-level converter based on combining MPC and feed-forward ANN, with the aim of getting lower THD and improving the steady and dynamic performance of the system for different types of loads. First, MPC is used, as an expert, in the training phase to generate data required for training the proposed neural network. Then, once the neural network is fine-tuned, it can be successfully used online for voltage tracking purpose, without the need of using MPC. The proposed ANN-based control strategy is validated through simulation, using MATLAB/Simulink tools, taking into account different loads conditions. Moreover, the performance of the ANN-based controller is evaluated, on several samples of linear and non-linear loads under various operating conditions, and compared to that of MPC, demonstrating the excellent steady-state and dynamic performance of the proposed ANN-based control strategy.","['Inverters', 'Switches', 'Mathematical model', 'Neural networks', 'Voltage control', 'Training']","['Three-phase inverter', 'model predictive control', 'artificial neural network', 'UPS systems']"
"Bolted joint are among the key components that enable the robust assembly of a wide variety of structures. However, due to wear and tear over time, bolted joint may loosen, and if not detected in its early stages, can lead to devastating results. A monitoring method that can detect bolted joint looseness prior to bolt failure will be essential for the continued operation of the host structure and depending on the situation, the safety of the occupants. Prior research has proven the electromechanical impedance method (EMI) to be an effective technique for detecting the loosening of bolted joints, however, EMI-based methods until now are focused on qualitative health monitoring, which can only provide limited information about the damage. Thus, this paper attempts to quantify EMI based methods through the integration of fractal contact theory, the result of which is a novel electromechanical impedance model for quantitative monitoring of bolted looseness. The method determines the effective impedance of the bolted joint and is applied to develop the relationship between the electrical impedance of a piezoceramic patch installed on the joint and the mechanical impedance of the bolted joint. The mechanical impedance of the bolted joint under various preloads is computed by using the fractal contact theory. Then, the bolted looseness can be monitored quantitatively. At last, a set of verification tests under different applied preload of bolted joint are conducted to verify the validity of the proposed model in this paper.","['Impedance', 'Monitoring', 'Fractals', 'Electromagnetic interference', 'Strain', 'Fasteners', 'Electric fields']","['Structural health monitoring', 'bolted looseness monitoring', 'electromechanical impedance modeling', 'fractal contact theory', 'piezoceramic transducers']"
"As the population in cities continues to increase rapidly, air pollution becomes a serious issue from public health to social economy. Among all pollutants, fine particulate matters (PM2.5) directly related to various serious health concerns, e.g., lung cancer, premature death, asthma, and cardiovascular and respiratory diseases. To enhance the quality of urban living, sensors are deployed to create smart cities. In this paper, we present a participatory urban sensing framework for PM2.5 monitoring with more than 2500 devices deployed in Taiwan and 29 other countries. It is one of the largest deployment project for PM2.5 monitor in the world as we know until May 2017. The key feature of the framework is its open system architecture, which is based on the principles of open hardware, open source software, and open data. To facilitate the deployment of the framework, we investigate the accuracy issue of low-cost particle sensors with a comprehensive set of comparison evaluations to identify the most reliable sensor. By working closely with government authorities, industry partners, and maker communities, we can construct an effective eco-system for participatory urban sensing of PM2.5 particles. Based on our deployment achievements to date, we provide a number of data services to improve environmental awareness, trigger on-demand responses, and assist future government policymaking. The proposed framework is highly scalable and sustainable with the potential to facilitate the Internet of Things, smart cities, and citizen science in the future.","['Sensors', 'Monitoring', 'Lungs', 'Air pollution', 'Hardware', 'Atmospheric modeling']","['Air pollution', 'crowdsourcing', 'environmental monitoring', 'Internet of Things']"
"About half of the people who develop heart failure (HF) die within five years of diagnosis. Over the years, researchers have developed several machine learning-based models for the early prediction of HF and to help cardiologists to improve the diagnosis process. In this paper, we introduce an expert system that stacks two support vector machine (SVM) models for the effective prediction of HF. The first SVM model is linear and L_{1} regularized. It has the capability to eliminate irrelevant features by shrinking their coefficients to zero. The second SVM model is L_{2} regularized. It is used as a predictive model. To optimize the two models, we propose a hybrid grid search algorithm (HGSA) that is capable of optimizing the two models simultaneously. The effectiveness of the proposed method is evaluated using six different evaluation metrics: accuracy, sensitivity, specificity, the Matthews correlation coefficient (MCC), ROC charts, and area under the curve (AUC). The experimental results confirm that the proposed method improves the performance of a conventional SVM model by 3.3%. Moreover, the proposed method shows better performance compared to the ten previously proposed methods that achieved accuracies in the range of 57.85%–91.83%. In addition, the proposed method also shows better performance than the other state-of-the-art machine learning ensemble models.","['Support vector machines', 'Predictive models', 'Heart', 'Expert systems', 'Kernel', 'Optimization', 'Diseases']","['Clinical expert system', 'feature selection', 'heart failure prediction', 'hybrid grid search algorithm', 'support vector machine']"
"In this paper, we propose a solution to the problem of scheduling of a smart home appliance operation in a given time range. In addition to power-consuming appliances, we adopt a photovoltaic (PV) panel as a power-producing appliance that acts as a micro-grid. An appliance operation is modeled in terms of uninterruptible sequence phases, given in a load demand profile with a goal of minimizing electricity cost fulfilling duration, energy requirement, and user preference constraints. An optimization algorithm, which can provide a schedule for smart home appliance usage, is proposed based on the mixed-integer programming technique. Simulation results demonstrate the utility of our proposed solution for appliance scheduling. We further show that adding a PV system in the home results in the reduction of electricity bills and the export of energy to the national grid in times when solar energy production is more than the demand of the home.","['Smart phones', 'Household applicances', 'Scheduling', 'Home automation', 'Smart grids']","['Appliance scheduling', 'optimization', 'branch and- bound', 'smart home network', 'smart grid']"
"Mobile learning applications have been growing in demand and popularity and have become a common phenomenon in modern educational systems, especially with the implementation of mobile learning projects. This study applies the Unified Theory of Acceptance and Use Technology (UTAUT) model to examine the effects of different factors that were identified from the literature on students' acceptance of mobile learning applications in higher education. The data was collected from a 697 university students responded to an online questionnaire. SEM method was used for data analysis. The results showed that perceived information quality, perceived compatibility, perceived trust, perceived awareness, and availability of resources, self-efficacy, and perceived security are the main motivators of students' acceptance of mobile learning system, and consequently success the implementation of mobile learning projects. Results from this study provide the necessary information as to how higher education institutions can enhance students' acceptance of mobile learning system in order to support the usage of mobile technologies in learning and teaching process. These results offer important implications for mobile learning acceptance and usage.","['Learning systems', 'Education', 'Security', 'Information systems', 'Predictive models', 'Mobile applications', 'Analytical models']","['Mobile learning acceptance', 'adoption', 'information system acceptance', 'success factors', 'UTAUT model']"
"To address the problem of detecting malicious codes in malware and extracting the corresponding evidences in mobile devices, we construct a consortium blockchain framework, which is composed of a detecting consortium chain shared by test members and a public chain shared by users. Specifically, in view of different malware families in Android-based system, we perform feature modeling by utilizing statistical analysis method, so as to extract malware family features, including software package feature, permission and application feature, and function call feature. Moreover, for reducing false-positive rate and improving the detecting ability of malware variants, we design a multi-feature detection method of Android-based system for detecting and classifying malware. In addition, we establish a fact-base of distributed Android malicious codes by blockchain technology. The experimental results show that, compared with the previously published algorithms, the new proposed method can achieve higher detection accuracy in limited time with lower false-positive and false-negative rates.","['Malware', 'Feature extraction', 'Androids', 'Humanoid robots', 'Encryption', 'Mobile communication']","['Consortium Blockchain', 'malware detection', 'multi-feature']"
"Predicting the presence of Microaneurysms in the fundus images and the identification of diabetic retinopathy in early-stage has always been a major challenge for decades. Diabetic Retinopathy (DR) is affected by prolonged high blood glucose level which leads to microvascular complications and irreversible vision loss. Microaneurysms formation and macular edema in the retinal is the initial sign of DR and diagnosis at the right time can reduce the risk of non proliferated diabetic retinopathy. The rapid improvement of deep learning makes it gradually become an efficient technique to provide an interesting solution for medical image analysis problems. The proposed system analysis the presence of microaneurysm in fundus image using convolutional neural network algorithms that embeds deep learning as a core component accelerated with GPU(Graphics Processing Unit) which will perform medical image detection and segmentation with high-performance and low-latency inference. The semantic segmentation algorithm is utilized to classify the fundus picture as normal or infected. Semantic segmentation divides the image pixels based on their common semantic to identify the feature of microaneurysm. This provides an automated system that will assist ophthalmologists to grade the fundus images as early NPDR, moderate NPDR, and severe NPDR. The Prognosis of Microaneurysm and early diagnosis system for non - proliferative diabetic retinopathy system has been proposed that is capable to train effectively a deep convolution neural network for semantic segmentation of fundus images which can increase the efficiency and accuracy of NPDR (non proliferated diabetic retinopathy) prediction.","['Diabetes', 'Retinopathy', 'Retina', 'Lesions', 'Image segmentation', 'Semantics', 'Biomedical imaging']","['Microaneurysm', 'diabetic retinopathy', 'deep convolution neural network', 'semantic segmentation', 'non proliferated diabetic retinopathy']"
"This paper proposes a novel tuning design of proportional integral derivative (PID) controller via an improved kidney-inspired algorithm (IKA) with a new objective function. The main objective of the proposed approach is to optimize the transient response of the AVR system by minimizing the maximum overshoot, settling time, rise time and peak time values of the terminal voltage, and eliminating the steady state error. After obtaining the optimal values of the three gains of the PID controller (K P , K I , and K D ) with the proposed approach, the transient response analysis was performed and compared with some of the current heuristic algorithms-based approaches in literature to show the superiority of the optimized PID controller. In order to evaluate the stability of the automatic voltage regulator (AVR) system tuned by IKA method, the pole/zero map analysis and Bode analysis are performed. Finally, the robustness analysis of the proposed approach has been carried out with variations in the parameters of the AVR system. The numerical simulation results demonstrated that the proposed IKA tuned PID controller has better control performances compared to the other existing approaches. The essence of the presented study points out that the proposed approach may successfully be applied for the AVR system.","['Optimization', 'Heuristic algorithms', 'Tuning', 'Linear programming', 'Transient response', 'Voltage control', 'Generators']","['Automatic voltage regulator', 'improved kidney-inspired algorithm', 'PID tuning', 'robustness analysis', 'transient response']"
"A significant growth in solar photovoltaic (PV) installation has observed during the last decade in standalone and grid-connected power generation systems. The solar PV system has a non-linear output characteristic because of weather intermittency, which tends to have a substantial effect on overall PV system output. Hence, to optimize the output of a PV system, different maximum power point tracking (MPPT) techniques have been used. But, the confusion lies while selecting an appropriate MPPT, as every method has its own merits and demerits. Therefore, a proper review of these techniques is essential. A “Google Scholar” survey of the last five years (2015-2020) was conducted. It has found that overall seventy-one review articles are published on different MPPT techniques; out of those seventy-one, only four are on uniform solar irradiance, seven on non-uniform and none on hybrid optimization MPPT techniques. Most of them have discussed the limited number of MPPT techniques, and none of them has discussed the online and offline under uniform and hybrid MPPT techniques under non-uniform solar irradiance conditions all together in one. Unfortunately, very few attempts have made in this regard. Therefore, a comprehensive review paper on this topic is need of time, in which almost all the well-known MPPT techniques should be encapsulated in one paper. This article focuses on classifications of online, offline, and hybrid optimization MPPT algorithms, under the uniform and non-uniform irradiance conditions. It summarizes various MPPT methods along with their mathematical expression, operating principle, and block diagram/flow charts. This research will provide a valuable pathway to researchers, energy engineers, and strategists for future research and implementation in the field of maximum power point tracking optimization.","['Maximum power point trackers', 'Radiation effects', 'Optimization', 'Meteorology', 'Hybrid power systems']","['Maximum power point tracking', 'photovoltaic array', 'uniform solar irradiance', 'non-uniform solar irradiation', 'online and offline MPPT', 'hybrid MPPT methods']"
"A multimodal biometric system integrates information from more than one biometric modality to improve the performance of each individual biometric system and make the system robust to spoof attacks. In this paper, we propose a secure multimodal biometric system that uses convolution neural network (CNN) and Q-Gaussian multi support vector machine (QG-MSVM) based on a different level fusion. We developed two authentication systems with two different level fusion algorithms: a feature level fusion and a decision level fusion. The feature extraction for individual modalities is performed using CNN. In this step, we selected two layers from CNN that achieved the highest accuracy, in which each layer is regarded as separated feature descriptors. After that, we combined them using the proposed internal fusion to generate the biometric templates. In the next step, we applied one of the cancelable biometric techniques to protect these templates and increase the security of the proposed system. In the authentication stage, we applied QG-MSVM as a classifier for authentication to improve the performance. Our systems were tested on several publicly available databases for ECG and fingerprint. The experimental results show that the proposed multimodal systems are efficient, robust, and reliable than existing multimodal authentication systems.","['Electrocardiography', 'Fingerprint recognition', 'Authentication', 'Feature extraction', 'Databases', 'Convolution', 'Filtering']","['Authentication', 'CNN', 'decision fusion', 'ECG', 'feature fusion', 'fingerprint', 'multimodal']"
"An approach is proposed to reduce mutual coupling between two closely spaced radiating elements. This is achieved by inserting a fractal isolator between the radiating elements. The fractal isolator is an electromagnetic bandgap structure based on metamaterial. With this technique, the gap between radiators is reduced to ~0.65λ for the reduction in the mutual coupling of up to 37, 21, 20, and 31 dB in the X-, Ku-, K-, and Ka-bands, respectively. With the proposed technique, the two-element antenna is shown to operate over a wide frequency range, i.e., 8.7-11.7, 11.9-14.6, 15.6-17.1, 22-26, and 29-34.2 GHz. Maximum gain improvement is 71% with no deterioration in the radiation patterns. The antenna's characteristics were validated through measurement. The proposed technique can be applied retrospectively and is applicable in closely placed patch antennas in arrays found in multiple-input multiple-output and radar systems.","['Fractals', 'Isolators', 'Mutual coupling', 'Patch antennas', 'Antenna radiation patterns', 'Couplings', 'Photonic band gap']","['Fractal', 'EM bandgap', 'two-element patch antenna', 'mutual coupling reduction', 'metamaterials', 'multiple-input multiple-output (MIMO)', 'radar']"
"Diagnosis is a critical preventive step in Coronavirus research which has similar manifestations with other types of pneumonia. CT scans and X-rays play an important role in that direction. However, processing chest CT images and using them to accurately diagnose COVID-19 is a computationally expensive task. Machine Learning techniques have the potential to overcome this challenge. This article proposes two optimization algorithms for feature selection and classification of COVID-19. The proposed framework has three cascaded phases. Firstly, the features are extracted from the CT scans using a Convolutional Neural Network (CNN) named AlexNet. Secondly, a proposed features selection algorithm, Guided Whale Optimization Algorithm (Guided WOA) based on Stochastic Fractal Search (SFS), is then applied followed by balancing the selected features. Finally, a proposed voting classifier, Guided WOA based on Particle Swarm Optimization (PSO), aggregates different classifiers’ predictions to choose the most voted class. This increases the chance that individual classifiers, e.g. Support Vector Machine (SVM), Neural Networks (NN), k-Nearest Neighbor (KNN), and Decision Trees (DT), to show significant discrepancies. Two datasets are used to test the proposed model: CT images containing clinical findings of positive COVID-19 and CT images negative COVID-19. The proposed feature selection algorithm (SFS-Guided WOA) is compared with other optimization algorithms widely used in recent literature to validate its efficiency. The proposed voting classifier (PSO-Guided-WOA) achieved AUC (area under the curve) of 0.995 that is superior to other voting classifiers in terms of performance metrics. Wilcoxon rank-sum, ANOVA, and T-test statistical tests are applied to statistically assess the quality of the proposed algorithms as well.","['Computed tomography', 'Feature extraction', 'Optimization', 'Support vector machines', 'Sensitivity', 'Lung', 'Machine learning']","['COVID-19', 'CT scans', 'convolutional neural network', 'guided whale optimization algorithm', 'features selection', 'voting ensemble']"
"For heterogeneous network, which has been viewed as one pioneering technology for making cellular networks be evolved into 5G systems, reducing energy consumption by dynamically switching off base stations (BSs) has attracted increasing attention recently. With aiming at optimization on energy saving only or another energy-related performance tradeoffs, several BS switch-off strategies have been proposed from different design perspectives, such as random, distance-aware, load-aware, and auction-based strategies. Furthermore, work has been done to consider joint design for BS switch-off strategy and another strategies, such as user association, resource allocation, and physical-layer interference cancellation strategies. Finally, there have been research results about this topic in emerging cloud radio access networks. In this paper, we take an overview on these technologies and present the state of the art on each aspect. Some challenges that need to be solved in this research filed for future work are also described.","['Switches', 'Heterogeneous networks', '5G mobile communication', 'Energy consumption', 'Base stations', 'Resource management', 'Cloud computing', 'Green products', 'Radio access networks']","['Energy consumption', 'BS switch-off (or called sleeping) strategy', 'heterogeneous networks', 'cloud radio access networks', 'greener 5G systems']"
"Digital twinning is one of the top ten technology trends in the last couple of years, due to its high applicability in the industrial sector. The integration of big data analytics and artificial intelligence/machine learning (AI-ML) techniques with digital twinning, further enriches its significance and research potential with new opportunities and unique challenges. To date, a number of scientific models have been designed and implemented related to this evolving topic. However, there is no systematic review of digital twinning, particularly focusing on the role of AI-ML and big data, to guide the academia and industry towards future developments. Therefore, this article emphasizes the role of big data and AI-ML in the creation of digital twins (DTs) or DT-based systems for various industrial applications, by highlighting the current state-of-the-art deployments. We performed a systematic review on top of multidisciplinary electronic bibliographic databases, in addition to existing patents in the field. Also, we identified development-tools that can facilitate various levels of the digital twinning. Further, we designed a big data driven and AI-enriched reference architecture that leads developers to a complete DT-enabled system. Finally, we highlighted the research potential of AI-ML for digital twinning by unveiling challenges and current opportunities.","['Big Data', 'Digital twin', 'Patents', 'Industries', 'Systematics', 'Tools', 'Libraries']","['Digital twin', 'artificial intelligence', 'machine learning', 'big data', 'industry 40']"
"An edge detection is important for its reliability and security which delivers a better understanding of object recognition in the applications of computer vision, such as pedestrian detection, face detection, and video surveillance. This paper introduced two fundamental limitations encountered in edge detection: edge connectivity and edge thickness, those have been used by various developments in the state-of-the-art. An optimal selection of the threshold for effectual edge detection has constantly been a key challenge in computer vision. Therefore, a robust edge detection algorithm using multiple threshold approaches (B-Edge) is proposed to cover both the limitations. The majorly used canny edge operator focuses on two thresholds selections and still witnesses a few gaps for optimal results. To handle the loopholes of the canny edge operator, our method selects the simulated triple thresholds that target to the prime issues of the edge detection: image contrast, effective edge pixels selection, errors handling, and similarity to the ground truth. The qualitative and quantitative experimental evaluations demonstrate that our edge detection method outperforms competing algorithms for mentioned issues. The proposed approach endeavors an improvement for both grayscale and colored images.","['Image edge detection', 'Frequency-domain analysis', 'Computer vision', 'Sensitivity', 'Classification algorithms', 'Clustering algorithms', 'Synthetic aperture radar']","['Edge', 'edge connectivity', 'edge detection', 'edge width uniformity', 'threshold']"
"Classification features are crucial for an intrusion detection system (IDS), and the detection performance of IDS will change dramatically when providing different input features. Moreover, the large number of network traffic and their high-dimensional features will result in a very lengthy classification process. Recently, there is an increasing interest in the application of deep learning approaches for classification and learn feature representations. So, in this paper, we propose using the stacked sparse autoencoder (SSAE), an instance of a deep learning strategy, to extract high-level feature representations of intrusive behavior information. The original classification features are introduced into SSAE to learn the deep sparse features automatically for the first time. Then, the low-dimensional sparse features are used to build different basic classifiers. We compare SSAE with other feature extraction methods proposed by previous researchers. The experimental results both in binary classification and multiclass classification indicate the following: 1) the high-dimensional sparse features learned by SSAE are more discriminative for intrusion behaviors compared to previous methods and 2) the classification process of basic classifiers is significantly accelerated by using high-dimensional sparse features. In summary, it is shown that the SSAE is a feasible and efficient feature extraction method and provides a new research method for intrusion detection.","['Feature extraction', 'Intrusion detection', 'Machine learning', 'Machine learning algorithms', 'Anomaly detection']","['Intrusion detection', 'deep learning', 'machine learning', 'SSAE', 'feature extraction']"
"Hybrid analog/digital precoding architectures are a low-complexity alternative for fully digital precoding in millimeter-wave (mmWave) MIMO wireless systems. This is motivated by the reduction in the number of radio frequency and mixed signal hardware components. Hybrid precoding involves a combination of analog and digital processing that enables both beamforming and spatial multiplexing gains in mmWave systems. This paper develops hybrid analog/digital precoding and combining designs for mmWave multiuser systems, based on the mean-squared error (MSE) criteria. In the first design with the analog combiners being determined at the users, the proposed hybrid minimum MSE (MMSE) precoder is realized by minimizing the sum-MSE of the data streams intended for the users. In the second design, both the hybrid precoder and combiners are jointly designed in an iterative manner to minimize a weighted sum-MSE cost function. By leveraging the sparse structure of mmWave channels, the MMSE precoding/combining design problems are then formulated as sparse reconstruction problems. An orthogonal matching pursuit-based algorithm is then developed to determine the MMSE precoder and combiners. Simulation results show the performance advantages of the proposed precoding/combining designs in various system settings.","['Radio frequency', 'Precoding', 'Algorithm design and analysis', 'Antenna arrays', 'MIMO', 'Matching pursuit algorithms', 'Baseband']","['Millimeter wave', 'multiple-input multiple-output (MIMO)', 'antenna arrays', 'beamforming', 'precoding', 'sparse reconstruction', 'minimum mean squared-error (MMSE)']"
"Urban intelligence is an emerging concept which guides a series of infrastructure developments in modern smart cities. Human-computer interaction (HCI) is the interface between residents and the smart cities, it plays a key role in bridging the gap in applicating information technologies in modern cities. Hand gestures have been widely acknowledged as a promising HCI method, recognition human hand gestures using surface electromyogram (sEMG) is an important research topic in the application of sEMG. However, state-of-the-art signal processing technologies are not robust in feature extraction and pattern recognition with sEMG signals, several technical problems are still yet to be solved. For example, how to maintain the availability of myoelectric control in intermittent use, since pattern recognition qualities are greatly affected by time variability, but it is unavoidable during daily use. How to ensure the reliability and effectiveness of myoelectric control system also important in developing a good human-machine interface. In this paper, linear discriminant analysis (LDA) and extreme learning machine (ELM) are implemented in hand gesture recognition system, which is able to reduce the redundant information in sEMG signals and improve recognition efficiency and accuracy. The characteristic map slope (CMS) is extracted by using the feature re-extraction method because CMS can strengthen the relationship of features cross time domain and enhance the feasibility of cross-time identification. This study is focusing on optimizing the time differences in sEMG pattern recognition, the experimental results are beneficial to reducing the time differences in gesture recognition based on sEMG. The recognition framework proposed in this paper can enhance the generalization ability of HCI in the long term use and it also simplifies the data collection stage before training the device ready for daily use, which is of great significance to improve the time generalization performance of an HCI system.","['Feature extraction', 'Gesture recognition', 'Electromyography', 'Human computer interaction', 'Thumb', 'Time-domain analysis']","['Urban intelligence', 'human-computer interaction', 'sEMG', 'gesture recognition']"
"We present a large-scale study exploring the capability of temporal deep neural networks to interpret natural human kinematics and introduce the first method for active biometric authentication with mobile inertial sensors. At Google, we have created a first-of-its-kind data set of human movements, passively collected by 1500 volunteers using their smartphones daily over several months. We compare several neural architectures for efficient learning of temporal multi-modal data representations, propose an optimized shift-invariant dense convolutional mechanism, and incorporate the discriminatively trained dynamic features in a probabilistic generative framework taking into account temporal characteristics. Our results demonstrate that human kinematics convey important information about user identity and can serve as a valuable component of multi-modal authentication systems. Finally, we demonstrate that the proposed model can also be successfully applied in a visual context.","['Authentication', 'Biometrics', 'Access control', 'Learning systems', 'Mobile computing', 'Neural networks', 'Recurrent neural networks', 'Context modeling', 'Kinematics', 'Biosensors']","['Authentication', 'Biometrics (access control)', 'Learning', 'Mobile computing', 'Recurrent neural networks']"
"In computer vision, convolutional networks (CNNs) often adopt pooling to enlarge receptive field which has the advantage of low computational complexity. However, pooling can cause information loss and thus is detrimental to further operations such as features extraction and analysis. Recently, dilated filter has been proposed to tradeoff between receptive field size and efficiency. But the accompanying gridding effect can cause a sparse sampling of input images with checkerboard patterns. To address this problem, in this paper, we propose a novel multi-level wavelet CNN (MWCNN) model to achieve a better tradeoff between receptive field size and computational efficiency. The core idea is to embed wavelet transform into CNN architecture to reduce the resolution of feature maps while at the same time, increasing receptive field. Specifically, MWCNN for image restoration is based on U-Net architecture, and inverse wavelet transform (IWT) is deployed to reconstruct the high resolution (HR) feature maps. The proposed MWCNN can also be viewed as an improvement of dilated filter and a generalization of average pooling and can be applied to not only image restoration tasks, but also any CNNs requiring a pooling operation. The experimental results demonstrate the effectiveness of the proposed MWCNN for tasks, such as image denoising, single image super-resolution, JPEG image artifacts removal and object classification.","['Image restoration', 'Task analysis', 'Discrete wavelet transforms', 'Computer architecture', 'Feature extraction']","['Convolutional networks', 'receptive field size', 'efficiency', 'multi-level wavelet']"
"This paper studies the application of cooperative techniques for non-orthogonal multiple access (NOMA). More particularly, the fixed gain amplify-and-forward (AF) relaying with NOMA is investigated over Nakagami-m fading channels. Two scenarios are considered insightfully: 1) the first scenario is that the base station (BS) intends to communicate with multiple users through the assistance of AF relaying, where the direct links are existent between the BS and users and 2) the second scenario is that the AF relaying is inexistent between the BS and users. To characterize the performance of the considered scenarios, new closed-form expressions for both exact and asymptomatic outage probabilities are derived. Based on the analytical results, the diversity orders achieved by the users are obtained. For the first and second scenarios, the diversity order for the nth user are μ(n + 1) and μn, respectively. Simulation results unveil that NOMA is capable of outperforming orthogonal multiple access (OMA) in terms of outage probability and system throughput. It is also worth noting that NOMA can provide better fairness compared with conventional OMA. By comparing the two scenarios, cooperative NOMA scenario can provide better outage performance relative to the second scenario.","['NOMA', 'Fading channels', 'Interference', 'Signal to noise ratio', 'Silicon carbide', 'Throughput', 'Electronic mail']","['Non-orthogonal multiple access', 'amplify-and-forward relaying', 'Nakagami-m fading channels', 'diversity order']"
"Multi-class pest detection is one of the crucial components in pest management involving localization in addition to classification which is much more difficult than generic object detection because of the apparent differences among pest species. This paper proposes a region-based end-to-end approach named PestNet for large-scale multi-class pest detection and classification based on deep learning. PestNet consists of three major parts. First, a novel module channel-spatial attention (CSA) is proposed to be fused into the convolutional neural network (CNN) backbone for feature extraction and enhancement. The second one is called region proposal network (RPN) that is adopted for providing region proposals as potential pest positions based on extracted feature maps from images. Position-sensitive score map (PSSM), the third component, is used to replace fully connected (FC) layers for pest classification and bounding box regression. Furthermore, we apply contextual regions of interest (RoIs) as contextual information of pest features to improve detection accuracy. We evaluate PestNet on our newly collected large-scale pests' image dataset, Multi-class Pests Dataset 2018 (MPD2018) captured by our designed task-specific image acquisition equipment, covering more than 80k images with over 580k pests labeled by agricultural experts and categorized in 16 classes. The experimental results show that the proposed PestNet performs well on multi-class pest detection with 75.46% mean average precision (mAP), which outperforms the state-of-the-art methods.","['Feature extraction', 'Proposals', 'Insects', 'Training', 'Deep learning', 'Task analysis', 'Computer architecture']","['Channel-spatial attention', 'convolutional neural network', 'multi-class pest detection', 'position-sensitive score map', 'region proposal network']"
"In order to overcome the problem of power generation in distributed energy, microgrid(MG) emerges as an alternative scheme. Compared with the ac microgrids, the dc microgrids have the advantages of high system efficiency, good power quality, low cost, and simple control. However, due to the complexity of the distributed generation system, the conventional droop control shows the drawbacks of low current sharing accuracy. Therefore, the improved primary control methods to enhance current sharing accuracy are systematically reviewed, such as particle swarm optimization programming, probabilistic algorithm and voltage correction factor scheme. However, it is difficult to achieve stable and coordinated operation of the dc microgrids by relying on the primary control. Hence, the various secondary control approaches, such as dynamic current sharing scheme, muti-agent system (MAS) control and virtual voltage control methods have been summarized for voltage regulation. Furthermore, the energy management system (EMS), modular-based energy router (MBER) and other coordinated control methods are reviewed to achieve power management. Besides, various control methods to compensate the effect of communication delay are summarized. Moreover, linear matrix inequality (LMI), Lyapunov-Krasovskii functional stability and Takagi-Sugeno model prediction scheme can be adopted to eliminate the influence of communication delay. In addition, due to the constant power loads (CPL) exhibit negative impedance characteristics, which may result in the output oscillation of filter. Thus, various control approaches have been reviewed to match the impedance, such as the nonlinear disturbance observer (NDO) feedforward compensation method, linear programming algorithm, hybrid potential theory and linear system analysis of polyhedral uncertainty. The merits and drawbacks of those control strategies are compared in this paper. Finally, the future research trends of hierarchical control and stability in dc microgrids and dc microgrid clusters are also presented.","['Voltage control', 'Stability criteria', 'Microgrids', 'Impedance', 'Power system stability', 'Delays']","['DC microgrid', 'nonlinear droop control', 'multi-agent system', 'consensus control', 'communication delay', 'constant power load', 'hierarchical control']"
"As the next generation network architecture, software-defined networking (SDN) has exciting application prospects. Its core idea is to separate the forwarding layer and control layer of network system, where network operators can program packet forwarding behavior to significantly improve the innovation capability of network applications. Traffic engineering (TE) is an important network application, which studies measurement and management of network traffic, and designs reasonable routing mechanisms to guide network traffic to improve utilization of network resources, and better meet requirements of the network quality of service (QoS). Compared with the traditional networks, the SDN has many advantages to support TE due to its distinguish characteristics, such as isolation of control and forwarding, global centralized control, and programmability of network behavior. This paper focuses on the traffic engineering technology based on the SDN. First, we propose a reference framework for TE in the SDN, which consists of two parts, traffic measurement and traffic management. Traffic measurement is responsible for monitoring and analyzing real-time network traffic, as a prerequisite for traffic management. In the proposed framework, technologies related to traffic measurement include network parameters measurement, a general measurement framework, and traffic analysis and prediction; technologies related to traffic management include traffic load balancing, QoS-guarantee scheduling, energy-saving scheduling, and traffic management for the hybrid IP/SDN. Current existing technologies are discussed in detail, and our insights into future development of TE in the SDN are offered.","['Software defined networks', 'Telecommunication traffic', 'Telecommunication network management', 'Network monitoring', 'Quality of service', 'Current measurement', 'Energy measurement', 'Next generatoin networking', 'Resource management']","['Software-defined networkin', 'SDN', 'traffic engineering', 'network monitoring', 'network measurement', 'network management']"
"Data offloading plays an important role for the mobile data explosion problem that occurs in cellular networks. This paper proposed an idea and control scheme for offloading vehicular communication traffic in the cellular network to vehicle to vehicle (V2V) paths that can exist in vehicular ad hoc networks (VANETs). A software-defined network (SDN) inside the mobile edge computing (MEC) architecture, which is abbreviated as the SDNi-MEC server, is devised in this paper to tackle the complicated issues of VANET V2V offloading. Using the proposed SDNi-MEC architecture, each vehicle reports its contextual information to the context database of the SDNi-MEC server, and the SDN controller of the SDNi-MEC server calculates whether there is a V2V path between the two vehicles that are currently communicating with each other through the cellular network. This proposed method: 1) uses each vehicle's context; 2) adopts a centralized management strategy for calculation and notification; and 3) tries to establish a VANET routing path for paired vehicles that are currently communicating with each other using a cellular network. The performance analysis for the proposed offloading control scheme based on the SDNi-MEC server architecture shows that it has better throughput in both the cellular networking link and the V2V paths when the vehicle's density is in the middle.","['Vehicular ad hoc networks', 'Cellular networks', 'Servers', 'Computer architecture', 'Cloud computing', 'Software defined networking', 'Routing']","['Cellular networks', 'mobile edge computing (MEC)', 'software defined network (SDN)', 'VANET offloading', 'V2V communication']"
"Load forecasting is a pivotal part of the power utility companies. To provide load-shedding free and uninterrupted power to the consumer, decision-makers in the utility sector must forecast the future demand for electricity with a minimum error percentage. Load prediction with less percentage of error can save millions of dollars to the utility companies. There are numerous Machine Learning (ML) techniques to amicably forecast electricity demand, among which the hybrid models show the best result. Two or more than two predictive models are amalgamated to design a hybrid model, each of which provides improved performances by the merit of individual algorithms. This paper reviews the current state-of-the-art of electric load forecasting technologies and presents recent works pertaining to the combination of different ML algorithms into two or more methods for the construction of hybrid models. A comprehensive study of each single and multiple load forecasting model is performed with an in-depth analysis of their advantages, disadvantages, and functions. A comparison between their performance in terms of Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE) values are developed with pertinent literature of several models to aid the researchers with the selection of suitable models for load prediction.","['Load forecasting', 'Predictive models', 'Load modeling', 'Support vector machines', 'Prediction algorithms', 'Forecasting', 'Clustering algorithms']","['Load forecasting', 'predictive models', 'machine learning', 'support vector machines', 'artificial neural networks', 'computational intelligence', 'power industry', 'smart grid']"
"The grid denotes the electric grid which consists of communication lines, control stations, transformers, and distributors that aids in supplying power from the electrical plant to the consumers. Presently, the electric grid constitutes humongous power production units which generates millions of megawatts of power distributed across several demographic regions. There is a dire need to efficiently manage this power supplied to the various consumer domains such as industries, smart cities, household and organizations. In this regard, a smart grid with intelligent systems is being deployed to cater the dynamic power requirements. A smart grid system follows the Cyber-Physical Systems (CPS) model, in which Information Technology (IT) infrastructure is integrated with physical systems. In the scenario of the smart grid embedded with CPS, the Machine Learning (ML) module is the IT aspect and the power dissipation units are the physical entities. In this research, a novel Multidirectional Long Short-Term Memory (MLSTM) technique is being proposed to predict the stability of the smart grid network. The results obtained are evaluated against other popular Deep Learning approaches such as Gated Recurrent Units (GRU), traditional LSTM and Recurrent Neural Networks (RNN). The experimental results prove that the MLSTM approach outperforms the other ML approaches.","['Smart grids', 'Power system stability', 'Stability analysis', 'Machine learning algorithms', 'Predictive models', 'Machine learning', 'Prediction algorithms']","['Multidirectional long short-term memory (MLSTM)', 'machine learning (ML)', 'smart grid (SG)', 'cyber physical systems (CPS)']"
"The sharing of electronic health records (EHRs) has great positive significance for research of disease and doctors' diagnosis. In recent years, cloud-based electronic medical record sharing scheme has brought a lot of conveniences, but the centralization of cloud exposes threats inevitably to data security and privacy preservation. Blockchain technology can be seen as a promising solution to address these problems on account of its unique propertis of decentration, anonymity, unforgeability and verifiability. In this paper, we propose a blockchain based secure and privacy-preserving EHR sharing protocol. Data requester can search desired keyword from data provider to find relevant EHRs on the EHR consortium blockchain and get the re-encryption ciphertext from cloud server after getting the data owner's authorization. The scheme mainly uses searchable encryption and conditional proxy re-encryption to realize data security, privacy preservation, and access control. Furthermore, proof of authorization is designed as the consensus mechanism for consortium blockchain to guarantee system's availability. Security analysis demonstrates that the proposed protocol can achieve security goals. Besides, we emulate the cryptographic primitives and implement the proposed scheme on Ethereum platform. Performance evaluation shows that the proposed scheme has high computational efficiency.","['Blockchain', 'Cloud computing', 'Data privacy', 'Data security', 'Medical diagnostic imaging', 'Privacy']","['Electronic health records', 'data sharing', 'blockchain', 'data security', 'privacy preservation']"
"In recent years, chaos-based image encryption algorithms have aroused extensive research interest. However, some image encryption algorithms still have several security defects, and the research on cryptanalysis is relatively inadequate. This paper performs the cryptanalysis of a newly proposed color image encryption scheme using RT-enhanced chaotic tent map. By using chosen-plaintext attacks, the equivalent keys of the cryptosystem are successfully broken, so that the target ciphertext image can be decoded. Based on the cryptanalysis, we then proposed an improved encryption algorithm. A new logistic-tent map is proposed and applied to the improved encryption algorithm, and a parameter related to the SHA-3 hash value of the plaintext image is introduced as a secret key parameter so that the improved algorithm can resist chosen-plaintext attacks. The security analysis and experimental tests for the improved algorithm are given in detail, which show that the improved algorithm can significantly increase the security of encryption images while still possessing all the merits of the original algorithm.","['Encryption', 'Color', 'Chaotic communication', 'Transforms', 'Machinery']","['Chaotic cryptography', 'cryptanalysis', 'image encryption', 'logistic-tent map (LTM)']"
"Society and individuals are negatively influenced both politically and socially by the widespread increase of fake news either way generated by humans or machines. In the era of social networks, the quick rotation of news makes it challenging to evaluate its reliability promptly. Therefore, automated fake news detection tools have become a crucial requirement. To address the aforementioned issue, a hybrid Neural Network architecture, that combines the capabilities of CNN and LSTM, is used with two different dimensionality reduction approaches, Principle Component Analysis (PCA) and Chi-Square. This work proposed to employ the dimensionality reduction techniques to reduce the dimensionality of the feature vectors before passing them to the classifier. To develop the reasoning, this work acquired a dataset from the Fake News Challenges (FNC) website which has four types of stances: agree, disagree, discuss, and unrelated. The nonlinear features are fed to PCA and chi-square which provides more contextual features for fake news detection. The motivation of this research is to determine the relative stance of a news article towards its headline. The proposed model improves results by ~4% and ~20% in terms of Accuracy and F1-score . The experimental results show that PCA outperforms than Chi-square and state-of-the-art methods with 97.8% accuracy.","['Feature extraction', 'Principal component analysis', 'Task analysis', 'Machine learning', 'Pregnancy', 'Computer science', 'Computational modeling']","['Fake news detection', 'text mining', 'deep learning', 'PCA', 'Chi-square', 'CNN-LSTM', 'word embedding']"
"Network function virtualization (NFV) has already been a new paradigm for network architectures. By migrating NFs from dedicated hardware to virtualization platform, NFV can effectively improve the flexibility to deploy and manage service function chains (SFCs). However, resource allocation for requested SFC in NFV-based infrastructures is not trivial as it mainly consists of three phases: virtual network functions (VNFs) chain composition, VNFs forwarding graph embedding, and VNFs scheduling. The decision of these three phases can be mutually dependent, which also makes it a tough task. Therefore, a coordinated approach is studied in this paper to jointly optimize NFV resource allocation in these three phases. We apply a general cost model to consider both network costs and service performance. The coordinate NFV-RA is formulated as a mixed-integer linear programming, and a heuristic-based algorithm (JoraNFV) is proposed to get the near optimal solution. To make the coordinated NFV-RA more tractable, JoraNFV is divided into two sub-algorithms, one-hop optimal traffic scheduling and a multi-path greedy algorithm for VNF chain composition and VNF forwarding graph embedding. Last, extensive simulations are performed to evaluate the performance of JoraNFV, and results have shown that JoraNFV can get a solution within 1.25 times of the optimal solution with reasonable execution time, which indicates that JoraNFV can be used for online NFV planning.","['Resource management', 'Noise measurement', 'Telecommunication traffic', 'Scheduling', 'Mix integer linear programming', 'Virtual function placement']","['NFV', 'resource allocation', 'service function chain', 'traffic scheduling', 'virtual function placement']"
"Women who have recovered from breast cancer (BC) always fear its recurrence. The fact that they have endured the painstaking treatment makes recurrence their greatest fear. However, with current advancements in technology, early recurrence prediction can help patients receive treatment earlier. The availability of extensive data and advanced methods make accurate and fast prediction possible. This research aims to compare the accuracy of a few existing data mining algorithms in predicting BC recurrence. It embeds a particle swarm optimization as feature selection into three renowned classifiers, namely, naive Bayes, K-nearest neighbor, and fast decision tree learner, with the objective of increasing the accuracy level of the prediction model.","['Breast cancer', 'Feature extraction', 'Data mining', 'Predictive models', 'Data models', 'Classification algorithms']","['Breast cancer', 'recurrence', 'feature selection', 'REPTree', 'naïve Bayes', 'K-nearest neighbor', 'particle swarm optimization']"
"Ship detection is of great importance and full of challenges in the field of remote sensing. The complexity of application scenarios, the redundancy of detection region, and the difficulty of dense ship detection are all the main obstacles that limit the successful operation of traditional methods in ship detection. In this paper, we propose a brand new detection model based on multitask rotational region convolutional neural network to solve the problems above. This model is mainly consisting of five consecutive parts: dense feature pyramid network, adaptive region of interest (ROI) align, rotational bounding box regression, prow direction prediction and rotational nonmaximum suppression (R-NMS). First of all, the low-level location information and high-level semantic information are fully utilized through multiscale feature networks. Then, we design adaptive ROI align to obtain high quality proposals which remain complete spatial and semantic information. Unlike most previous approaches, the prediction obtained by our method is the minimum bounding rectangle of the object with less redundant regions. Therefore, the rotational region detection framework is more suitable to detect the dense object than traditional detection model. Additionally, we can find the berthing and sailing direction of ship through prediction. A detailed evaluation based on SRSS for rotation detection shows that our detection method has a competitive performance.","['Marine vehicles', 'Feature extraction', 'Proposals', 'Object detection', 'Remote sensing', 'Semantics', 'Detection algorithms']","['Convolutional neural network', 'remote sensing', 'ship detection']"
"In this paper, a method for detecting rapid rice disease based on FCM-KM and Faster R-CNN fusion is proposed to address various problems with the rice disease images, such as noise, blurred image edge, large background interference and low detection accuracy. Firstly, the method uses a two-dimensional filtering mask combined with a weighted multilevel median filter (2DFM-AMMF) for noise reduction, and uses a faster two-dimensional Otsu threshold segmentation algorithm (Faster 2D-Otsu) to reduce the interference of complex background with the detection of target blade in the image. Then the dynamic population firefly algorithm based on the chaos theory as well as the maximum and minimum distance algorithm is applied for optimization of the K-Means clustering algorithm (FCM-KM) to determine the optimal clustering class k value while addressing the tendency of the algorithm to fall into the local optimum problem. Combined with the R-CNN algorithm for the identification of rice diseases, FCM-KM analysis is conducted to determine the different sizes of the Faster R-CNN target frame. As revealed by the application results of 3010 images, the accuracy and time required for detection of rice blast, bacterial blight and blight were 96.71%/0.65s, 97.53%/0.82s and 98.26%/0.53s, respectively, indicating clearly that the method is more capable of detecting rice diseases and improving the identification accuracy of Faster R-CNN algorithm, while reducing the time required for identification.","['Diseases', 'Clustering algorithms', 'Feature extraction', 'Heuristic algorithms', 'Filtering', 'Image segmentation', 'Microorganisms']","['Chaos theory', 'faster R-CNN', 'firefly algorithm', 'Otsu threshold segmentation', 'K-means clustering algorithm', 'rice disease detection', 'weighted multistage median filter']"
"Maintaining frequency stability of low inertia microgrids with high penetration of renewable energy sources (RESs) is a critical challenge. Solving this challenge, the inertia of microgrids would be enhanced by virtual inertia control-based energy storage systems. However, in such systems, the virtual inertia constant is fixed and selection of its value will significantly affect frequency stability of microgrids under different penetration levels of RESs. Higher frequency oscillations may occur due to the fixed virtual inertia constant or unsuitable selection of its value. To overcome such a problem and provide adaptive inertia control, this paper proposes a self-adaptive virtual inertia control system using fuzzy logic for ensuring stable frequency stabilization, which is required for successful microgrid operation in the presence of high RESs penetration. In this concept, the virtual inertia constant is automatically adjusted based on input signals of real power injection of RESs and system frequency deviations, avoiding unsuitable selection and delivering rapid inertia response. To verify the efficiency of the proposed control method, the contrastive simulation results are compared with the conventional method for serious load disturbances and various rates of RESs penetration. The proposed control method shows remarkable performance in transient response improvement and fast damping of oscillations, preserving robustness of operation.","['Microgrids', 'Frequency control', 'Power system stability', 'Power generation', 'Stability analysis', 'Control systems', 'Fuzzy logic']","['Frequency control', 'fuzzy logic', 'intelligent control', 'islanded microgrid', 'virtual inertia control', 'virtual synchronous generator']"
"Since the noise statistics of large-scale battery energy storage systems (BESSs) are often unknown or inaccurate in actual applications, the estimation precision of state of charge (SOC) of BESSs using extended Kalman filter (EKF) or unscented Kalman filter (UKF) is usually inaccurate or even divergent. To resolve this problem, a method based on adaptive UKF (AUKF) with a noise statistics estimator is proposed to estimate accurately SOC of BESSs. The noise statistics estimator based on the modified Sage-Husa maximum posterior is aimed to estimate adaptively the mean and error covariance of measurement and system process noises online for the AUKF when the prior noise statistics are unknown or inaccurate. The accuracy and adaptation of the proposed method is validated by the comparison with the UKF and EKF under different real-time conditions. The comparison shows that the proposed method can achieve better SOC estimation accuracy when the noise statistics of BESSs are unknown or inaccurate.","['Batteries', 'State of charge', 'Estimation', 'Kalman filters', 'Integrated circuit modeling', 'Battery charge measurement', 'Voltage measurement']","['Adaptive unscented Kalman filter', 'battery energy storage systems', 'noise statistics estimator', 'state of charge']"
"The artificial intelligence (AI) techniques have been widely used in the transient stability analysis of a power system. They are recognized as the most promising approaches for predicting the post-fault transient stability status with the use of phasor measurement units data. However, the popular AI methods used for power systems are often “black boxes,” which result in the poor interpretation of the model. In this paper, a transient stability prediction method based on extreme gradient boosting is proposed. In this model, a decision graph and feature importance scores are provided to discover the relationship between the features of the power system and transient stability. Meanwhile, the key features are selected according to the feature importance scores to remove redundant variables. The simulation results on the New England 39-bus system have demonstrated the superiority of the proposed model over the prior methods in the computation speed and prediction accuracy. Finally, an algorithm is proposed to interpret the prediction results for a specific fault of the power system, which further improves the interpretability of the model and makes it attractive for real-time transient stability prediction.","['Power system stability', 'Transient analysis', 'Generators', 'Stability criteria', 'Predictive models']","['Feature importance scores', 'model interpretation', 'XGBoost model', 'transient stability prediction']"
"With the ubiquitous deployment of wireless systems and pervasive availability of smart devices, indoor localization is empowering numerous location-based services. With the established radio maps, WiFi fingerprinting has become one of the most practical approaches to localize mobile users. However, most fingerprint-based localization algorithms are computation-intensive, with heavy dependence on both offline training phase and online localization phase. In this paper, we propose CNNLoc, a Convolutional Neural Network (CNN) based indoor localization system with WiFi fingerprints for multi-building and multi-floor localization. Specifically, we devise a novel classification model and a novel positioning model by combining a Stacked Auto-Encoder (SAE) with a one-dimensional CNN. The SAE is utilized to precisely extract key features from sparse Received Signal Strength (RSS) data while the CNN is trained to effectively achieve high accuracy in the positioning phase. We evaluate the proposed system on the UJIIndoorLoc dataset and Tampere dataset and compare the performance with several state-of-the-art methods. Moreover, we further propose a newly collected WiFi fingerprinting dataset UTSIndoorLoc and test the positioning model of CNNLoc on it. The results show CNNLoc outperforms the existing solutions with 100% and 95% success rates on building-level localization and floor-level localization, respectively.","['Wireless fidelity', 'Buildings', 'Training', 'Wireless communication', 'Convolutional neural networks', 'Fingerprint recognition', 'Databases']","['Indoor localization', 'deep learning', 'convolutional neural network', 'WiFi fingerprinting']"
"Cyber-physical systems (CPS) are a collection of transformative technologies for managing interconnected physical and computational capabilities. Recent developments in technology are increasing the availability and affordability of sensors, data acquisition systems, and computer networks. The competitive nature of industry requires manufacturers to implement new methodologies. CPS is a broad area of engineering which supports applications across industries, such as manufacturing, healthcare, electric power grids, agriculture, and transportation. In particular, CPS is the core technology enabling the transition from Industry 3.0 to Industry 4.0 (I 4.0) and is transforming global advanced manufacturing. This paper provides a consolidated review of the latest CPS literature, a complete review of international standards, and a complete analysis of patent portfolios related to the 5C's CPS architecture model by Lee et al. The critical evaluation of international standards and the intellectual property contained in CPS patents is unaddressed by the previous research and will benefit both academic scholars and industry practitioners. The analysis provides a basis for predicting research and development future trends and helps policy makers manage technology changes that will result from CPS in I 4.0. This paper covers the emerging I 4.0 standards from the International Organization for Standardization, the International Electrotechnical Commission, and China's Guobiao standards followed by a patent analysis covering global patents issued in the U.S., Europe, China, and the World Intellectual Property Organization.","['Cyber-physical systems', 'Patents', 'Manufacturing processes', 'Intellectual property', 'Sensor systems', 'Standards development', 'International standards']","['Cyber physical systems (CPS)', 'Industry 4.0', 'patent analysis']"
"Recently, due to the increasing popularity of enjoying various multimedia services on mobile devices (e.g., smartphones, ipads, and electronic tablets), the generated mobile data traffic has been explosively growing and has become a serve burden on mobile network operators. To address such a serious challenge in mobile networks, an effective approach is to manage data traffic by using complementary technologies (e.g., small cell network, WiFi network, and so on) to achieve mobile data offloading. In this paper, we discuss the recent advances in the techniques of mobile data offloading. Particularly, based on the initiator diversity of data offloading, we classify the existing mobile data offloading technologies into four categories, i.e., data offloading through small cell networks, data offloading through WiFi networks, data offloading through opportunistic mobile networks, and data offloading through heterogeneous networks. Besides, we show a detailed taxonomy of the related mobile data offloading technologies by discussing the pros and cons for various offloading technologies for different problems in mobile networks. Finally, we outline some opening research issues and challenges, which can provide guidelines for future research work.","['Mobile computing', 'Wireless fidelity', 'Base stations', 'Mobile handsets', 'Microcell networks']","['Mobile data offloading', 'small cell networks', 'WiFi networks', 'opportunistic mobile networks', 'heterogeneous networks']"
"The integration of communication networks and the Internet of Things (IoT) in Industrial Control Systems (ICSs) increases their vulnerability towards cyber-attacks, causing devastating outcomes. Traditional Intrusion Detection Systems (IDSs), which are mainly developed to support information technology systems, count vastly on predefined models and are trained mostly on specific cyber-attacks. Besides, most IDSs do not consider the imbalanced nature of ICS datasets, thereby suffering from low accuracy and high false-positive when being put to use. In this paper, we propose a deep learning model to construct new balanced representations of the imbalanced datasets. The new representations are fed into an ensemble deep learning attack detection model specifically designed for an ICS environment. The proposed attack detection model leverages Deep Neural Network (DNN) and Decision Tree (DT) classifiers to detect cyber-attacks from the new representations. The performance of the proposed model is evaluated based on 10-fold cross-validation on two real ICS datasets. The results show that the proposed method outperforms conventional classifiers, including Random Forest (RF), DNN, and AdaBoost, as well as recent existing models in the literature. The proposed approach is a generalized technique, which can be implemented in existing ICS infrastructures with minimum effort.","['Integrated circuit modeling', 'Deep learning', 'Critical infrastructure', 'Security', 'Industrial control', 'Internet of Things']","['Cyber-attacks', 'critical infrastructure', 'industrial control system', 'integrity attack', 'operation technology', 'information technology', 'deep learning', 'neural network']"
"In recent years, machine learning-based intrusion detection systems (IDSs) have proven to be effective; especially, deep neural networks improve the detection rates of intrusion detection models. However, as models become more and more complex, people can hardly get the explanations behind their decisions. At the same time, most of the works about model interpretation focuses on other fields like computer vision, natural language processing, and biology. This leads to the fact that in practical use, cybersecurity experts can hardly optimize their decisions according to the judgments of the model. To solve these issues, a framework is proposed in this paper to give an explanation for IDSs. This framework uses SHapley Additive exPlanations (SHAP), and combines local and global explanations to improve the interpretation of IDSs. The local explanations give the reasons why the model makes certain decisions on the specific input. The global explanations give the important features extracted from IDSs, present the relationships between the feature values and different types of attacks. At the same time, the interpretations between two different classifiers, one-vs-all classifier and multiclass classifier, are compared. NSL-KDD dataset is used to test the feasibility of the framework. The framework proposed in this paper leads to improve the transparency of any IDS, and helps the cybersecurity staff have a better understanding of IDSs' judgments. Furthermore, the different interpretations between different kinds of classifiers can also help security experts better design the structures of the IDSs. More importantly, this work is unique in the intrusion detection field, presenting the first use of the SHAP method to give explanations for IDSs.","['Intrusion detection', 'Computational modeling', 'Predictive models', 'Machine learning', 'Biological system modeling', 'Feature extraction']","['Intrusion detection system', 'Shapley value', 'SHapley Additive exPlanations', 'model interpretation', 'machine learning']"
"Recently, mobile networking systems have been designed with more complexity of infrastructure and higher diversity of associated devices and resources, as well as more dynamical formations of networks, due to the fast development of current Internet and mobile communication industry. In such emerging mobile heterogeneous networks (HetNets), there are a large number of technical challenges focusing on the efficient organization, management, maintenance, and optimization, over the complicated system resources. In particular, HetNets have attracted great interest from academia and industry in deploying more effective solutions based on artificial intelligence (AI) techniques, e.g., machine learning, bio-inspired algorithms, fuzzy neural network, and so on, because AI techniques can naturally handle the problems of large-scale complex systems, such as HetNets towards more intelligent and automatic-evolving ones. In this paper, we discuss the state-of-the-art AI-based techniques for evolving the smarter HetNets infrastructure and systems, focusing on the research issues of self-configuration, self-healing, and self-optimization, respectively. A detailed taxonomy of the related AI-based techniques of HetNets is also shown by discussing the pros and cons for various AI-based techniques for different problems in HetNets. Opening research issues and pending challenges are concluded as well, which can provide guidelines for future research work.","['Mobile communication', 'Genetic algorithms', 'Ant colony optimization', 'Artificial intelligence', 'Heterogeneous networks', 'Biological system modeling', 'Complexity theory', 'Neural networks']","['Artificial Intelligence', 'Genetic Algorithms', 'Ant Colony Optimization', 'Self-Organization Networks', 'Heterogeneous Networks']"
"Automated pavement crack image segmentation is challenging because of inherent irregular patterns, lighting conditions, and noise in images. Conventional approaches require a substantial amount of feature engineering to differentiate crack regions from non-affected regions. In this paper, we propose a deep learning technique based on a convolutional neural network to perform segmentation tasks on pavement crack images. Our approach requires minimal feature engineering compared to other machine learning techniques. We propose a U-Net-based network architecture in which we replace the encoder with a pretrained ResNet-34 neural network. We use a “one-cycle” training schedule based on cyclical learning rates to speed up the convergence. Our method achieves an F1 score of 96% on the CFD dataset and 73% on the Crack500 dataset, outperforming other algorithms tested on these datasets. We perform ablation studies on various techniques that helped us get marginal performance boosts, i.e., the addition of spatial and channel squeeze and excitation (SCSE) modules, training with gradually increasing image sizes, and training various neural network layers with different learning rates.","['Convolutional neural networks', 'Image segmentation', 'Network architecture', 'Training', 'Deep learning', 'Feature extraction']","['Convolutional neural network', 'deep learning', 'fully convolutional network', 'pavement crack segmentation', 'U-Net']"
"The Internet of Medical Things (IoMT) is a kind of connected infrastructure of smart medical devices along with software applications, health systems and services. These medical devices and applications are connected to healthcare systems through the Internet. The Wi-Fi enabled devices facilitate machine-to-machine communication and link to the cloud platforms for data storage. IoMT has the ability to make accurate diagnoses, with fewer mistakes and lower costs of care. IoMT with smartphone applications permits the patients to exchange their health related confidential and private information to the healthcare experts (i.e., doctors) for the better control of diseases, and also for tracking and preventing chronic illnesses. Due to insecure communication among the entities involved in IoMT, an attacker can tamper with the confidential and private health related information for example an attacker can not only intercept the messages, but can also modify, delete or insert malicious messages during communication. To deal this sensitive issue, we design a novel blockchain enabled authentication key agreement protocol for IoMT environment, called BAKMP-IoMT. BAKMP-IoMT provides secure key management between implantable medical devices and personal servers and between personal servers and cloud servers. The legitimate users can also access the healthcare data from the cloud servers in a secure way. The entire healthcare data is stored in a blockchain maintained by the cloud servers. A detailed formal security including the security verification of BAKMP-IoMT using the widely-accepted Automated Validation of Internet Security Protocols and Applications (AVISPA) tool is performed to demonstrate its resilience against the different types of possible attack. The comparison of BAKMP-IoMT with relevant existing schemes is conducted which identifies that the proposed system furnishes better security and functionality, and also needs low communication and computational costs as compared to other schemes. Finally, the simulation of BAKMP-IoMT is conducted to demonstrate its impact on the performance parameters.","['Medical services', 'Authentication', 'Internet', 'Computational modeling', 'Privacy']","['Blockchain', 'Internet of Medical Things (IoMT)', 'authentication', 'key management', 'security', 'simulation']"
"Mobile crowdsensing (MCS) is a human-driven Internet of Things service empowering citizens to observe the phenomena of individual, community, or even societal value by sharing sensor data about their environment while on the move. Typical MCS service implementations utilize cloud-based centralized architectures, which consume a lot of computational resources and generate significant network traffic, both in mobile networks and toward cloud-based MCS services. Mobile edge computing (MEC) is a natural choice to distribute MCS solutions by moving computation to network edge, since an MEC-based architecture enables significant performance improvements due to the partitioning of problem space based on location, where real-time data processing and aggregation is performed close to data sources. This in turn reduces the associated traffic in mobile core and will facilitate MCS deployments of massive scale. This paper proposes an edge computing architecture adequate for massive scale MCS services by placing key MCS features within the reference MEC architecture. In addition to improved performance, the proposed architecture decreases privacy threats and permits citizens to control the flow of contributed sensor data. It is adequate for both data analytics and real-time MCS scenarios, in line with the 5G vision to integrate a huge number of devices and enable innovative applications requiring low network latency. Our analysis of service overhead introduced by distributed architecture and service reconfiguration at network edge performed on real user traces shows that this overhead is controllable and small compared with the aforementioned benefits. When enhanced by interoperability concepts, the proposed architecture creates an environment for the establishment of an MCS marketplace for bartering and trading of both raw sensor data and aggregated/processed information.","['Computer architecture', 'Task analysis', 'Mobile communication', 'Edge computing', 'Real-time systems', 'Mobile handsets', 'Mobile computing']","['Mobile crowdsensing', 'mobile edge computing', 'MCS functional architecture', 'MEC reference architecture']"
"In recent years, due to the extensive use of the Internet, the number of networked computers has been increasing in our daily lives. Weaknesses of the servers enable hackers to intrude on computers by using not only known but also new attack-types, which are more sophisticated and harder to detect. To protect the computers from them, Intrusion Detection System (IDS), which is trained with some machine learning techniques by using a pre-collected dataset, is one of the most preferred protection mechanisms. The used datasets were collected during a limited period in some specific networks and generally don't contain up-to-date data. Additionally, they are imbalanced and cannot hold sufficient data for all types of attacks. These imbalanced and outdated datasets decrease the efficiency of current IDSs, especially for rarely encountered attack types. In this paper, we propose six machine-learning-based IDSs by using K Nearest Neighbor, Random Forest, Gradient Boosting, Adaboost, Decision Tree, and Linear Discriminant Analysis algorithms. To implement a more realistic IDS, an up-to-date security dataset, CSE-CIC-IDS2018, is used instead of older and mostly worked datasets. The selected dataset is also imbalanced. Therefore, to increase the efficiency of the system depending on attack types and to decrease missed intrusions and false alarms, the imbalance ratio is reduced by using a synthetic data generation model called Synthetic Minority Oversampling TEchnique (SMOTE). Data generation is performed for minor classes, and their numbers are increased to the average data size via this technique. Experimental results demonstrated that the proposed approach considerably increases the detection rate for rarely encountered intrusions.","['Support vector machines', 'Intrusion detection', 'Random forests', 'Computer hacking', 'Servers']","['IDS', 'intrusion detection', 'SMOTE', 'machine learning', 'CSE-CIC-IDS2018', 'imbalanced dataset']"
"The massive multiple-input multiple-output (MIMO) system has drawn increasing attention recently as it is expected to boost the system throughput and result in lower costs. Previous studies mainly focus on time division duplexing (TDD) systems, which are more amenable to practical implementations due to channel reciprocity. However, there are many frequency division duplexing (FDD) systems deployed worldwide. Consequently, it is of great importance to investigate the design and performance of FDD massive MIMO systems. To reduce the overhead of channel estimation in FDD systems, a two-stage precoding scheme was recently proposed to decompose the precoding procedure into intergroup precoding and intragroup precoding. The problem of user grouping and scheduling thus arises. In this paper, we first propose three novel similarity measures for user grouping based on weighted likelihood, subspace projection, and Fubini-Study, respectively, as well as two novel clustering methods, including hierarchical and K-medoids clustering. We then propose a dynamic user scheduling scheme to further enhance the system throughput once the user groups are formed. The load balancing problem is considered when few users are active and solved with an effective algorithm. The efficacy of the proposed schemes are validated with theoretical analysis and simulations.","['MIMO', 'Design methodology', 'Throughtput', 'Dynamic scheduling', 'Frequency conversion', 'Channel estimation', 'Clustering methods', 'Weight measurement', 'Costs', 'Finite difference methods', 'Time division multiplexing']","['Massive multiple-input multiple-output (MIMO)', 'frequency division duplexing (FDD)', 'precoding', 'user grouping', 'load balancing']"
"Recommender systems have been based on context and content, and now the technological challenge of making personalized recommendations based on the user emotional state arises through physiological signals that are obtained from devices or sensors. This paper applies the deep learning approach using a deep convolutional neural network on a dataset of physiological signals (electrocardiogram and galvanic skin response), in this case, the AMIGOS dataset. The detection of emotions is done by correlating these physiological signals with the data of arousal and valence of this dataset, to classify the affective state of a person. In addition, an application for emotion recognition based on classic machine learning algorithms is proposed to extract the features of physiological signals in the domain of time, frequency, and non-linear. This application uses a convolutional neural network for the automatic feature extraction of the physiological signals, and through fully connected network layers, the emotion prediction is made. The experimental results on the AMIGOS dataset show that the method proposed in this paper achieves a better precision of the classification of the emotional states, in comparison with the originally obtained by the authors of this dataset.","['Physiology', 'Emotion recognition', 'Feature extraction', 'Electrocardiography', 'Videos', 'Electroencephalography', 'Brain modeling']","['Emotion recognition', 'deep convolutional neural network', 'physiological signals', 'machine learning', 'AMIGOS dataset']"
"Rolling element bearing is a critical component in rotating machinery that reduces the friction between moving pairs. Bearing fault diagnosis is always considered as a research hotspot in the field of prognostics and health management, especially with the application of deep learning. Deep learning, such as a convolutional neural network (CNN), can extract features automatically compared with traditional methods. However, the construction of the CNN model and the training process still need a lot of prior knowledge, and it takes a lot of time to build an optimal model to achieve a high classification accuracy. In addition, great challenges of universal applicability exist when different input forms (e.g., different sampling lengths or signal forms) are considered. This paper presents a universal bearing fault diagnosis model transferred from a well-known Alexnet model, and only the last fully connected layer needs to be replaced, which could reduce prior knowledge and extra time in establishing a new model. Accordingly, it is necessary to convert a raw acceleration signal to a uniform-sized time-frequency image, even when these data have different sizes. Furthermore, standardized images created by eight time-frequency analysis methods are applied to validate the effectiveness of the proposed method in two case studies. The results indicate that this method can be applied in bearing fault diagnosis, and t-SNE helps to understand the process of feature extraction and condition classification.","['Time-frequency analysis', 'Fault diagnosis', 'Deep learning', 'Feature extraction', 'Transforms', 'Data models']","['Bearing fault diagnosis', 'deep learning', 'time-frequency analysis', 'visualization technology']"
"Scene classification is a highly useful task in Remote Sensing (RS) applications. Many efforts have been made to improve the accuracy of RS scene classification. Scene classification is a challenging problem, especially for large datasets with tens of thousands of images with a large number of classes and taken under different circumstances. One problem that is observed in scene classification is the fact that for a given scene, only one part of it indicates which class it belongs to, whereas the other parts are either irrelevant or they actually tend to belong to another class. To address this issue, this paper proposes a deep attention Convolutional Neural Network (CNN) for scene classification in remote sensing. CNN models use successive convolutional layers to learn feature maps from larger and larger regions (or receptive fields) of the scene. The attention mechanism computes a new feature map as a weighted average of these original feature maps. In particular, we propose a solution, named EfficientNet-B3-Attn-2, based on the pre-trained EfficientNet-B3 CNN enhanced with an attention mechanism. A dedicated branch is added to layer 262 of the network, to compute the required weights. These weights are learned automatically by training the whole CNN model end-to-end using the backpropagation algorithm. In this way, the network learns to emphasize important regions of the scene and suppress the regions that are irrelevant to the classification. We tested the proposed EfficientNet-B3-Attn-2 on six popular remote sensing datasets, namely UC Merced, KSA, OPTIMAL-31, RSSCN7, WHU-RS19, and AID datasets, showing its strong capabilities in classifying RS scenes.","['Image analysis', 'Remote sensing', 'Feature extraction', 'Computational modeling', 'Solid modeling', 'Convolution', 'Deep learning']","['Remote sensing', 'scene classification', 'EfficientNet-B3', 'convolutional neural networks (CNNs)', 'attention mechanisms']"
"This paper proposes a dual-band eight-antenna array for multiple-input and multiple-output (MIMO) applications in 5G mobile terminals. The designed MIMO antenna array comprises eight L-shaped slot antennas based on stepped impedance resonators (SIRs). The required dual-resonance can be obtained by adjusting the impedance ratio of the SIR, and good impedance matching can be ensured for each antenna element by tuning the position of the microstrip feed line. The experimental results show that a measured return loss of higher than 10 dB and a measured inter-element isolation of greater than 11.2 dB have been obtained for each antenna element with a simulated total efficiency of larger than 51% across the long term evolution (LTE) band 42 (3400-3600 MHz) and LTE band 46 (5150-5925 MHz). In addition, the measured envelope correlation coefficient (ECC) is lower than 0.1 between arbitrary two antenna elements, and the proposed MIMO antenna array realizes a simulated channel capacity of higher than 36.9 bps/Hz within both operation bands. Furthermore, the MIMO antenna array can maintain acceptable radiation and MIMO performance in the presence of specific anthropomorphic mannequin (SAM) head and human hands.","['Antenna arrays', 'MIMO communication', 'Channel capacity', 'Slot antennas', '5G mobile communication', 'Long Term Evolution']","['Channel capacity', 'dual-band', 'multiple input and multiple output (MIMO)', 'slot antenna', 'stepped impedance resonator (SIR)']"
"In this paper, we propose a new comprehensive realistic cyber security dataset of IoT and IIoT applications, called Edge-IIoTset, which can be used by machine learning-based intrusion detection systems in two different modes, namely, centralized and federated learning. Specifically, the dataset has been generated using a purpose-built IoT/IIoT testbed with a large representative set of devices, sensors, protocols and cloud/edge configurations. The IoT data are generated from various IoT devices (more than 10 types) such as Low-cost digital sensors for sensing temperature and humidity, Ultrasonic sensor, Water level detection sensor, pH Sensor Meter, Soil Moisture sensor, Heart Rate Sensor, Flame Sensor, etc.). Furthermore, we identify and analyze fourteen attacks related to IoT and IIoT connectivity protocols, which are categorized into five threats, including, DoS/DDoS attacks, Information gathering, Man in the middle attacks, Injection attacks, and Malware attacks. In addition, we extract features obtained from different sources, including alerts, system resources, logs, network traffic, and propose new 61 features with high correlations from 1176 found features. After processing and analyzing the proposed realistic cyber security dataset, we provide a primary exploratory data analysis and evaluate the performance of machine learning approaches (i.e., traditional machine learning as well as deep learning) in both centralized and federated learning modes. The Edge-IIoTset dataset can be publicly accessed from http://ieee-dataport.org/8939 .","['Industrial Internet of Things', 'Sensors', 'Temperature sensors', 'Computer crime', 'Security', 'Protocols', 'Computer security']","['Cybersecurity applications', 'IoT datasets', 'deep learning', 'federated learning', 'edge {computing}']"
"Widely deployed cellular networks are an attractive solution to provide large scale radio connectivity to unmanned aerial vehicles. One main prerequisite is that co-existence and optimal performance for both aerial and terrestrial users can be provided. Today's cellular networks are, however, not designed for aerial coverage, and deployments are primarily optimized to provide good service for terrestrial users. These considerations, in combination with the strict regulatory requirements, lead to extensive research and standardization efforts to ensure that the current cellular networks can enable reliable operation of aerial vehicles in various deployment scenarios. In this paper, we investigate the performance of aerial radio connectivity in a typical rural area network deployment using extensive channel measurements and system simulations. First, we highlight that downlink and uplink radio interference play a key role, and yield relatively poor performance for the aerial traffic, when load is high in the network. Second, we analyze two potential terminal side interference mitigation solutions: interference cancellation and antenna beam selection. We show that each of these can improve the overall, aerial and terrestrial, system performance to a certain degree, with up to 30% throughput gain, and an increase in the reliability of the aerial radio connectivity to over 99%. Further, we introduce and evaluate a novel downlink inter-cell interference coordination mechanism applied to the aerial command and control traffic. Our proposed coordination mechanism is shown to provide the required aerial downlink performance at the cost of 10% capacity degradation in the serving and interfering cells.","['Interference', 'Cellular networks', 'Drones', 'Antennas', 'Long Term Evolution', 'Reliability', '3GPP']","['3D coverage', 'aerial vehicles', 'cellular network', 'drone', 'LTE', 'interference management', 'reliable communication', 'propagation channel', 'UAV']"
"In current epoch, the economic operation of micro-grid under soaring renewable energy integration has become a major concern in the smart grid environment. There are several meta-heuristic optimization techniques available under different categories in literature. One of the most difficult tasks in cost minimization of micro-grid is to select the best suitable optimization technique. To resolve the problem of selecting a suitable optimization technique, a rigorous review of six meta-heuristic algorithms (Whale Optimization, Fire Fly, Particle Swarm Optimization, Differential Evaluation, Genetic Algorithm, and Teaching Learning-based Optimization) selected from three categories (Swarm Intelligence, Evolutionary Algorithms, and Teaching Learning) is conducted. It presents, a comparative analysis using different performance indicators for standard benchmark functions and proposed a smart micro-grid (SMG) operation cost minimization problem. A proposed SMG is modeled which incorporates utility connected power resources, e.g., wind turbine, photovoltaic, fuel cell, micro-turbine, battery storage, electric vehicle technology, and diesel power generator. The proposed work will help researchers and engineers to select an appropriate optimization method to solve micro-grid optimization problems with constraints. This paper concludes with a detailed review of micro-grid operation cost minimization techniques based on an exhaustive survey and implementation.","['Optimization', 'Batteries', 'Genetic algorithms', 'Particle swarm optimization', 'Minimization', 'Standards']","['Smart micro-grid', 'meta-heuristic optimization techniques', 'electric vehicle technology', 'fuel cell']"
"Epilepsy is a common neurological disease that can cause seizures and loss of consciousness and can have a severe negative impact on long-term cognitive function. Reducing the severity of impact requires early diagnosis and treatment. Epilepsy is traditionally diagnosed using electroencephalography (EEG) performed by trained physicians or technicians but this process is time-consuming and prone to interference, which can negatively impact accuracy. This paper develops a model for epilepsy diagnosis using discrete wavelet transform to analyze sub-bands within the EEG parameter and select EEG characteristics for epilepsy detection. The minimize entropy principle approach is used to build fuzzy membership functions of the characteristics of each brain wave and are then used as the basis for the construction of an associative Petri net model. Using our APN model, the associative Petri net approach provides diagnosis accuracy rates of 93.8%, outperforming similar approaches using decision tree, support vector machine, neural network, Bayes net, naïve Bayes, and tree augmented naïve Bayes. Thus, the proposed approach shows promise for fast, accurate, and objective diagnosis of epilepsy in clinical settings.","['Epilepsy', 'Electroencephalography', 'Entropy', 'Discrete wavelet transforms', 'Petri nets', 'Cognition']","['Epilepsy', 'electroencephalogram', 'wavelet transform', 'associative petri net']"
"Fog computing is a paradigm that extends the cloud to intermediate network devices with computational and storage capacities. This allows the execution of applications closer to edge devices and end-users by allocating services in those intermediate devices. The placement of those services has an influence on the performance of the fog architecture. We propose a fog computing simulator for analyzing the design and deployment of applications through customized and dynamical strategies. We model the relationships among deployed applications, network connections, and infrastructure characteristics through complex network theory, enabling the integration of topological measures in dynamic and customizable strategies, such as the placement of application modules, workload location, and path routing and scheduling of services. We present a comparative analysis of the efficiency and the convergence of results of our simulator with the most referenced one, iFogSim. To highlight the YAFS functionalities, we model three scenarios that, to the best of our knowledge, cannot be implemented with current fog simulators: dynamic allocation of new application modules, dynamic failures of network nodes, and user mobility along with the topology.","['Relays', 'Large scale integration', 'Wireless communication', 'OFDM', 'Interference cancellation', 'Channel estimation', 'Real-time systems']","['Complex networks', 'fog computing', 'Internet of Things', 'simulator']"
"In recent years, the increased use of wireless networks for the transmission of large volumes of information has generated a myriad of security threats and privacy concerns; consequently, there has been the development of a number of preventive and protective measures including intrusion detection systems (IDS). Intrusion detection mechanisms play a pivotal role in securing computer and network systems; however, for various IDS, the performance remains a major issue. Moreover, the accuracy of existing methodologies for IDS using machine learning is heavily affected when the feature space grows. In this paper, we propose a IDS based on deep learning using feed forward deep neural networks (FFDNNs) coupled with a filter-based feature selection algorithm. The FFDNN-IDS is evaluated using the well-known NSL-knowledge discovery and data mining (NSL-KDD) dataset and it is compared to the following existing machine learning methods: support vectors machines, decision tree, K-Nearest Neighbor, and Naïve Bayes. The experimental results prove that the FFDNN-IDS achieves an increase in accuracy in comparison to other methods.","['Intrusion detection', 'Feature extraction', 'Support vector machines', 'Deep learning', 'Wireless networks', 'Communication system security']","['Deep learning', 'feature extraction', 'intrusion detection', 'machine learning', 'wireless networks']"
"While there have been extensive studies of denial of service (DoS) attacks and DDoS attack mitigation, such attacks remain challenging to mitigate. For example, Low-Rate DDoS (LR-DDoS) attacks are known to be difficult to detect, particularly in a software-defined network (SDN). Hence, in this paper we present a flexible modular architecture that allows the identification and mitigation of LR-DDoS attacks in SDN settings. Specifically, we train the intrusion detection system (IDS) in our architecture using six machine learning (ML) models (i.e., J48, Random Tree, REP Tree, Random Forest, Multi-Layer Perceptron (MLP), and Support Vector Machines (SVM)) and evaluate their performance using the Canadian Institute of Cybersecurity (CIC) DoS dataset. The findings from the evaluation demonstrate that our approach achieves a detection rate of 95%, despite the difficulty in detecting LR-DoS attacks. We also remark that in our deployment, we use the open network operating system (ONOS) controller running on Mininet virtual machine in order for our simulated environment to be as close to real-world production networks as possible. In our testing topology, the intrusion prevention detection system mitigates all attacks previously detected by the IDS system. This demonstrates the utility of our architecture in identifying and mitigating LR-DDoS attacks.","['Computer crime', 'Computer architecture', 'Machine learning', 'Vegetation', 'Support vector machines', 'Control systems', 'IP networks']","['DDoS attack mitigation', 'low-rate DDoS (LR-DDoS) attacks', 'machine learning', 'software-defined network (SDN)']"
"Fault diagnosis in photovoltaic (PV) arrays is essential in enhancing power output as well as the useful life span of a PV system. Severe faults such as Partial Shading (PS) and high impedance faults, low location mismatch, and the presence of Maximum Power Point Tracking (MPPT) make fault detection challenging in harsh environmental conditions. In this regard, there have been several attempts made by various researchers to identify PV array faults. However, most of the previous work has focused on fault detection and classification in only a few faulty scenarios. This paper presents a novel approach that utilizes deep two-dimensional (2-D) Convolutional Neural Networks (CNN) to extract features from 2-D scalograms generated from PV system data in order to effectively detect and classify PV system faults. An in-depth quantitative evaluation of the proposed approach is presented and compared with previous classification methods for PV array faults – both classical machine learning based and deep learning based. Unlike contemporary work, five different faulty cases (including faults in PS – on which no work has been done before in the machine learning domain) have been considered in our study, along with the incorporation of MPPT. We generate a consistent dataset over which to compare ours and previous approaches, to make for the first (to the best of our knowledge) comprehensive and meaningful comparative evaluation of fault diagnosis. It is observed that the proposed method involving fine-tuned pre-trained CNN outperforms existing techniques, achieving a high fault detection accuracy of 73.53%. Our study also highlights the importance of representative and discriminative features to classify faults (as opposed to the use of raw data), especially in the noisy scenario, where our method achieves the best performance of 70.45%. We believe that our work will serve to guide future research in PV system fault diagnosis.","['Circuit faults', 'Fault detection', 'Fault diagnosis', 'Machine learning', 'Impedance', 'Maximum power point trackers', 'Feature extraction']","['Photovoltaic array', 'maximum power point tracking', 'fault classification', 'convolutional neural network', 'scalograms', 'transfer learning']"
"Small cell base stations (SBSs) and multiple antennas are seen as fundamental technologies in the emergence of the next generation [i.e., 5th generation (5G)] of cellular wireless technology. This paper provides a comprehensive survey of literature relating to the applications and challenges associated with using multiple antennas in SBSs. The use of multiple antenna techniques in conventional wireless base stations has undergone much study and is widespread. With heterogeneity in current networks and a furthering of this theme together with greater densification expected in 5G systems, their use in SBSs is at an evolutionary stage. In this paper, unique design challenges associated with size, cost, and performance in SBSs are presented. We present a clear understanding of this increasingly important research area, identifying a clear classification of use and design guidelines. We present a state-of-the-art review of the literature to show how researchers are using and considering the use of multiple antennas in small cells. Attention is given to current generation networks, and with SBSs being a dominant technology necessary for 5G, we also provide insights into the design challenges in such possible future networks.","['Multiple antennas', '5G mobile communication', 'Base stations', 'Wireless communication', 'Next generation networking', 'Microcells', 'Cellular networks', 'Design methodology']","['Multiple antennas', 'small cell base stations', '5G']"
"To satisfy the high data demands in future cellular networks, an ultra-densification approach is introduced to shrink the coverage of base station (BS) and improve the frequency reuse. The gain in capacity is expected but at the expense of increased interference, frequent handovers (HOs), increased HO failure (HOF) rates, increased HO delays, increase in ping pong rate, high energy consumption, increased overheads due to frequent HO, high packet losses and bad user experience mostly in high-speed user equipment (UE) scenarios. This paper presents the general concepts of radio access mobility in cellular networks with possible challenges and current research focus. In this article, we provide an overview of HO management in long-term evolution (LTE) and 5G new radio (NR) to highlight the main differences in basic HO scenarios. A detailed literature survey on radio access mobility in LTE, heterogeneous networks (HetNets) and NR is provided. In addition, this paper suggests HO management challenges and enhancing techniques with a discussion on the key points that need to be considered in formulating an efficient HO scheme.","['5G mobile communication', 'Long Term Evolution', 'Cellular networks', 'Energy consumption', 'Handover', 'Interference']","['Radio access mobility', 'cell selection', 'handover', 'LTE', '5G', 'NR', 'mobility enhancers']"
"Convolutional Neural Networks (CNNs) achieve excellent computer-assisted diagnosis with sufficient annotated training data. However, most medical imaging datasets are small and fragmented. In this context, Generative Adversarial Networks (GANs) can synthesize realistic/diverse additional training images to fill the data lack in the real image distribution; researchers have improved classification by augmenting data with noise-to-image (e.g., random noise samples to diverse pathological images) or image-to-image GANs (e.g., a benign image to a malignant one). Yet, no research has reported results combining noise-to-image and image-to-image GANs for further performance boost. Therefore, to maximize the DA effect with the GAN combinations, we propose a two-step GAN-based DA that generates and refines brain Magnetic Resonance (MR) images with/without tumors separately: (i) Progressive Growing of GANs (PGGANs), multi-stage noise-to-image GAN for high-resolution MR image generation, first generates realistic/diverse 256×256 images; (ii) Multimodal UNsupervised Image-to-image Translation (MUNIT) that combines GANs/Variational AutoEncoders or SimGAN that uses a DA-focused GAN loss, further refines the texture/shape of the PGGAN-generated images similarly to the real ones. We thoroughly investigate CNN-based tumor classification results, also considering the influence of pre-training on ImageNet and discarding weird-looking GAN-generated images. The results show that, when combined with classic DA, our two-step GAN-based DA can significantly outperform the classic DA alone, in tumor detection (i.e., boosting sensitivity 93.67% to 97.48%) and also in other medical imaging tasks.","['Gallium nitride', 'Training', 'Tumors', 'Generative adversarial networks', 'Medical diagnostic imaging', 'Image synthesis']","['Data augmentation', 'synthetic image generation', 'GANs', 'brain MRI', 'tumor detection']"
"Device-to-device (D2D) communications have been proposed as an underlay to long-term evolution (LTE) networks as a means of harvesting the proximity, reuse, and hop gains. However, D2D communications can also serve as a technology component for providing public protection and disaster relief (PPDR) and national security and public safety (NSPS) services. In the United States, for example, spectrum has been reserved in the 700-MHz band for an LTE-based public safety network. The key requirement for the evolving broadband PPDR and NSPS services capable systems is to provide access to cellular services when the infrastructure is available and to efficiently support local services even if a subset or all of the network nodes become dysfunctional due to public disaster or emergency situations. This paper reviews some of the key requirements, technology challenges, and solution approaches that must be in place in order to enable LTE networks and, in particular, D2D communications, to meet PPDR and NSPS-related requirements. In particular, we propose a clustering-procedure-based approach to the design of a system that integrates cellular and ad hoc operation modes depending on the availability of infrastructure nodes. System simulations demonstrate the viability of the proposed design. The proposed scheme is currently considered as a technology component of the evolving 5G concept developed by the European 5G research project METIS.","['Emergency services', 'Long Term Evolution', 'Safety', 'National security', 'Broadband communication', 'Disasters', 'Mobile communication', '5G mobile communication']","['Wireless communications', 'cellular networks', 'ad hoc networks', 'mobile communications']"
"Blockchain, originated from Bitcoin system, has drawn intense attention from the academic community because of its decentralization, persistency, anonymity and auditability. In the past decade, the blockchain technology has evolved and became viable for various applications beyond the domain of finance. However, due to the complexity of blockchain technology, it is usually difficult and costly for most developers or teams to build, maintain and monitor a blockchain network that supports their applications. Most common developers or teams are unable to ensure the reliability and security of the blockchain system, which to a certain extent affects the quality of their applications. In this paper, we develop a BaaS platform called NutBaaS, which provides blockchain service over cloud computing environments, such as network deployment and system monitoring, smart contracts analysis and testing. Based on these services, developers can focus on the business code to explore how to apply blockchain technology more appropriately to their business scenarios, without bothering to maintain and monitor the system.","['Blockchain', 'Peer-to-peer computing', 'Monitoring', 'Cloud computing', 'Smart contracts']","['Blockchain', 'blockchain-as-a-service', 'cloud computing', 'smart contracts']"
"Blockchain has been envisioned to be a disruptive technology with potential for applications in various industries. As more and more different blockchain platforms have emerged, it is essential to assess their performance in different use cases and scenarios. In this paper, we conduct a systematic survey on the blockchain performance evaluation by categorizing all reviewed solutions into two general categories, namely, empirical analysis and analytical modelling. In the empirical analysis, we comparatively review the current empirical blockchain evaluation methodologies, including benchmarking, monitoring, experimental analysis and simulation. In analytical modelling, we investigate the stochastic models applied to performance evaluation of mainstream blockchain consensus algorithms. Through contrasting, comparison and grouping different methods together, we extract important criteria that can be used for selecting the most suitable evaluation technique for optimizing the performance of blockchain systems based on their identified bottlenecks. Finally, we conclude the survey by presenting a list of possible directions for future research.","['Blockchain', 'Distributed ledger', 'Performance evaluation', 'Analytical models', 'Smart contracts', 'Systematics', 'Bitcoin']","['Blockchain', 'distributed ledger technology', 'performance modelling', 'performance evaluation', 'systematic survey']"
"Reinforcement learning (RL), which is a class of machine learning, provides a framework by which a system can learn from its previous interactions with its environment to efficiently select its actions in the future. RL has been used in a number of application fields, including game playing, robotics and control, networks, and telecommunications, for building autonomous systems that improve themselves with experience. It is commonly accepted that RL is suitable for solving optimization problems related to distributed systems in general and to routing in networks in particular. RL also has reasonable overhead-in terms of control packets, memory and computation-compared to other optimization techniques used to solve the same problems. Since the mid-1990s, over 60 protocols have been proposed, with major or minor contributions in the field of optimal route selection to convey packets in different types of communication networks under various user QoS requirements. This paper provides a comprehensive review of the literature on the topic. The review is structured in a way that shows how network characteristics and requirements were gradually considered over time. Classification criteria are proposed to present and qualitatively compare existing RL-based routing protocols.","['Routing', 'Routing protocols', 'Computational modeling', 'Quality of service', 'Reinforcement learning', 'Optimization']","['Reinforcement learning', 'communication networks', 'routing protocols', 'path optimization', 'quality of service']"
"Mixed data comprises both numeric and categorical features, and mixed datasets occur frequently in many domains, such as health, finance, and marketing. Clustering is often applied to mixed datasets to find structures and to group similar objects for further analysis. However, clustering mixed data are challenging because it is difficult to directly apply mathematical operations, such as summation or averaging, to the feature values of these datasets. In this paper, we present a taxonomy for the study of mixed data clustering algorithms by identifying five major research themes. We then present the state-of-the-art review of the research works within each research theme. We analyze the strengths and weaknesses of these methods with pointers for future research directions. At last, we present an in-depth analysis of the overall challenges in this field, highlight open research questions, and discuss guidelines to make progress in the field.",[],[]
"The Internet of Things (IoT) is a revolutionizing technology which aims to create an ecosystem of connected objects and embedded devices and provide ubiquitous connectivity between trillions of not only smart devices but also simple sensors and actuators. Although recent advancements in miniaturization of devices with higher computational capabilities and ultra-low power communication technologies have enabled the vast deployment of sensors and actuators everywhere, such an evolution calls for fundamental changes in hardware design, software, network architecture, data analytics, data storage, and power sources. A large portion of the IoT devices cannot be powered by batteries only anymore, as they will be installed in hard to reach areas and regular battery replacement and maintenance are infeasible. A viable solution is to scavenge and harvest energy from the environment and then provide enough energy to the devices to perform their operations. This will significantly increase the device life time and eliminate the need for the battery as an energy source. This survey aims at providing a comprehensive study on energy harvesting techniques as alternative and promising solutions to power the IoT devices. We present the main design challenges of the IoT devices in terms of energy and power and provide design considerations for a successful implementation of self-powered the IoT devices. We then specifically focus on piezoelectric energy harvesting as one of the most promising solutions to power the IoT devices and present the main challenges and research directions. We also shed lights on the hybrid energy harvesting for the IoT and security challenges of energy harvesting enabled the IoT systems.","['Internet of Things', 'Batteries', 'Energy harvesting', 'Wireless sensor networks', 'Intelligent sensors', 'Ecosystems']","['Energy harvesting', 'Internet of Things (IoT)', 'RF energy harvesting', 'piezoelectric']"
"Systems based on fog computing produce massive amounts of data; accordingly, an increasing number of fog computing apps and services are emerging. In addition, machine learning (ML), which is an essential area, has gained considerable progress in various research domains, including robotics, neuromorphic computing, computer graphics, natural language processing (NLP), decision-making, and speech recognition. Several researches have been proposed that study how to employ ML to settle fog computing problems. In recent years, an increasing trend has been observed in adopting ML to enhance fog computing applications and provide fog services, like efficient resource management, security, mitigating latency and energy consumption, and traffic modeling. Based on our understanding and knowledge, there is no study has yet investigated the role of ML in the fog computing paradigm. Accordingly, the current research shed light on presenting an overview of the ML functions in fog computing area. The ML application for fog computing become strong end-user and high layers services to gain profound analytics and more smart responses for needed tasks. We present a comprehensive review to underline the latest improvements in ML techniques that are associated with three aspects of fog computing: management of resource, accuracy, and security. The role of ML in edge computing is also highlighted. Moreover, other perspectives related to the ML domain, such as types of application support, technique, and dataset are provided. Lastly, research challenges and open issues are discussed.","['Edge computing', 'Cloud computing', 'Internet of Things', 'Sensors', 'Security', 'Computational modeling', 'Monitoring']","['Fog computing', 'machine learning', 'Internet of Things (IoT)', 'applications']"
"Deep learning has attracted intense interest in Prognostics and Health Management (PHM), because of its enormous representing power, automated feature learning capability and best-in-class performance in solving complex problems. This paper surveys recent advancements in PHM methodologies using deep learning with the aim of identifying research gaps and suggesting further improvements. After a brief introduction to several deep learning models, we review and analyze applications of fault detection, diagnosis and prognosis using deep learning. The survey validates the universal applicability of deep learning to various types of input in PHM, including vibration, imagery, time-series and structured data. It also reveals that deep learning provides a one-fits-all framework for the primary PHM subfields: fault detection uses either reconstruction error or stacks a binary classifier on top of the network to detect anomalies; fault diagnosis typically adds a soft-max layer to perform multi-class classification; prognosis adds a continuous regression layer to predict remaining useful life. The general framework suggests the possibility of transfer learning across PHM applications. The survey reveals some common properties and identifies the research gaps in each PHM subfield. It concludes by summarizing some major challenges and potential opportunities in the domain.","['Prognostics and health management', 'Deep learning', 'Fault detection', 'Fault diagnosis', 'Feature extraction', 'Vibrations', 'Image reconstruction']","['Condition-based maintenance', 'deep learning', 'fault detection', 'fault diagnosis', 'prognosis']"
"An interconnected multi-microgrids (IMMGs) system takes advantage of various complementary power sources and effectively coordinates the energy sharing/trading among the MGs and the main grid to improve the stability, reliability, and energy efficiency of the system. The core of this structure is to achieve the optimal distribution of energy sharing through proper strategies. However, the volatility and intermittent characteristics of renewable resources, time-varying loads in the MGs, their correlated power generations, and the coupled energy among the MGs during energy trading, all bring about new challenges to achieving a stable operation and optimal scheduling in the power system. Many solutions have been proposed to solve these problems. In this paper, we provide an overview of the current energy management systems (EMS) in IMMGs, focusing on the IMMG structure, EMS objectives, timescales, and scheduling optimization structure. We then provide a review of the distributed optimization algorithms in IMMGs. We conclude this survey with a discussion of future directions.","['Renewable energy sources', 'Power system stability', 'Reliability', 'Optimization', 'Economics', 'Microgrids']","['Smart grid', 'microgrid (MG)', 'interconnected multi-microgrids (IMMG)', 'energy sharing', 'energy management']"
"In recent years, deep learning’s revolutionary advances in speech recognition, image analysis, and natural language processing have gained significant attention. Deep learning technology has become a hotspot research field in the artificial intelligence and has been applied into recommender system. In contrast to traditional recommendation models, deep learning is able to effectively capture the non-linear and non-trivial user-item relationships and enables the codification of more complex abstractions as data representations in the higher layers. In this paper, we provide a comprehensive review of the related research contents of deep learning-based recommender systems. First, we introduce the basic terminologies and the background concepts of recommender systems and deep learning technology. Second, we describe the main current research on deep learning-based recommender systems. Third, we provide the possible research directions of deep learning-based recommender systems in the future. Finally, concludes this paper.","['Recommender systems', 'Collaboration', 'Feature extraction', 'Information filters']","['Deep learning', 'recommender systems', 'deep learning-based recommender systems', 'machine learning', 'terminology']"
"Credit card fraud is a criminal offense. It causes severe damage to financial institutions and individuals. Therefore, the detection and prevention of fraudulent activities are critically important to financial institutions. Fraud detection and prevention are costly, time-consuming, and labor-intensive tasks. A number of significant research works have been dedicated to developing innovative solutions to detect different types of fraud. However, these solutions have been proved ineffective. According to Cifa, 33 305 cases of credit card identity fraud were reported between January and June in 2018. 1 Various weaknesses of existing solutions have been reported in the literature. Among them all, the imbalance classification is the most critical and well-known problem. Imbalance classification consists of having a small number of observations of the minority class compared with the majority in the data set. In this problem, the ratio fraud: legitimate is very small, which makes it extremely difficult for the classification algorithm to detect fraud cases. In this paper, we will conduct a rigorous experimental study with the solutions that tackle the imbalance classification problem. We explored these solutions along with the machine learning algorithms used for fraud detection. We identified their weaknesses and summarized the results that we obtained using a credit card fraud labeled dataset. According to this paper, imbalanced classification approaches are ineffective, especially when the data are highly imbalanced. This paper reveals that the existing approaches result in a large number of false alarms, which are costly to financial institutions. This may lead to inaccurate detection as well as increasing the occurrence of fraud cases.","['Credit cards', 'Neural networks', 'Hidden Markov models', 'Support vector machines', 'Classification algorithms', 'Decision trees', 'Machine learning algorithms']","['Fraud analysis and detection', 'fraud cybercrimes', 'imbalanced classification', 'secure society']"
"In this paper, a simulation model describing the operation of a PV/wind/diesel hybrid microgrid system with battery bank storage has been proposed. Optimal sizing of the proposed system has been presented to minimize the cost of energy (COE) supplied by the system while increasing the reliability and efficiency of the system presented by the loss of power supply probability (LPSP). Novel optimization algorithms of Whale Optimization Algorithm (WOA), Water Cycle Algorithm (WCA), Moth-Flame Optimizer (MFO), and Hybrid particle swarm-gravitational search algorithm (PSOGSA) have been applied for designing the optimized microgrid. Moreover, a comprehensive comparison has been accomplished between the proposed optimization techniques. The optimal sizing of the system components has been carried out using real-time meteorological data of Abu-Monqar village located in the Western Desert of Egypt for the first time for developing this promising remote area. Statistical study for determining the capability of the optimization algorithm in finding the optimal solution has been presented. Simulation results confirmed the promising performance of the hybrid WOA over the other algorithms.","['Optimization', 'Batteries', 'Microgrids', 'Generators', 'Wind turbines', 'Hybrid power systems', 'Power system reliability']","['Isolated microgrids', 'cost of energy (COE)', 'loss of power supply probability (LPSP)', 'optimization']"
"The Internet of Vehicles (IoV) is a convergence of the mobile Internet and the Internet of Things (IoT), where vehicles function as smart moving intelligent nodes or objects within the sensing network. This paper gives two contributions to the state-of-the-art for IoV technology research. First, we present a comprehensive review of the current and emerging IoV paradigms and communication models with an emphasis on deployment in smart cities. Currently, surveys from many authors have focused concentration on the IoV as only serving applications for intelligent transportation like driver safety, traffic efficiency, and infotainment. This paper presents a more inclusive review of the IoV for also serving the needs of smart cities for large-scale data sensing, collection, information processing, and storage. The second component of the paper presents a new universal architecture for the IoV which can be used for different communication models in smart cities to address the above challenges. It consists of seven layers: vehicle identification layer, object layer, inter-intra devices layer, communication layer, servers and cloud services layer, big data and multimedia computation layer, and application layer. The final part of this paper discusses various challenges and gives some experimental results and insights for future research direction such as the effects of a large and growing number of vehicles and the packet delivery success rate in the dynamic network structure in a smart city scenario.","['Smart cities', 'Big Data', 'Computer architecture', 'Transportation', 'Internet of Things', 'Collision avoidance']","['Internet of Vehicles', 'IoV', 'layer architecture', 'smart city', 'applications', 'big data']"
"Fog computing is a technology that brings computing and storage resources near to the end user. Being in its infancy, fog computing lacks standardization in terms of architectures and simulation platforms. There are a number of fog simulators available today, among which a few are open-source, whereas rest are commercially available. The existing fog simulators mainly focus on a number of devices that can be simulated. Generally, the existing simulators are more inclined toward sensors’ configurations, where sensors generate raw data and fog nodes are used to intelligently process the data before sending to back-end cloud or other nodes. Therefore, these simulators lack network properties and assume reliable and error-free delivery on every service request. Moreover, no simulator allows researchers to incorporate their own fog nodes management algorithms, such as scheduling. In existing work, device handover is also not supported. In this paper, we propose a new fog simulator called FogNetSim++ 1 that provides users with detailed configuration options to simulate a large fog network. It enables researchers to incorporate customized mobility models and fog node scheduling algorithms, and manage handover mechanisms. In our evaluation setup, a traffic management system is evaluated to demonstrate the scalability and effectiveness of proposed simulator in terms of CPU and memory usage. We have also benchmarked the network parameters, such as execution delay, packet error rate, handovers, and latency. 1available at https://fognetsimpp.com","['Cloud computing', 'Edge computing', 'Computational modeling', 'Sensors', 'Data centers', 'Protocols', 'Resource management']","['Cloud', 'fog', 'edge network', 'IoT', 'mobility models', 'OMNeT++']"
"In this paper, a simultaneous cooperative spectrum sensing and energy harvesting model is proposed to improve the transmission performance of the multichannel cognitive radio. The frame structure is divided into sensing slot and transmission slot. In the sensing slot, the secondary user (SU) splits the subchannels into two subchannel sets, one for sensing the primary user (PU) by multichannel cooperative spectrum sensing and the other one for collecting the radio frequency energy of the PU signal and noise by multichannel energy harvesting. In the transmission slot, the harvested energy is supplied to compensate the sensing energy loss in order to guarantee the throughput. We have formulated the resource allocation of the proposed model as a class of optimization problems, which maximize aggregate throughput, harvested energy, and energy efficiency of the SU over all the subchannels through jointly optimizing subchannel set, sensing time, and transmission power, respectively. To achieve the sub-optimal solutions to the optimization problems, we have proposed the subchannel allocation algorithm and the joint optimization algorithm of sensing time and transmission power based on the Greedy algorithm and the alternating direction optimization. The stopping criteria of SU is described, when the PU is not present but the harvested energy is not enough. The simulation results are presented to demonstrate the validity and predominance of our proposed algorithms.","['Sensors', 'Energy harvesting', 'Optimization', 'Resource management', 'Radio frequency', 'Throughput', 'Interference']","['Cognitive radio', 'cooperative spectrum sensing', 'energy harvesting', 'throughput', 'joint optimization']"
"Ubiquity of mobile devices with rich sensory capabilities has given rise to the mobile crowd-sensing (MCS) concept, in which a central authority (the platform) and its participants (mobile users) work collaboratively to acquire sensory data over a wide geographic area. Recent research in MCS highlights the following facts: 1) a utility metric can be defined for both the platform and the users, quantifying the value received by either side; 2) incentivizing the users to participate is a non-trivial challenge; 3) correctness and truthfulness of the acquired data must be verified, because the users might provide incorrect or inaccurate data, whether due to malicious intent or malfunctioning devices; and 4) an intricate relationship exists among platform utility, user utility, user reputation, and data trustworthiness, suggesting a co-quantification of these inter-related metrics. In this paper, we study two existing approaches that quantify crowd-sensed data trustworthiness, based on statistical and vote-based user reputation scores. We introduce a new metric - collaborative reputation scores - to expand this definition. Our simulation results show that collaborative reputation scores can provide an effective alternative to the previously proposed metrics and are able to extend crowd sensing to applications that are driven by a centralized as well as decentralized control.","['Mobile communication', 'Measurement', 'Sensors', 'Mobile handsets', 'Collaboration', 'Social network services', 'Computers']","['Mobile crowd-sensing (MCS)', 'smart city', 'reputation systems', 'collaborative sensing', 'user incentives', 'reputation score', 'data trustworthiness', 'auction theory', 'social network theory', 'statistical methods']"
"As it becomes increasingly apparent that 4G will not be able to meet the emerging demands of future mobile communication systems, the question what could make up a 5G system, what are the crucial challenges, and what are the key drivers is part of intensive, ongoing discussions. Partly due to the advent of compressive sensing, methods that can optimally exploit sparsity in signals have received tremendous attention in recent years. In this paper, we will describe a variety of scenarios in which signal sparsity arises naturally in 5G wireless systems. Signal sparsity and the associated rich collection of tools and algorithms will thus be a viable source for innovation in 5G wireless system design. We will also describe applications of this sparse signal processing paradigm in Multiple Input Multiple Output random access, cloud radio access networks, compressive channel-source network coding, and embedded security. We will also emphasize an important open problem that may arise in 5G system design, for which sparsity will potentially play a key role in their solution.","['Network security', 'Signal processing', '4G mobile communication', 'Sparse matrices', 'Compressed sensing', 'Wireless communication', 'Mobile communication', '5G mobile communication']","['Compressed Sensing', 'Cloud Radio Acess Networks', 'Massive Random Access']"
"A novel metaheuristic optimization algorithm, named supply-demand-based optimization (SDO), is presented in this paper. SDO is a swarm-based optimizer motivated by the supply-demand mechanism in economics. This algorithm mimics both the demand relation of consumers and supply relation of producers. The proposed algorithm is compared with other state-of-the-art counterparts on 29 benchmark test functions and six engineering optimization problems. The results on the unconstrained test functions prove that SDO is able to provide very promising results in terms of exploration, exploitation, local optima avoidance, and convergence rate. The results on the constrained engineering problems suggest that SDO is considerately competitive in terms of computational expense, convergence rate, and solution accuracy. The codes are available at https://www.mathworks.com/matlabcentral/fileexchange/71764-supply-demand-based-optimization.","['Sociology', 'Statistics', 'Convergence', 'Optimization methods', 'Classification algorithms', 'Genetic algorithms']","['Supply-demand-based optimization', 'global optimization', 'engineering design', 'constrained problems', 'optimization algorithm', 'particle swarm optimization', 'swarm intelligence']"
"Moving towards autonomy, unmanned vehicles rely heavily on state-of-the-art collision avoidance systems (CAS). A lot of work is being done to make the CAS as safe and reliable as possible, necessitating a comparative study of the recent work in this important area. The paper provides a comprehensive review of collision avoidance strategies used for unmanned vehicles, with the main emphasis on unmanned aerial vehicles (UAV). It is an in-depth survey of different collision avoidance techniques that are categorically explained along with a comparative analysis of the considered approaches w.r.t. different scenarios and technical aspects. This also includes a discussion on the use of different types of sensors for collision avoidance in the context of UAVs.","['Collision avoidance', 'Sensors', 'Cameras', 'Drones', 'Path planning']","['Autonomous aerial vehicles', 'autonomous vehicles', 'collision avoidance', 'active and passive sensors', 'optimisation-based', 'force-field based', 'sense and avoid', 'geometry based']"
"Electronic health record (EHR) has recorded the process of occurrence, development, and treatment of diseases. So it has high medical value. Owing to the private and sensitive nature of medical data for patients, the data sharing and privacy preservation are critical issues in EHR. Blockchain technology may be a promising solution for the problems above since it holds the features of decentralization and tamper resistance. In the paper, we propose a medical data sharing and protection scheme based on the hospital’s private blockchain to improve the electronic health system of the hospital. Firstly, the scheme can satisfy various security properties such as decentralization, openness, and tamper resistance. A reliable mechanism is created for the doctors to store medical data or access the historical data of patients while meeting privacy preservation. Furthermore, a symptoms-matching mechanism is given between patients. It allows patients who get the same symptoms to conduct mutual authentication and create a session key for their future communication about the illness. The proposed scheme is implemented by using PBC and OpenSSL libraries. Finally, the security and performance evaluation of the proposed scheme is given.","['Blockchain', 'Medical diagnostic imaging', 'Hospitals', 'Security', 'Cloud computing', 'Data models']","['Blockchain', 'electronic health record', 'medical data', 'sharing and protection', 'symptoms-matching']"
"The dilated convolution algorithm, which is widely used for image segmentation, is applied in the image classification field in this paper. In many traditional image classification algorithms, convolution neural network (CNN) plays an important role. However, the classical CNN has the problem of consuming too much computing resources. To solve this problem, first, this paper proposed a dilated CNN model which is built through replacing the convolution kernels of traditional CNN by the dilated convolution kernels, and then, the dilated CNN model is tested on the Mnist handwritten digital recognition data set. Second, to solve the detail loss problem in the dilated CNN model, the hybrid dilated CNN (HDC) is built by stacking dilated convolution kernels with different dilation rates, and then the HDC model is tested on the wide-band remote sensing image data set of earth's terrain. The results show that under the same environment, compared with the traditional CNN model, the dilated CNN model reduces the training time by 12.99% and improves the training accuracy by 2.86% averagely, compared with the dilated CNN model, the HDC model reduces the training time by 2.02% and improves the training and testing accuracy by 14.15% and 15.35% averagely. Therefore, the dilated CNN and HDC model proposed in this paper can significantly improve the image classification performance.","['Convolution', 'Kernel', 'Data models', 'Computational modeling', 'Training', 'Feature extraction', 'Image classification']","['Image classification', 'CNN', 'dilated convolution', 'hybrid dilated CNN']"
"The integration of Internet of Things (IoT) and edge computing is currently a new research hotspot. However, the lack of trust between IoT edge devices has hindered the universal acceptance of IoT edge computing as outsourced computing services. In order to increase the adoption of IoT edge computing applications, first, IoT edge computing architecture should establish efficient trust calculation mechanism to alleviate the concerns of numerous users. In this paper, a reliable and lightweight trust mechanism is originally proposed for IoT edge devices based on multi-source feedback information fusion. First, due to the multi-source feedback mechanism is used for global trust calculation, our trust calculation mechanism is more reliable against bad-mouthing attacks caused by malicious feedback providers. Then, we adopt lightweight trust evaluating mechanism for cooperations of IoT edge devices, which is suitable for largescale IoT edge computing because it facilitates low-overhead trust computing algorithms. At the same time, we adopt a feedback information fusion algorithm based on objective information entropy theory, which can overcome the limitations of traditional trust schemes, whereby the trust factors are weighted manually or subjectively. And the experimental results show that the proposed trust calculation scheme significantly outperforms existing approaches in both computational efficiency and reliability.","['Edge computing', 'Reliability', 'Security', 'Internet of Things', 'Computational modeling', 'Information entropy', 'Cloud computing']","['Internet of Things', 'edge computing', 'trust computing mechanism', 'feedback trust', 'multi-source feedback information fusion', 'objective information entropy theory']"
"Wireless sensor networks (WSNs) have been widely applied in various industrial applications, which involve collecting a massive amount of heterogeneous sensory data. However, most of the data-gathering strategies for WSNs cannot avoid the hotspot problem in local or whole deployment area. Hotspot problem affects the network connectivity and decreases the network lifetime. Hence, we propose a tree-cluster-based data-gathering algorithm (TCBDGA) for WSNs with a mobile sink. A novel weight-based tree-construction method is introduced. The root nodes of the constructed trees are defined as rendezvous points (RPs). Additionally, some special nodes called subrendezvous points (SRPs) are selected according to their traffic load and hops to root nodes. RPs and SRPs are viewed as stop points of the mobile sink for data collection, and can be reselected after a certain period. The simulation and comparison with other algorithms show that our TCBDGA can significantly balance the load of the whole network, reduce the energy consumption, alleviate the hotspot problem, and prolong the network lifetime.","['Wireless sensor networks', 'Industrial plants', 'Information analysis', 'Data collection', 'Clustering algorithms', 'Mobile communication', 'Load modeling', 'Energy consumption', 'Tree data structures']","['data gathering scheme', 'cluster', 'mobile sink', 'wireless sensor networks']"
"Since the end of the 1990s, the world has witnessed a tremendous growth in the area of information and communication technology (ICT), starting with grid computing, cloud computing (CC), and fog computing to recently introduced edge computing. Although, these technologies are still in very good shape, they do heavily rely on connectivity, i.e., Internet. To address this challenge, this paper proposes a novel dew-cloud architecture that brings the power of CC together with the dew computing (DC). Originally, the dew-cloud architecture is an extension of the existing client-server architecture, where two servers are placed at both ends of the communication link. With the help of a dew server, a user has more control and flexibility to access his/her personal data in the absence of an Internet connection. Primarily, the data are stored at the dew server as a local copy upon which instantiation of the Internet is synchronized with the master copy at the cloud side. Users can browse, read, write, or append data on the local dew site, which is a local Web form of an actual website. With the incorporation of the dew domain naming system and dew domain name redirection, mapping between different local dew sites has become possible. Novel services, such as infrastructure-as-a-dew, software-as-a-dew service, and software-as-a-dew product, are, hereby, introduced along with the DC. This paper presents the following as key contributions: 1) a precise and concrete definition of DC; 2) detailed and comprehensive discussions of its concept and working principle; 3) application potentials; and 4) technical challenges. The motto of this paper is to conceptualize the fact of empowerment of the ICT-user base with almost an Internet-free surfing experience in coming days.","['Cloud computing', 'Edge computing', 'Computer architecture', 'Computational modeling', 'Servers', 'Biological system modeling']","['Dew-cloud architecture', 'dew server', 'dew site', 'dew database', 'DDNS', 'DDNR', 'dew service']"
"Coronavirus disease 2019 (COVID-19) poses massive challenges for the world. Public sentiment analysis during the outbreak provides insightful information in making appropriate public health responses. On Sina Weibo, a popular Chinese social media, posts with negative sentiment are valuable in analyzing public concerns. 999,978 randomly selected COVID-19 related Weibo posts from 1 January 2020 to 18 February 2020 are analyzed. Specifically, the unsupervised BERT (Bidirectional Encoder Representations from Transformers) model is adopted to classify sentiment categories (positive, neutral, and negative) and TF-IDF (term frequency-inverse document frequency) model is used to summarize the topics of posts. Trend analysis and thematic analysis are conducted to identify characteristics of negative sentiment. In general, the fine-tuned BERT conducts sentiment classification with considerable accuracy. Besides, topics extracted by TF-IDF precisely convey characteristics of posts regarding COVID-19. As a result, we observed that people concern four aspects regarding COVID-19, the virus Origin (Gamey Food, 3.08%; Bat, 2.70%; Conspiracy Theory, 1.43%), Symptom (Fever, 2.13%; Cough, 1.19%), Production Activity (Go to Work, 1.94%; Resume Work, 1.12%; School New Semester Beginning, 1.06%) and Public Health Control (Temperature Taking, 1.39%; Coronavirus Cover-up, 1.26%; City Shutdown, 1.09%). Results from Weibo posts provide constructive instructions on public health responses, that transparent information sharing and scientific guidance might help alleviate public concerns.","['Bit error rate', 'Public healthcare', 'Social network services', 'Sentiment analysis', 'Analytical models', 'Diseases', 'Market research']","['COVID-19 sensing', 'public health', 'sentiment classification', 'social media in China']"
"In order to gather data more efficiently, a clustering hierarchy algorithm is used for data communication in wireless sensor networks (WSNs). This algorithm is one of the major techniques to improve the energy efficiency in WSNs and it provides an effective manner to maximize the lifetime of WSNs. Hierarchical protocols based on clustering hierarchy are proposed to save energy of WSNs in which the nodes with higher remaining energy could be used to collect data and transmit it to a base station. However, most of the previous approaches based on clustering hierarchy have not considered the redundant data collected by the adjacent nodes or nodes overlap each other. In this paper, an enhanced clustering hierarchy (ECH) approach has been proposed to achieve energy efficiency in WSNs by using sleeping-waking mechanism for overlapping and neighboring nodes. Thus, the data redundancy is minimized and then network lifetime is maximized. In contrast of previous hierarchical routing protocols where all nodes are required for collecting and transmitting data, the proposed approach only requires the waking nodes to do these tasks, which are keys of energy consumption in WSNs. We implement (ECH) approach in homogeneous and heterogeneous networks. Results of the simulation show its effectiveness.","['Wireless sensor networks', 'Task analysis', 'Clustering algorithms', 'Routing protocols', 'Sensors', 'Heterogeneous networks']","['Wireless sensor networks (WSNs)', 'energy efficiency', 'clustering', 'hierarchical protocols', 'cluster head selection', 'data redundancy']"
"This research introduces a path planning method based on the geometric A-star algorithm. The whole approach is applied to an Automated Guided Vehicle (AGV) in order to avoid the problems of many nodes, long-distance and large turning angle, and these problems usually exist in the sawtooth and cross paths produced by the traditional A-star algorithm. First, a grid method models a port environment. Second, the nodes in the close-list are filtered by the functions P(x,y ) and W(x,y ) and the nodes that do not meet the requirements are removed to avoid the generation of irregular paths. Simultaneously, to enhance the stability of the AGV regarding turning paths, the polyline at the turning path is replaced by a cubic B-spline curve. The path planning experimental results applied to different scenarios and different specifications showed that compared with other seven different algorithms, the geometric A-star algorithm reduces the number of nodes by 10% ~ 40%, while the number of turns is reduced by 25%, the turning angle is reduced by 33.3%, and the total distance is reduced by 25.5%. Overall, the simulation results of the path planning confirmed the effectiveness of the geometric A-star algorithm.","['Path planning', 'Satellites', 'Turning', 'Layout', 'Heuristic algorithms', 'Splines (mathematics)', 'Computational modeling']","['A-star algorithm', 'automated guided vehicle (AGV)', 'grid method', 'path planning']"
"This paper surveys current literature on modeling methods, control techniques, protection schemes, applications, and real-world implementations pertaining to grid forming inverters (GFMIs). Electric power systems are increasingly being augmented with inverter-based resources (IBRs). While having a growing share of IBRs, conventional synchronous generator-based voltage and frequency control mechanisms are still prevalent in the power industry. Therefore, IBRs are experiencing a growing demand for mimicking the behavior of synchronous generators, which is not possible with conventional grid following inverters (GFLIs). As a solution, the concept of GFMIs is currently emerging, which is drawing increased attention from academia and the industry. This paper presents a comprehensive review of GFMIs covering recent advancements in control technologies, fault ride-through capabilities, stability enhancement measures, and practical implementations. Moreover, the challenges in adding GFMIs into existing power systems, including a seamless transition from grid-connected mode to the standalone mode and vice versa, are also discussed in detail. Recently commissioned projects in Australia, the UK, and the US are taken as examples to highlight the trend in the power industry in adding GFMIs to address issues related to weak grid scenarios. Research directions in terms of voltage control, frequency control, system strength improvement, and regulatory framework are also discussed. This paper serves as a resource for researchers and power system engineers exploring solutions to the emerging problems with high penetration of IBRs, focusing on GFMIs.","['Inverters', 'Power system stability', 'Voltage control', 'Reactive power', 'Frequency control', 'Stability analysis', 'Synchronous generators']","['Current control', 'fault ride-through', 'grid forming inverters', 'power synchronization control', 'small-signal and transient stability', 'virtual inertia']"
"Today, and possibly for a long time to come, the full driving task is too complex an activity to be fully formalized as a sensing-acting robotics system that can be explicitly solved through model-based and learning-based approaches in order to achieve full unconstrained vehicle autonomy. Localization, mapping, scene perception, vehicle control, trajectory optimization, and higher-level planning decisions associated with autonomous vehicle development remain full of open challenges. This is especially true for unconstrained, real-world operation where the margin of allowable error is extremely small and the number of edge-cases is extremely large. Until these problems are solved, human beings will remain an integral part of the driving task, monitoring the AI system as it performs anywhere from just over 0% to just under 100% of the driving. The governing objectives of the MIT Advanced Vehicle Technology (MIT-AVT) study are to 1) undertake large-scale real-world driving data collection that includes high-definition video to fuel the development of deep learning-based internal and external perception systems; 2) gain a holistic understanding of how human beings interact with vehicle automation technology by integrating video data with vehicle state data, driver characteristics, mental models, and self-reported experiences with technology; and 3) identify how technology and other factors related to automation adoption and use can be improved in ways that save lives. In pursuing these objectives, we have instrumented 23 Tesla Model S and Model X vehicles, 2 Volvo S90 vehicles, 2 Range Rover Evoque, and 2 Cadillac CT6 vehicles for both long-term (over a year per driver) and medium-term (one month per driver) naturalistic driving data collection. Furthermore, we are continually developing new methods for the analysis of the massive-scale dataset collected from the instrumented vehicle fleet. The recorded data streams include IMU, GPS, and CAN messages, and high-definition video streams of the driver's face, the driver cabin, the forward roadway, and the instrument cluster (on select vehicles). The study is on-going and growing. To date, we have 122 participants, 15610 days of participation, 511638 mi, and 7.1 billion video frames. This paper presents the design of the study, the data collection hardware, the processing of the data, and the computer vision algorithms currently being used to extract actionable knowledge from the data.","['Task analysis', 'Autonomous vehicles', 'Automation', 'Instruments', 'Roads', 'Sensors']","['Artificial intelligence', 'automation', 'human factors', 'autonomous vehicles', 'human-robot interaction', 'computer vision', 'machine learning', 'neural networks']"
"For the last few years, Android is known to be the most widely used operating system and this rapidly increasing popularity has attracted the malware developer's attention. Android allows downloading and installation of apps from other unofficial market places. This gives malware developers an opportunity to put repackaged malicious applications in third-party app-stores and attack the Android devices. A large number of malware analysis and detection systems have been developed which uses static analysis, dynamic analysis, or hybrid analysis to keep Android devices secure from malware. However, the existing research clearly lags in detecting malware efficiently and accurately. For accurate malware detection, multilayer analysis is required which consumes large amount of hardware resources of resource constrained mobile devices. This research proposes an efficient and accurate solution to this problem, named SAMADroid, which is a novel 3-level hybrid malware detection model for Android operating systems. The research contribution includes multiple folds. First, many of the existing Android malware detection techniques are thoroughly investigated and categorized on the basis of their detection methods. Also, their benefits along with limitations are deduced. A novel 3-level hybrid malware detection model for Android operating systems is developed, that can provide high detection accuracy by combining the benefits of the three different levels: 1) Static and Dynamic Analysis; 2) Local and Remote Host; and 3) Machine Learning Intelligence. Experimental results show that SAMADroid achieves high malware detection accuracy by ensuring the efficiency in terms of power and storage consumption.","['Malware', 'Androids', 'Humanoid robots', 'Operating systems', 'Feature extraction', 'Runtime']","['Accuracy', 'android operating system', 'dynamic analysis', 'efficiency', 'hybrid malware detection', 'machine learning', 'memory usage', 'performance overhead', 'power consumption', 'static analysis']"
"Blockchain (e.g., Bitcoin and Ethereum) has drawn much attention and has been widely-deployed in recent years. However, blockchain scalability is emerging as a challenging issue. This paper outlines the existing solutions to blockchain scalability, which can be classified into two categories: first layer and second layer solutions. First layer solutions propose modifications to the blockchain (i.e., changing the blockchain structure, such as block size) while second layer solutions propose mechanisms that are implemented outside of the blockchain. In particular, we focus on sharding as a promising first layer solution to the scalability issue; the basic idea behind sharding is to divide the blockchain network into multiple committees, each processing a separate set of transactions. More specifically, (a) we propose a taxonomy based on committee formation and intra-committee consensus; and (b) we compare the main existing sharding-based blockchain protocols. We also present a performance-based comparative analysis (i.e., throughput and latency), of the advantages, and disadvantages in existing scalability solutions.","['Blockchain', 'Scalability', 'Protocols', 'Bitcoin', 'Peer-to-peer computing', 'Taxonomy']","['Blockchain', 'scalability', 'sharding', 'first layer solutions', 'second layer solutions']"
"Pervasive computing and Internet of Things (IoTs) paradigms have created a huge potential for new business. To fully realize this potential, there is a need for a common way to abstract the heterogeneity of devices so that their functionality can be represented as a virtual computing platform. To this end, we present novel semantic level interoperability architecture for pervasive computing and IoTs. There are two main principles in the proposed architecture. First, information and capabilities of devices are represented with semantic web knowledge representation technologies and interaction with devices and the physical world is achieved by accessing and modifying their virtual representations. Second, global IoT is divided into numerous local smart spaces managed by a semantic information broker (SIB) that provides a means to monitor and update the virtual representation of the physical world. An integral part of the architecture is a resolution infrastructure that provides a means to resolve the network address of a SIB either using a physical object identifier as a pointer to information or by searching SIBs matching a specification represented with SPARQL. We present several reference implementations and applications that we have developed to evaluate the architecture in practice. The evaluation also includes performance studies that, together with the applications, demonstrate the suitability of the architecture to real-life IoT scenarios. In addition, to validate that the proposed architecture conforms to the common IoT-A architecture reference model (ARM), we map the central components of the architecture to the IoT-ARM.","['Semantics', 'Computer architecture', 'Interoperability', 'Pervasive computing', 'Context awareness', 'Sensors', 'Resource description framework']","['Internet of Things', 'pervasive computing', 'RDF', 'semantic interoperability', 'system architecture', 'SPARQL']"
"Accurate state-of-charge (SOC) estimation is critical for driving range prediction of electric vehicles and optimal charge control of batteries. In this paper, a stacked long short-term memory network is proposed to model the complex dynamics of lithium iron phosphate batteries and infer battery SOC from current, voltage, and temperature measurements. The proposed network is trained and tested using data collected from the dynamic stress test, US06 test, and federal urban driving schedule. The performance on SOC estimation is evaluated regarding tracking accuracy, computation time, robustness against unknown initial states, and compared with results from the model-based filtering approach (unscented Kalman filter). Moreover, different training and testing data sets are constructed to test its robustness against varying loading profiles. The experimental results show that the proposed network well captures the nonlinear correlation between SOC and measurable signals and provides better tracking performance than the unscented Kalman filter. In case of inaccurate initial SOCs, the proposed network presents quick convergence to the true SOC, with root mean square errors within 2% and mean average errors within 1%. Moreover, the estimation time at each time step is sub-millisecond, making it appropriate for real-time applications.","['Batteries', 'State of charge', 'Estimation', 'Voltage measurement', 'Battery charge measurement', 'Temperature measurement', 'Current measurement']","['State-of-charge estimation', 'lithium iron phosphate batteries', 'long short-term memory', 'recurrent neural network', 'unscented Kalman filter']"
"Global terrorist threats and illegal migration have intensified concerns for the security of citizens, and every effort is made to exploit all available technological advances to prevent adverse events and protect people and their property. Due to the ability to use at night and in weather conditions where RGB cameras do not perform well, thermal cameras have become an important component of sophisticated video surveillance systems. In this paper, we investigate the task of automatic person detection in thermal images using convolutional neural network models originally intended for detection in RGB images. We compare the performance of the standard state-of-the-art object detectors such as Faster R-CNN, SSD, Cascade R-CNN, and YOLOv3, that were retrained on a dataset of thermal images extracted from videos that simulate illegal movements around the border and in protected areas. Videos are recorded at night in clear weather, rain, and in the fog, at different ranges, and with different movement types. YOLOv3 was significantly faster than other detectors while achieving performance comparable with the best, so it was used in further experiments. We experimented with different training dataset settings in order to determine the minimum number of images needed to achieve good detection results on test datasets. We achieved excellent detection results with respect to average accuracy for all test scenarios although a modest set of thermal images was used for training. We test our trained model on different well known and widely used thermal imaging datasets as well. In addition, we present the results of the recognition of humans and animals in thermal images, which is particularly important in the case of sneaking around objects and illegal border crossings. Also, we present our original thermal dataset used for experimentation that contains surveillance videos recorded at different weather and shooting conditions.","['Meteorology', 'Cameras', 'Object detection', 'Detectors', 'Temperature sensors', 'Convolutional neural networks']","['Convolutional neural networks', 'object detector', 'person detection', 'surveillance', 'thermal imaging', 'YOLO']"
"In an aircraft electric power system, one or more supervisory control units actuate a set of electromechanical switches to dynamically distribute power from generators to loads, while satisfying safety, reliability, and real-time performance requirements. To reduce expensive redesign steps, this control problem is generally addressed by minor incremental changes on top of consolidated solutions. A more systematic approach is hindered by a lack of rigorous design methodologies that allow estimating the impact of earlier design decisions on the final implementation. To achieve an optimal implementation that satisfies a set of requirements, we propose a platform-based methodology for electric power system design, which enables independent implementation of system topology (i.e., interconnection among elements) and control protocol by using a compositional approach. In our flow, design space exploration is carried out as a sequence of refinement steps from the initial specification toward a final implementation by mapping higher level behavioral and performance models into a set of either existing or virtual library components at the lower level of abstraction. Specifications are first expressed using the formalisms of linear temporal logic, signal temporal logic, and arithmetic constraints on Boolean variables. To reason about different requirements, we use specialized analysis and synthesis frameworks and formulate assume guarantee contracts at the articulation points in the design flow. We show the effectiveness of our approach on a proof-of-concept electric power system design.","['Aircraft manufacture', 'Design automation', 'Power system stabilty', 'Design methodology', 'Cyberphysical systems']","['Design methodology', 'design automation', 'aircraft', 'power systems', 'control system synthesis', 'contract-based design', 'platform-based design', 'cyber-physical systems']"
"Irregular human behaviors and univariate datasets remain as two main obstacles of data-driven energy consumption predictions for individual households. In this study, a hybrid deep learning model is proposed combining an ensemble long short term memory (LSTM) neural network with the stationary wavelet transform (SWT) technique. The SWT alleviates the volatility and increases the data dimensions, which potentially help improve the LSTM forecasting accuracy. Moreover, the ensemble LSTM neural network further enhances the forecasting performance of the proposed method. Verification experiments were performed based on a real-world household energy consumption dataset collected by the `UK-DALE project. The results show that, with a competitive training efficiency, the proposed method outperforms all compared state-of-art methods, including the persistent method, support vector regression (SVR), long short term memory (LSTM) neural network and convolutional neural network combining long short term memory (CNN-LSTM), with different step sizes at 5, 10, 20 and 30 minutes, using three error metrics.","['Forecasting', 'Neural networks', 'Energy consumption', 'Deep learning', 'Discrete wavelet transforms']","['Energy consumption', 'forecasting', 'long short term memory', 'wavelet transform']"
"False data injection cyber-physical threat is a typical integrity attack in modern smart grids. These days, data analytical methods have been employed to mitigate false data injection attacks (FDIAs), especially when large scale smart grids generate huge amounts of data. In this paper, a novel data analytical method is proposed to detect FDIAs based on data-centric paradigm employing the margin setting algorithm (MSA). The performance of the proposed method is demonstrated through simulation using the six-bus power network in a wide area measurement system environment, as well as experimental data sets. Two FDIA scenarios, playback attack and time attack, are investigated. Experimental results are compared with the support vector machine (SVM) and artificial neural network (ANN). The results indicate that MSA yields better results in terms of detection accuracy than both the SVM and ANN when applied to FDIA detection.","['Phasor measurement units', 'Smart grids', 'Support vector machines', 'Artificial neural networks', 'Machine learning algorithms', 'Data mining', 'Topology']","['Data analytical', 'false data injection', 'cyber-physical attack', 'smart grid']"
"With the popularity of Android smartphones, malicious applications targeted Android platform have explosively increased. Proposing effective Android malware detection method for preventing the spread of malware has become an emerging issue. Various features extracted through static and dynamic analysis in conjunction with machine learning algorithm have been the mainstream in largescale malware identification. In general, static analysis becomes invalid in detecting applications which adopt sophisticated obfuscation techniques like encryption or dynamic code loading. However, dynamic analysis is suitable to deal with these evasion techniques. In this paper, we propose an effective dynamic analysis framework, called EnDroid, in the aim of implementing highly precise malware detection based on multiple types of dynamic behavior features. These features cover system-level behavior trace and common application-level malicious behaviors like personal information stealing, premium service subscription, and malicious service communication. In addition, EnDroid adopts feature selection algorithm to remove noisy or irrelevant features and extracts critical behavior features. Extracting behavior features through runtime monitor, EnDroid is able to distinguish malicious from benign applications with ensemble learning algorithm. Through experiments, we prove the effectiveness of EnDroid on two datasets. Furthermore, we find Stacking achieves the best classification performance and is promising in Android malware detection.","['Feature extraction', 'Malware', 'Androids', 'Humanoid robots', 'Heuristic algorithms', 'Static analysis', 'Monitoring']","['Android security', 'dynamic analysis', 'ensemble learning', 'Android malware detection']"
"The fast development of electric vehicles (EVs) provides significant opportunities to further utilize clean energies in the automotive. On-board chargers (OBCs) are widely used in EVs because of their simple installation and low cost. Limited space in the vehicle and short charging time require an OBC to be power-dense and highly efficient. Moreover, the possibility for EVs to deliver power back to the grid has increased the interest in bidirectional power flow solutions in the automotive market. This paper presents a comprehensive overview and investigation on the state-of-the-art solutions of bidirectional OBCs. It reviews the current status, including architectures and configurations, smart operation modes, industry standards, major components, and commercially available products. A detailed overview of the promising topologies for bidirectional OBCs, including two-stage and single-stage structures, is provided. Future trends and challenges for topologies, wide bandgap technologies, thermal management, system integration, and wireless charging systems are also discussed in this paper.","['Topology', 'Batteries', 'Vehicle-to-grid', 'Industries', 'Power system measurements', 'Power harmonic filters', 'Electromagnetic interference']","['Bidirectional on-board charger', 'DC/DC converter', 'electric vehicle', 'power factor correction converter', 'single-stage topology', 'wide bandgap devices']"
"Brain tumor segmentation technology plays a pivotal role in the process of diagnosis and treatment of MRI brain tumors. It helps doctors to locate and measure tumors, as well as develop treatment and rehabilitation strategies. Recently, MRI brain tumor segmentation methods based on U-Net architecture have become popular as they largely improve the segmentation accuracy by applying skip connection to combine high-level feature information and low-level feature information. Meanwhile, researchers have demonstrated that introducing attention mechanism into U-Net can enhance local feature expression and improve the performance of medical image segmentation. In this work, we aim to explore the effectiveness of a recent attention module called attention gate for brain tumor segmentation task, and a novel Attention Gate Residual U-Net model, i.e., AGResU-Net, is further presented. AGResU-Net integrates residual modules and attention gates with a primeval and single U-Net architecture, in which a series of attention gate units are added into the skip connection for highlighting salient feature information while disambiguating irrelevant and noisy feature responses. AGResU-Net not only extracts abundant semantic information to enhance the ability of feature learning, but also pays attention to the information of small-scale brain tumors. We extensively evaluate attention gate units on three authoritative MRI brain tumor benchmarks, i.e., BraTS 2017, BraTS 2018 and BraTS 2019. Experimental results illuminate that models with attention gate units, i.e., Attention Gate U-Net (AGU-Net) and AGResU-Net, outperform their baselines of U-Net and ResU-Net, respectively. In addition, AGResU-Net achieves competitive performance than the representative brain tumor segmentation methods.","['Tumors', 'Image segmentation', 'Logic gates', 'Task analysis', 'Magnetic resonance imaging', 'Feature extraction', 'Brain']","['MRI', 'brain tumor segmentation', 'U-Net', 'attention gate', 'residual module']"
"Blockchain is considered one of the most disruptive technologies of our time. Numerous cities around the world are launching blockchain initiatives as part of the overall efforts toward shaping the urban future. However, the infancy stage of the blockchain industry leads to a severe gap between the knowledge we have and the actions urban policy makers are taking. This paper is an effort to narrow this rift. We provide a systematic literature review on concrete blockchain use cases proposed by the research community. At the macro-level, we discuss and organize use cases from 159 selected papers into nine sectors recognized as crucial for sustainable and smart urban future. At the micro-level, we identify a component-based framework and analyze the design and prototypes of blockchain systems studied in a subset of 71 papers. The high-level use case review allows us to illustrate the relationship between them and the four pillars of urban sustainability: social, economic, environmental, and governmental. The system level analysis helps us highlight interesting inconsistencies between well-known blockchain applicability decision rules and the approaches taken by the literature. We also offer two classification methodologies for blockchain use cases and elaborate on how they can be applied to stimulate cross-sector insights in the blockchain knowledge domain.","['Peer-to-peer computing', 'Urban areas', 'Bitcoin', 'Bibliographies', 'Sustainable development']","['Bitcoin', 'blockchain', 'computer networks', 'consensus', 'crypto token', 'distributed computing', 'Ethereum', 'Hyperledger Fabric', 'systematic literature review', 'smart city', 'smart contract', 'system analysis and design', 'peer-to-peer computing', 'urban sustainability', 'use case']"
"The growing demand for lithium-ion (Li-ion) battery in electric vehicles has expedited the need for new optimal charging approaches to improve the speed and reliability of the charging process without deteriorating battery performances. Many efforts have been deployed to develop optimal charging strategies for commercial Li-ion batteries over the last decade. The active optimal charging strategies have great potential to meet the requirement. This paper is a review of the studies on constructing the optimal charging algorithms for Li-ion batteries. The battery models on which these protocols rest are stated, the generalized structures are examined, the advantages and the drawbacks of the mathematical controller algorithms are discussed, and their applications are presented. Suggestions for overcoming the shortcomings of the proposed strategies are proposed. Challenges and future directions in the development of optimal charging strategies for commercial Li-ion batteries are also discussed.","['State of charge', 'Lithium-ion batteries', 'Mathematical model', 'Protocols', 'Resistance', 'Integrated circuit modeling']","['Fast charging', 'optimal charging strategies', 'lithium-ion battery']"
"Advanced persistent threat (APT) is a serious threat to the Internet. With the aid of APT malware, attackers can remotely control infected machines and steal sensitive information. DNS is popular for malware to locate command and control (C&C) servers. In this paper, we propose a novel system placed at the network egress point that aims to efficiently and effectively detect APT malware infections based on malicious DNS and traffic analysis. The system uses malicious DNS analysis techniques to detect suspicious APT malware C&C domains, and then analyzes the traffic of the corresponding suspicious IP using the signature-based and anomaly based detection technology. We extracted 14 features based on big data to characterize different properties of malware-related DNS and the ways that they are queried, and we also defined network traffic features that can identify the traffic of compromised clients that have remotely been controlled. We built a reputation engine to compute a reputation score for an IP address using these features vector together. Our experiment was performed at a large local institute network for two months, and all the features were studied with big data, which includes ~400 million DNS queries. Our security approach cannot only substantially reduce the volume of network traffic that needs to be recorded and analyzed but also improve the sustainability of the system.","['Malware', 'Feature extraction', 'IP networks', 'Command and control systems', 'Web servers', 'Intrusion detection']","['APT', 'malware infections', 'DNS', 'intrusion detection']"
"With the increasing attention paid to many-objective optimization in the evolutionary multi-objective optimization community, various approaches have been proposed to solve many-objective problems. However, existing experimental comparative studies are usually restricted to a few methods. Few studies have encompassed most of the recently proposed state-of-the-art approaches and made an experimental comparison. To this end, this paper offers a systematic comparison of 13 algorithms covering various categories to solve many-objective problems. The experimental comparison is conducted on three groups of test functions by using two performance metrics and a visual observation in the decision space. The experimental results demonstrate that different approaches have different search abilities. None of the test approaches outperform the others on all types of problems. However, some of the approaches are competitive on a large number of test problems. Moreover, inconsistent results from the hypervolume and the inverted generational distance metrics are revealed in this paper. Based on these comparative results, researchers can obtain useful suggestions for choosing appropriate algorithms for different problems.","['Convergence', 'Pareto optimization', 'Evolutionary computation', 'Linear programming', 'Systems engineering and theory', 'Measurement']","['Evolutionary computation', 'experimental comparison', 'HV', 'IGD', 'multi-objective optimization']"
"In this study, a new non-isolated high voltage gains dc/dc converter using coupled inductor and voltage multiplier techniques (diode/capacitor) is presented. The voltage gain will be increased by increasing the turns ratio (N) and the number of stages of the VM units. The proposed converter capable to more increase the output voltage gains with transfer energy which is stored in coupled inductance. Also, the voltage multiplier unit causes to further increase in the output voltage level of the proposed converter. Besides, the nominal value of the semiconductors is low due to these are clamped to the capacitors available on the voltage multiplier units. The normalized voltage stress across the semiconductors is low which this case is compared in the comparison section. Therefore, the power loss of switch can be reduced by using a switch with a lower rating (lower RDS(on)) and power diodes with the low nominal rating. As a result, the overall efficiency of the proposed converter will be high. To confirm the benefits of working in this paper, comparison results for different items with other works are provided in section 4. The principle of operation, the theoretical analysis and the experimental results of a laboratory prototype for N(N2/N1) = 2 and n = 2 stage in about 260W with operating at 40kHz are provided.","['Inductors', 'Semiconductor diodes', 'Capacitors', 'Switches', 'High-voltage techniques', 'Inductance', 'Energy storage']","['DC/DC converter', 'high voltage gain', 'coupled-inductor techniques', 'lower losses']"
"Ambient-assisted living (AAL) is promising to become a supplement of the current care models, providing enhanced living experience to people within context-aware homes and smart environments. Activity recognition based on sensory data in AAL systems is an important task because 1) it can be used for estimation of levels of physical activity, 2) it can lead to detecting changes of daily patterns that may indicate an emerging medical condition, or 3) it can be used for detection of accidents and emergencies. To be accepted, AAL systems must be affordable while providing reliable performance. These two factors hugely depend on optimizing the number of utilized sensors and extracting robust features from them. This paper proposes a generic feature engineering method for selecting robust features from a variety of sensors, which can be used for generating reliable classification models. From the originally recorded time series and some newly generated time series [i.e., magnitudes, first derivatives, delta series, and fast Fourier transformation (FFT)-based series], a variety of time and frequency domain features are extracted. Then, using two-phase feature selection, the number of generated features is greatly reduced. Finally, different classification models are trained and evaluated on an independent test set. The proposed method was evaluated on five publicly available data sets, and on all of them, it yielded better accuracy than when using hand-tailored features. The benefits of the proposed systematic feature engineering method are quickly discovering good feature sets for any given task than manually finding ones suitable for a particular task, selecting a small feature set that outperforms manually determined features in both execution time and accuracy, and identification of relevant sensor types and body locations automatically. Ultimately, the proposed method could reduce the cost of AAL systems by facilitating execution of algorithms on devices with limited resources and by using as few sensors as possible.","['Feature extraction', 'Windows', 'Activity recognition', 'Sensor phenomena and characterization', 'Robustness', 'Ambient assisted living']","['Feature extraction', 'time series analysis', 'ambient intelligence', 'wearable sensors', 'sensor fusion', 'pattern recognition', 'data mining', 'data preprocessing', 'body sensor networks']"
"The detection of insulators with cluttered backgrounds in aerial images is a challenging task for an automatic transmission line inspection system. In this paper, we propose an effective and reliable insulator detection method based on a deep learning technique for aerial images. In the proposed deep detection approach, the single shot multibox detector (SSD), a powerful deep meta-architecture, is incorporated with a strategy of two-stage fine-tuning. The SSD-based model can realize automatic multi-level feature extractor from aerial images instead of manually extracting features. Inspired by transfer learning, a two-stage fine-tuning strategy is implemented using separate training sets. In the first stage, the basic insulator model is obtained by fine-tuning the COCO model with aerial images, including different types of insulators and various backgrounds. In the second stage, the basic model is fine-tuned by the training sets of the specific insulator types and specific situations to be detected. After the two-stage fine-tuning, the well-trained SSD model can directly and accurately identify the insulator by feeding the aerial images. The results show that both the porcelain insulator and composite insulator can be quickly and accurately identified in the aerial images with complex background. The proposed approach can enhance the accuracy, efficiency, and robustness significantly.","['Insulators', 'Feature extraction', 'Inspection', 'Power transmission lines', 'Training', 'Deep learning', 'Detectors']","['Insulator detection', 'deep learning', 'single shot multibox detector (SSD)', 'fine-tuning']"
"The increasing number of studies that underline the relationship between industry 4.0 and sustainability shows that sustainability is one of the pillars of smart factories. Through a bibliometric performance and network analysis (BPNA), this research describes the existing relationship between industry 4.0 and sustainability, the strategic themes from 2010 to March 2019, as well as the research gaps for proposing future work. With this goal in mind, 894 documents and 5621 keywords were included for bibliometric analysis, which were treated with the support of Science Mapping Analysis Software Tool (SciMAT). The bibliometric performance analysis presented the number of publications over time and the most productive journals. The strategic diagram shown 12 main research clusters, which were measured according to bibliometric indicators. Moreover, the network structure of each cluster was depicted, and the patterns found were discussed based on the documents associated to the network. Our findings show the scientific efforts are focused to enhance economic and environmental aspects and highlights a lack of effort relating the social sphere. Finally, the paper concludes the challenges, perspectives, and suggestions for the potential future work in the field of study relating to industry 4.0 and sustainability.","['Sustainable development', 'Bibliometrics', 'Industries', 'Production facilities', 'Smart manufacturing', 'Software']","['Industry 4.0', 'sustainable manufacturing', 'sustainability', 'bibliometric', 'strategic intelligence', 'co-word analysis', 'SciMAT']"
"The study on the sizing of renewable energy generation systems and energy storage systems together in a household considering different price mechanisms can further promote the development of the home energy management system (HEMS). In this paper, a HEMS expressed as a bi-level model is provided to investigated capacity allocation strategy of the photovoltaic (PV) and battery energy storage system (BESS) in a smart household considering: 1) the impact of electricity price mechanisms which include the time-of-use pricing (TOU), the real-time pricing (RTP), and the stepwise power tariff (SPT); 2) the effect of subsidies of PV; and 3) the uncertainty in the PV output and seasonal load profiles. Then, the hybrid approach which combines the cataclysmic genetic algorithm and the DICOPT solver in GAMS is employed to find an optimal solution. Finally, six cases with different price mechanisms and approaches, as well as the sensitivity analysis of optimal solution to subsidies are presented. Results indicate that, with the subsidies, only the PV system needs to be equipped in a household under the SPT, while the PV system and BESS need to be equipped together under the RTP and TOU. Only when the subsidies of PV reach a certain level will the installation of PV be considered.","['Programming', 'Renewable energy sources', 'Energy storage', 'Investment', 'Pricing', 'Buildings', 'Linear programming']","['Photovoltaic system', 'battery energy storage system', 'smart household', 'home energy management system', 'electricity price', 'subsidy']"
"As a result of the difficulties brought by COVID-19 and its associated lockdowns, many individuals and companies have turned to robots in order to overcome the challenges of the pandemic. Compared with traditional human labor, robotic and autonomous systems have advantages such as an intrinsic immunity to the virus and an inability for human-robot-human spread of any disease-causing pathogens, though there are still many technical hurdles for the robotics industry to overcome. This survey comprehensively reviews over 200 reports covering robotic systems which have emerged or have been repurposed during the past several months, to provide insights to both academia and industry. In each chapter, we cover both the advantages and the challenges for each robot, finding that robotics systems are overall apt solutions for dealing with many of the problems brought on by COVID-19, including: diagnosis, screening, disinfection, surgery, telehealth, care, logistics, manufacturing and broader interpersonal problems unique to the lockdowns of the pandemic. By discussing the potential new robot capabilities and fields they applied to, we expect the robotics industry to take a leap forward due to this unexpected pandemic.","['Robots', 'COVID-19', 'Service robots', 'Testing', 'Pandemics', 'Viruses (medical)', 'Industries']","['COVID-19', 'SARS-CoV-2', 'robots', 'autonomous systems', 'drones', 'review', 'survey', 'public health', 'sensors', 'learning']"
"Recently, broadband maritime communication has attracted much attention due to the rapid development of blue economy. In addition to the conventional MF/HF/VHF bands, there has been increasing interests in the utilization of higher frequency bands to provide broadband data service to the sea area. To design efficient maritime communication systems, the first and a fundamental requirement is to develop a framework to understand the wireless channels. In an integrated air-ground-sea communications network, there are two major type of channels to be investigated, namely the air-to-sea channel (e.g., for communication links from the aircraft-based base stations or relays) and the near-sea-surface channel (for land-to-ship/ship-to-land or ship-to-ship communications). Due to the unique features of the maritime propagation environment such as sparse scattering, sea wave movement, and the ducting effect over the sea surface, the modeling of these maritime channel links differs from conventional terrestrial wireless channels in many aspects and, consequently, will result in significant impact on the transceiver design. In this survey, we highlight the most notable differences from the modeling perspective as well as the channel characteristics for the air-to-sea and near-sea-surface channel links, with more focus on the latter. After a thorough review of existing modeling approaches and measurement campaigns, we conclude that the sparse and the location-dependent properties constitute the most important and distinctive characteristics of the maritime wireless channels. As such, we further remark on the challenges and research topics for future development of maritime communications.","['Wireless communication', 'Atmospheric modeling', 'Channel models', 'Scattering', 'Sea measurements', 'Fading channels']","['Maritime communications', 'channel model', 'evaporation duct', 'finite scattering', 'beyond line-of-sight']"
"Mobile edge computing (MEC) is being introduced and leveraged in many domains, but few studies have addressed MEC for secure in-home therapy management. To this end, this paper presents an in-home therapy management framework, which leverages the IoT nodes and the blockchain-based decentralized MEC paradigm to support low-latency, secure, anonymous, and always-available spatiotemporal multimedia therapeutic data communication within an on-demand data-sharing scenario. To the best of our knowledge, this non-invasive, MEC-based IoT therapy platform is first done by our group. This platform can provide a full-body joint range of motion data for physically challenged individuals in a decentralized manner. With MEC, the framework can provide therapy diagnostic and analytical data on demand to a large portion of humanity who are either born with disabilities or became disabled due to accidents, war-time injuries, or old age. For security, the framework uses blockchain–Tor-based distributed transactions to preserve the therapeutic data privacy, ownership, generation, storage, and sharing. Our initial test results from a complete implementation of the framework show that it can support a sufficiently large number of users without considerable increase in mean processing time.","['Medical treatment', 'Task analysis', 'Cloud computing', '5G mobile communication']","['Blockchain', 'mobile edge computing', 'therapy', 'IoT']"
"In addition to being environment friendly, vehicle-to-grid (V2G) systems can help the plug-in electric vehicle (PEV) users in reducing their energy costs and can also help stabilizing energy demand in the power grid. In V2G systems, since the PEV users need to obtain system information (e.g., locations of charging/discharging stations, current load, and supply of the power grid) to achieve the best charging and discharging performance, data communication plays a crucial role. However, since the PEV users are highly mobile, information from V2G systems is not always available for many reasons, e.g., wireless link failures and cyber attacks. Therefore, in this paper, we introduce a novel concept using cyber insurance to “transfer” cyber risks, e.g., unavailable information, of a PEV user to a third party, e.g., a cyber-insurance company. Under the insurance coverage, even without information about V2G systems, a PEV user is always guaranteed the best price for charging/discharging. In particular, we formulate the optimal energy cost problem for the PEV user by adopting a Markov decision process framework. We then propose a learning algorithm to help the PEV user make optimal decisions, e.g., to charge or discharge and to buy or not to buy insurance, in an online fashion. Through simulations, we show that cyber insurance is an efficient solution not only in dealing with cyber risks, but also in maximizing revenue for the PEV user.","['Batteries', 'Markov processes', 'Power grids', 'Electric vehicles', 'Generators', 'Charging stations', 'Discharges (electric)']","['Cyber insurance', 'plug-in electric vehicle', 'vehicle charging', 'vehicle-to-grid', 'Markov decision process']"
"The method of text sentiment analysis based on sentiment dictionary often has the problems that the sentiment dictionary doesn't contain enough sentiment words or omits some field sentiment words. In addition, due to the existence of some polysemic sentiment words with positivity, negativity, and neutrality, the words' polarity cannot be accurately expressed, so the accuracy of text sentiment analysis is reduced to some extent. In this paper, an extended sentiment dictionary is constructed. The extended sentiment dictionary contains the basic sentiment words, the field sentiment words, and the polysemic sentiment words, which improves the accuracy of sentiment analysis. The naive Bayesian classifier is used to determine the field of the text in which the polysemic sentiment word is. Thus, the sentiment value of the polysemic sentiment word in the field is obtained. By utilizing the extended sentiment dictionary and the designed sentiment score rules, the sentiment of the text is achieved. The experimental results prove that the proposed sentiment analysis method based on extended sentiment dictionary has certain feasibility and accuracy. The research is meaningful for the sentiment recognition of the comment texts.","['Dictionaries', 'Sentiment analysis', 'Internet', 'Semantics', 'Machine learning', 'Classification algorithms', 'Task analysis']","['Chinese text sentiment analysis', 'text classification', 'naive Bayesian', 'sentiment dictionary']"
"The relationship between face and disease has been discussed from thousands years ago, which leads to the occurrence of facial diagnosis. The objective here is to explore the possibility of identifying diseases from uncontrolled 2D face images by deep learning techniques. In this paper, we propose using deep transfer learning from face recognition to perform the computer-aided facial diagnosis on various diseases. In the experiments, we perform the computer-aided facial diagnosis on single (beta-thalassemia) and multiple diseases (beta-thalassemia, hyperthyroidism, Down syndrome, and leprosy) with a relatively small dataset. The overall top-1 accuracy by deep transfer learning from face recognition can reach over 90% which outperforms the performance of both traditional machine learning methods and clinicians in the experiments. In practical, collecting disease-specific face images is complex, expensive and time consuming, and imposes ethical limitations due to personal data treatment. Therefore, the datasets of facial diagnosis related researches are private and generally small comparing with the ones of other machine learning application areas. The success of deep transfer learning applications in the facial diagnosis with a small dataset could provide a low-cost and noninvasive way for disease screening and detection.","['Face', 'Diseases', 'Face recognition', 'Deep learning', 'Medical diagnostic imaging', 'Task analysis']","['Facial diagnosis', 'deep transfer learning (DTL)', 'face recognition', 'beta-thalassemia', 'hyperthyroidism', 'down syndrome', 'leprosy']"
"To satisfy the delay constraint, the computation tasks can be offloaded to some computing servers, referred to as offloading destinations. Different to most of existing works which usually consider only a single type of offloading destinations, in this paper, we study the hybrid computation offloading problem considering diverse computation and communication capabilities of two types of offloading destinations, i.e., cloud computing servers and fog computing servers. The aim is to minimize the total energy consumption for both communication and computation while completing the computation tasks within a given delay constraint. It is quite challenging because the delay cannot be easily formulated as an explicit expression but depends on the embedded communication-computation scheduling problem for the computation offloading to different destinations. To solve the computation offloading problem, we first define a new concept named computation energy efficiency and divide the problem into four subproblems according to the computation energy efficiency of different types of computation offloading and the maximum tolerable delay. For each subproblem, we give a closed-form computation offloading solution with the analysis of communicationcomputation scheduling under the delay constraint. The numerical results show that the proposed hybrid computation offloading solution achieves lower energy consumption than the conventional single-type computation offloading under the delay constraint.","['Delays', 'Servers', 'Cloud computing', 'Energy consumption', 'Edge computing', 'Processor scheduling', 'Computational modeling']","['Cloud computing', 'computation offloading', 'delay optimization', 'wireless communications']"
"Face and fingerprint are, currently, the most thoroughly explored biometric traits, promising reliable recognition in diverse applications. Commercial products using these traits for biometric identification or authentication are increasingly widespread, from smartphones to border control. However, increasingly smart techniques to counterfeit such traits raise the need for traits that are less vulnerable to stealthy trait measurement or spoofing attacks. This has sparked interest on the electrocardiogram (ECG), most commonly associated with medical diagnosis, whose hidden nature and inherent liveness information make it highly resistant to attacks. In the last years, the topic of ECG-based biometrics has quickly evolved toward the commercial applications, mainly by addressing the reduced acceptability and comfort by proposing new off-the-person, wearable, and seamless acquisition settings. Furthermore, researchers have recently started to address the issues of spoofing prevention and data security in ECG biometrics, as well as the potential of deep learning methodologies to enhance the recognition accuracy and robustness. In this paper, we conduct a deep review and discussion of 93 state-of-the-art publications on their proposed methods, signal datasets, and publicly available ECG collections. The extracted knowledge is used to present the fundamentals and the evolution of ECG biometrics, describe the current state of the art, and draw conclusions on prior art approaches and current challenges. With this paper, we aim to delve into the current opportunities as well as inspire and guide future research in ECG biometrics.","['Biometrics (access control)', 'Electrocardiography', 'Heart rate', 'Feature extraction', 'Electrodes', 'Blood']","['Acquisition', 'authentication', 'biometrics', 'biosensors', 'classification algorithms', 'electrocardiography', 'feature extraction', 'identification of persons', 'machine learning', 'off-the-person', 'seamless', 'signal processing']"
"Image fusion is a well-recognized and a conventional field of image processing. Image fusion provides an efficient way of enhancing and combining pixel-level data resulting in highly informative data for human perception as compared with individual input source data. In this paper, we have demonstrated a comprehensive survey of multi-scale and non-multi-scale decomposition-based image fusion methods in detail. The reference-based and non-reference-based image quality evaluation metrics are summarized together with recent trends in image fusion. Several image fusion applications in various fields have also been reported. It has been stated that though a lot of singular fusion techniques seemed to have given optimum results, the focus of researchers is shifting toward amalgamated or hybrid fusion techniques, which could harness the attributes of both multi-scale and non-multi-scale decomposition methods. Toward the end, the review is concluded with various open challenges for researchers. Thus, the descriptive study in this paper would form basis for stimulating and nurturing advanced research ideas in image fusion.","['Image fusion', 'Transforms', 'Level measurement', 'Laplace equations', 'Image sensors', 'Sensor phenomena and characterization']","['Image fusion', 'multi-scale decomposition', 'medical-imaging', 'sparse representation', 'fusion metrics', 'edge-information']"
"In this paper, an eight-element MIMO array for 5G smartphone applications in the 3.45-GHz band (3.3–3.6 GHz) is presented. The array consists of two types of four-antenna arrays (U-shaped and L-shaped coupled-fed loop elements), which are symmetrically distributed in the inner of the smartphone frame. The dimension of the system circuit board is 124\,\,\text {mm}\times 74 mm and the size of two elements is 4.8\,\,\text {mm}\times 9.8 mm ( 0.055\lambda \times 0.11\lambda , \lambda represents the free-space wavelength at 3.45 GHz) and 4.9 \text {mm}\times 12.5 mm ( 0.056\lambda \times 0.14\lambda ), respectively. The proposed MIMO array is simulated, and a prototype is fabricated and tested. The results show that all the elements can cover the desired band of 3.3–3.6 GHz under the condition of −6-dB impendence bandwidth. The isolations are enhanced to 15 dB by combining the inverted-I ground slots with neutralization line (NL) structure. In addition, the envelope correlation coefficient (ECC) via any two elements is below 0.15 that shows good independence in far-field radiation characteristic. The measured efficiencies of the elements in the operating band are higher than 40%. Moreover, the array ergodic channel capacity is also calculated based on the correlation matrix method to be about 35 bps/Hz with a 20-dB signal-to-noise ratio. In addition, the effects of the user’s hand and the head has been analyzed as well. Based on the above, the proposed eight-element MIMO array is a prospective candidate for future 5G smartphone applications.","['MIMO communication', 'Antenna arrays', 'Strips', '5G mobile communication', 'Channel capacity', 'Mutual coupling']","['Channel capacity', 'eight-element array', 'high isolation', 'MIMO antenna']"
"Orthogonal frequency division multiplexing (OFDM) is an efficient multi-carrier modulation technique for wireless communication. However, one of the main drawbacks encountered in implementing it is its resultant high peak-to-average power ratio (PAPR). Many techniques have been proposed in the literature to substantially decrease the peaks in the OFDM signal. The problem with these, however, is that their effects on other parameters are not always positive. These effects include a decrease in the bit error rate (BER), an increase in complexity, or a reduction in the bit rate. The objective of this paper is to describe the PAPR problem in a bid to reduce the peaks in the OFDM signal. The paper proposes a classification, performance evaluation and optimization of PAPR reduction techniques for commercial, public safety, and tactical applications. In the taxonomy proposed herein, we also include a new category, namely, hybrid techniques. Furthermore, we compare the principal characteristics through a complementary cumulative distribution function and BER evaluation, and conclude on the importance of hybrid techniques, when the goal is to both improve the BER and reduce the PAPR.","['Peak to average power ratio', 'Wireless communication', 'MIMO', 'Gain', 'Modulation', 'Bit error rate']","['Orthogonal frequency division multiplexing', 'peak-to-average power ratio', 'high power amplifier', 'hybrid PAPR reduction technique', 'commercial communication', 'tactical communication']"
"In visual reasoning, the achievement of deep learning significantly improved the accuracy of results. Image features are primarily used as input to get answers. However, the image features are too redundant to learn accurate characterizations within a limited complexity and time. While in the process of human reasoning, abstract description of an image is usually to avoid irrelevant details. Inspired by this, a higher-level representation named semantic representation is introduced. In this paper, a detailed visual reasoning model is proposed. This new model contains an image understanding model based on semantic representation, feature extraction and process model refined with watershed and u-distance method, a feature vector learning model using pyramidal pooling and residual network, and a question understanding model combining problem embedding coding method and machine translation decoding method. The feature vector could better represent the whole image instead of overly focused on specific characteristics. The model using semantic representation as input verifies that more accurate results can be obtained by introducing a high-level semantic representation. The result also shows that it is feasible and effective to introduce high-level and abstract forms of knowledge representation into deep learning tasks. This study lays a theoretical and experimental foundation for introducing different levels of knowledge representation into deep learning in the future.","['Feature extraction', 'Semantics', 'Cognition', 'Visualization', 'Deep learning', 'Object detection', 'Task analysis']","['VQA', 'the semantic net', 'visual reasoning', 'deep learning']"
"Feature extraction and classification play an important role in brain–computer interface (BCI) systems. In traditional approaches, methods in pattern recognition field are adopted to solve these problems. Nowadays, the deep learning theory has developed so fast that researchers have employed it in many areas like computer vision and speech recognition, which have achieved remarkable results. However, few people introduce the deep learning method into the study of biomedical signals, especially EEG signals. In this paper, a wavelet transform-based input, which combines the time-frequency images of C3, Cz, and C4 channels, is proposed to extract the feature of motor imagery EEG signal. Then, a 2-Layer convolutional neural network is built as the classifier and convolutional kernels of different sizes are validated. The performance obtained by the proposed approach is evaluated by accuracy and Kappa value. The accuracy on dataset III from BCI competition II reaches 90%, and the best Kappa value on dataset 2a from competition IV is greater than many of other methods. In addition, the proposed method utilizes a resized small input, which reduces calculation complexity, so the training period is relatively faster. The results show that the method using convolutional neural network can be comparable or better than the other state-of-the-art approaches, and the performance will be improved when there is sufficient data.","['Electroencephalography', 'Feature extraction', 'Time-frequency analysis', 'Wavelet transforms', 'Brain modeling', 'Task analysis']","['Brain computer interface (BCI)', 'motor imagery (MI)', 'wavelet transform time-frequency image', 'convolutional neural network (CNN)']"
"Android malware severely threaten system and user security in terms of privilege escalation, remote control, tariff theft, and privacy leakage. Therefore, it is of great importance and necessity to detect Android malware. In this paper, we present a combination method for Android malware detection based on the machine learning algorithm. First, we construct the control flow graph of the application to obtain API information. Based on the API information, we innovatively construct Boolean, frequency, and time-series data sets. Based on these three data sets, three detection models for Android malware detection regarding API calls, API frequency, and API sequence aspects are constructed. Ultimately, an ensemble model is constructed for conformity. We tested and compared the accuracy and stability of our detection models through a large number of experiments. The experiments were conducted on 10010 benign applications and 10683 malicious applications. The results show that our detection model achieves 98.98% detection precision and has high accuracy and stability. All of the results are consistent with the theoretical analysis in this paper.","['Malware', 'Smart phones', 'Data models', 'Security', 'Machine learning algorithms', 'Privacy', 'Machine learning']","['Control flow graph', 'application programming interface', 'machine learning', 'malware detection']"
"Vehicular communication networks is a powerful tool that enables numerous vehicular data services and applications. The rapid growth in vehicles has also resulted in the vehicular network becoming heterogeneous, dynamic, and large-scale, making it hard to meet the strict requirements, such as extremely latency, high mobility, top security, and enormous connections of the fifth-generation network. Previous studies have shown that with the increase in the application of Software-Defined Networking (SDN) on Vehicular Ad-hoc Network (VANET) in industries, researchers have exerted considerable efforts to improve vehicular communications. This study presents an exhaustive review of previous works by classifying them based on based on wireless communication, particularly VANET. First, a concise summary of the VANET structure and SDN controller with layers and details of their infrastructure is provided. Second, a description of SDN-VANET applications in different wireless communications, such as the Internet of Things (IoT) and VANET is provided with concentration on the examination and comparison of SDN-VANET works on several parameters. This paper also provides a detailed analysis of the open issues and research directions accomplished while integrating the VANET with SDN. It also highlights the current and emerging technologies with use cases in vehicular networks to address the several challenges in the VANET infrastructure. This survey acts as a catalyst in raising the emergent robustness routing protocol, latency, connectivity and security issues of future SDN-VANET architectures.","['Vehicular ad hoc networks', 'Security', 'Wireless communication', 'Routing protocols', 'Industries', 'Quality of service']","['Vehicular ad hoc network (VANET)', 'SDN', '5G', 'Internet of Vehicles (IoV)', 'routing protocol', 'connectivity', 'mobility management', 'security']"
"The principles of the Industry 4.0 are guiding manufacturing companies toward more automated and computerized factories. Such principles are also applied in shipbuilding, which usually involves numerous complex processes whose automation will improve its efficiency and performance. Navantia, a company that has been building ships for 300 years, is modernizing its shipyards according to the Industry 4.0 principles with the help of the latest technologies. Augmented reality (AR), which when utilized in an industrial environment is called industrial AR (IAR), is one of such technologies, since it can be applied in numerous situations in order to provide useful and attractive interfaces that allow shipyard operators to obtain information on their tasks and to interact with certain elements that surround them. This article first reviews the state of the art on IAR applications for shipbuilding and smart manufacturing. Then, the most relevant IAR hardware and software tools are detailed, as well as the main use cases for the application of IAR in a shipyard. Next, it is described Navantia's IAR system, which is based on a fog-computing architecture. Such a system is evaluated when making the use of three IAR devices (a smartphone, a tablet, and a pair of smart glasses), two AR software development kits (ARToolKit and Vuforia) and multiple IAR markers, with the objective of determining their performance in a shipyard workshop and inside a ship under construction. The results obtained show a remarkable performance differences among the different IAR tools and the impact of factors like lighting, pointing out the best combinations of markers, and hardware and software to be used depending on the characteristics of the shipyard scenario.","['Industries', 'Hardware', 'Marine vehicles', 'Augmented reality', 'Maintenance engineering', 'Companies', 'Software']","['Augmented Reality', 'cyber-physical systems', 'identification', 'industrial augmented reality', 'industry 4.0', 'Internet of Things', 'traceability', 'industrial Internet of Things', 'smart factory']"
"Time series analysis and forecasting is of vital significance, owing to its widespread use in various practical domains. Time series data refers to an ordered sequence or a set of data points that a variable takes at equal time intervals. The stock market is considered to be one of the most highly complex financial systems which consist of various components or stocks, the price of which fluctuates greatly with respect to time. Stock market forecasting involves uncovering the market trends with respect to time. All the stock market investors aim to maximize the returns over their investments and minimize the risks associated. Stock markets being highly sensitive and susceptible to quick changes, the main aim of stock-trend prediction is to develop new innovative approaches to foresee the stocks that result in high profits. This research tries to analyze the time series data of the Indian stock market and build a statistical model that could efficiently predict the future stocks.","['Forecasting', 'Stock markets', 'Predictive models', 'Business', 'Time series analysis', 'Analytical models', 'Indexes']","['ARIMA model', 'forecasting', 'stock market forecasts', 'time series analysis', 'Box-Jenkins method']"
"Software-Defined Network (SDN) has become a promising network architecture in current days that provide network operators more control over the network infrastructure. The controller, also called as the operating system of the SDN, is responsible for running various network applications and maintaining several network services and functionalities. Despite all its capabilities, the introduction of various architectural entities of SDN poses many security threats and potential targets. Distributed Denial of Services (DDoS) is a rapidly growing attack that poses a tremendous threat to the Internet. As the control layer is vulnerable to DDoS attacks, the goal of this paper is to detect the attack traffic, by taking the centralized control aspect of SDN. Nowadays, in the field of SDN, various machine learning (ML) techniques are being deployed for detecting malicious traffic. Despite these works, choosing the relevant features and accurate classifiers for attack detection is an open question. For better detection accuracy, in this work, Support Vector Machine (SVM) is assisted by kernel principal component analysis (KPCA) with genetic algorithm (GA). In the proposed SVM model, KPCA is used for reducing the dimension of feature vectors, and GA is used for optimizing different SVM parameters. In order to reduce the noise caused by feature differences, an improved kernel function (N-RBF) is proposed. The experimental results show that compared to single-SVM, the proposed model achieves more accurate classification with better generalization. Moreover, the proposed model can be embedded within the controller to define security rules to prevent possible attacks by the attackers.","['Support vector machines', 'Computer crime', 'Feature extraction', 'Genetic algorithms', 'Control systems', 'Machine learning']","['DDoS attack', 'GA', 'KPCA', 'N-RB', 'SDN', 'SVM']"
"The emergence of Internet connectivity has led to a significant increase in the volume and complexity of cyber attacks. Abnormal behavior detection systems are valuable tools for ensuring the security in computer networks. However, due to the huge amount and ever increasing diversity of the intrusions, the existing intrusion detection systems, which use machine learning techniques to learn a classifier based on a handcrafted feature vector, are not robust enough to detect sophisticated attacks which cause a high false alarm rate. Therefore, building a flexible in-depth defense system to detect abnormal behavior requires an ability to automatically learn powerful features and analyze large amounts of network traffic. To address these concerns, this paper proposes a novel distributed approach for the detection of abnormal behavior in largescale networks. The developed model discovers the abnormal behavior from large-scale network traffic data using a combination of a deep feature extraction and multi-layer ensemble support vector machines (SVMs) in a distributed way. First, we perform a non-linear dimensionality reduction, achieved through a distributed deep belief networks on large-scale network traffic data. Then, the obtained features are fed to the multi-layer ensemble SVM. The construction of the ensemble is accomplished through the iterative reduce paradigm based on Spark. Empirical results show a promising gain in performance compared with other existing models.","['Support vector machines', 'Feature extraction', 'Intrusion detection', 'Big Data', 'Distributed databases', 'Dimensionality reduction']","['Abnormal behavior detection', 'big data', 'deep belief networks', 'deep learning', 'ensemble classifier']"
"A multitude of cyber-physical system (CPS) applications, including design, control, diagnosis, prognostics, and a host of other problems, are predicated on the assumption of model availability. There are mainly two approaches to modeling: Physics/Equation based modeling (Model-Based, MB) and Machine Learning (ML). Recently, there is a growing consensus that ML methodologies relying on data need to be coupled with prior scientific knowledge (or physics, MB) for modeling CPS. We refer to the paradigm that combines MB approaches with ML as hybrid learning methods. Hybrid modeling (HB) methods is a growing field within both the ML and scientific communities, and are recognized as an important emerging but nascent area of research. Recently, several works have attempted to merge MB and ML models for the complete exploitation of their combined potential. However, the research literature is scattered and unorganized. So, we make a meticulous and systematic attempt at organizing and standardizing the methods of combining ML and MB models. In addition to that, we outline five metrics for the comprehensive evaluation of hybrid models. Finally, we conclude by shedding some light on the challenges of hybrid models, which we, as a research community, should focus on for harnessing the full potential of hybrid models. An additional feature of this survey is that the hybrid modeling work has been discussed with a focus on modeling cyber-physical systems.","['Mathematical model', 'Physics', 'Computational modeling', 'Machine learning', 'Data models', 'Cyber-physical systems', 'Sensors']","['Cyber-physical systems', 'deep learning', 'deep neural networks', 'hybrid models', 'model-based', 'machine learning', 'physics guided', 'physics informed', 'physics prior', 'theory guided']"
"The current thinking concerning computations required by Internet of Things (IoT) applications is shifting toward fog computing instead of cloud computing, thereby achieving most of the required computations at the network edge of the IoT devices. Fog computing can thus improve the quality of service of delay-sensitive applications by allowing such applications to take advantage of the low latency provided by fog computing rather than the high latency of the cloud. Therefore, tasks in various IoT applications must be effectively distributed over the fog nodes to improve the quality of service, specifically the task response time. In this paper, two nature-inspired meta-heuristic schedulers, namely ant colony optimization (ACO) and particle swarm optimization (PSO), are used to propose two different scheduling algorithms to effectively load balance IoT tasks over the fog nodes under communication cost and response time considerations. The experimental results of the proposed algorithms are compared with those of the round robin (RR) algorithm. The evaluations show that the proposed ACO-based scheduler achieves an improvement in the response times of IoT applications compared to the proposed PSO-based and RR algorithms and effectively load balances the fog nodes.","['Task analysis', 'Cloud computing', 'Edge computing', 'Time factors', 'Quality of service', 'Delays', 'Computer architecture']","['Fog computing', 'Internet of Things', 'quality of service', 'task offloading and scheduling']"
"Due to the more vigorous regulations on carbon gas emissions and fuel economy, Fuel cell electric vehicles (FCEV) are becoming more popular in the automobile industry. This paper presents a neural network-based maximum power point tracking (MPPT) controller for 1.26-kW proton exchange membrane fuel cell (PEMFC), supplying electric vehicle powertrain through a high voltage-gain dc-dc boost converter. The proposed neural network MPPT controller uses a radial basis function network (RBFN) algorithm for tracking the maximum power point of the PEMFC. High switching-frequency and high voltage-gain dc-dc converters are essential for the propulsion of FCEV. In order to attain high voltage-gain, a three-phase high voltage-gain interleaved boost converter is also designed for FCEV system. The interleaving technique reduces the input current ripple and voltage stress on the power semiconductor devices. The performance analysis of the FCEV system with RBFN-based MPPT controller is compared with the fuzzy logic controller in MATLAB/Simulink platform.","['Fuel cells', 'DC motors', 'Maximum power point trackers', 'Permanent magnet motors', 'Voltage control', 'Switches', 'Electric vehicles']","['Fuel cell electric vehicle', 'high voltage gain IBC', 'PEMFC', 'MPPT', 'RBFN']"
"Fault diagnosis is an important topic both in practice and research. There is intense pressure on industrial systems to continue reducing unscheduled downtime, performance degradation, and safety hazards, which requires detecting and recovering from potential faults as early as possible. From the historical perspective, this paper divides fault diagnosis into previous research and industrial big data era. According to primary drivers, this paper classifies fault diagnosis into knowledge-driven, data-driven, and value-driven methods. Among them, the former two approaches belong to the previous research on fault diagnosis. They mainly depend on expert experience and shallow models to detect and extract failures from relatively small size data. With the continuous exponential growth of data, it is insufficient to mine valuable fault information from massive multi-source heterogeneous data. The huge diagnostic value embodied in industrial big data has driven the emergence of the third category, which belongs to fault diagnosis based on big data. It consists of big data processing and analysis corresponding to high efficiency, cost effectiveness, and generality, which can deal well with problems that previous methods faced. We introduce the concept of a device electrocardiogram from the perspective of applicability to outline the present status of fault diagnosis for big data, and compare it with traditional diagnostic system. We also discuss issues and challenges that need to be further considered. It would be great valuable to integrate or explore more advanced diagnostic methods to handle collected industrial big data and put them into practice to mine the huge hidden diagnostic value.","['Fault diagnosis', 'Big Data', 'Data mining', 'Robustness', 'Signal processing', 'Feature extraction', 'Computational modeling']","['Fault diagnosis', 'industrial big data', 'value discovery', 'device electrocardiogram']"
"The rapid development of information technology has led to the development of medical informatization in the direction of intelligence. Medical health big data provides a basic data resource guarantee for medical service intelligence and smart healthcare. The classification of medical health big data is of great significance for the intelligentization of medical information. Due to the simplicity of KNN (K-Nearest Neighbor) classification algorithm, it has been widely used in many fields. However, when the sample size is large and the feature attributes are large, the efficiency of the KNN algorithm classification will be greatly reduced. This paper proposes an improved KNN algorithm and compares it with the traditional KNN algorithm. The classification is performed in the query instance neighborhood of the conventional KNN classifier, and weights are assigned to each class. The algorithm considers the class distribution around the query instance to ensure that the assigned weight does not adversely affect the outliers. Aiming at the shortcomings of traditional KNN algorithm in processing large data sets, this paper proposes an improved KNN algorithm based on cluster denoising and density cropping. The algorithm performs denoising processing by clustering, and improves the classification efficiency of KNN algorithm by speeding up the search speed of K-nearest neighbors, while maintaining the classification accuracy of KNN algorithm. The experimental results show that the proposed algorithm can effectively improve the classification efficiency of KNN algorithm in processing large data sets, and maintain the classification accuracy of KNN algorithm well, and has good classification performance.","['Classification algorithms', 'Big Data', 'Clustering algorithms', 'Training', 'Mathematical model', 'Medical services', 'Feature extraction']","['Improved KNN classifier', 'weighted KNN algorithm', 'cluster denoising', 'density cropping']"
"This paper investigated the multiple unmanned aerial vehicle (UAV) relays' assisted network in the Internet of Things (IoT) systems enhanced with energy harvesting in order to overcome the large-scale fading between source and sink as well as achieve the green cooperative communications, where time switch (TS) and power splitting (PS) strategies were typically applied for UAV relays to implement energy harvesting transmission, which was also selected via signal to noise ratio (SNR) maximization criterion so that the terminal node can obtain the optimal signal. Meanwhile, it was worth noting that the terminal node may be disturbed by aggregated interference caused by dense network signaling interaction in the future 5G/B5G systems. Therefore, after TS and PS protocols designing and utilizing, the closed-form expressions of outage probability and bit error rate (BER) for UAV relay assisted IoT systems suffered from aggregated interference were derived in detail. In addition, the throughput and delay limited state of UAV relay assisted transmission were also analyzed thoroughly. The derivations and analysis results showed that the proposed multi-parameter joint optimization of transmitting power, scaling factor, and UAV relay selection could effectively improve the system throughput and reduce the system outage probability and BER. The simulation experiments verified the effectiveness of the proposed schemes and the correctness of theoretical analysis.","['Relays', 'Energy harvesting', 'Protocols', 'Unmanned aerial vehicles', 'Interference', 'Throughput', 'Information processing']","['Unmanned aerial vehicles (UAV)', 'relay assisted', 'IoT', 'energy harvesting', 'protocol design', 'aggregate interference']"
"In order to improve the accuracy of bearings fault diagnosis, one of the most crucial components of rotating machinery, a novel features extraction procedure incorporating an improved features dimensionality reduction method is proposed. In the first step, using the empirical mode decomposition method, the original statistical characteristics were calculated from intrinsic mode functions of the vibration signal. Due to information redundancy of the original statistical characteristics, this paper presents a novel features extraction method that combines K-means method and standard deviation to select the most sensitive characteristics. Furthermore, a modified features dimensionality reduction method is proposed, to realize the low-dimensional representations for high-dimensional feature space. Finally, the performance of the fault diagnosis model is evaluated by vibration signals with 12 bearing fault conditions, which are provided by Bearing Data Center of Case Western Reserve University. Experiment results show that the proposed fault diagnosis model can serve as an effective and adaptive bearing fault diagnosis system.","['Feature extraction', 'Fault diagnosis', 'Vibrations', 'Rolling bearings', 'Machinery', 'Time-frequency analysis']","['Fault diagnosis', 'features extraction', 'features reduction', 'sensitive features']"
"Unmanned Aerial Vehicles (UAVs) have become increasingly important in assisting 5G and beyond 5G (B5G) mobile networks. Indeed, UAVs have all the potentials to both satisfy the ever-increasing mobile data demands of such mobile networks and provide ubiquitous connectivity to different kinds of wireless devices. However, the UAV assistance paradigm faces a set of crucial issues and challenges. For example, the network management of current UAV-assisted systems is time consuming, complicated, and carried out manually, thus causing a multitude of interoperability issues. To efficiently address all these issues, Software-Defined Network (SDN) and Network Function Virtualization (NFV) are two promising technologies to efficiently manage and improve the UAV assistance for the next generation of mobile networks. In the literature, no clear guidelines are describing the different use cases of SDN and NFV in the context of UAV assistance to terrestrial networks, including mobile networks. Motivated by this fact, in this survey, we guide the reader through a comprehensive discussion of the main characteristics of SDN and NFV technologies. Moreover, we provide a thorough analysis of the different classifications, use cases, and challenges related to UAV-assisted systems. We then discuss SDN/NFV-enabled UAV-assisted systems, along with several case studies and issues, such as the involvement of UAVs in cellular communications, monitoring, and routing, to name a few. We furthermore present a set of open research challenges, high-level insights, and future research directions related to UAV-assisted systems.","['Unmanned aerial vehicles', '5G mobile communication', 'Security', 'Wireless communication', 'Routing protocols', 'Routing', 'Cellular networks']","['UAV', 'SDN', 'NFV', '5G', 'B5G', 'Cellular networks']"
"Cognitive radio (CR)-based Internet of Things (IoT) system is an effective step toward a world of smart technology. Many frameworks have been proposed to build CR-based IoT systems. The CR-based IoT frameworks are the key points on which this survey focuses. Efficient spectrum sensing and sharing are the main functional components of the CR-based IoT. Reviews of recent SS and sharing approaches are presented in this survey. This survey classifies the SS and sharing approaches and discusses the merits and limitations of those approaches. Moreover, this survey discusses the design factors of the CR-based IoT and the criteria by which the proper SS and access approaches are selected. Furthermore, the survey explores the integration of newly emerging technologies with the CR-based IoT systems. Finally, the survey highlights some emerging challenges and concludes with suggesting future research directions and open issues.","['Internet of Things', 'Sensors', 'Interference', 'Wireless sensor networks', 'Media Access Protocol', 'Cognitive radio']","['Cognitive radio', 'spectrum sensing', 'IoT', 'MAC', 'spectrum accessing', 'spectrum sharing', 'spectrum management', 'security', 'data privacy', 'blockchain', 'machine learning']"
"This paper reports the latest technological advances made by the Industrial Technology Research Institute (ITRI) in flexible displays, especially the flexible substrate, thin-film transistor (TFT) backplane, and active matrix organic light-emitting diode display. Using the leading cholesteric liquid crystal technology of ITRI, we develop a rewritable, environmentally friendly thermal printable e-paper. The epaper, devised to reduce traditional paper consumption, achieves a high resolution of 300 dpi with a memory function. In addition, we report on the ITRI's initial success in demonstrating a complete R2R process for multisensing touch panels on 100-μm thick flexible glass substrates provided by Corning.","['Active matrix organic light emitting diodes', 'Substrates', 'Thin film transistors', 'Light emitting diodes', 'Thermal stability', 'Consumer electronics', 'Organic light emitting diodes', 'Flexible structures', 'Glass']","['Active matrix organic light-emitting diode display (AMOLED)', 'cholesteric liquid crystal (ChLC)', 'flexible substrate', 'roll-to-roll process', 'ultrathin flexible glass']"
"Smart health care is an important aspect of connected living. Health care is one of the basic pillars of human need, and smart health care is projected to produce several billion dollars in revenue in the near future. There are several components of smart health care, including the Internet of Things (IoT), the Internet of Medical Things (IoMT), medical sensors, artificial intelligence (AI), edge computing, cloud computing, and next-generation wireless communication technology. Many papers in the literature deal with smart health care or health care in general. Here, we present a comprehensive survey of IoT- and IoMT-based edge-intelligent smart health care, mainly focusing on journal articles published between 2014 and 2020. We survey this literature by answering several research areas on IoT and IoMT, AI, edge and cloud computing, security, and medical signals fusion. We also address current research challenges and offer some future research directions.","['Medical services', 'Medical diagnostic imaging', 'Smart healthcare', 'Internet of Things', 'Electroencephalography', 'Intelligent sensors', 'Feature extraction']","['Internet of Things (IoT)', 'Internet of Medical Things (IoMT)', 'edge computing', 'cloud computing', 'medical signals', 'smart health care', 'artificial intelligence']"
"Multilevel Inverters (MLIs) are becoming more and more popular in medium and high power applications. This is due to several inherent advantages of MLI over two-level inverters such as high-quality output, lower device ratings, and several others. While the classical topologies are still having applications in most of the key areas, there is a growing interest in newer multilevel topologies with an objective of reducing power semiconductor device count, gate drivers and/or isolated DC sources. In this paper, a comprehensive review of some of the recently proposed newer multilevel inverter topologies with the abovementioned objectives is presented. In this article, a detailed investigation in terms of total power semiconductor switch count, number of DC sources, passive component requirement, highest switch voltage rating, total standing voltage etc. has been presented.","['Topology', 'Inverters', 'Switches', 'Voltage control', 'Power quality', 'Generators']","['Multilevel inverters', 'reduced switch count', 'fundamental switching', 'H-bridge', 'even power distribution', 'symmetric source', 'asymmetric source']"
"A number of algorithms in the field of artificial intelligence offer poorly interpretable decisions. To disclose the reasoning behind such algorithms, their output can be explained by means of so-called evidence-based (or factual) explanations. Alternatively, contrastive and counterfactual explanations justify why the output of the algorithms is not any different and how it could be changed, respectively. It is of crucial importance to bridge the gap between theoretical approaches to contrastive and counterfactual explanation and the corresponding computational frameworks. In this work we conduct a systematic literature review which provides readers with a thorough and reproducible analysis of the interdisciplinary research field under study. We first examine theoretical foundations of contrastive and counterfactual accounts of explanation. Then, we report the state-of-the-art computational frameworks for contrastive and counterfactual explanation generation. In addition, we analyze how grounded such frameworks are on the insights from the inspected theoretical approaches. As a result, we highlight a variety of properties of the approaches under study and reveal a number of shortcomings thereof. Moreover, we define a taxonomy regarding both theoretical and practical approaches to contrastive and counterfactual explanation.","['Cognition', 'Artificial intelligence', 'Training', 'Terminology', 'Taxonomy', 'Systematics', 'Signal to noise ratio']","['Computational intelligence', 'contrastive explanations', 'counterfactuals', 'explainable artificial intelligence', 'systematic literature review']"
"With the emergence of smart grid (SG), the consumers have the opportunity to integrate renewable energy sources (RESs) and take part in demand side management. In this paper, we introduce generic home energy management control system (HEMCS) to efficiently schedule the household load and integrate RESs. The HEMCS is based on the genetic algorithm, binary particle swarm optimization, winddriven optimization (WDO), and our proposed genetic WDO algorithm to schedule appliances of single and multiple homes. For energy cost calculation, real-time pricing (RTP) and inclined block rate schemes are combined, because in case of only RTP, there is a possibility of building peaks during off-peak hours that may damage the entire power system. Moreover, to control the demand under the grid station capacity, the feasible region is defined and a problem is formulated using multiple knapsack. Energy efficient integration of RESs in SG is a challenging task due to time varying and their intermittent nature. The simulation results show that the proposed scheme avoids voltage rise problem in areas with high penetration of renewable energy. Moreover, the proposed scheme also reduces the electricity cost up to 48% and peak to average ratio of aggregated load up to 37.69%.","['Home appliances', 'Schedules', 'Peak to average power ratio', 'Energy consumption', 'Energy exchange', 'Renewable energy sources']","['Renewable energy sources', 'demand side management', 'load scheduling', 'meta-heuristic techniques', 'trading/cooperation']"
"Due to the explosion of available information on the Internet, the need for effective means of accessing and processing them has become vital for everyone. Recommender systems have been developed to help users to find what they may be interested in and business owners to sell their products more efficiently. They have found much attention in both academia and industry. A recommender algorithm takes into account user–item interactions, i.e., rating (or purchase) history of users on items, and their contextual information, if available. It then provides a list of potential items for each target user, such that the user is likely to positively rate (or purchase) them. In this paper, we review evaluation metrics used to assess performance of recommendation algorithms. We also survey a number of classical and modern recommendation algorithms and compare their performance in terms of different evaluation metrics on five benchmark datasets. Our experiments show that there is no golden recommendation algorithm showing the best performance in all evaluation metrics. We also find large variability across the datasets. This indicates that one should carefully consider the evaluation criteria in choosing a recommendation algorithm for a particular application.","['Measurement', 'Collaboration', 'Prediction algorithms', 'Motion pictures', 'History', 'Recommender systems']","['Recommender systems', 'collaborative filtering', 'evaluation metrics', 'precision', 'ranking', 'diversity']"
"Long short-term memory fully convolutional neural networks (LSTM-FCNs) and Attention LSTM-FCN (ALSTM-FCN) have shown to achieve the state-of-the-art performance on the task of classifying time series signals on the old University of California-Riverside (UCR) time series repository. However, there has been no study on why LSTM-FCN and ALSTM-FCN perform well. In this paper, we perform a series of ablation tests (3627 experiments) on the LSTM-FCN and ALSTM-FCN to provide a better understanding of the model and each of its sub-modules. The results from the ablation tests on the ALSTM-FCN and LSTM-FCN show that the LSTM and the FCN blocks perform better when applied in a conjoined manner. Two z-normalizing techniques, z-normalizing each sample independently and z-normalizing the whole dataset, are compared using a Wilcoxson signed-rank test to show a statistical difference in performance. In addition, we provide an understanding of the impact dimension shuffle that has on LSTM-FCN by comparing its performance with LSTM-FCN when no dimension shuffle is applied. Finally, we demonstrate the performance of the LSTM-FCN when the LSTM block is replaced by a gated recurrent unit (GRU), basic neural network (RNN), and dense block.","['Time series analysis', 'Logic gates', 'Convolution', 'Computational modeling', 'Recurrent neural networks', 'Data models', 'Deep learning']","['Convolutional neural network', 'long short term memory recurrent neural network', 'time series classification']"
"In this paper, we propose a novel method to identify the presence of malaria parasites in human peripheral blood smear images using a deep belief network (DBN). This paper introduces a trained model based on a DBN to classify 4100 peripheral blood smear images into the parasite or non-parasite class. The proposed DBN is pre-trained by stacking restricted Boltzmann machines using the contrastive divergence method for pre-training. To train the DBN, we extract features from the images and initialize the visible variables of the DBN. A concatenated feature of color and texture is used as a feature vector in this paper. Finally, the DBN is discriminatively fine-tuned using a backpropagation algorithm that computes the probability of class labels. The optimum size of the DBN architecture used in this paper is 484-600-600-600-600-2, in which the visible layer has 484 nodes and the output layer has two nodes with four hidden layers containing 600 hidden nodes in every layer. The proposed method has performed significantly better than the other state-of-the-art methods with an F-score of 89.66%, a sensitivity of 97.60%, and specificity of 95.92%. This paper is the first application of a DBN for malaria parasite detection in human peripheral blood smear images.","['Diseases', 'Blood', 'Computer architecture', 'Feature extraction', 'Image color analysis', 'Training', 'Microscopy']","['Deep learning', 'deep belief network', 'malaria parasite detection', 'restricted Boltzmann machine', 'contrastive divergence', 'discriminative training']"
"This paper presents an overview of the cloud radio access network (C-RAN), which is a key enabler for future mobile networks in order to meet the explosive capacity demand of mobile traffic, and reduce the capital and operating expenditure burden faced by operators. We start by reviewing the requirements of future mobile networks, called 5G, followed by a discussion on emerging network concepts for 5G network architecture. Then, an overview of C-RAN and related works are presented. As a significant scenario of a 5G system, the ultra dense network deployment based on C-RAN is discussed with focuses on flexible backhauling, automated network organization, and advanced mobility management. Another import feature of a 5G system is the long-term coexistence of multiple radio access technologies (multi-RATs). Therefore, we present some directions and preliminary thoughts for future C-RAN-supporting Multi-RATs, including joint resource allocation, mobility management, as well as traffic steering and service mapping.","['Mobile communication', 'Next generation networking', 'Cloud computing', 'Radio communication', 'Radio access networks', 'Mobile radio mobility management', 'Resource management', 'Cellular networks']","['5G', 'C-RAN', 'UDN', 'Multi-RATs']"
"We propose a reservoir computing device utilizing spin waves that propagate in a garnet film equipped with multiple input/output electrodes. In recent years, reservoir computing has been expected to realize energy-efficient and/or high-speed machine learning. Our proposed device enhances such significant merits in a hardware approach. It utilizes the nonlinear interference of history-dependent asymmetrically propagating spin waves excited by the magneto-electric effect. First, we investigate a feasible device structure with practical physical parameters in micromagnetic numerical analysis, and show the detailed characteristics of the forward volume magnetostatic spin waves. Then, we demonstrate high generalization ability in the estimation of input-signal parameters performed by the spin-wave-based reservoir computing. We find that the hysteresis characteristics of the spin waves propagating asymmetrically with respect to excitation points, as well as the nonlinear interference, works advantageously to realize high diversity in the time-sequential signals in high-dimensional information space, which has the highest significance for effective learning in reservoir computing. The spin wave device is highly promising for next-generation machine-learning electronics.","['Reservoirs', 'Garnet films', 'Electrodes', 'Interference', 'Magnetic anisotropy', 'Magnetomechanical effects', 'Detectors']","['Learning device', 'physical reservoir computing', 'spin wave']"
"Globally, the recommendation services have become important due to the fact that they support e-commerce applications and different research communities. Recommender systems have a large number of applications in many fields, including economic, education, and scientific research. Different empirical studies have shown that the recommender systems are more effective and reliable than the keyword-based search engines for extracting useful knowledge from massive amounts of data. The problem of recommending similar scientific articles in scientific community is called scientific paper recommendation. Scientific paper recommendation aims to recommend new articles or classical articles that match researchers' interests. It has become an attractive area of study since the number of scholarly papers increases exponentially. In this paper, we first introduce the importance and advantages of the paper recommender systems. Second, we review the recommendation algorithms and methods, such as Content-based, collaborative filtering, graph-based, and hybrid methods. Then, we introduce the evaluation methods of different recommender systems. Finally, we summarize the open issues in the paper recommender systems, including cold start, sparsity, scalability, privacy, serendipity, and unified scholarly data standards. The purpose of this survey is to provide comprehensive reviews on the scholarly paper recommendation.","['Recommender systems', 'Computational modeling', 'Collaboration', 'Libraries', 'Education', 'Search engines']","['Recommender systems', 'scientific paper recommendation', 'recommendation algorithms']"
"The electronic voting has emerged over time as a replacement to the paper-based voting to reduce the redundancies and inconsistencies. The historical perspective presented in the last two decades suggests that it has not been so successful due to the security and privacy flaws observed over time. This paper suggests a framework by using effective hashing techniques to ensure the security of the data. The concept of block creation and block sealing is introduced in this paper. The introduction of a block sealing concept helps in making the blockchain adjustable to meet the need of the polling process. The use of consortium blockchain is suggested, which ensures that the blockchain is owned by a governing body (e.g., election commission), and no unauthorized access can be made from outside. The framework proposed in this paper discusses the effectiveness of the polling process, hashing algorithms' utility, block creation and sealing, data accumulation, and result declaration by using the adjustable blockchain method. This paper claims to apprehend the security and data management challenges in blockchain and provides an improved manifestation of the electronic voting process.","['Blockchain', 'Electronic voting', 'Security', 'Privacy', 'Software']","['Electronic voting', 'blockchain voting', 'i-voting', 'e-voting', 'blockchain Pakistan', 'future voting']"
"In order to overcome the difficulty of password management and improve the usability of authentication systems, biometric authentication has been widely studied and has attracted special attention in both academia and industry. Many biometric authentication systems have been researched and developed, especially for mobile devices. However, the existing biometric authentication systems still have defects. Some biological features have not been deeply investigated. The existing systems could be vulnerable to attacks, such as replay attack and suffer from user privacy intrusion, which seriously hinder their wide acceptance by end users. The literature still lacks a thorough review on the recent advances of biometric authentication for the purpose of secure and privacy-preserving identification. In this paper, we classify and thoroughly review the existing biometric authentication systems by focusing on the security and privacy solutions. We analyze the threats of biometric authentication and propose a number of criteria with regard to secure and privacy-preserving authentication. We further review the existing works of biometric authentication by analyzing their differences and summarizing the advantages and disadvantages of each based on the proposed criteria. In particular, we discuss the problems of aliveness detection and privacy protection in biometric authentication. Based on our survey, we figure out a number of open research issues and further specify a number of significant research directions that are worth special efforts in future research.","['Authentication', 'Privacy', 'Biology', 'Iris recognition', 'Password', 'Sensors']","['Aliveness detection', 'biometric authentication', 'password management', 'privacy protection']"
"Effective signal processing methods are essential for machinery fault diagnosis. Most conventional signal processing methods lack adaptability, thus being unable to well extract the embedded meaningful information. Adaptive mode decomposition methods have excellent adaptability and high flexibility in describing arbitrary complicated signals, and are free from the limitations imposed by conventional basis expansion, thus being able to adapt to the signal characteristics, extract rich characteristic information, and therefore reveal the underlying physical nature. This paper presents a systematic and up-to-date review on adaptive mode decomposition in two major topics, i.e., mono-component decomposition algorithms (such as empirical mode composition, local mean decomposition, intrinsic time-scale decomposition, local characteristic scale decomposition, Hilbert vibration decomposition, empirical wavelet transform, variational mode decomposition, nonlinear mode decomposition, and adaptive local iterative filtering) and instantaneous frequency estimation approaches (including Hilbert-transform-based analytic signal, direct quadrature, and normalized Hilbert transform based on empirical AM-FM decomposition, as well as generalized zero-crossing and energy separation) reported in more than 80 representative articles published since 1998. Their fundamental principles, advantages and disadvantages, and applications to signal analysis in machinery fault diagnosis, are examined. Examples are provided to illustrate their performance.","['Fault diagnosis', 'Machinery', 'Frequency estimation', 'Time-frequency analysis', 'Transforms', 'Feature extraction']","['Adaptive mode decomposition', 'mono-component', 'instantaneous frequency', 'time-frequency representation', 'fault diagnosis']"
"At present times, the real-time requirement on the multiaccess healthcare monitoring system, information mining, and efficient disease diagnosis of health conditions is a difficult process. The recent advances in information technology and the internet of medical things (IoMT) have fostered extensive utilization of the smart system. A complex, 24/7 healthcare service is needed for effective and trustworthy monitoring of patients on a daily basis. To accomplish this need, edge computing and cloud platforms are highly required to satisfy the requirements of smart healthcare systems. This paper presents a new effective training scheme for the deep neural network (DNN), called ETS-DNN model in edge computing enabled IoMT system. The proposed ETS-DNN intends to facilitate timely data collection and processing to make timely decisions using the patterns that exist in the data. Initially, the IoMT devices sense the patient's data and transfer the captured data to edge computing, which executes the ETS-DNN model to diagnose it. The proposed ETS-DNN model incorporates a Hybrid Modified Water Wave Optimization (HMWWO) technique to tune the parameters of the DNN structure, which comprises of several autoencoder layers cascaded to a softmax (SM) layer. The SM classification layer is placed at the end of the DNN to perform the classification task. The HMWWO algorithm integrates the MWWO technique with limited memory Broyden-Fletcher-Goldfarb-Shannon (L-BFGS). Once the ETS-DNN model generates the report in edge computing, then it will be sent to the cloud server, which is then forwarded to the healthcare professionals, hospital database, and concerned patients. The proposed ETS-DNN model intends to facilitate timely data collection and processing to identify the patterns exist in the data. An extensive set of experimental analysis takes place and the results are investigated under several aspects. The simulation outcome pointed out the superior characteristics of the ETS-DNN model over the compared methods.","['Medical services', 'Edge computing', 'Computational modeling', 'Medical diagnostic imaging', 'Monitoring', 'Cloud computing', 'Training']","['Deep neural network', 'Internet of Medical Things', 'edge computing', 'training scheme', 'healthcare', 'optimization']"
"The arrangement of nodes impacts the quality of connectivity and energy consumption in wireless sensor network (WSN) for prolonging the lifetime. This paper presents an improved flower pollination algorithm based on a hybrid of the parallel and compact techniques for global optimizations and a layout of nodes in WSN. The parallel enhances diversity pollinations for exploring in space search and sharing computation load. The compact can save storing variables for computation in the optimization process. In the experimental section, the selected test functions and the network topology issue WSN are used to test the performance of the proposed approach. Compared results with the other methods in the literature show that the proposed algorithm achieves the practical way of reducing the number of its stored memory variables and running times.","['Wireless sensor networks', 'Optimization', 'Layout', 'Linear programming', 'Probabilistic logic', 'Sociology', 'Statistics']","['Improved flower pollination algorithm', 'layout optimization problems', 'probabilistic model', 'wireless sensor network']"
"A large number of new consumer and industrial applications are likely to change the classic operator’s business models and provide a wide range of new markets to enter. This paper analyzes the most relevant 5G use cases that require ultra-low latency, from both technical and business perspectives. Low latency services pose challenging requirements to the network, and to fulfill them, operators need to invest in costly changes in their network. In this sense, it is not clear whether such investments are going to be amortized with these new business models. In light of this, specific applications and requirements are described and the potential market benefits for operators are analyzed. Conclusions show that the operators have clear opportunities to add value and position themselves strongly with the increasing number of services to be provided by 5G.","['Industries', '5G mobile communication', 'Telecommunications', 'Medical services', 'Market research']","['Market drivers', 'use cases', 'business models', 'low latency', 'tactile internet']"
"Data-driven fault diagnosis has been a hot topic in recent years with the development of machine learning techniques. However, the prerequisite that the training data and the test data should follow an identical distribution prevents the conventional data-driven diagnosis methods from being applied to the engineering diagnosis problems. To tackle this dilemma, cross-domain fault diagnosis using knowledge transfer strategy is becoming popular in the past five years. The diagnosis methods based on transfer learning aim to build models that can perform well on target tasks by leveraging knowledge from semantic related but distribution different source domains. This paper for the first time summarizes the state-of-art cross-domain fault diagnosis research works. The literatures are introduced from three different viewpoints: research motivations, cross-domain strategies, and application objects. In addition, the corresponding open-source fault datasets and several future directions are also presented. The survey provides readers a framework for better understanding and identifying the research status, challenges and future directions of cross-domain fault diagnosis.","['Fault diagnosis', 'Task analysis', 'Neural networks', 'Support vector machines', 'Kernel', 'Data models', 'Feature extraction']","['Cross-domain', 'domain adaptation', 'fault diagnosis', 'review', 'transfer learning']"
"This paper presents a wearable inertial sensor network and its associated activity recognition algorithm for accurately recognizing human daily and sport activities. The proposed wearable inertial sensor network is composed of two wearable inertial sensing devices, which comprise a microcontroller, a triaxial accelerometer, a triaxial gyroscope, an RF wireless transmission module, and a power supply circuit. The activity recognition algorithm, consisting of procedures of motion signal acquisition, signal preprocessing, dynamic human motion detection, signal normalization, feature extraction, feature normalization, feature reduction, and activity recognition, has been developed to recognize human daily and sport activities by using accelerations and angular velocities. In order to reduce the computational complexity and improve the recognition rate simultaneously, we have utilized the nonparametric weighted feature extraction algorithm with the principal component analysis method for reducing the feature dimensions of inertial signals. All 23 participants wore the wearable sensor network on their wrist and ankle to execute 10 common domestic activities in human daily lives and 11 sport activities in a laboratory environment, and their activity recordings were collected to validate the effectiveness of the proposed wearable inertial sensor network and activity recognition algorithm. Experimental results showed that our approach could achieve recognition rates for the 10 common domestic activities of 98.23% and 11 sport activities of 99.55% by the 10-fold cross-validation strategy, which have successfully validated the effectiveness of the proposed wearable inertial sensor network and its activity recognition algorithm.","['Feature extraction', 'Activity recognition', 'Heuristic algorithms', 'Accelerometers', 'Principal component analysis']","['Wearable inertial sensing device', 'body sensor network', 'daily activity recognition', 'sport activity recognition', 'nonparametric weighted feature extraction', 'support vector machine']"
"Anomaly detection has a wide range of applications in security area such as network monitoring and smart city/campus construction. It has become an active research issue of great concern in recent years. However, most algorithms of the existing studies are powerless for large-scale and high-dimensional data, and the intermediate data extracted by some methods that can handle high-dimensional data will consume lots of storage space. In this paper, we propose a novel sparse representation framework that learns dictionaries based on the latent space of variational auto-encoder. For large-scale data sets, it can play the role of dimensionality reduction to obtain hidden information, and extract more high-level features than hand-crafted features. At the same time, for the storage of normal information, the space cost can be greatly reduced. To verify the versatility and performance of the proposed learning algorithm, we have experimented on different types of anomaly detection tasks, including KDD-CUP data set for network intrusion detection, Mnist data set for image anomaly detection, and UCSD pedestrian's data set for abnormal event detection in surveillance videos. The experimental results demonstrate that the proposed algorithm outperforms competing algorithms in all kinds of anomaly detection tasks.","['Anomaly detection', 'Feature extraction', 'Machine learning', 'Dictionaries', 'Data models', 'Monitoring']","['Anomaly detection', 'campus surveillance video', 'dictionary learning']"
"Achieving accurate and reliable remaining useful life (RUL) prediction of lithium-ion batteries is very vital for the normal operation of the battery system. The direct RUL prediction based on capacity largely depends on the laboratory condition. A novel method that combines indirect health indicator (HI) and multiple Gaussian process regression (GPR) model is presented for the RUL forecast to solve the capacity unmeasurable problem of operating battery in this paper. First, three measurable HIs are extracted in the constant-current and constant-voltage charge process. Both the Pearson and Spearman rank correlation analytical approaches show that the correlations between HIs and the capacity are good. Then, the GPR model is optimized with combined kernel functions to improve the ability to predict capacity regeneration. Next, based on the measurable HI versus cycle number data, three GPR models are built, and HIs prognosis results are achieved at a single point. The HIs prediction results are added in the multidimensional GPR model, which is accomplished by using HIs and capacity as input and output, respectively. The predicted capacity is used to compare with the threshold to acquire the RUL prediction result. The approach is validated by the two different life-cycle test datasets. The results indicate that an accurate and reliable RUL forecast of lithium-ion batteries can be realized by using the proposed approach.","['Predictive models', 'Lithium-ion batteries', 'Discharges (electric)', 'Ground penetrating radar', 'Current measurement', 'Degradation']","['Remaining useful life', 'lithium-ion battery', 'health indicator', 'Gaussian process regression']"
"Virtual inertia emulation could be regarded as an inevitable component of microgrids with renewable energy, enhancing microgrid inertia and damping properties. In applying this control technique, a phase-locked loop (PLL) is necessary to obtain the estimation of the system frequency data. However, the employment of PLL could cause larger frequency oscillation to the microgrid due to its dynamics. This issue would be exacerbated in a low-inertia microgrid driven by high renewable penetration, severely deteriorating the frequency stability. Thus, the effect of PLL with measurement delay is a critical issue in utilizing the virtual inertia control. To overcome such problem, this paper proposes a robust virtual inertia control for a low-inertia microgrid to minimize the undesirable frequency measurement effects, improving the microgrid frequency stability. The robust H ∞ control design using a linear fractional transformation (LFT) technique is used to develop the virtual inertia control loop, considering the dynamics of PLL with measurement delay and the uncertainties of system inertia and damping. The efficacy of the proposed H ∞ control method is compared to the conventional and optimum proportional-integral (PI)based inertia control. The results show that the H ∞ -based robust virtual inertia control is superior to both conventional virtual inertia control and optimum PI-based virtual inertia control against a wide range of microgrid operating conditions, disturbances, and parametric uncertainties.","['Microgrids', 'Phase locked loops', 'Frequency measurement', 'Frequency control', 'Power system stability', 'Uncertainty', 'Delays']","['Frequency stability', 'H∞ control', 'inertia control', 'microgrid', 'renewable energy', 'virtual synchronous generator']"
"The Blockchain technology, featured with its decentralized tamper-resistance based on a Peer-to-Peer network, has been widely applied in financial applications, and even further been extended to industrial applications. However, the weak scalability of traditional Blockchain technology severely affects the wide adoption due to the well-known trillema of decentralization-security-scalability in Blockchains. In regards to this issue, a number of solutions have been proposed, targeting to boost the scalability while preserving the decentralization and security. They range from modifying the on-chain data structure and consensus algorithms to adding the off-chain technologies. Therein, one of the most practical methods to achieve horizontal scalability along with the increasing network size is sharding, by partitioning network into multiple shards so that the overhead of duplicating communication, storage, and computation in each full node can be avoided. This paper presents a survey focusing on sharding in Blockchains in a systematic and comprehensive way. We provide detailed comparison and quantitative evaluation of major sharding mechanisms, along with our insights analyzing the features and restrictions of the existing solutions. We also provide theoretical upper-bound of the throughput for each considered sharding mechanism. The remaining challenges and future research directions are also reviewed.","['Blockchain', 'Throughput', 'Scalability', 'Australia', 'Bitcoin', 'Systematics']","['Blockchain', 'scalability', 'throughput', 'scale-out mechanism', 'sharding', 'survey']"
"Leakage detection and localization in pipelines has become an important aspect of water management systems. Since monitoring leakage in large-scale water distribution networks (WDNs) is a challenging task, the need to develop a reliable and robust leak detection and localization technique is essential for loss reduction in potable WDNs. In this paper, some of the existing techniques for water leakage detection are discussed and open research areas and challenges are highlighted. It is concluded that despite the numerous research efforts and advancement in leakage detection technologies, a large scope is still open for further research in this domain. One such area is the effective detection of background type leakages that have not been covered fully in the literature. The utilization of wireless sensor networks for leakage detection purposes, its technical challenges as well as some future research areas are also presented. In a general remark, practical application of these techniques for large-scale water distribution networks is still a major concern. In this paper, an overview of this important problem is addressed.","['Pipelines', 'Optical fibers', 'Ground penetrating radar', 'Water resources', 'Temperature sensors', 'Temperature measurement']","['Leakage detection', 'leakage localization', 'pipeline', 'water distribution network', 'wireless sensor network']"
"The feasibility and popularity of mobile healthcare are currently increasing. The advancement of modern technologies, such as wireless communication, data processing, the Internet of Things, cloud, and edge computing, makes mobile healthcare simpler than before. In addition, the deep learning approach brings a revolution in the machine learning domain. In this paper, we investigate a voice pathology detection system using deep learning on the mobile healthcare framework. A mobile multimedia healthcare framework is also designed. In the voice pathology detection system, voices are captured using smart mobile devices. Voice signals are processed before being fed to a convolutional neural network (CNN). We use a transfer learning technique to use the existing robust CNN models. In particular, the VGG-16 and CaffeNet models are investigated in the paper. The Saarbrucken voice disorder database is used in the experiments. Experimental results show that the voice pathology detection accuracy reaches up to 97.5% using the transfer learning of CNN models.","['Pathology', 'Medical services', 'Databases', 'Cloud computing', 'Machine learning', 'Feature extraction', 'Servers']","['Mobile multimedia healthcare', 'voice pathology detection', 'deep learning', 'Saarbrucken voice database']"
"Widespread proliferation of wireless coverage has enabled culmination of number of advanced location-based services (LBS). Continuous tracking of accurate physical location is the foundation of these services, which is a challenging task especially indoors. Multitude of techniques and algorithms have been proposed for indoor positioning systems (IPS's). However, accuracy, reliability, scalability and, adaptability to the environment still remain as challenges for widespread deployment. Especially, unpredictable radio propagation characteristics in vastly varying indoor environments plus access technology limitations contribute to these challenges. Machine learning (ML) approaches have been widely attempted recently to overcome these challenges with reasonable success. In this paper, we aim to provide a comprehensive survey of ML enabled localization techniques using most common wireless technologies. First, we provide a brief background on indoor localization techniques. Afterwards, we discuss various ML techniques (supervised and unsupervised) that could alleviate different challenges in indoor localization including Non-line-of-sight (NLOS) issue, device heterogeneity and environmental variations with reasonable complexity. The trade-offs among multitude of issues are discussed using numerous published results. We also discuss how the ML algorithms can be effectively used for fusing different technologies and algorithms to achieve a comprehensive IPS. In essence, this survey will serve as a reference material to acquire a detailed knowledge on recent development of machine learning for accurate indoor positioning.","['Distance measurement', 'IP networks', 'Synchronization', 'Antenna arrays', 'Maximum likelihood estimation', 'Wireless communication', 'Time difference of arrival']","['Indoor positioning system (IPS)', 'location-based services (LBS)', 'machine learning (ML)', 'non-line-of-sight (NLOS)', 'wireless positioning', 'indoor tracking']"
"The use of Unmanned Aerial Vehicles (UAVs) for wireless networks is rapidly growing as key enablers of new applications, including: surveillance and monitoring, military, delivery of medical supplies, telecommunications, etc. In particular, due to their unique proprieties such as flexibility, mobility, and adaptive altitude, UAVs can act as mobile base stations to improve capacity, coverage, and energy efficiency of wireless networks. On the other hand, UAVs can operate as mobile terminals to enable many applications such as item delivery and real-time video streaming. In such context, data-driven Deep Learning-assisted (DL) approaches are gaining a growing interest to not only exploit the huge amount of generated data, but also to optimize the network operations, and hence ensure the QoS requirements of these emerging wireless networks. However, UAVs are resource-constrained devices especially in terms of computing and power resources, and traditional DL-assisted schemes are cloud-centric, which require UAVs' data to be sent and stored in a centralized server. This represents a critical issue since it generates a huge network communication overhead to send raw data towards the centralized entity, and hence may lead to network bandwidth and energy inefficiency of UAV devices. In addition, the transferred data may contain personnel data such as UAVs' localization and identity, which can directly affect UAVs' privacy concerns. As a solution, Federated Deep Learning (FDL), or distributed DL, was introduced, where the basic idea is to keep raw data where it is generated, while sending only users' local trained DL models to the centralized entity for aggregation. Due to its privacy-preserving and low communication overhead and latency, FDL is much more adequate for many UAVs-enabled wireless applications. In this work, we provide a general introduction of FDL application for UAV-enabled wireless networks. We first introduce the FDL concept and its fundamentals. Then, we highlight the possible applications of FDL in UAVs-enabled wireless networks by addressing the suitability and how to use FDL to deal with target challenges. Finally, we discuss about key technical challenges, open issues, and future research directions on FDL-based approaches in such context.","['Wireless networks', 'Data models', 'Deep learning', 'Servers', 'Solid modeling', 'Wireless sensor networks']","['Deep learning', 'federated deep learning', 'UAVs-based wireless networks', 'wireless communications']"
"In the context of Industry 4.0, it is necessary to meet customization manufacturing demands on a timely basis. Based on the related concepts of Industry 4.0, this paper intends to introduce mobile services and cloud computing technology into the intelligent manufacturing environment. A customization manufacturing system is designed to meet the demands of personalization requests and flexible production mechanisms. This system consists of three layers, namely, a manufacturing device layer, cloud service system layer, and mobile service layer. The manufacturing device layer forms the production platform. This platform is composed of a number of physical devices, such as a flexible conveyor belt, industrial robots, and corresponding sensors. The physical devices are connected to the cloud via the support of a wireless module. In the cloud, the manufacturing big data are processed, and the optimization decision-making mechanism pertaining to customization manufacturing is formed. Then, mobile services running in a mobile terminal are used to receive orders from customers and to inquire the necessary production information. To verify the feasibility of the proposed customization manufacturing system, we also established a customizable candy production system.","['Mobile communication', 'Cloud computing', 'Phase change materials', 'Internet of things', 'Manufacturing systems']","['Mobile services', 'Industry 4.0', 'cloud computing', 'intelligent manufacturing', 'Internet of Things']"
"To fully unleash the potentials of quantum computing, several new challenges and open problems need to be addressed. From a routing perspective, the optimal routing problem, i.e., the problem of jointly designing a routing protocol and a route metric assuring the discovery of the route providing the highest quantum communication opportunities between an arbitrary couple of quantum devices, is crucial. In this paper, the optimal routing problem is addressed for generic quantum network architectures composed by repeaters operating through single atoms in optical cavities. Specifically, we first model the entanglement generation through a stochastic framework that allows us to jointly account for the key physical-mechanisms affecting the end-to-end entanglement rate, such as decoherence time, atom-photon and photon-photon entanglement generation, entanglement swapping, and imperfect Bell-state measurement. Then, we derive the closed-form expression of the end-to-end entanglement rate for an arbitrary path and we design an efficient algorithm for entanglement rate computation. Finally, we design a routing protocol and we prove its optimality when used in conjunction with the entanglement rate as routing metric.","['Quantum entanglement', 'Routing', 'Atomic measurements', 'Cavity resonators', 'Atom optics', 'Photonics']","['Quantum networks', 'quantum routing', 'entanglement rate', 'route metric', 'optimal routing']"
"The significance of the Internet of Drones (IoD) is increasing steadily and now IoD is being practiced in many military and civilian-based applications. IoD facilitates real-time data access to the users especially the surveillance data in smart cities using the current cellular networks. However, due to the openness of communication channel and battery operations, the drones and the sensitive data collected through drones are subject to many security threats. To cope the security challenges, recently, Srinivas et al. proposed a temporal credential based anonymous lightweight authentication scheme (TCALAS) for IoD networks. Contrary to the IoD monitoring framework proposed by Srinivas et al., their own scheme can work only when there is one and only one cluster/flying zone and is not scalable. Moreover, despite their claim of robustness, the investigation in this paper reveals that Srinivas et al.'s scheme cannot resist traceability and stolen verifier attacks. Using the lightweight symmetric key primitives and temporal credentials, an improved scheme (iTCALAS) is then proposed. The proposed scheme while maintaining the lightweightness provides security against many known attacks including traceability and stolen verifier. The proposed iTCALAS extends scalability and can work when there are several flying zone/clusters in the IoD environment. The formal security proof along with automated verification using ProVerif show robustness of proposed iTCALAS. Moreover, the security discussion and performance comparisons show that the iTCALAS provides the known security features and completes authentication in just 2.295~ms.","['Drones', 'Authentication', 'Surveillance', 'Smart cities']","['Surveillance', 'security', 'key-agreement', 'drones', 'IoT', 'IoD', 'session key leakage', 'traceability', 'user anonymity']"
"State of charge (SOC) is one of the crucial parameters in a lithium-ion battery. The accurate estimation of SOC guarantees the safe and efficient operation of a specific application. However, SOC estimation with high accuracy is a serious concern to the automobile engineer due to the battery nonlinear characteristics and complex electrochemical reactions. This paper presents an improved nonlinear autoregressive with exogenous input (NARX)-based neural network (NARXNN) algorithm for an accurate and robust SOC estimation of lithium-ion battery which is effective and computationally rich for controlling dynamic system and predicting time series. However, the accuracy of recurrent NARXNN depends on the amount of input order, output order, and hidden layer neurons. The unique contribution of the improved recurrent NARXNN-based SOC estimation is developed using lighting search algorithm (LSA) for finding the best value of input delays, feedback delays, and hidden layer neurons. The contributions are summarized as: 1) the computational capability of NARXNN model which does not require battery model and parameters rather only needs current, voltage, and temperature sensors; 2) the effectiveness of LSA which is verified with particle swarm optimization; 3) the adaptability, efficiency, and robustness of the model which are evaluated using FUDS and US06 drive cycles at varying temperatures conditions; and 4) the performance of the proposed model which is compared with back propagation neural network and radial basis function neural network optimized by LSA using different error statistical terms and computational time. Furthermore, a comparative analysis of SOC estimation in proposed method and existing techniques is presented for validation of NARXNN performance. The results prove that the proposed NARXNN model achieves higher accuracy with less computational time than other existing SOC algorithms under different temperature conditions and electric vehicle drive cycles.","['State of charge', 'Estimation', 'Projectiles', 'Computational modeling', 'Mathematical model', 'Lithium-ion batteries']","['State of charge', 'lithium-ion battery', 'NARX neural network', 'lighting search algorithm']"
"Even if measuring the outcome of binary classifications is a pivotal task in machine learning and statistics, no consensus has been reached yet about which statistical rate to employ to this end. In the last century, the computer science and statistics communities have introduced several scores summing up the correctness of the predictions with respect to the ground truth values. Among these scores, the Matthews correlation coefficient (MCC) was shown to have several advantages over confusion entropy, accuracy, F 1 score, balanced accuracy, bookmaker informedness, markedness, and diagnostic odds ratio: MCC, in fact, produces a high score only if the majority of the predicted negative data instances and the majority of the positive data instances are correct, and therefore it results being very trustworthy on imbalanced datasets. In this study, we compare MCC with two other popular scores: Cohen's Kappa, a metric that originated in social sciences, and the Brier score, a strictly proper scoring function which emerged in weather forecasting studies. After explaining the mathematical properties and the relationships between MCC and each of these two rates, we report some use cases where these scores generate different values, which lead to discordant outcomes, where MCC provides a more truthful and informative result. We highlight the reasons why it is more advisable to use MCC rather that Cohen's Kappa and the Brier score to evaluate binary classifications.","['Correlation', 'Measurement', 'Machine learning', 'Standards', 'Calibration', 'Blogs', 'Task analysis']","['Matthews correlation coefficient', 'Cohen’s Kappa', 'binary classification', 'confusion matrix', 'supervised machine learning', 'Brier score', 'confusion matrix', 'applied machine learning']"
"Distributed Ledger Technology (DLT) has emerged as one of the most disruptive technologies in the last decade. It promises to change the way people do their business, track their products, and manage their personal data. Though the concept of DLT was first implemented in 2009 as Bitcoin, it has gained significant attention only in the past few years. During this time, different DLT enthusiasts and commercial companies have proposed and developed several DLT platforms. These platforms are usually categorized as public vs private, general purpose vs application specific and so on. As a growing number of people are interested to build DLT applications, it is important to understand their underlying architecture and capabilities in order to determine which DLT platform should be leveraged for a specific DLT application. In addition, the platforms need to be evaluated and critically analyzed to assess their applicability, resiliency and sustainability in the long run. In this paper, we have surveyed several leading DLT platforms and evaluated their capabilities based on a number of quantitative and qualitative criteria. The comparative analysis presented in this paper will help the DLT developers and architects to choose the best platform as per their requirement(s).","['Distributed ledger', 'Bitcoin', 'Blockchain', 'Peer-to-peer computing', 'Internet of Things', 'Consensus algorithm']","['Distributed ledger technology', 'blockchain', 'immutability', 'DLT platforms']"
"Traditional centralized commerce on the Internet relies on trusted third parties to process electronic payments. It suffers from the weakness of the trust-based model. A pure decentralized mechanism called blockchain tackles the above problem and has become a hot research area. However, since each node in a blockchain system needs to store all transactions of the other nodes, as time continues, the storage room required to store the entire blockchain will be huge. Therefore, the current storage mechanism needs to be revised to cater to the rapidly increasing need for storage. Network coded (NC) distributed storage (DS) can significantly reduce the required storage room. This paper proposes a NC-DS framework to store the blockchain and proposes corresponding solutions to apply the NC-DS to the blockchain systems. Analysis shows that the proposed scheme achieves significant improvement in saving storage room.","['Bitcoin', 'Encoding', 'Network coding', 'Decoding']","['Blockchain', 'distributed storage', 'network coding']"
"Accurate short-term prediction of the natural gas load is of great significance to the operation and allocation of the pipeline network. Because the short-term natural gas load has obvious nonlinearity and randomness, the traditional regression model is difficult to predict accurately. Therefore, this paper proposes a hybrid prediction model that integrates an improved whale swarm algorithm (IWOA) and relevance vector machine (RVM). In addition, empirical mode decomposition (EMD), approximate entropy (ApEn), and C-C method are introduced to aid the calculation. In this paper, the IWOA is used to test the four functions and compared with the other five algorithms. The results show that the convergence accuracy and convergence speed of the new algorithm are higher than other algorithms, indicating that it has better global optimization ability. Second, the IWOA-RVM model is used to predict the supply data of two natural gas stations in Anhui Province, China. The prediction results are compared with the five algorithms including RBFNN, GRNN, ELMANNN, LSSVM, and SMOSVM. The results show that: 1) through the test of four functions, IWOA has better ability to jump out of local optimum, has higher optimization performance, and the calculation speed is at a medium level and 2) compared with other models, the IOWA-RVM model has higher prediction accuracy when the amount of data is larger or smaller, but the calculation time is relatively long, but the calculation time is acceptable in engineering.","['Predictive models', 'Autoregressive processes', 'Load modeling', 'Prediction algorithms', 'Support vector machines', 'Forecasting', 'Natural gas']","['Short-term', 'natural gas demand', 'prediction', 'relevance vector machine', 'improved whale swarm algorithm']"
"In industrial environments, over several decades, Automated Guided Vehicles (AGVs) and Autonomous Mobile Robots (AMRs) have served to improve efficiencies of intralogistics and material handling tasks. However, for system integrators, the choice and effective deployment of improved, suitable and reliable communication and control technologies for these unmanned vehicles remains a very challenging task. Specifics of communication for AGVs and AMRs imposes stringent performance requirements on latency and reliability of communication links which many existing wireless technologies struggle to satisfy. In this paper, a review of latest AGVs and AMRs research results in the past decade is presented. The review encompasses results from different past and present research domains of AGVs. In addition, performance requirements of communication networks in terms of their latencies and reliabilities when they are deployed for AGVs and AMRs coordination, control and fleet management in smart manufacturing environments are discussed. Integration challenges and limitations of present state-of-the-art AGV and AMR technologies when those technologies are used for facilitating AGV-based smart manufacturing and factory of the future applications are also thoroughly discussed. The paper also present a thorough discussion of areas in need of further research regarding the application of 5G networks for AGVs and AMRs fleet management in smart manufacturing environments. In addition, novel integration ideas by which tactile Internet, 5G network slicing and virtual reality applications can be used to facilitate AGV and AMR based factory of the future (FoF) and smart manufacturing applications were motivated.","['Tactile Internet', '5G mobile communication', 'Virtual reality', 'Production facilities', 'Reliability', 'Task analysis', 'Smart manufacturing']","['Intelligent factory', 'factory of the future', '5G', 'smart manufacturing', 'industry 4.0', 'autonomous industrial equipment', 'AGV', 'AMR', 'tactile Internet', 'virtual reality', 'lean manufacturing']"
"The seminal work on Affective Computing in 1995 by Picard set the base for computing that relates to, arises from, or influences emotions. Affective computing is a multidisciplinary field of research spanning the areas of computer science, psychology, and cognitive science. Potential applications include automated driver assistance, healthcare, human-computer interaction, entertainment, marketing, teaching and many others. Thus, quickly, the field acquired high interest, with an enormous growth of the number of papers published on the topic since its inception. This paper aims to (1) Present an introduction to the field of affective computing though the description of key theoretical concepts; (2) Describe the current state-of-the-art of emotion recognition, tracing the developments that helped foster the growth of the field; and lastly, (3) point the literature take-home messages and conclusions, evidencing the main challenges and future opportunities that lie ahead, in particular for the development of novel machine learning (ML) algorithms in the context of emotion recognition using physiological signals.","['Emotion recognition', 'Physiology', 'Affective computing', 'Biomedical monitoring', 'Machine learning', 'Heart rate', 'Computer science']","['Affective computing', 'emotion recognition', 'machine learning', 'physiological signals', 'signal processing']"
"The emergence of DNA Microarray technology has enabled researchers to analyze the expression level of thousands of genes simultaneously. The Microarray data analysis is the process of finding the most informative genes as well as remove redundant and irrelevant genes. One of the most important applications of the Microarray data analysis is cancer classification. However, the curse of dimensionality and the curse of sparsity make classifying gene expression profiles a challenging task. One of the most effective methods to overcome these challenges is feature (gene) selection. In this paper, we aim to review and compare the most recent hybrid approaches that employ bio-inspired evolutionary methods as the wrapper method.","['Feature extraction', 'Gene expression', 'Cancer', 'Data analysis', 'DNA', 'Filtering algorithms']","['Microarray', 'gene selection', 'bio-inspired', 'hybrid approach', 'cancer classification', 'gene expression']"
"In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. Although, there are many existing energy-aware approaches focusing on minimizing energy consumption while ignoring the SLA violation at the time of a virtual machine (VM) selection from overloaded hosts. Also, they do not consider that the current network traffic causes performance degradation and thus may not really reduce SLA violation under a variety of workloads. In this context, this paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation. Energy-aware methods for overloaded host detection and VM selection from an overloaded host are necessary to improve the energy efficiency and SLA violation of a cloud data center after migrating all VM from underloaded host turn to idle host, which switch to energy-saving mode is also beneficial. Gdr and MCP are adaptive energy-aware algorithms based on the robust regression model, for overloaded host detection. A Bw dynamic VM selection policy selects VM according to the network traffic from the overloaded host under SLAs. Experimental results on the real workload traces show that the proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center using a CloudSim simulator to validate the proposed algorithms.","['Cloud computing', 'Data centers', 'Heuristic algorithms', 'Servers', 'Energy consumption', 'Resource management', 'Dynamic scheduling']","['Cloud computing', 'cloud data center', 'energy-efficiency', 'green computing', 'host overloaded detection', 'regression method', 'service level agreements']"
"Recent studies show that pattern-recognition-based transient stability assessment (PRTSA) is a promising approach for predicting the transient stability status of power systems. However, many of the current well-known PRTSA methods suffer from excessive training time and complex tuning of parameters, resulting in inefficiency for real-time implementation and lacking the online model updating ability. In this paper, a novel PRTSA approach based on an ensemble of OS-extreme learning machine (EOSELM) with binary Jaya (BinJaya)-based feature selection is proposed with the use of phasor measurement units (PMUs) data. After briefly describing the principles of OS-ELM, an EOS-ELM-based PRTSA model is built to predict the post-fault transient stability status of power systems in real time by integrating OS-ELM and an online boosting algorithm, respectively, as a weak classifier and an ensemble learning algorithm. Furthermore, a BinJaya-based feature selection approach is put forward for selecting an optimal feature subset from the entire feature space constituted by a group of system-level classification features extracted from PMU data. The application results on the IEEE 39-bus system and a real provincial system show that the proposal has superior computation speed and prediction accuracy than other state-of-the-art sequential learning algorithms. In addition, without sacrificing the classification performance, the dimension of the input space has been reduced to about one-third of its initial value.","['Power system stability', 'Feature extraction', 'Transient analysis', 'Stability criteria', 'Training']","['Transient stability', 'feature selection', 'binary Jaya algorithm', 'extreme learning machine', 'ensemble learning']"
"Melanoma is considered a fatal type of skin cancer. However, it is sometimes hard to distinguish it from nevus due to their identical visual appearance and symptoms. The mortality rate because of this disease is higher than all other skin-related consolidated malignancies. The number of cases is growing among young people, but if it is diagnosed at an earlier stage, then the survival rates become very high. The cost and time required for the doctors to diagnose all patients for melanoma are very high. In this paper, we propose an intelligent system to detect and distinguish melanoma from nevus by using the state-of-the-art image processing techniques. At first, the Gaussian filter is used for removing noise from the skin lesion of the acquired images followed by the use of improved K-mean clustering to segment out the lesion. A distinctive hybrid superfeature vector is formed by the extraction of textural and color features from the lesion. Support vector machine (SVM) is utilized for the classification of skin cancer into melanoma and nevus. Our aim is to test the effectiveness of the proposed segmentation technique, extract the most suitable features, and compare the classification results with the other techniques present in the literature. The proposed methodology is tested on the DERMIS dataset having a total number of 397 skin cancer images: 146 are melanoma and 251 are nevus skin lesions. Our proposed methodology archives encouraging results having 96% accuracy.","['Feature extraction', 'Image color analysis', 'Melanoma', 'Skin', 'Lesions']","['Melanoma', 'nevus', 'feature', 'K-means clustering', 'centroid selection']"
"DC offset in the input of phase-locked loops (PLLs) is a challenging problem since it will result in fundamental frequency oscillations in the estimated phase and frequency. In this paper, a comprehensive analysis and performance evaluation of several advanced second-order generalized integrator (SOGI)based PLL methods in enhancing the dc offset rejection capability for single-phase grid-connected power converters is presented. These methods include the cascade SOGI, modified SOGI, αβ-frame delayed signal cancellation (DSC), complex coefficient filter, in-loop dq-frame DSC, notch filter, and moving average filter-based SOGI-PLL. Main characteristics and design aspects of these methods are presented. Main performance indexes, such as the setting time, frequency or phase errors are defined and these methods are systematically compared under various scenarios with both numerical and experimental results.","['Phase locked loops', 'Frequency estimation', 'Frequency response', 'Resonant frequency', 'Low pass filters', 'Harmonic analysis', 'Transfer functions']","['Phase-locked loop', 'dc offset', 'single phase grid-connected converter', 'filter']"
"Mobile ad hoc network (MANET) is a collection of wireless mobile nodes that dynamically form a temporary network without the reliance of any infrastructure or central administration. Energy consumption is considered as one of the major limitations in MANET, as the mobile nodes do not possess permanent power supply and have to rely on batteries, thus reducing network lifetime as batteries get exhausted very quickly as nodes move and change their positions rapidly across MANET. This paper highlights the energy consumption in MANET by applying the fitness function technique to optimize the energy consumption in ad hoc on demand multipath distance vector (AOMDV) routing protocol. The proposed protocol is called AOMDV with the fitness function (FF-AOMDV). The fitness function is used to find the optimal path from source node to destination node to reduce the energy consumption in multipath routing. The performance of the proposed FF-AOMDV protocol has been evaluated by using network simulator version 2, where the performance was compared with AOMDV and ad hoc on demand multipath routing with life maximization (AOMR-LM) protocols, the two most popular protocols proposed in this area. The comparison was evaluated based on energy consumption, throughput, packet delivery ratio, end-to-end delay, network lifetime and routing overhead ratio performance metrics, varying the node speed, packet size, and simulation time. The results clearly demonstrate that the proposed FF-AOMDV outperformed AOMDV and AOMR-LM under majority of the network performance metrics and parameters.","['Routing protocols', 'Routing', 'Mobile ad hoc networks', 'Mobile nodes', 'Energy consumption']","['Energy efficient protocol', 'mobile ad hoc network', 'multipath routing', 'fitness function']"
"In recent times, with the advent of blockchain technology, there is an optimism surrounding the concept of self-sovereign identity which is regarded to have an influential effect on how we interact with each other over the Internet in future. There are a few works in the literature which examine different aspects of self-sovereign identity. Unfortunately, the existing works are not methodological and comprehensive at all. Moreover, there exist different notions of what the term self-sovereign identity means. To exploit its full potential, it is essential to ensure a common understanding in a formal way. This paper aims to achieve this goal by providing the first-ever formal and rigorous treatment of the concept of self-sovereign identity using a mathematical model. This paper examines the properties that a self-sovereign identity should have and explores the impact of self-sovereign identity over the laws of identity. It also highlights the essential life-cycles of an identity management system and inter-relates how the notion of self-sovereign identity can be applied in these life-cycles. In addition, the paper illustrates several envisioned flows involving a self-sovereign identity leveraging blockchain technology covering different aspects of an identity management system. All in all, this paper presents the first formal and comprehensive step toward an academic investigation of self-sovereign identity.","['5G mobile communication', 'Solid modeling', 'Blockchain', 'Indexes']","['Identity', 'identity management system', 'self-sovereign identity', 'blockchain']"
"This paper proposes a multi-objective Slime Mould Algorithm (MOSMA), a multi-objective variant of the recently-developed Slime Mould Algorithm (SMA) for handling the multi-objective optimization problems in industries. Recently, for handling optimization problems, several meta-heuristic and evolutionary optimization techniques have been suggested for the optimization community. These methods tend to suffer from low-quality solutions when evaluating multi-objective optimization (MOO) problems than addressing the objective functions of identifying Pareto optimal solutions’ accurate estimation and increasing the distribution throughout all objectives. The SMA method follows the logic gained from the oscillation behaviors of slime mould in the laboratory experiments. The SMA algorithm shows a powerful performance compared to other well-established methods, and it is designed by incorporating the optimal food path using the positive-negative feedback system. The proposed MOSMA algorithm employs the same underlying SMA mechanisms for convergence combined with an elitist non-dominated sorting approach to estimate Pareto optimal solutions. As a posteriori method, the multi-objective formulation is maintained in the MOSMA, and a crowding distance operator is utilized to ensure increasing the coverage of optimal solutions across all objectives. To verify and validate the performance of MOSMA, 41 different case studies, including unconstrained, constrained, and real-world engineering design problems are considered. The performance of the MOSMA is compared with Multiobjective Symbiotic-Organism Search (MOSOS), Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D), and Multiobjective Water-Cycle Algorithm (MOWCA) in terms of different performance metrics, such as Generational Distance (GD), Inverted Generational Distance (IGD), Maximum Spread (MS), Spacing, and Run-time. The simulation results demonstrated the superiority of the proposed algorithm in realizing high-quality solutions to all multi-objective problems, including linear, nonlinear, continuous, and discrete Pareto optimal front. The results indicate the effectiveness of the proposed algorithm in solving complicated multi-objective problems. This research will be backed up with extra online service and guidance for the paper’s source code at https://premkumarmanoharan.wixsite.com/mysite and https://aliasgharheidari.com/SMA.html . Also, the source code of SMA is shared with the public at https://aliasgharheidari.com/SMA.html .","['Optimization', 'Pareto optimization', 'Sorting', 'Linear programming', 'Classification algorithms', 'Genetic algorithms']","['Constrained', 'multi-objective optimization problems', 'multi-objective slime mould algorithm (MOSMA)', 'real-world problems', 'slime mould algorithm (SMA)', 'unconstrained']"
"In 5G-based cognitive radio, the primary user signal is more active due to the broad frequency band. The traditional cooperative spectrum sensing only detects one characteristic of PU using one kind of detector, which may decrease the sensing performance when the wideband PU is in severe fading channel. In this paper, a multi-modal cooperative spectrum sensing is proposed to make an accurate decision through combining multi-modal sensing data of the PU signal, such as energy, power spectrum, and signal waveform. Each secondary user (SU) deploys multiple kinds of detectors, such as energy detector, spectral detector and waveform detector. The multi-modal sensing data from different detectors are sent to a fusion center. In the fusion center, the local decision is achieved through the Bayesian fusion, while the global decision is determined by the DS fusion. The sensing credibility of each detector can be fully considered in the DS fusion, in order to avoid the performance difference of different detectors. Weight DS fusion is also proposed to improve the decision performance through decreasing the sensing impact of malicious SU while increasing the fusion proportion of dominant SU. The simulation results have shown that the proposed multimodal cooperative spectrum sensing can achieve better sensing performance in fading channel.","['Detectors', 'Fading channels', 'Signal to noise ratio', 'Data integration', 'Bayes methods', 'Cognitive radio']","['Cognitive radio', 'cooperative spectrum sensing', 'multi-modal data fusion', 'DS fusion', 'detection probability']"
"Silicon nanowire field-effect transistors (Si-NW FETs) have been demonstrated as a versatile class of potentiometric nanobiosensors for real time, label-free, and highly sensitive detection of a wide range of biomolecules. In this review, we summarize the principles of such devices and recent developments in device fabrication, fluid integration, surface functionalization, and biosensing applications. The main focus of this review is on CMOS compatible Si-NW FET nanobiosensors.","['Biosensors', 'Field effect transistors', 'Nanobioscience', 'Transistors', 'Silicon', 'Nanoscale devices', 'Semiconductor device measurement']","['Biosensors', 'Field effect transistors', 'Nanowires', 'Semiconductor nanostructures', 'Nanobiosensors']"
"This research work presents a modified sine-cosine optimized maximum power point tracking (MPPT) algorithm for grid integration. The developed algorithm provides the maximum power extraction from a photovoltaic (PV) panel and simplified implementation with a benefit of high convergence velocity. Moreover, the performance and ability of the modified sine-cosine optimized (MSCO) algorithm is equated with recent particle swarm optimization and artificial bee colony algorithms for comparative observation. Practical responses is analyzed under steady state, dynamic, and partial shading conditions by using dSPACE real controlling board laboratory scale hardware implementation. The MSCO-based MPPT algorithm always shows fast convergence rate, easy implementation, less computational burden and the accuracy to track the optimal PV power under varying weather conditions. The experimental results provided in this paper clearly show the validation of the proposed algorithm.","['Inverters', 'Maximum power point trackers', 'Convergence', 'Optimization', 'Inductors', 'Hardware', 'Complexity theory']","['Artificial bee colony', 'sine-cosine optimized', 'maximum power point tracking', 'photovoltaic', 'particle swarm optimization']"
"Several papers reviewing fractional order calculus in control applications have been published recently. These papers focus on general tuning procedures, especially for the fractional order proportional integral derivative controller. However, not all these tuning procedures are applicable to all kinds of processes, such as the delicate time delay systems. This motivates the need for synthesizing fractional order control applications, problems, and advances completely dedicated to time delay processes. The purpose of this paper is to provide a state of the art that can be easily used as a basis to familiarize oneself with fractional order tuning strategies targeted for time delayed processes. Solely, the most recent advances, dating from the last decade, are included in this review.","['Delay effects', 'Tuning', 'Process control', 'Gain', 'Robustness', 'Sensitivity', 'Fractional calculus']","['Fractional calculus', 'time delay process', 'fractional order control']"
"Modern industry 4.0 applications are shifting towards decentralized automation of computing and cyber-physical systems (CPS), which necessitates building a robust, secure, and efficient system that performs complex interactions with other physical processes. To handle complex interactions in CPS, trust and consensus among various stakeholders is a prime concern. In a similar direction, consensus algorithms in blockchain have evolved over the years that focus on building smart, robust, and secure CPS. Thus, it is imperative to understand the key components, functional characteristics, and architecture of different consensus algorithms used in CPS. Many consensus algorithms exist in the literature with a specified set of functionalities, performance, and computing services. Motivated from these facts, in this survey, we present a comprehensive analysis of existing state-of-the-art consensus mechanisms and highlight their strength and weaknesses in decentralized CPS applications. In the first part, we present the scope of the proposed survey and identify gaps in the existing surveys. Secondly, we present the review method and objectives of the proposed survey based on research questions that address the gaps in existing studies. Then, we present a solution taxonomy of decentralized consensus mechanisms for various CPS applications. Then, open issues and challenges are also discussed in deploying various consensus mechanisms in the CPS with their merits and demerits. The proposed survey will act as a road-map for blockchain developers and researchers to evaluate and design future consensus mechanisms, which helps to build an efficient CPS for industry 4.0 stakeholders.","['Consensus algorithm', 'Peer-to-peer computing', 'Industries', 'Cloud computing', 'Blockchain', 'Security', 'Ecosystems']","['Blockchain', 'consensus algorithms', 'cyber-physical systems', 'IoT', 'smart grid', 'supply chain management', 'intelligent transportation']"
"Fog computing is deemed as a highly virtualized paradigm that can enable computing at the Internet of Things devices, residing in the edge of the network, for the purpose of delivering services and applications more efficiently and effectively. Since fog computing originates from and is a non-trivial extension of cloud computing, it inherits many security and privacy challenges of cloud computing, causing the extensive concerns in the research community. To enable authentic and confidential communications among a group of fog nodes, in this paper, we propose an efficient key exchange protocol based on ciphertext-policy attribute-based encryption (CP-ABE) to establish secure communications among the participants. To achieve confidentiality, authentication, verifiability, and access control, we combine CP-ABE and digital signature techniques. We analyze the efficiency of our protocol in terms of security and performance. We also implement our protocol and compare it with the certificate-based scheme to illustrate its feasibility.","['Edge computing', 'Protocols', 'Cloud computing', 'Encryption', 'Access control', 'Smart grids']","['Fog computing', 'security', 'ciphertext-policy attribute based encryption (CP-ABE)', 'cloud computing', 'communications security']"
"Maximizing network lifetime is a major objective for designing and deploying a wireless sensor network. Clustering sensor nodes is an effective topology control approach helping achieve this goal. In this paper, we present a new method to prolong the network lifetime based on the improved particle swarm optimization algorithm, which is an optimization method designed to select target nodes. The protocol takes into account both energy efficiency and transmission distance, and relay nodes are used to alleviate the excessive power consumption of the cluster heads. The proposed protocol results in better distributed sensors and a well-balanced clustering system enhancing the network's lifetime. We compare the proposed protocol with comparative protocols by varying a number of parameters, e.g., the number of nodes, the network area size, and the position of the base station. Simulation results show that the proposed protocol performs well against other comparative protocols in various scenarios.","['Clustering algorithms', 'Energy efficiency', 'Wireless sensor networks', 'Network topology', 'Particle swarm optimization', 'Algorithm design and analysis']","['WSN', 'clustering', 'energy efficiency', 'network lifetime', 'PSO']"
"Unmanned aerial vehicles (UAVs) are fast gaining popularity in a wide variety of areas and are already being used for a range of tasks. Despite their many desirable features, a number of drawbacks hinder the potential of UAV applications. As typical UAVs are powered by on-board batteries, limited battery lifetime is identified as a key limitation in UAV applications. Thus, in order to preserve the available energy, planning UAV missions in an energy efficient manner is of utmost importance. For energy efficient UAV mission planning, it is necessary to predict the energy consumption of specific UAV manoeuvring actions. Accurate energy prediction requires a reliable and realistic energy consumption model. In this paper, we present a consistent and complete energy consumption model for UAVs based on empirical studies of battery usage for various UAV activities. We considered the impact of different flight scenarios and conditions on UAV energy consumption when developing the proposed model. The energy consumption model presented in this paper can be readily used for energy efficient UAV mission planning.","['Unmanned aerial vehicles', 'Energy consumption', 'Power demand', 'Batteries', 'Voltage measurement', 'Propellers', 'Planning']","['Energy consumption', 'energy consumption model', 'power consumption', 'UAV']"
"Streamflow forecasting is essential for hydrological engineering. In accordance with the advancement of computer aids in this field, various machine learning (ML) models have been explored to solve this highly non-stationary, stochastic, and nonlinear problem. In the current research, a newly explored version of an ML model called the long short-term memory (LSTM) was investigated for streamflow prediction using historical data for forecasting for a particular period. For a case study located in a tropical environment, the Kelantan river in the northeast region of the Malaysia Peninsula was selected. The modelling was performed according to several perspectives: (i) The feasibility of applying the developed LSTM model to streamflow prediction was verified, and the performance of the developed LSTM model was compared with the classic backpropagation neural network model; (ii) In the experimental process of applying the LSTM model to the prediction of streamflow, the influence of the training set size on the performance of the developed LSTM model was tested; (iii) The effect of the time interval between the training set and the testing set on the performance of the developed LSTM model was tested; (iv) The effect of the time span of the prediction data on the performance of the developed LSTM model was tested. The experimental data show that not only does the developed LSTM model have obvious advantages in processing steady streamflow data in the dry season but it also shows good ability to capture data features in the rapidly fluctuant streamflow data in the rainy season.","['Predictive models', 'Data models', 'Forecasting', 'Rivers', 'Computational modeling', 'Solid modeling', 'Time series analysis']","['Deep learning model', 'streamflow forecasting', 'tropical environment', 'window scale forecasting', 'LSTM']"
"Indoor localization is one of the key enablers for various application and service areas that rely on precise locations of people, goods, and assets, ranging from home automation and assisted living to increased automation of production and logistic processes and wireless network optimization. Existing solutions provide various levels of precision, which also depends on the complexity of the indoor radio environment. In this paper, we propose two methods for reducing the localization error in indoor non-line-of-sight (NLoS) conditions using raw channel impulse response (CIR) information obtained from ultra-wide band radios requiring no prior knowledge about the radio environment. The methods are based on NLoS channel classification and ranging error regression models, both using convolutional neural networks (CNNs) and implemented in the TensorFlow computational framework. We first show that NLoS channel classification using raw CIR data outperforms existing approaches that are based on derived input signal features. We further demonstrate that the predicted NLoS channel state and predicted ranging error information, used in combination with least squares (LS) and weighted LS location estimation algorithms, significantly improve indoor localization performance. We also evaluate the computational performance and suitability of the proposed CNN-based algorithms on various computing platforms with a wide range of different capabilities and show that in a distributed localization system, they can also be used on computationally restricted devices.","['Distance measurement', 'Convolutional neural networks', 'Heuristic algorithms', 'Performance evaluation', 'Computational modeling', 'Estimation', 'Prediction algorithms']","['Channel impulse response', 'convolutional neural network', 'deep learning', 'indoor localization', 'non-line-of-sight', 'ranging error mitigation', 'ultra-wide band']"
"With the expansion of the network and increasing their users, as well as emerging new technologies, such as cloud computing and big data, managing traditional networks is difficult. Therefore, it is necessary to change the traditional network architecture. Lately, to address this issue, a notion named software-defined network (SDN) has been proposed, which makes network management more conformable. Due to limited network resources and to meet the requirements of quality of service, one of the points that must be considered is load balancing issue that serves to distribute data traffic among multiple resources in order to maximize the efficiency and reliability of network resources. Load balancing is established based on the local information of the network in the conventional network. Hence, it is not very precise. However, SDN controllers have a global view of the network and can produce more optimized load balances. Although load balancing mechanisms are important in the SDN, to the best of our knowledge, there exists no precise and systematic review or survey on investigating these issues. Hence, this paper reviews the load balancing mechanisms which have been used in the SDN systematically based on two categories, deterministic and non-deterministic. Also, this paper represents benefits and some weakness regarded of the selected load balancing algorithms and investigates the metrics of their algorithms. In addition, the important challenges of these algorithms have been reviewed, so better load balancing techniques can be applied by the researchers in the future.","['Load management', 'Servers', 'Control systems', 'Software defined networking', 'Protocols', 'Systematics', 'Routing']","['Load balancing', 'review', 'SDN', 'software defined networks', 'systematic']"
"It is expected that peer to peer energy trading will constitute a significant share of research in upcoming generation power systems due to the rising demand of energy in smart microgrids. However, the on-demand use of energy is considered a big challenge to achieve the optimal cost for households. This paper proposes a blockchain-based predictive energy trading platform to provide real-time support, day-ahead controlling, and generation scheduling of distributed energy resources. The proposed blockchain-based platform consists of two modules; blockchain-based energy trading and smart contract enabled predictive analytics modules. The blockchain module allows peers with real-time energy consumption monitoring, easy energy trading control, reward model, and unchangeable energy trading transaction logs. The smart contract enabled predictive analytics module aims to build a prediction model based on historical energy consumption data to predict short-term energy consumption. This paper uses real energy consumption data acquired from the Jeju province energy department, the Republic of Korea. This study aims to achieve optimal power flow and energy crowdsourcing, supporting energy trading among the consumer and prosumer. Energy trading is based on day-ahead, real-time control, and scheduling of distributed energy resources to meet the smart grid’s load demand. Moreover, we use data mining techniques to perform time-series analysis to extract and analyze underlying patterns from the historical energy consumption data. The time-series analysis supports energy management to devise better future decisions to plan and manage energy resources effectively. To evaluate the proposed predictive model’s performance, we have used several statistical measures, such as mean square error and root mean square error on various machine learning models, namely recurrent neural networks and alike. Moreover, we also evaluate the blockchain platform’s effectiveness through hyperledger calliper in terms of latency, throughput, and resource utilization. Based on the experimental results, the proposed model is effectively used for energy crowdsourcing between the prosumer and consumer to attain service quality.","['Blockchain', 'Smart contracts', 'Predictive models', 'Crowdsourcing', 'Machine learning', 'Peer-to-peer computing', 'Energy consumption']","['Energy trading', 'energy prediction', 'predictive analysis', 'machine learning', 'blockchain']"
"As an interesting network architecture for future wireless communication systems, cellfree (CF) massive multiple-input multiple-output (MIMO) distributes an excess number of access points (APs) with single or multiple antennas to cooperatively communicate with several user equipments (UEs). To realize CF massive MIMO in production, hardware impairments become a crucial problem since cheaper and low-quality antennas are needed to ensure economic and energy feasibility. In this paper, we propose a framework for performance analysis in the CF massive MIMO with classical hardware distortion models. For both uplink and downlink, closed-form spectral and energy efficiency expressions are derived, respectively. Based on these results, we provide significant insights into the practical impact of hardware impairments on CF massive MIMO. For example, the impact of hardware distortion at the APs asymptotically vanishes. Furthermore, in order to ensure uniformly good service to the users, we propose a max-min power control algorithm to maximize the minimum UE rate. Via analytical and numerical results, we prove that CF massive MIMO can tolerate hardware impairments without performance reduction.","['MIMO communication', 'Hardware', 'Distortion', 'Uplink', 'Antennas', 'Power control', 'Downlink']","['CF massive MIMO', 'spectral efficiency', 'energy efficiency', 'power control', 'hardware impairments']"
"Vehicle detection and counting in aerial images have become an interesting research focus since the last decade. It is important for a wide range of applications, such as urban planning and traffic management. However, this task is a challenging one due to the small size of the vehicles, their different types and orientations, and similarity in their visual appearance, and some other objects, such as air conditioning units on buildings, trash bins, and road marks. Many methods have been introduced in the literature for solving this problem. These methods are either based on shallow learning or deep learning approaches. However, these methods suffer from relatively low precision and recall rate. This paper introduces an automated vehicle detection and counting system in aerial images. The proposed system utilizes convolution neural network to regress a vehicle spatial density map across the aerial image. It has been evaluated on two publicly available data sets, namely, Munich and Overhead Imagery Research Data Set. The experimental results show that our proposed system is efficient and effective, and produces higher precision and recall rate than the comparative methods.","['Vehicle detection', 'Feature extraction', 'Automobiles', 'Training', 'Sensors', 'Support vector machines']","['Aerial images', 'convolution neural network (CNN)', 'deep learning', 'regression', 'vehicle detection']"
"Next-generation of the cellular network will attempt to overcome the limitations of the current Fifth Generation (5G) networks and equip itself to address the challenges which become obvious in the future. Currently, academia and industry have focused their attention on the Sixth Generation (6G) network, which is anticipated to be the next big game-changer in the telecom industry. The outbreak of COVID'19 has made the whole world to opt for virtual meetings, live video interactions ranging from healthcare, business to education. However, we miss an immersive experience due to the lack of supporting technology. Experts have anticipated that starting from the post-pandemic age, the performance requirements of technology for virtual and real-time communication, the rise of several verticals such as industrial automation, robotics, and autonomous driving will increase tremendously, and will skyrocket during the next decade. In this manuscript, we study the latest perspectives and future megatrends that are most likely to drive 6G. Initially, we describe the instances that lead us to the vision of 6G. Later, we narrate some of the use cases and the KPIs essential to meet their performance requirement. Further, we highlight the key requirements of 6G based on contemporary research such as UN sustainability goals, business model, edge intelligence, digital divide, and the trends in machine learning for 6G.","['6G mobile communication', '5G mobile communication', 'Reliability', 'Security', 'Industries', 'Surgery', 'Ecosystems']","['6G', 'artificial intelligence', 'cloud computing', 'sustainability goals', 'digital divide', 'healthcare', 'machine learning', 'Tera hertz communication', 'cellular network', '6G architecture']"
"Nowadays, society is growing and crowded, the construction of automatic smart waste sorter machine utilizing the intelligent sensors is important and necessary. To build this system, trash classification from trash images is an important issue in computer vision to be addressed for integrating into sensors. Therefore, this study proposes a robust model using deep neural networks to classify trash automatically which can be applied in smart waste sorter machines. Firstly, we collect the VN-trash dataset that consists of 5904 images belonging to three different classes including Organic, Inorganic and Medical wastes from Vietnam. Next, this study develops a deep neural network model for trash classification named DNN-TC which is an improvement of ResNext model to improve the predictive performance. Finally, the experiments are conducted to compare the performances of DNN-TC and the state-of-the-art methods for trash classification on VN-trash dataset as well as Trashnet dataset to show the effectiveness of the proposed model. The experimental results indicate that DNN-TC yields 94% and 98% in terms of accuracy for Trashnet and VN-trash datasets respectively and thus it outperforms the state-of-the-art methods for trash classification on both experimental datasets.","['Deep learning', 'Testing', 'Predictive models', 'Convolutional neural networks', 'Feature extraction', 'Biological neural networks']","['Trash classification', 'computer vision', 'deep neural networks']"
"In recent years, the popularity of depth sensors and 3D scanners has led to a rapid development of 3D point clouds. Semantic segmentation of point cloud, as a key step in understanding 3D scenes, has attracted extensive attention of researchers. Recent advances in this topic are dominantly led by deep learning-based methods. In this paper, we provide a survey covering various aspects ranging from indirect segmentation to direct segmentation. Firstly, we review methods of indirect segmentation based on multi-views and voxel grids, as well as direct segmentation methods from different perspectives including point ordering, multi-scale, feature fusion and fusion of graph convolutional neural network (GCNN). Then, the common datasets for point cloud segmentation are exposed to help researchers choose which one is the most suitable for their tasks. Following that, we devote a part of the paper to analyze the quantitative results of these methods. Finally, the development trend of point cloud semantic segmentation technology is prospected.","['Three-dimensional displays', 'Semantics', 'Image segmentation', 'Deep learning', 'Feature extraction', 'Convolutional neural networks', 'Two dimensional displays']","['3D point clouds', 'deep learning', 'feature fusion', 'graph convolutional neural network', 'semantic segmentation']"
"Orthogonal frequency division multiplexing (OFDM) is a superior technology for the high-speed data rate of wire-line and wireless communication systems. The OFDM has many advantages over other techniques such as its high capacity and immunity against multipath fading channels. However, one of the main drawbacks of the OFDM system is the high-peak-to-average power ratio (PAPR) that leads the system to produce in-band distortion and out-of-band radiation because of the non-linearity of the high-power amplifiers. Therefore, numerous techniques have been proposed to overcome the PAPR problem such as selective mapping, partial transmit sequence (PTS), clipping, and nonlinear companding. In this paper, the PTS technique was analytically reviewed as one of the important methods to reduce the high PAPR problem. The PAPR performance and the computational complexity level are discussed in terms of modifying the PTS technique in the frequency domain, time domain and modulation stage (inverse fast Fourier transform block). Moreover, the numerical statistic comparison of the current modified-PTS methods is introduced, and the criteria for selecting the suitable modified-PTS method in the OFDM system are also given. The simulation and the numerical calculations results show that the rows exchange-interleaving PTS scheme is the best method for reducing the PAPR value with low complexly in the frequency domain, and the cooperative PTS method is the best among the modulation stage methods, while the cyclic shift sequence PTS method achieves the superior performance in PAPR reduction and computational complexity for the time domain methods.","['Peak to average power ratio', 'Partial transmit sequences', 'Computational complexity', 'Distortion', 'Time-domain analysis', 'Frequency-domain analysis']","['OFDM', 'PAPR', 'PTS', 'modified-PTS', 'computational complexity']"
"During the past decade, deep learning is one of the essential breakthroughs made in artificial intelligence. In particular, it has achieved great success in image processing. Correspondingly, various applications related to image processing are also promoting the rapid development of deep learning in all aspects of network structure, layer designing, and training tricks. However, the deeper structure makes the back-propagation algorithm more difficult. At the same time, the scale of training images without labels is also rapidly increasing, and class imbalance severely affects the performance of deep learning, these urgently require more novelty deep models and new parallel computing system to more effectively interpret the content of the image and form a suitable analysis mechanism. In this context, this survey provides four deep learning model series, which includes CNN series, GAN series, ELM-RVFL series, and other series, for comprehensive understanding towards the analytical techniques of image processing field, clarify the most important advancements and shed some light on future studies. By further studying the relationship between deep learning and image processing tasks, which can not only help us understand the reasons for the success of deep learning but also inspires new deep models and training methods. More importantly, this survey aims to improve or arouse other researchers to catch a glimpse of the state-of-the-art deep learning methods in the field of image processing and facilitate the applications of these deep learning technologies in their research tasks. Besides, we discuss the open issues and the promising directions of future research in image processing using the new generation of deep learning.","['Machine learning', 'Task analysis', 'Generative adversarial networks', 'Convolutional neural networks', 'Image resolution', 'Mathematical model']","['Image processing', 'deep learning', 'convolutional neural network', 'generative adversarial network', 'extreme learning machine', 'deep forest', 'capsule networks', 'ADMM-Net', 'image classification', 'style transfer', 'object detection', 'super-resolution']"
"This paper is focused on providing the analytical framework for the quantification and evaluation of the joint effect of misalignment fading and hardware imperfections in the presence of multipath fading at terahertz (THz) wireless fiber extenders. In this context, we present the appropriate system model that incorporates the different operation, design, and environmental parameters. In more detail, it takes into account the transceivers antenna gains, the operation frequency, the distance between the transmitter (TX) and the receiver (RX), the environmental conditions, i.e., temperature, humidity, and pressure, the spatial jitter between the TX and RX antennas that results to antennas misalignment, the level of transceivers' hardware imperfections, and the stochastic characteristics of the wireless channel. Based on this model, we analyze and quantify the joint impact of misalignment and multipath fading by providing novel closed-form expressions for the probability and cumulative density functions of the composite channel. Moreover, we derive exact closed-form expressions for the outage probability for both cases of ideal and non-ideal radio frequency (RF) front-end. In addition, in order to quantify the detrimental effect of misalignment fading, we analytically obtain the outage probability in the absence of misalignment cases for both cases of ideal and non-ideal RF front-end. In addition, we extract the novel closed-form expressions for the ergodic capacity for the case of the ideal RF front-end and tight upper bounds for both the cases of ideal and non-ideal RF front-end. Finally, an insightful ergodic capacity ceiling for the non-ideal RF front-end case is provided.","['Wireless communication', 'Fading channels', 'Radio frequency', 'Hardware', 'Channel models', 'Transceivers', 'Atmospheric modeling']","['Beyond 5G systems', 'ergodic capacity', 'fiber extender', 'hardware impairments', 'high frequency communications', 'misalignment fading', 'outage probability', 'performance analysis', 'terahertz communications', 'theoretical framework', 'α-μ fading']"
"Two popular representation learning paradigms are dictionary learning and deep learning. While dictionary learning focuses on learning “basis” and “features” by matrix factorization, deep learning focuses on extracting features via learning “weights” or “filter” in a greedy layer by layer fashion. This paper focuses on combining the concepts of these two paradigms by proposing deep dictionary learning and show how deeper architectures can be built using the layers of dictionary learning. The proposed technique is compared with other deep learning approaches, such as stacked autoencoder, deep belief network, and convolutional neural network. Experiments on benchmark data sets show that the proposed technique achieves higher classification and clustering accuracies. On a real-world problem of electrical appliance classification, we show that deep dictionary learning excels where others do not yield at-par performance. We postulate that the proposed formulation can pave the path for a new class of deep learning tools.","['Dictionaries', 'Feature extraction', 'Machine learning', 'Matrix decomposition', 'Sparse matrices', 'Neural networks']","['Deep learning', 'dictionary learning', 'feature representation']"
"Electroencephalogram (EEG), boasting the advantages of portability, low cost, and hightemporal resolution, is a non-invasive brain-imaging modality that can be used to measure different brain states. However, EEG recordings are always contaminated with artifacts from different sources other than neurons, which renders EEG data analysis more difficult, and which potentially results in misleading findings. Therefore, it is essential for many medical and practical applications to remove these artifacts in the preprocessing stage before analyzing EEG data. In the last thirty years, various methods have been developed to remove different types of artifacts from contaminated EEG data; still though, there is no standard method that can be used optimally, and therefore, the research remains attractive as well as challenging. This paper presents an extensive overview of the existing methods for ocular, muscle, and cardiac artifact identification and removal with their comparative advantages and limitations. We also reviewed the schemes developed for validating the performances of algorithms with simulated and real EEG data. In future studies, researchers should focus not only on the combining of different methods with multiple processing stages for efficient removal of artifactual interferences but also on the development of standard criteria for validation of recorded EEG signals.","['Electroencephalography', 'Filtering', 'Electrooculography', 'Physiology', 'Contamination', 'Muscles', 'Electrodes']","['Electroencephalography', 'physiological artifacts', 'artifact removal', 'regression', 'filtering', 'blind source separation', 'independent component analysis', 'principal component analysis', 'canonical correlation analysis', 'morphological component analysis', 'empirical-mode decomposition', 'wavelet transform', 'signal space projection', 'beamformers', 'hybrid methods', 'brain-computer interface', 'high-density EEG', 'clinical EEG']"
"Motivated by the vast applications of knowledge graph and the increasing demand in education domain, we propose a system, called KnowEdu, to automatically construct knowledge graph for education. By leveraging on heterogeneous data (e.g., pedagogical data and learning assessment data) from the education domain, this system first extracts the concepts of subjects or courses and then identifies the educational relations between the concepts. More specifically, it adopts the neural sequence labeling algorithm on pedagogical data to extract instructional concepts and employs probabilistic association rule mining on learning assessment data to identify the relations with educational significance. We detail all the above mentioned efforts through an exemplary case of constructing a demonstrative knowledge graph for mathematics, where the instructional concepts and their prerequisite relations are derived from curriculum standards and concept-based performance data of students. Evaluation results show that the F1 score for concept extraction exceeds 0.70, and for relation identification, the area under the curve and mean average precision achieve 0.95 and 0.87, respectively.","['Data mining', 'Education', 'Labeling', 'Data models', 'Task analysis', 'Standards', 'Google']","['Educational knowledge graph', 'instructional concept', 'educational relation', 'pedagogical data', 'learning assessment', 'educational data mining']"
"Owing to the ever-growing popularity of mobile computing, a large number of services have been developed for a variety of users. Considering this, recommending useful services to users is an urgent problem that needs to be addressed. Collaborative filtering (CF) approaches have been successfully adopted for services recommendation. Nevertheless, the prediction accuracy of the existing CF approaches is likely to reduce due to many reasons, such as inability to use side information and high data sparsity, which further lead to low quality of services recommendation. In order to solve these problems, some model-based CF approaches have been proposed. In this paper, we propose a novel quality of service prediction approach based on probabilistic matrix factorization (PMF), which has the capability of incorporating network location (an important factor in mobile computing) and implicit associations among users and services. First, we propose a novel clustering method that is capable of utilizing network location to cluster users. Based on the clustering results, we further propose an enhanced PMF model. The proposed model also incorporates the implicit associations among users and services. In addition, our model incorporates the implicit relationships between the users and the services. We conducted experiments on one real-world data set, and the experimental results show that our model outperforms the compared methods.","['Quality of service', 'Predictive models', 'Clustering algorithms', 'Prediction algorithms', 'Computational modeling', 'Mobile computing', 'Numerical models']","['Implicit association', 'network location', 'probabilistic matrix factorization', 'QoS prediction', 'services recommendation']"
"In real-time problems, the possibilities of having a precise mathematical model describing the dynamics of the nonlinear system are scarce. Besides, the measurements invariably are tainted with noise which makes the problem of estimating the actual states of the system more difficult. The most common way of solving this issue involves the application of the Kalman Filter (KF) or the Extended Kalman Filter (EKF), for linear and nonlinear systems, respectively; although in both cases, the estimation heavily relies on linear techniques. In a different way, the James-Stein Filter provides a robust approach to estimate linear and nonlinear systems under parametric uncertainties of the mathematical model. In this brief note, a slightly different James-Stein State Estimator (JSSE), named Modified James-Stein State Estimator (JSSE-M), is presented as an alternative to filtering the states of nonlinear systems within a control scheme. The main contribution of this paper is the comparison of performance between KF, EKF, JSSE, and JSSE-M when they are used on a relatively complex nonlinear system which is extremely dependent on its parameters, namely the quadrotor. In this sense, some interesting comparisons focused on both, the effectiveness and processing time are provided.","['Kalman filters', 'Nonlinear systems', 'Estimation', 'Noise measurement', 'Uncertainty', 'Mathematical model', 'Rotors']","['Control systems', 'nonlinear systems', 'stochastic systems', 'state estimation', 'filtering']"
"Deep convolutional networks have demonstrated state-of-the-art performance on various challenging medical image processing tasks. Leveraging images from different modalities for the same analysis task holds large clinical benefits. However, the generalization capability of deep networks on test data sampled from different distribution remains as a major challenge. In this paper, we propose a plug-and-play adversarial domain adaptation network (PnP-AdaNet) for adapting segmentation networks between different modalities of medical images, e.g., MRI and CT. We tackle the significant domain shift by aligning the feature spaces of source and target domains at multiple scales in an unsupervised manner. With the adversarial loss, we learn a domain adaptation module which flexibly replaces the early encoder layers of the source network, and the higher layers are shared between two domains. We validate our domain adaptation method on cardiac segmentation in unpaired MRI and CT, with four different anatomical structures. The average Dice achieved 63.9%, which is a significant recover from the complete failure (Dice score of 13.2%) if we directly test an MRI segmentation network on CT data. In addition, our proposed PnP-AdaNet outperforms many state-of-the-art unsupervised domain adaptation approaches on the same dataset. The experimental results with comprehensive ablation studies have demonstrated the excellent efficacy of our proposed method for unsupervised cross-modality domain adaptation. Our code is publically available at https://github.com/carrenD/Medical-Cross-Modality-Domain-Adaptation","['Image segmentation', 'Magnetic resonance imaging', 'Computed tomography', 'Feature extraction', 'Task analysis', 'Biomedical imaging', 'Adaptation models']","['Domain adaptation', 'adversarial learning', 'cardiac segmentation', 'medical imaging']"
"The rapid development of the Internet of Things (IoT) and the explosive growth of valuable data produced by user equipment have led to strong demand for access control, especially hierarchical access control, which is performed from a group communication perspective. However, the key management strategies for such a future Internet are based mostly on a trusted third party that requires full trust of the key generation center (KGC) or central authority (CA). Recent studies indicate that centralized cloud centers will be unlikely to deliver satisfactory services to customers because we place too much trust in third parties; therefore, these centers do not apply to user privacy-oriented scenarios. This paper addresses these issues by proposing a novel blockchain-based distributed key management architecture (BDKMA) with fog computing to reduce latency and multiblockchains operated in the cloud to achieve cross-domain access. The proposed scheme utilizes blockchain technology to satisfy the decentralization, fine-grained auditability, high scalability, and extensibility requirements, as well as the privacy-preserving principles for hierarchical access control in IoT. We designed system operations methods and introduced different authorization assignment modes and group access patterns to reinforce the extensibility. We evaluated the performance of our proposed architecture and compared it with existing models using various performance measures. The simulation results show that the multiblockchain structure substantially improves system performance, and the scalability is excellent as the network size increases. Furthermore, dynamic transaction collection time adjustment enables the performance and system capacity to be optimized for various environments.","['Blockchain', 'Access control', 'Cloud computing', 'Internet of Things', 'Resilience', 'Computer architecture']","['Blockchain', 'fog computing', 'hierarchical key management', 'Internet of Things']"
"For secure communication between any two neighboring sensing devices on the Internet of Things (IoT) environment, it is essential to design a secure device access control and key agreement protocol, in which the two phases, namely, “node authentication” and “key agreement” are involved. While the node authentication allows two sensing devices to authenticate each other using their own pre-loaded secret credentials in memory, the key agreement phase permits to establish a secret key between them if the mutual authentication is successful. In this paper, we propose a new certificate-based “lightweight access control and key agreement protocol in the IoT environment, called LACKA-IoT,” that utilizes the elliptic curve cryptography (ECC) along with the “collision-resistant one-way cryptographic hash function.” Through a detailed security analysis using the formal security under the “Real-Or-Random (ROR) model,” informal (non-mathematical) security analysis, and formal security verification using the broadly used “Automated Validation of Internet Security Protocols and Applications (AVISPA)” tool, we show that the LACKA-IoT can protect various known attacks that are needed for a secure device access control mechanism in the IoT. Furthermore, through a comparative study of the LACKA-IoT and other relevant schemes, we show that there is a better tradeoff among the security and functionality features and communication and computational costs of the LACKA-IoT as compared to other schemes. Finally, the “practical demonstration using the NS2 simulation” has been carried out on the LACKA-IoT to measure various network parameters.","['Smart devices', 'Access control', 'Protocols', 'Authentication', 'Internet of Things', 'Tools']","['Internet of Things (IoT)', 'smart devices', 'device access control', 'key agreement', 'security', 'AVISPA']"
"Narrowband Internet of Things (NB-IoT) is the prominent technology that fits the requirements of future IoT networks. However, due to the limited spectrum (i.e., 180 kHz) availability for NB-IoT systems, one of the key issues is how to efficiently use these resources to support massive IoT devices? Furthermore, in NB-IoT, to reduce the computation complexity and to provide coverage extension, the concept of time offset and repetition has been introduced. Considering these new features, the existing resource management schemes are no longer applicable. Moreover, the allocation of frequency band for NB-IoT within LTE band, or as a standalone, might not be synchronous in all the cells, resulting in intercell interference (ICI) from the neighboring cells’ LTE users or NB-IoT users (synchronous case). In this paper, first a theoretical framework for the upper bound on the achievable data rate is formulated in the presence of control channel and repetition factor. From the conducted analysis, it is shown that the maximum achievable data rates are 89.2 Kbps and 92 Kbps for downlink and uplink, respectively. Second, we propose an interference aware resource allocation for NB-IoT by formulating the rate maximization problem considering the overhead of control channels, time offset, and repetition factor. Due to the complexity of finding the globally optimum solution of the formulated problem, a sub-optimal solution with an iterative algorithm based on cooperative approaches is proposed. The proposed algorithm is then evaluated to investigate the impact of repetition factor, time offset and ICI on the NB-IoT data rate, and energy consumption. Furthermore, a detailed comparison between the non-cooperative, cooperative, and optimal scheme (i.e., no repetition) is also presented. It is shown through the simulation results that the cooperative scheme provides up to 8% rate improvement and 17% energy reduction as compared with the non-cooperative scheme.","['Resource management', 'Downlink', 'Uplink', 'Long Term Evolution', 'Interference', 'Internet of Things', 'Data communication']","['Narrowband Internet of Things (NB-IoT)', 'radio resource allocation', 'power allocation', 'repetition factor', 'system-level evaluation']"
"The image segmentation refers to the extraction of region of interest and it plays a vital role in medical image processing. This work proposes multilevel thresholding based on optimization technique for the extraction of region of interest and compression of DICOM images by an improved prediction lossless algorithm for telemedicine applications. The role of compression algorithm is inevitable in data storage and transfer. Compared to the conventional thresholding, multilevel thresholding technique plays an efficient role in image analysis. In this paper, the Particle Swarm Optimization (PSO), Darwinian Particle Swarm Optimization (DPSO), and Fractional Order Darwinian Particle Swarm Optimization (FODPSO) are employed in the estimation of the threshold value. The simulation results reveal that the FODPSO-based multilevel level thresholding generate superior results. The fractional coefficient in FODPSO algorithm makes it effective optimization with fast convergence rate. The classification and blending prediction-based lossless compression algorithm generates efficient results when compared with the JPEG lossy and JPEG lossless approaches. The algorithms are tested for various threshold values and higher value of PSNR indicates the proficiency of the proposed segmentation approach. The performance of the compression algorithms was validated by metrics and was found to be appropriate for data transfer in telemedicine. The algorithms are developed in Matlab2010a and tested on DICOM CT images.","['Image segmentation', 'Particle swarm optimization', 'Optimization', 'Image coding', 'Prediction algorithms', 'Compression algorithms', 'Biomedical imaging']","['Compression', 'Darwinian Particle Swarm Optimization', 'Fractional Order Darwinian Particle Swarm Optimization', 'Particle Swarm Optimization', 'segmentation', 'thresholding']"
"Wide-scale adoption and projected growth of electric vehicles (EVs) necessitate research and development of power electronic converters to achieve high power, low-cost, and reliable charging solutions for the EV battery. This paper presents a comprehensive review of EV off-board chargers that consist of ac-dc and dc-dc power stages from the power network to the EV battery. Although EV chargers are categorized into two types, namely, on-board and off-board chargers, it is essential to utilize off-board chargers for dc fast and ultra-fast charging so that volume and weight of EV can be reduced significantly. Here, we discuss the state-of-the-art topologies and control methods of both ac-dc and dc-dc power stages for off-board chargers, focusing on technical details, ongoing progress, and challenges. In addition, most of the recent multiport EV chargers integrating PV, energy storage, EV, and grid are presented. Moreover, comparative analysis has been carried out for the topologies and the control schemes of ac-dc rectifiers, dc-dc converters, and multiport converters in terms of architecture, power and voltage levels, efficiency, bidirectionality, control variables, advantages, and disadvantages which can be used as a guideline for future research directions in EV charging solutions.","['Topology', 'Batteries', 'Electric vehicle charging', 'Costs', 'Voltage control', 'Power system reliability', 'Power system harmonics']","['Charging stations', 'converter control', 'converter topologies', 'DC fast chargers', 'electric vehicle (EV)', 'EV fast chargers', 'multilevel AC-DC converter', 'multiport converter', 'off-board charger']"
"The tremendously growing problem of phishing e-mail, also known as spam including spear phishing or spam borne malware, has demanded a need for reliable intelligent anti-spam e-mail filters. This survey paper describes a focused literature survey of Artificial Intelligence (AI) and Machine Learning (ML) methods for intelligent spam email detection, which we believe can help in developing appropriate countermeasures. In this paper, we considered 4 parts in the email's structure that can be used for intelligent analysis: (A) Headers Provide Routing Information, contain mail transfer agents (MTA) that provide information like email and IP address of each sender and recipient of where the email originated and what stopovers, and final destination. (B) The SMTP Envelope, containing mail exchangers' identification, originating source and destination domains\users. (C) First part of SMTP Data, containing information like from, to, date, subject - appearing in most email clients (D) Second part of SMTP Data, containing email body including text content, and attachment. Based on the number the relevance of an emerging intelligent method, papers representing each method were identified, read, and summarized. Insightful findings, challenges and research problems are disclosed in this paper. This comprehensive survey paves the way for future research endeavors addressing theoretical and empirical aspects related to intelligent spam email detection.","['Unsolicited e-mail', 'Phishing', 'Machine learning', 'Companies', 'Malware']","['Machine learning', 'phishing attack', 'spear phishing', 'spam detection', 'spam email', 'spam filtering']"
"This paper presents a novel energy-management method for a microgrid that includes renewable energy, diesel generators, battery storage, and various loads. We assume that the microgrid takes part in a pool market and responds actively to the electricity price to maximize its profit by scheduling its controllable resources. To address various uncertainties, a risk-constrained scenario-based stochastic programming framework is proposed using the conditional value at risk method. The designed model is solved by two levels of stochastic optimization methods. One level of optimization is to submit optimal hourly bids to the day-ahead market under the forecast data. The other level of optimization is to determine the optimal scheduling using the scenario-based stochastic data of the uncertain resources. The proposed energy management system is not only beneficial for the microgrid and customers, but also applies the microgrid aggregator and virtual power plant. The results are shown to prove the validity of the proposed framework.","['Microgrids', 'Stochastic processes', 'Wind turbines', 'Renewable energy sources', 'Uncertainty', 'Reactive power', 'Electricity supply industry']","['Controllable load', 'Smart grid', 'Energy management', 'Electricity market', 'Microgrid', 'Renewable energy', 'Risk management', 'Stochastic optimization']"
"Minimum entropy deconvolution (MED) is widely used in the gearbox fault diagnosis because it can enhance the energy of the impact signal. However, it is sensitive to single abnormal impulsive oscillation. This is because it takes kurtosis as the objective function and solves the optimal filter by iteration. In addition, the filter length is not adaptive and needs to be determined artificially. This paper proposes a maximum kurtosis spectral entropy deconvolution (MKSED) method and applies it to bearing fault diagnosis. Considering that the kurtosis spectral entropy has the advantage of highlighting the continuous impact oscillation, the kurtosis spectral entropy is chosen as the objective function of deconvolution. At the same time, kurtosis spectral entropy is also used as the fitness function of improved local particle swarm optimization algorithm (LPSO), and the filter length is optimized by LPSO, which makes that MKSED adaptively determines the length of the filter while solving the deconvolution, so that it can accurately extract the continuous pulse signal. The results of the simulation signal analysis show that the proposed MKSED method is superior to MED, and the proposed method is applied to bearing fault diagnosis, which verifies its ability to extract continuous impact.","['Entropy', 'Deconvolution', 'Fault diagnosis', 'Particle swarm optimization', 'Linear programming', 'Finite impulse response filters', 'Machinery']","['Minimum entropy deconvolution', 'particle swarm optimization', 'maximum kurtosis spectral entropy deconvolution', 'fault diagnosis']"
"Nowadays, blockchain has become one of the most cutting-edge technologies, which has been widely concerned and researched. However, the quantum computing attack seriously threatens the security of blockchain, and related research is still less. Targeting at this issue, in this paper, we present the definition of post-quantum blockchain (PQB) and propose a secure cryptocurrency scheme based on PQB, which can resist quantum computing attacks. First, we propose a signature scheme based on lattice problem. We use lattice basis delegation algorithm to generate secret keys with selecting a random value, and sign message by preimage sampling algorithm. In addition, we design the first-signature and last-signature in our scheme, which are defined as double-signature. It is used to reduce the correlation between the message and the signature. Second, by combining the proposed signature scheme with blockchain, we construct the PQB and propose this cryptocurrency scheme. Its security can be reduced to the lattice short integer solution (SIS) problem. At last, through our analysis, the proposed cryptocurrency scheme is able to resist the quantum computing attack and its signature satisfies correctness and one-more unforgeability under the lattice SIS assumption. Furthermore, compared with previous signature schemes, the sizes of signature and secret keys are relatively shorter than that of others, which can decrease the computational complexity. These make our cryptocurrency scheme more secure and efficient.","['Lattices', 'Cryptocurrency', 'Quantum computing', 'Computer security']","['Blockchain', 'post-quantum', 'lattice', 'cryptocurrency', 'security']"
"This article assesses the energy management of reconfigurable residential smart hybrid AC/DC microgrids considering the combined heat and power (CHP) loads as well as the electric vehicles charging/discharging behaviors. A holistic model is developed for the proton exchange membrane fuel cell to retrieve the unwanted thermal energy generated at the operation time. The proposed model makes use of the unoccupied capacity of the fuel cell for producing/storing hydrogen for the later usage and increasing its efficiency. A stochastic framework is designed using point estimate method (PEM) to capture the uncertainties of the photovoltaic and wind turbine forecast error, power company price, the operating temperature of the proton exchange membrane fuel cell, the price for natural gas, price for selling hydrogen, and the pressure of the H2 and O2 in the fuel cell stack. The PEM approach has shown superior advantages in terms of accuracy and running time. Considering the complex and nonlinear structure of the proposed framework, a proficient optimization technique based on the teacher learning algorithm (TLA) is devised. A two-phase modification method is proposed to increase the algorithm variety and help its convergence characteristics. The performance of the proposed algorithm is compared with the TLA, particle swarm optimization (PSO) algorithm and genetic algorithm (GA). For enhancing the security of the energy and data transaction within the system, a directed acyclic graph (DAG)-based security framework is introduced to guarantee the performance of the system against the subversive accesses. By using this scheme, the essential data of the units are recorded and secured in the form of public, private and transaction blockchains. The economic characteristics of the proposed method are assessed on a residential hybrid AC-DC microgrid test system.","['Microgrids', 'Hydrogen', 'Economics', 'Fuel cells', 'Hybrid power systems', 'Companies', 'Batteries']","['Combined heat and power', 'smart AC-DC microgrid', 'point estimate method', 'uncertainty', 'energy management']"
"Accurate segmentation of brain tumor is an indispensable component for cancer diagnosis and treatment. In this paper, we propose a novel brain tumor segmentation method based on multi-cascaded convolutional neural network (MCCNN) and fully connected conditional random fields (CRFs). The segmentation process mainly includes the following two steps. First, we design a multi-cascaded network architecture by combining the intermediate results of several connected components to take the local dependencies of labels into account and make use of multi-scale features for the coarse segmentation. Second, we apply CRFs to consider the spatial contextual information and eliminate some spurious outputs for the fine segmentation. In addition, we use image patches obtained from axial, coronal, and sagittal views to respectively train three segmentation models, and then combine them to obtain the final segmentation result. The validity of the proposed method is evaluated on three publicly available databases. The experimental results show that our method achieves competitive performance compared with the state-of-the-art approaches.","['Image segmentation', 'Tumors', 'Brain modeling', 'Feature extraction', 'Convolutional neural networks', 'Magnetic resonance imaging', 'Three-dimensional displays']","['Brain tumor segmentation', 'convolutional neural network', 'multi-cascaded convolutional neural network', 'conditional random field', 'multi-modality']"
"Network densification, massive multiple-input multiple-output (MIMO), and millimeter-wave (mmWave) bands have recently emerged as some of the physical layer enablers for the future generations of wireless communication networks (5G and beyond). Grounded on prior work on sub-6-GHz cell-free massive MIMO architectures, a novel framework for cell-free mmWave massive MIMO systems is introduced that considers the use of low-complexity hybrid precoders/decoders while factors in the impact of using capacity-constrained fronthaul links. A suboptimal pilot allocation strategy is proposed that is grounded on the idea of clustering by dissimilarity. Furthermore, based on mathematically tractable expressions for the per-user achievable rates and the fronthaul capacity consumption, max-min power allocation and fronthaul quantization optimization algorithms are proposed that, combining the use of block coordinate descent methods with sequential linear optimization programs, ensure a uniformly good quality of service over the whole coverage area of the network. The simulation results show that the proposed pilot allocation strategy eludes the computational burden of the optimal small-scale CSI-based scheme while clearly outperforming the classical random pilot allocation approaches. Moreover, they also reveal the various existing trade-offs among the achievable max-min per-user rate, the fronthaul requirements, and the optimal hardware complexity (i.e., the number of antennas and the number of RF chains).","['MIMO communication', 'Radio frequency', 'Resource management', 'Antenna arrays', 'Quantization (signal)', 'Array signal processing']","['Cell-free', 'massive MIMO', 'millimeter wave', 'hybrid precoding', 'constrained-capacity fronthaul']"
"Containers emerged as a lightweight alternative to virtual machines (VMs) that offer better microservice architecture support. The value of the container market is expected to reach 2.7 billion in 2020 as compared to 762 million in 2016. Although they are considered the standardized method for microservices deployment, playing an important role in cloud computing emerging fields such as service meshes, market surveys show that container security is the main concern and adoption barrier for many companies. In this paper, we survey the literature on container security and solutions. We have derived four generalized use cases that should cover security requirements within the host-container threat landscape. The use cases include: (I) protecting a container from applications inside it, (II) inter-container protection, (III) protecting the host from containers, and (IV) protecting containers from a malicious or semi-honest host. We found that the first three use cases utilize a software-based solutions that mainly rely on Linux kernel features (e.g., namespaces, CGroups, capabilities, and seccomp) and Linux security modules (e.g., AppArmor). The last use case relies on hardware-based solutions such as trusted platform modules (TPMs) and trusted platform support (e.g., Intel SGX). We hope that our analysis will help researchers understand container security requirements and obtain a clearer picture of possible vulnerabilities and attacks. Finally, we highlight open research problems and future research directions that may spawn further research in this area.","['Containers', 'Security', 'Computer architecture', 'Kernel', 'Cloud computing', 'Linux']","['Containers', 'Docker', 'Linux containers', 'OS level virtualization', 'lightweight virtualization', 'security', 'survey']"
"Breast cancer is one of the most dangerous diseases and the second largest cause of female cancer death. Breast cancer starts when malignant, cancerous lumps start to grow from the breast cells. Self-tests and Periodic clinical checks help to early diagnosis and thereby improve the survival chances significantly. The breast cancer classification is a medical method that provides researchers and scientists with a great challenge. Neural networks have recently become a popular tool in cancer data classification. In this paper, Deep Learning assisted Efficient Adaboost Algorithm (DLA-EABA) for breast cancer detection has been mathematically proposed with advanced computational techniques. In addition to traditional computer vision approaches, tumor classification methods using transfers are being actively developed through the use of deep convolutional neural networks (CNNs). This study starts with examining the CNN-based transfer learning to characterize breast masses for different diagnostic, predictive tasks or prognostic or in several imaging modalities, such as Magnetic Resonance Imaging (MRI), Ultrasound (US), digital breast tomosynthesis and mammography. The deep learning framework contains several convolutional layers, LSTM, Max-pooling layers. The classification and error estimation that has been included in a fully connected layer and a softmax layer. This paper focuses on combining these machine learning approaches with the methods of selecting features and extracting them through evaluating their output using classification and segmentation techniques to find the most appropriate approach. The experimental results show that the high accuracy level of 97.2%, Sensitivity 98.3%, and Specificity 96.5% has been compared to other existing systems.","['Breast cancer', 'Machine learning', 'Feature extraction', 'Training', 'Classification algorithms']","['Breast cancer detection', 'deep learning', 'convolutional neural network', 'MRI', 'CT', 'US', 'long short-term memory']"
"Information hiding aims to embed secret data into the multimedia, such as image, audio, video, and text. In this paper, two new quantum information hiding approaches are put forward. A quantum steganography approach is proposed to hide a quantum secret image into a quantum cover image. The quantum secret image is encrypted first using a controlled-NOT gate to demonstrate the security of the embedded data. The encrypted secret image is embedded into the quantum cover image using the two most and least significant qubits. In addition, a quantum image watermarking approach is presented to hide a quantum watermark gray image into a quantum carrier image. The quantum watermark image, which is scrambled by utilizing Arnold's cat map, is then embedded into the quantum carrier image using the two least and most significant qubits. Only the watermarked image and the key are sufficient to extract the embedded quantum watermark image. The proposed novelty has been illustrated using a scenario of sharing medical imagery between two remote hospitals. The simulation and analysis demonstrate that the two newly proposed approaches have excellent visual quality and high embedding capacity and security.","['Watermarking', 'Medical services', 'Cryptography', 'Quantum mechanics', 'Image processing', 'Logistics', 'Biomedical imaging']","['Medical images', 'quantum image processing', 'steganography', 'watermarking']"
"Future buildings will offer new convenience, comfort, and efficiency possibilities to their residents. Changes will occur to the way people live as technology involves people's lives and information processing is fully integrated into their daily living activities and objects. The future expectation of smart buildings includes making the residents' experience as easy and comfortable as possible. The massive streaming data generated and captured by smart building appliances and devices contain valuable information that needs to be mined to facilitate timely actions and better decision making. Machine learning and big data analytics will undoubtedly play a critical role to enable the delivery of such smart services. In this paper, we survey the area of smart building with a special focus on the role of techniques from machine learning and big data analytics. This survey also reviews the current trends and challenges faced in the development of smart building services.","['Smart homes', 'Big Data', 'Machine learning', 'Internet of Things', 'Robot sensing systems', 'Smart buildings']","['Smart buildings', 'smart homes', 'the Internet of Things (IoT)', 'big data analytics', 'machine learning (ML)']"
"In this paper, a novel energy storage method based on pumped hydropower energy storage (PHES) for a renewable energy integrated micro-grid (REMG) is proposed, and the load frequency control (LFC) for the system is studied. In a typical REMG, micro pumped storage units are built that rely on a tall building to convert energy by pumping water up to store energy and releasing the stored water to generate energy. Because of the fluctuation of renewable energy (RE) and the perturbation of the load demand, frequency deviation, and tie-line power interchange are inevitable. In this paper, the LFC controller optimization problem for the REMG is investigated, and the optimal controllers for multi-areas in the REMG are designed. To solve the optimization problem of LFC, a novel meta-heuristic algorithm called artificial sheep algorithm (ASA) is applied in the task of LFC optimization. In the experiments, RE scenarios of different seasons, the impact of PHES, and the control robustness are studied. The results not only prove the feasibility of the proposed REMG but also show the effectiveness of the optimized controllers in maintaining frequency stability under various conditions.","['Buildings', 'Optimization', 'Reservoirs', 'Frequency control', 'Photovoltaic systems', 'Hydroelectric power generation', 'Energy storage']","['Renewable energy integrated micro-grid', 'micro pumped storage unit', 'load frequency control', 'artificial sheep algorithm', 'controller optimization']"
"Emotion detection and recognition from text is a recent essential research area in Natural Language Processing (NLP) which may reveal some valuable input to a variety of purposes. Nowadays, writings take many forms of social media posts, micro-blogs, news articles, customer review, etc., and the content of these short-texts can be a useful resource for text mining to discover an unhide various aspects, including emotions. The previously presented models mainly adopted word embedding vectors that represent rich semantic/syntactic information and those models cannot capture the emotional relationship between words. Recently, some emotional word embeddings are proposed but it requires semantic and syntactic information vice versa. To address this issue, we proposed a novel neural network architecture, called SENN (Semantic-Emotion Neural Network) which can utilize both semantic/syntactic and emotional information by adopting pre-trained word representations. SENN model has mainly two sub-networks, the first sub-network uses bidirectional Long-Short Term Memory (BiLSTM) to capture contextual information and focuses on semantic relationship, the second sub-network uses the convolutional neural network (CNN) to extract emotional features and focuses on the emotional relationship between words from the text. We conducted a comprehensive performance evaluation for the proposed model using standard real-world datasets. We adopted the notion of Ekman's six basic emotions. The experimental results show that the proposed model achieves a significantly superior quality of emotion recognition with various state-of-the-art approaches and further can be improved by other emotional word embeddings.","['Emotion recognition', 'Semantics', 'Neural networks', 'Task analysis', 'Deep learning', 'Dictionaries']","['Emotion recognition', 'natural language processing', 'deep learning']"
"As novel technologies continue to reshape the digital era, cyberattacks are also increasingly becoming more commonplace and sophisticated. Distributed denial of service (DDoS) attacks are, perhaps, the most prevalent and exponentially-growing attack, targeting the varied and emerging computational network infrastructures across the globe. This necessitates the design of an efficient and early detection of large-scale sophisticated DDoS attacks. Software defined networks (SDN) point to a promising solution, as a network paradigm which decouples the centralized control intelligence from the forwarding logic. In this work, a deep convolutional neural network (CNN) ensemble framework for efficient DDoS attack detection in SDNs is proposed. The proposed framework is evaluated on a current state-of-the-art Flow-based dataset under established benchmarks. Improved accuracy is demonstrated against existing related detection approaches.","['Computer crime', 'Machine learning', 'Software', 'Anomaly detection', 'Feature extraction', 'Benchmark testing', 'Computer architecture']","['Software defined network (SDN)', 'anomaly detection', 'distributed denial of service (DDoS)', 'deep learning', 'deep convolutional neural network (CNN)']"
"Chronic kidney disease (CKD) is a global health problem with high morbidity and mortality rate, and it induces other diseases. Since there are no obvious symptoms during the early stages of CKD, patients often fail to notice the disease. Early detection of CKD enables patients to receive timely treatment to ameliorate the progression of this disease. Machine learning models can effectively aid clinicians achieve this goal due to their fast and accurate recognition performance. In this study, we propose a machine learning methodology for diagnosing CKD. The CKD data set was obtained from the University of California Irvine (UCI) machine learning repository, which has a large number of missing values. KNN imputation was used to fill in the missing values, which selects several complete samples with the most similar measurements to process the missing data for each incomplete sample. Missing values are usually seen in real-life medical situations because patients may miss some measurements for various reasons. After effectively filling out the incomplete data set, six machine learning algorithms (logistic regression, random forest, support vector machine, k-nearest neighbor, naive Bayes classifier and feed forward neural network) were used to establish models. Among these machine learning models, random forest achieved the best performance with 99.75% diagnosis accuracy. By analyzing the misjudgments generated by the established models, we proposed an integrated model that combines logistic regression and random forest by using perceptron, which could achieve an average accuracy of 99.83% after ten times of simulation. Hence, we speculated that this methodology could be applicable to more complicated clinical data for disease diagnosis.","['Diseases', 'Machine learning', 'Feature extraction', 'Support vector machines', 'Analytical models', 'Kidney', 'Neural networks']","['Chronic kidney disease', 'machine learning', 'KNN imputation', 'integrated model']"
"In recent years, recommendation systems have been widely used in various commercial platforms to provide recommendations for users. Collaborative filtering algorithms are one of the main algorithms used in recommendation systems. Such algorithms are simple and efficient; however, the sparsity of the data and the scalability of the method limit the performance of these algorithms, and it is difficult to further improve the quality of the recommendation results. Therefore, a model combining a collaborative filtering recommendation algorithm with deep learning technology is proposed, therein consisting of two parts. First, the model uses a feature representation method based on a quadric polynomial regression model, which obtains the latent features more accurately by improving upon the traditional matrix factorization algorithm. Then, these latent features are regarded as the input data of the deep neural network model, which is the second part of the proposed model and is used to predict the rating scores. Finally, by comparing with other recommendation algorithms on three public datasets, it is verified that the recommendation performance can be effectively improved by our model.","['Matrix decomposition', 'Machine learning', 'Collaboration', 'Algorithm design and analysis', 'Data models', 'Artificial neural networks']","['Recommendation system', 'collaborative filtering', 'quadric polynomial regression', 'deep neural network (DNN)']"
"Cardiovascular diseases currently pose the highest threat to human health around the world. Proper investigation of the abnormalities in heart sounds is known to provide vital clinical information that can assist in the diagnosis and management of cardiac conditions. However, despite significant advances in the development of algorithms for automated classification and analysis of heart sounds, the validity of different approaches has not been systematically reviewed. This paper provides an in-depth systematic review and critical analysis of all the existing approaches for automatic identification and classification of the heart sounds. All statements on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses 2009 Checklist were followed and addressed thoroughly to maintain the quality of the accounted systematic review. Out of 1347 research articles available in the academic databases from 1963 to 2018, 117 peer-reviewed articles were found to fall under the search and selection criteria of this paper. Amongst them: 53 articles are focused on segmentation, 72 of the studies are related to the feature extraction approaches and 88 to classification, and 56 reported on the databases and heart sounds acquisition. From this review, it is clear that, although a lot of research has been done in the field of automated analysis, there is still some work to be done to develop robust methods for identification and classification of various events in the cardiac cycle so that this could be effectively used to improve the diagnosis and management of cardiovascular diseases in combination with the wearable mobile technologies.","['Heart', 'Systematics', 'Feature extraction', 'Databases', 'Biomedical monitoring', 'Monitoring', 'Classification algorithms']","['Segmentation', 'feature extraction', 'classification', 'heart sounds databases', 'wearable cardiac monitoring', 'heart sounds analysis']"
"Due to the potential security problem about key management and distribution for the symmetric image encryption schemes, a novel asymmetric image encryption method is proposed in this paper, which is based on the elliptic curve ElGamal (EC-ElGamal) cryptography and chaotic theory. Specifically, the SHA-512 hash is first adopted to generate the initial values of a chaotic system, and a crossover permutation in terms of chaotic index sequence is used to scramble the plain-image. Furthermore, the generated scrambled image is embedded into the elliptic curve for the encrypted by EC-ElGamal which can not only improve the security but also can help solve the key management problems. Finally, the diffusion combined chaos game with DNA sequence is executed to get the cipher image. The experimental analysis and performance comparisons demonstrate that the proposed method has high security, good efficiency, and strong robustness against the chosen-plaintext attack which make it have potential applications for the image secure communications.","['Encryption', 'Elliptic curves', 'Elliptic curve cryptography', 'DNA', 'Chaotic communication']","['SHA-512 hash', 'elliptic curve ElGamal encryption', 'chaos game', 'crossover permutation']"
"Position-estimation systems for indoor localization play an important role in everyday life. The global positioning system (GPS) is a popular positioning system, which is mainly efficient for outdoor environments. In indoor scenarios, GPS signal reception is weak. Therefore, achieving good position estimation accuracy is a challenge. To overcome this challenge, it is necessary to utilize other position-estimation systems for indoor localization. However, other existing indoor localization systems, especially based on inertial measurement unit (IMU) sensor data, still face challenges such as accumulated errors from sensors and external magnetic field effects. This paper proposes a position-estimation algorithm that uses the combined features of the accelerometer, magnetometer, and gyroscope data from an IMU sensor for position estimation. In this paper, we first estimate the pitch and roll values based on a fusion of accelerometer and gyroscope sensor values. The estimated pitch values are used for step detection. The step lengths are estimated by using the pitching amplitude. The heading of the pedestrian is estimated by the fusion of magnetometer and gyroscope sensor values. Finally, the position is estimated based on the step length and heading information. The proposed pitch-based step detection algorithm achieves 2.5% error as compared with acceleration-based step detection approaches. The heading estimation proposed in this paper achieves a mean heading error of 4.72° as compared with the azimuth- and magnetometer-based approaches. The experimental results show that the proposed position-estimation algorithm achieves a high position accuracy that significantly outperforms that of conventional estimation methods used for validation in this paper.","['Estimation', 'Gyroscopes', 'Global Positioning System', 'Magnetometers', 'Acceleration', 'Sensor fusion', 'Accelerometers']","['Indoor positioning system (IPS)', 'pedestrian dead reckoning (PDR)', 'heading estimation', 'indoor navigation', 'Android-based smartphone', 'quaternion', 'Kalman filter', 'sensor fusion']"
"Agriculture is a major part of the world economy as it provides food safety. However, in recent years, it has been noted that plants are extensively infected by different diseases. This causes enormous economic losses in agriculture industry around the world. The manual inspection of fruit diseases is a difficult process which can be minimized by using automated methods for detection of plant diseases at the earlier stage. In this paper, a new method is implemented for apple diseases identification and recognition. Three pipeline procedures are followed by preprocessing, spot segmentation, and features extraction, and classification. In the first step, the apple leaf spots are enhanced by a hybrid method which is the conjunction of 3D box filtering, de-correlation, 3D-Gaussian filter, and 3D-median filter. After that, the lesion spots are segmented by the strong correlation-based method and optimized their results by fusion of expectation maximization (EM) segmentation. Finally, the color, color histogram, and local binary pattern (LBP) features are fused by comparison-based parallel fusion. The extracted features are optimized by genetic algorithm and classified by One-vs-All M-SVM. The experimental results are performed on plant village dataset. The proposed methodology is tested for four types of apple disease classes including healthy leaves, Blackrot, Rust, and Scab. The classification accuracy shows the improvement of our method on selected apple diseases. Moreover, the good preprocessing step always produced prominent features which later achieved significant classification accuracy.","['Diseases', 'Feature extraction', 'Image color analysis', 'Image segmentation', 'Genetic algorithms', 'Lesions', 'Support vector machines']","['Symptoms enhancement', 'symptoms segmentation', 'feature extraction', 'optimal features', 'recognition']"
"The rapid increase in network traffic has recently led to the importance of flow-based intrusion detection systems processing a small amount of traffic data. Furthermore, anomaly-based methods, which can identify unknown attacks are also integrated into these systems. In this study, the focus is concentrated on the detection of anomalous network traffic (or intrusions) from flow-based data using unsupervised deep learning methods with semi-supervised learning approach. More specifically, Autoencoder and Variational Autoencoder methods were employed to identify unknown attacks using flow features. In the experiments carried out, the flow-based features extracted out of network traffic data, including typical and different types of attacks, were used. The Receiver Operating Characteristics (ROC) and the area under ROC curve, resulting from these methods were calculated and compared with One-Class Support Vector Machine. The ROC curves were examined in detail to analyze the performance of the methods in various threshold values. The experimental results show that Variational Autoencoder performs, for the most part, better than Autoencoder and One-Class Support Vector Machine.","['Intrusion detection', 'Feature extraction', 'Telecommunication traffic', 'Deep learning', 'Support vector machines', 'Anomaly detection', 'Computer hacking']","['Flow anomaly detection', 'intrusion detection', 'deep learning', 'variational autoencoder', 'semi-supervised learning']"
"Fully convolutional deep neural networks have been asserted to be fast and precise frameworks with great potential in image segmentation. One of the major challenges in training such networks raises when the data are unbalanced, which is common in many medical imaging applications, such as lesion segmentation, where lesion class voxels are often much lower in numbers than non-lesion voxels. A trained network with unbalanced data may make predictions with high precision and low recall, being severely biased toward the non-lesion class which is particularly undesired in most medical applications where false negatives are actually more important than false positives. Various methods have been proposed to address this problem, including two-step training, sample re-weighting, balanced sampling, and more recently, similarity loss functions and focal loss. In this paper, we fully trained convolutional deep neural networks using an asymmetric similarity loss function to mitigate the issue of data imbalance and achieve much better tradeoff between precision and recall. To this end, we developed a 3D fully convolutional densely connected network (FC-DenseNet) with large overlapping image patches as input and an asymmetric similarity loss layer based on Tversky index (using $F_\beta $ scores). We used large overlapping image patches as inputs for intrinsic and extrinsic data augmentation, a patch selection algorithm, and a patch prediction fusion strategy using B-spline weighted soft voting to account for the uncertainty of prediction in patch borders. We applied this method to multiple sclerosis (MS) lesion segmentation based on two different datasets of MSSEG 2016 and ISBI longitudinal MS lesion segmentation challenge, where we achieved average Dice similarity coefficients of 69.9% and 65.74%, respectively, achieving top performance in both the challenges. We compared the performance of our network trained with $F_\beta $ loss, focal loss, and generalized Dice loss functions. Through September 2018, our network trained with focal loss ranked first according to the ISBI challenge overall score and resulted in the lowest reported lesion false positive rate among all submitted methods. Our network trained with the asymmetric similarity loss led to the lowest surface distance and the best lesion true positive rate that is arguably the most important performance metric in a clinical decision support system for lesion detection. The asymmetric similarity loss function based on $F_\beta $ scores allows training networks that make a better balance between precision and recall in highly unbalanced image segmentation. We achieved superior performance in MS lesion segmentation using a patch-wise 3D FC-DenseNet with a patch prediction fusion strategy, trained with asymmetric similarity loss functions.","['Image segmentation', 'Lesions', 'Three-dimensional displays', 'Biomedical imaging', 'Training', 'Indexes', 'Network architecture']","['Asymmetric loss function', 'Tversky index', 'Fᵦ scores', 'focal loss', 'convolutional neural network', 'FC-DenseNet', 'patch prediction fusion', 'multiple sclerosis', 'lesion segmentation', 'deep learning']"
"Breast mass is one of the most distinctive signs for the diagnosis of breast cancer, and the accurate segmentation of masses is critical for improving the accuracy of breast cancer detection and reducing the mortality rate. It is time-consuming for a physician to review the film. Besides, traditional medical segmentation techniques often require prior knowledge or manual extraction of features, which often lead to a subjective diagnosis. Therefore, developing an automatic image segmentation method is important for clinical application. In this paper, a fully automatic method based on deep learning for breast mass segmentation is proposed, which combines densely connected U-Net with attention gates (AGs). It contains an encoder and a decoder. The encoder is a densely connected convolutional network and the decoder is the decoder of U-Net integrated with AGs. The proposed method is tested on the public and authoritative database-Digital Database for Screening Mammography (DDSM) database. F1-score, mean intersection over union, sensitivity, specificity, and overall accuracy are used to evaluate the effectiveness of the proposed method. The experimental results show that dense U-Net integrated AGs achieve better segmentation results than U-Net, attention U-Net, DenseNet, and state-of-the-art methods.","['Image segmentation', 'Feature extraction', 'Breast cancer', 'Biomedical imaging', 'Shape']","['Breast masses segmentation', 'deep learning', 'biomedical image processing', 'attention gates', 'densely connected convolutional network']"
"Defect detection is an essential requirement for quality control in the production of printed circuit boards (PCBs) manufacturing. The traditional defect detection methods have various drawbacks, such as strongly depending on a carefully designed template, highly computational cost, and noise-susceptibility, which pose a significant challenge in a production environment. In this paper, a deep learning-based image detection method for PCB defect detection is proposed. This method builds a new network based on Faster RCNN. We use a ResNet50 with Feature Pyramid Networks as the backbone for feature extraction, to better detect small defects on the PCB. Secondly, we use GARPN to predict more accurate anchors and merge the residual units of ShuffleNetV2. The experimental results show that this method is more suitable for use in production than other PCB defect detection methods. We have also tested in other PCB defects dataset, and experiments have shown that this method is equally valid.","['Convolution', 'Feature extraction', 'Production', 'Inspection', 'Object detection', 'Kernel', 'Databases']","['Defect detection', 'deep learning', 'residual network', 'feature pyramid', 'ShuffleNetV2']"
"Systems based on deep neural networks have made a breakthrough in many different pattern recognition tasks. However, the use of these systems with traditional architectures seems not to work properly when the amount of training data is scarce. This is the case of the on-line signature verification task. In this paper, we propose a novel writer-independent on-line signature verification systems based on Recurrent Neural Networks (RNNs) with a Siamese architecture whose goal is to learn a dissimilarity metric from the pairs of signatures. To the best of our knowledge, this is the first time these recurrent Siamese networks are applied to the field of on-line signature verification, which provides our main motivation. We propose both Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) systems with a Siamese architecture. In addition, a bidirectional scheme (which is able to access both past and future context) is considered for both LSTMand GRU-based systems. An exhaustive analysis of the system performance and also the time consumed during the training process for each recurrent Siamese network is carried out in order to compare the advantages and disadvantages for practical applications. For the experimental work, we use the BiosecurID database comprised of 400 users who contributed a total of 11,200 signatures in four separated acquisition sessions. Results achieved using our proposed recurrent Siamese networks have outperformed the state-of-the-art on-line signature verification systems using the same database.","['Computer architecture', 'Training', 'Biometrics (access control)', 'Logic gates', 'Databases', 'Recurrent neural networks']","['Biometrics', 'deep learning', 'on-line handwritten signature verification', 'recurrent neural networks', 'LSTM', 'GRU', 'DTW', 'BiosecurID']"
"In this paper, radio-frequency (RF) electromagnetic field (EMF) exposure evaluations are conducted in the frequency range 10-60 GHz for array antennas intended for user equipment (UE) and low-power radio base stations in 5G mobile communication systems. A systematic study based on numerical power density simulations considering effects of frequency, array size, array topology, distance to exposed part of human body, and beam steering range is presented whereby the maximum transmitted power to comply with RF EMF exposure limits specified by the International Commission on Non-Ionizing Radiation Protection, the US Federal Communications Commission, and the Institute of Electrical and Electronics Engineers is determined. The maximum transmitted power is related to the maximum equivalent isotropically radiated power to highlight the relevance of the output power restrictions for a communication channel. A comparison between the simulation and measurement data is provided for a canonical monopole antenna. For small distances, with the antennas transmitting directly toward the human body, it is found that the maximum transmitted power is significantly below the UE power levels used in existing third and fourth generation mobile communication systems. Results for other conceivable exposure scenarios based on technical solutions that could allow for larger output power levels are also discussed. The obtained results constitute valuable information for the design of future mobile communication systems and for the standardization of EMF compliance assessment procedures of 5G devices and equipment.","['5G mobile communication', 'Antenna arrays', 'Beam steering', 'Handheld devices', 'Radio base stations', 'Radio frequency', 'Mobile antennas', 'Power generation', 'Antenna measurements', 'FCC']","['5G mobile communication', 'antenna arrays', 'beam steering', 'mobile device', 'mobile user equipment', 'radio base station', 'RF EMF exposure']"
"Low-power wide area (LPWA) technologies are strongly recommended as the underlying networks for Internet of Things (IoT) applications. They offer attractive features, including wide-range coverage, long battery life, and low data rates. This paper reviews the current trends in this technology, with an emphasis on the services it provides and the challenges it faces. The industrial paradigms for LPWA implementation are presented. Compared with other work in the field, this paper focuses on the need for integration among different LPWA technologies and recommends the appropriate LPWA solutions for a wide range of IoT application and service use cases. Opportunities created by these technologies in the market are also analyzed. The latest research efforts to investigate and improve the operation of LPWA networks are also compared and classified to enable researchers to quickly get up to speed on the current status of this technology. Finally, challenges facing LPWA are identified and directions for future research are recommended.","['Wireless communication', 'Bluetooth', 'Machine-to-machine communications', 'ZigBee', 'Wireless fidelity', 'Wireless sensor networks', 'Industries']","['Cellular', 'Internet of Things', 'IoT', 'low power wide area', 'low power wide area network', 'LPWA', 'LPWAN', 'M2M', 'machine-to-machine', 'wireless']"
"The inceptions of multilevel inverters (MLI) have caught the attention of researchers for medium and high power applications. However, there has always been a need for a topology with a lower number of device count for higher efficiency and reliability. A new single-phase MLI topology has been proposed in this paper to reduce the number of switches in the circuit and obtain higher voltage level at the output. The basic unit of the proposed topology produces 13 levels at the output with three dc voltage sources and eight switches. Three extentions of the basic unit have been proposed in this paper. A detailed analysis of the proposed topology has been carried out to show the superiority of the proposed converter with respect to the other existing MLI topologies. Power loss analysis has been done using PLECS software, resulting in a maximum efficiency of 98.5%. Nearest level control (NLC) pulse-width modulation technique has been used to produce gate pulses for the switches to achieve better output voltage waveform. The various simulation results have been performed in the PLECS software and a laboratory setup has been used to show the feasibility of the proposed MLI topology.","['Topology', 'Switches', 'Through-silicon vias', 'Inverters', 'Stress', 'Power supplies', 'Mathematical model']","['DC–AC converter', 'multilevel inverter', 'reduce switch count', 'nearest level control (NLC)']"
"In order to further improve the system capacity, we explore the integration of non-orthogonal multiple access (NOMA) in millimeter-wave communications (mmWave-NOMA) for future B5G and 6G systems. Compared with the conventional NOMA, the distinguishing feature of mmWave-NOMA is that, it is usually characterized by transmit/receive beamforming with large phased arrays. In this paper, we focus on the design challenges of mmWave-NOMA due to beamforming. Firstly, we study how beamforming affects the sum-rate performance of mmWave-NOMA, and find that with conventional single-beam forming, the performance may be offset by the relative angle between NOMA users. Then, we consider multi-beam forming for mmWave-NOMA, which is shown to be able to achieve promising performance enhancement as well as robustness. Next, we investigate the challenging joint design of the intertwined power allocation and user pairing for mmWave-NOMA. Relevant challenges are discussed and some potential solutions are proposed in detail. We further consider hybrid spatial division multiple access (SDMA) and NOMA in mmWave communications, where some possible system configurations and the corresponding solutions are discussed to address the multi-user issues including multi-user precoding and multi-user interference mitigation. Finally, we present future directions in mmWave-NOMA and summarize the paper.","['NOMA', 'Array signal processing', 'Millimeter wave communication', 'Gain', 'Resource management', 'Radio frequency', '6G mobile communication']","['Millimeter-wave (mmWave)', 'non-orthogonal multiple access (NOMA)', 'mmWave-NOMA', 'beamforming']"
"In this paper, we propose a drone assisted radio access networks architecture in which drone-cells are leveraged to relay data between base stations and users. Based on the state-of-the-art drone-to-user and drone-to-base station (D2B) channel models, we first analyze the user coverage and the D2B backhaul connection features of drone-cells. We then formulate the 3-D drone-cell deployment problem with the objective of maximizing the user coverage while maintaining D2B link qualities, for a given number of drone cells being deployed. To solve the problem, the particle swarm optimization (PSO) algorithm is leveraged for its low computational cost and unique features suiting the spatial deployment of drone-cells. We propose a per-drone iterated PSO (DI-PSO) algorithm that optimizes drone-cell deployments for different drone-cell numbers, and prevents the drawbacks of the pure PSO-based algorithm derived from related works. Simulations show that the DI-PSO algorithm can achieve higher coverage ratio with less complexity comparing to the pure PSO-based algorithm.","['Drones', 'Algorithm design and analysis', 'Radio access networks', 'Three-dimensional displays', 'Reliability', 'Electronic mail', 'Optimization']","['Drone', 'drone communication', 'radio access networks', 'particle swarm optimization', 'D2U', 'D2B']"
"Recent network research has demonstrated that the performance of convolutional neural networks can be improved by introducing a learning block that captures spatial correlations. In this paper, we propose a novel multiple feature reweight DenseNet (MFR-DenseNet) architecture. The MFR-DenseNet improves the representation power of the DenseNet by adaptively recalibrating the channel-wise feature responses and explicitly modeling the interdependencies between the features of different convolutional layers. First, in order to perform dynamic channel-wise feature recalibration, we construct the channel feature reweight DenseNet (CFR-DenseNet) by introducing the squeeze-and-excitation module (SEM) to DenseNet. Then, to model the interdependencies between the features of different convolutional layers, we propose the double squeeze-and-excitation module (DSEM) and construct the inter-layer feature reweight DenseNet (ILFR-DenseNet). In the last step, we designed the MFR-DenseNet by combining the CFR-DenseNet and the ILFR-DenseNet with an ensemble learning approach. Our experiments demonstrate the effectiveness of CFR-DenseNet, ILFR-DenseNet, and MFR-DenseNet. More importantly, the MFR-DenseNet drops the error rate on CIFAR-10 and CIFAR-100 by a large margin with significantly fewer parameters. Our 100-layer MFR-DenseNet (with 7.1M parameters) model achieves competitive results on CIFAR-10 and CIFAR-100 data sets, with test errors of 3.57% and 18.27% respectively, achieving a 4.5% relative improvement on CIFAR-10 and a 5.09% relative improvement on CIFAR-100 over the best result of DenseNet (with 27.2M parameters).","['Adaptation models', 'Correlation', 'Training', 'Convolutional neural networks', 'Feature extraction', 'Task analysis', 'Computer architecture']","['CFR-DenseNet', 'DenseNet', 'DSEM', 'image classification', 'ILFR-DenseNet', 'MFR-DenseNet']"
"Network intrusion detection plays a very important role in protecting computer network security. The abnormal traffic detection and analysis by extracting the statistical features of flow is the main analysis method in the field of network intrusion detection. However, these features need to be designed and extracted manually, which often loses the original information of the flow and leads to poor detection efficiency. In this paper, we do not manually design the features of the flow but directly extract the raw data information of the flow for analysis. In addition, we first proposed a new network intrusion detection model named the deep hierarchical network, which integrates the improved LeNet-5 and LSTM neural network structures, while learning the spatial and temporal features of flow. By designing a reasonable network cascading method, we can train our proposed hierarchical network at the same time instead of training two networks separately. In this paper, we use the CICIDS2017 dataset and the CTU dataset. The number and types of flow in these two datasets are large, and the attack types are relatively new. The experimental results show that the performance of the proposed hierarchical network model is significantly better than other network intrusion detection models, which can achieve the best detection accuracy. Finally, we also present an analysis method for traffic features which has an important contribution to abnormal traffic detection and gives the actual meanings of these important features.","['Feature extraction', 'Data mining', 'Intrusion detection', 'Data models', 'Machine learning algorithms', 'Neural networks', 'Inspection']","['Network intrusion detection', 'deep hierarchical network', 'raw feature', 'feature importance']"
"In this paper, we approach the problem of forecasting a time series (TS) of an electrical load measured on the Azienda Comunale Energia e Ambiente (ACEA) power grid, the company managing the electricity distribution in Rome, Italy, with an echo state network (ESN) considering two different leading times of 10 min and 1 day. We use a standard approach for predicting the load in the next 10 min, while, for a forecast horizon of one day, we represent the data with a high-dimensional multi-variate TS, where the number of variables is equivalent to the quantity of measurements registered in a day. Through the orthogonal transformation returned by PCA decomposition, we reduce the dimensionality of the TS to a lower number k of distinct variables; this allows us to cast the original prediction problem in k different one-step ahead predictions. The overall forecast can be effectively managed by k distinct prediction models, whose outputs are combined together to obtain the final result. We employ a genetic algorithm for tuning the parameters of the ESN and compare its prediction accuracy with a standard autoregressive integrated moving average model.","['Forecasting', 'Time series analysis', 'Load management', 'Predictive models', 'Genetic algorithms', 'Smart grids']","['Time-Series', 'Forecasting', 'Electric Load Prediction', 'Echo State Network', 'Genetic Algorithm', 'PCA', 'PCA', 'Dimensionality Reduction', 'Smart Grid']"
"This paper presents a novel system to obtain images from the underground based on ground penetrating radar (GPR). The proposed system is composed by a radar module mounted on board an unmanned aerial vehicle (UAV), which allows the safe inspection of difficult-to-access areas without being in direct contact with the soil. Therefore, it can be used to detect dangerous buried objects, such as landmines. The radar measurements are coherently combined using a synthetic aperture radar (SAR) algorithm, which requires cm-level accuracy positioning system. In addition, a clutter removal technique is applied to mitigate the reflection at the air-soil interface (which is caused by impedance mismatching). Besides the aforementioned advantages, the system can detect both metallic and dielectric targets (due to the use of a radar instead of a metal detector) and it allows to obtain high-resolution underground images (due to the SAR processing). The algorithms and the UAV payload are validated with measurements in both controlled and real scenarios, showing the feasibility of the proposed system.","['Landmine detection', 'Ground penetrating radar', 'Soil', 'Unmanned aerial vehicles', 'Radar imaging', 'Radar polarimetry']","['Ground penetrating radar (GPR)', 'subsurface sensing and imaging', 'synthetic aperture radar (SAR)', 'landmine detection', 'unmanned aerial vehicle (UAV)', 'drones', 'real time kinematic (RTK)']"
"Disasters (natural or man-made) can be lethal to human life, the environment, and infrastructure. The recent advancements in the Internet of Things (IoT) and the evolution in big data analytics (BDA) technologies have provided an open opportunity to develop highly needed disaster resilient smart city environments. In this paper, we propose and discuss the novel reference architecture and philosophy of a disaster resilient smart city (DRSC) through the integration of the IoT and BDA technologies. The proposed architecture offers a generic solution for disaster management activities in smart city incentives. A combination of the Hadoop Ecosystem and Spark are reviewed to develop an efficient DRSC environment that supports both real-time and offline analysis. The implementation model of the environment consists of data harvesting, data aggregation, data pre-processing, and big data analytics and service platform. A variety of datasets (i.e., smart buildings, city pollution, traffic simulator, and twitter) are utilized for the validation and evaluation of the system to detect and generate alerts for a fire in a building, pollution level in the city, emergency evacuation path, and the collection of information about natural disasters (i.e., earthquakes and tsunamis). The evaluation of the system efficiency is measured in terms of processing time and throughput that demonstrates the performance superiority of the proposed architecture. Moreover, the key challenges faced are identified and briefly discussed.","['Disaster management', 'Big Data', 'Smart cities', 'Social networking (online)', 'Internet of Things', 'Real-time systems', 'Sensors']","['Big data analytics', 'Internet of Things', 'smart city', 'disaster management', 'Hadoop', 'spark', 'smart data analytics', 'geo-social media analytics', 'disaster resilient smart city']"
"The penetration of electric vehicles (EVs) in the transportation sector is increasing but conventional internal combustion engine (ICE) based vehicles dominates. To accelerate the adoption of EVs and to achieve sustainable transportation, the bottlenecks need to be elevated that mainly include the high cost EVs, range anxiety, lack of EV charging infrastructure, and the pollution of the grid due to EV chargers. The high cost of EVs is due to costly energy storage systems (ESS) with high energy density. This paper provides a comprehensive review of EV technology that mainly includes electric vehicle supply equipment (EVSE), ESS, and EV chargers. A detailed discussion is presented on the state-of-the-art of EV chargers that include on-/off-board chargers. Different topologies are discussed with low-/high-frequency transformers. The different available power levels for charging are discussed. To reduce the range anxiety the EV chargers based on inductive power transfer (IPT) are discussed. The last part of the paper focuses on the negative impact of EV chargers along with the remedies that can be adopted. The international standards decided by different institutions and adopted universally are discussed in the latter part of this paper and finally, this paper concludes with the near to future advancement in EV technology.","['Batteries', 'Transportation', 'Fuels', 'Electric motors', 'Electric vehicle charging', 'Costs', 'Standards']","['Charge depletion', 'charge sustaining', 'electric vehicle', 'internal combustion engine', 'power factor', 'power quality']"
"In smart cities, wireless sensor networks (WSNs) act as a type of core infrastructure that collects data from the city to implement smart services. The security of WSNs is one of the key issues of smart cities. In resource-restrained WSNs, dynamic ongoing or unknown attacks usually steer clear of isolated defense components. Therefore, to resolve this problem, we propose a hierarchical framework based on chance discovery and usage control (UCON) technologies to improve the security of WSNs while still taking the low-complexity and high security requirements of WSNs into account. The features of continuous decision and dynamic attributes in UCON can address ongoing attacks using advanced persistent threat detection. In addition, we use a dynamic adaptive chance discovery mechanism to detect unknown attacks. To design and implement a system using the mechanism described above, a unified framework is proposed in which low-level attack detection with simple rules is performed in sensors, and high-level attack detection with complex rules is performed in sinks and at the base station. Moreover, software-defined networking and network function virtualization technologies are used to perform attack mitigation when either low-level or high-level attacks are detected. An experiment was performed to acquire an attack data set for evaluation. Then, a simulation was created to evaluate the resource consumption and attack detection rate. The results demonstrate the feasibility and efficiency of the proposed scheme.","['Wireless sensor networks', 'Sensors', 'Base stations', 'Access control', 'Smart cities', 'Hierarchical systems']","['Smart city', 'attack detection', 'chance discovery', 'wireless sensor networks (WSNs)', 'software-defined networking']"
"This paper deals the grid integration of photovoltaic (PV), fuel cell, and ultra-capacitor with maximum power point tracking (MPPT). The voltage oriented control for the grid-integrated inverter is proposed to regulate dc link voltage. Here, the fuel cell is employed as the main renewable energy source and PV as an auxiliary source with ultra-capacitor, which compensates power variation. An integrated CUK converter is proposed for peak power extraction from PV modules. The Jaya-based MPPT method is employed to achieve fast PV tracking ability with zero deviation around maximum power point (MPP) and has accelerated searched performance in equated with particle swarm optimization (PSO) and artificial bee colony (ABC) techniques. The hybrid PV-fuel cell with ultra-capacitor as energy storage works effectively under varying operating conditions. Compared to other energy storing devices, ultra-capacitor provides a fast dynamic response by absorbing/delivering power fluctuations. The hybrid PV-fuel storage control methodologies are experimentally validated using dSPACE (DS1104) board that provides optimal power extraction with stable power affirmation for a standalone/grid-connected system.","['Fuel cells', 'Capacitors', 'Resistance', 'Maximum power point trackers', 'Voltage control', 'Inverters', 'Photovoltaic systems']","['Fuel cell', 'maximum power point tracking', 'photovoltaic', 'ultra capacitor', 'utility grid']"
"Face recognition technology is a biometric technology, which is based on the identification of facial features of a person. People collect the face images, and the recognition equipment automatically processes the images. The paper introduces the related researches of face recognition from different perspectives. The paper describes the development stages and the related technologies of face recognition. We introduce the research of face recognition for real conditions, and we introduce the general evaluation standards and the general databases of face recognition. We give a forward-looking view of face recognition. Face recognition has become the future development direction and has many potential application prospects.","['Face recognition', 'Face', 'Principal component analysis', 'Feature extraction', 'Support vector machines', 'Machine learning', 'Biological neural networks']","['Face recognition', 'image processing', 'neural network', 'artificial intelligence']"
"Large-scale solar photovoltaic (PV) plants play an essential role in providing the increasing demand for energy in recent time. Therefore, in the purpose of achieving the highest harvested power under the partial shading conditions as well as protecting the PV array from the hot-spot calamity, the PV reconfiguration strategy is established as an efficient procedure. This is performed by redistribution of PV modules according to their levels of shading. Motivated by this, the authors in this article have introduced a novel population-based algorithm that is known as marine predators algorithm (MPA) to restructure the PV array dynamically. Moreover, a novel objective function is introduced to enhance the algorithm performance rather than utilizing the regular weighted objective function in the literature. The effectiveness of the proposed algorithms based on the novel objective function is evaluated using several metrics such as fill factor, mismatch losses, percentage of power loss, and percentage of power enhancement. Besides, the obtained results are compared with a regular total-cross-tied (TCT) connection, manta ray foraging optimization (MRFO), harris hawk optimizer (HHO) and particle swarm optimizer (PSO) based reconfiguration techniques. Furthermore, to demonstrate the suitability of the proposed methods, large scale PV arrays of $16\times16$ and $25\times25$ are considered and evaluated. The results reveal that MPA enhanced the PV array power by percentage of 28.6 %, 2.7 % and 5.7 % in cases of $9\times9$ , $16\times16$ and $25\times25$ PV arrays, respectively. The comprehensive comparisons endorse that MPA shows a successful shade dispersion; hence the number of multiple peaks in the PV characteristics has reduced, and high values of power have been harvested with least mean execution time in comparison with PSO, HHO and MRFO. Moreover, the Wilcoxon signed-rank test has been accomplished to confirm the reliability and applicability of the proposed approach for the PV large scale arrays as well.","['Integrated circuit modeling', 'Linear programming', 'Heuristic algorithms', 'Optimization', 'Maximum power point trackers', 'Switches']","['Renewable energy', 'energy efficiency', 'PV reconfiguration', 'partial shading', 'marine predators algorithm', 'partial shading', 'optimization']"
"During the past several years, as one of the most successful applications of sparse coding and dictionary learning, dictionary-based face recognition has received significant attention. Although some surveys of sparse coding and dictionary learning have been reported, there is no specialized survey concerning dictionary learning algorithms for face recognition. This paper provides a survey of dictionary learning algorithms for face recognition. To provide a comprehensive overview, we not only categorize existing dictionary learning algorithms for face recognition but also present details of each category. Since the number of atoms has an important impact on classification performance, we also review the algorithms for selecting the number of atoms. Specifically, we select six typical dictionary learning algorithms with different numbers of atoms to perform experiments on face databases. In summary, this paper provides a broad view of dictionary learning algorithms for face recognition and advances study in this field. It is very useful for readers to understand the profiles of this subject and to grasp the theoretical rationales and potentials as well as their applicability to different cases of face recognition.","['Dictionaries', 'Face recognition', 'Classification algorithms', 'Training', 'Face', 'Encoding', 'Image coding']","['Dictionary learning', 'sparse coding', 'face recognition']"
"With the increase of training data and the improvement of machine performance, the object detection method based on convolutional neural network (CNN) has become the mainstream algorithm in field of the current object detection. However, due to the complex background, occlusion and low resolution, there are still problems of small object detection. In this paper, we propose an improved algorithm based on faster region-based CNN (Faster R-CNN) for small object detection. Using the two-stage detection idea, in the positioning stage, we propose an improved loss function based on intersection over Union (IoU) for bounding box regression, and use bilinear interpolation to improve the regions of interest (RoI) pooling operation to solve the problem of positioning deviation, in the recognition stage, we use the multi-scale convolution feature fusion to make the feature map contain more information, and use the improved non-maximum suppression (NMS) algorithm to avoid loss of overlapping objects. The results show that the proposed algorithm has good performance on traffic signs whose resolution is in the range of (0, 32], the algorithm’s recall rate reaches 90%, and the accuracy rate reaches 87%. Detection performance is significantly better than Faster R- CNN. Therefore, our algorithm is an effective way to detect small objects.","['Object detection', 'Feature extraction', 'Proposals', 'Interpolation', 'Convolutional neural networks', 'Physics', 'Convolution']","['CNN', 'faster R-CNN', 'small object detection']"
"This paper presents a methodology for the joint capacity optimization of renewable energy (RE) sources, i.e., wind and solar, and the state-of-the-art hybrid energy storage system (HESS) comprised of battery energy storage (BES) and supercapacitor (SC) storage technology, employed in a grid-connected microgrid (MG). The problem involves multiple fields, i.e., RE, battery technology, SC technology, and control theory, and requires an efficient and precise co-ordination between sub-fields to harness the full benefits, making the problem labyrinthine. The optimization problem is formulated, and it involves a variety of realistic constraints from both hybrid generation and storage, and an objective function is proposed to: 1) minimize the cost; 2) improve the reliability; and 3) curtail greenhouse gases (GHG) emissions. The complex optimization problem is solved innovatively in piecewise fashion to decrease the complexity and computational time. First, sizes of solar photovoltaic (PV) and wind turbine (WT) are determined using an innovative search algorithm, and in the second step, the size of HESS is calculated, finally the optimal solution is determined. A comparison based upon cost, reliability, and GHG emissions is presented which plainly shows the effectiveness of the proposed methodology. The technique is also applied to determine the size of an MG employing PV, WT, and BES operating in grid-connected mode. And a brief cost analysis, reliability assessment, and emission reduction are given for three scenarios: 1) MG with HESS; 2) MG with BES; and 3) MG with conventional generation. It is shown that an MG with HESS is not only economical but also more reliable and has lower GHG emissions.","['Batteries', 'Optimization', 'Reliability', 'Supercapacitors', 'Microgrids', 'Minimization']","['Hybrid energy storage', 'microgrid', 'optimization', 'renewable power']"
"The classification in class imbalanced data has drawn significant interest in medical application. Most existing methods are prone to categorize the samples into the majority class, resulting in bias, in particular the insufficient identification of minority class. A kind of novel approach, class weights random forest is introduced to address the problem, by assigning individual weights for each class instead of a single weight. The validation test on UCI data sets demonstrates that for imbalanced medical data, the proposed method enhanced the overall performance of the classifier while producing high accuracy in identifying both majority and minority class.","['Classification algorithms', 'Radio frequency', 'Buildings', 'Prediction algorithms', 'Medical diagnostic imaging', 'Diseases']","['Class imbalanced', 'random forest', 'weighted voting', 'class weights voting']"
"Compared to the traditional orthogonal multiple access, non-orthogonal multiple access (NOMA) technology can achieve higher spectrum efficiency and support more massive connectivity. In this paper, we conduct comprehensive study and comparison on current NOMA technologies that many mainstream companies have proposed for the fifth generation (5G) wireless communication standard. According to the characteristics of the NOMA schemes, we classify these schemes into four categories: scrambling-based NOMA, spreading-based NOMA, coding-based NOMA, and interleaving-based NOMA. We systematically summarize the transceiver block diagram of each category, and detail basic principles, key features, and transmission-reception algorithms of all NOMA schemes. Furthermore, the theoretical analysis based on average mutual information is given to evaluate the achievable sum-rate performance of the NOMA systems and their potential performance gains as compared with OMA. Comprehensive simulations are carried out for the block-error-rate performance evaluation of these NOMA schemes as well, which coincide with the theoretical analysis. By comparing the performance of these technologies, some promising schemes and directions are suggested for the future 5G NOMA development.","['NOMA', '5G mobile communication', 'Decoding', 'Encoding', 'Receivers', 'Modulation', 'Transceivers']","['NOMA', '5G', 'scrambling', 'spreading', 'coding', 'interleaving']"
"This paper proposes DROM, a deep reinforcement learning mechanism for Software-Defined Networks (SDN) to achieve a universal and customizable routing optimization. DROM simplifies the network operation and maintenance by improving the network performance, such as delay and throughput, with a black-box optimization in continuous time. We evaluate the DROM with experiments. The experimental results show that DROM has the good convergence and effectiveness and provides better routing configurations than existing solutions to improve the network performance, such as reducing the delay and improving the throughput.","['Routing', 'Neural networks', 'Optimization', 'Heuristic algorithms', 'Decision making']","['Deep reinforcement learning', 'routing optimization', 'software-defined networking']"
"In this paper, a dual-band four-element multi-input and multi-output (MIMO) antenna system based on compact self-decoupled antenna pairs is proposed for the fifth-generation (5G) operation in mobile terminals. By sharing one common grounding branch for the two adjacent antenna units, dual-band antenna pairs with high isolation can be obtained. In particular, the two compact antenna pairs are placed perpendicularly on both sides of the system ground plane. The MIMO antenna system is optimized to operate in both 3.5 GHz (3.4-3.6 GHz) and 4.9 GHz (4.8-5.0 GHz) bands with isolation better than -17.5 dB for the low band and -20 dB for the high band. The proposed dual-band four-antenna MIMO system is fabricated and measured, and a good agreement between the simulation and measurement is obtained. Moreover, the influences of the phantom hand and display panel on the performance of the MIMO antenna system are also studied and discussed.","['MIMO communication', 'Dual band', 'Mobile antennas', '5G mobile communication', 'Grounding', 'Scattering parameters']","['5G', 'MIMO system', 'mobile antennas', 'self-decoupled antenna pairs', 'sub-6GHz']"
"Emotional health plays very vital role to improve people's quality of lives, especially for the elderly. Negative emotional states can lead to social or mental health problems. To cope with emotional health problems caused by negative emotions in daily life, we propose efficient facial expression recognition system to contribute in emotional healthcare system. Thus, facial expressions play a key role in our daily communications, and recent years have witnessed a great amount of research works for reliable facial expressions recognition (FER) systems. Therefore, facial expression evaluation or analysis from video information is very challenging and its accuracy depends on the extraction of robust features. In this paper, a unique feature extraction method is presented to extract distinguished features from the human face. For person independent expression recognition, depth video data is used as input to the system where in each frame, pixel intensities are distributed based on the distances to the camera. A novel robust feature extraction process is applied in this work which is named as local directional position pattern (LDPP). In LDPP, after extracting local directional strengths for each pixel such as applied in typical local directional pattern (LDP), top directional strength positions are considered in binary along with their strength sign bits. Considering top directional strength positions with strength signs in LDPP can differentiate edge pixels with bright as well as dark regions on their opposite sides by generating different patterns whereas typical LDP only considers directions representing the top strengths irrespective of their signs as well as position orders (i.e., directions with top strengths represent 1 and rest of them 0), which can generate the same patterns in this regard sometimes. Hence, LDP fails to distinguish edge pixels with opposite bright and dark regions in some cases which can be overcome by LDPP. Moreover, the LDPP capabilities are extended through principal component analysis (PCA) and generalized discriminant analysis (GDA) for better face characteristic illustration in expression. The proposed features are finally applied with deep belief network (DBN) for expression training and recognition.","['Face', 'Feature extraction', 'Cameras', 'Face recognition', 'Principal component analysis', 'Robustness', 'Training']","['Facial expressions recognition (FER)', 'deep belief network (DBN)', 'depth image', 'generalized discriminant analysis (GDA)', 'local directional pattern (LDP)', 'principal component analysis (PCA)']"
"As solar photovoltaic (PV) generation becomes cost-effective, solar power comes into its own as the alternative energy with the potential to make up a larger share of growing energy needs. Consequently, operations and maintenance cost now have a large impact on the profit of managing power modules, and the energy market participants need to estimate the solar power in short or long terms of future. In this paper, we propose a solar power forecasting technique by utilizing convolutional neural networks and long–short-term memory networks recently developed for analyzing time series data in the deep learning communities. Considering that weather information may not be always available for the location where PV modules are installed and sensors are often damaged, we empirically confirm that the proposed method predicts the solar power well with roughly estimated weather data obtained from national weather centers as well as it works robustly without sophisticatedly preprocessed input to remove outliers.","['Forecasting', 'Predictive models', 'Autoregressive processes', 'Power generation', 'Weather forecasting']","['Solar power forecasting', 'deep learning', 'convolutional neural networks', 'long-short term memory']"
"Network densification is foreseen as a potential solution to fulfill the 5G spectral efficiency requirements. The spectral efficiency is improved by shrinking base stations' (BSs) footprints, thus improving the spatial frequency reuse and reducing the number of users sharing the resources of each BS. However, the foreseen densification gains are achieved at the expense of increasing handover (HO) rates. Hence, HO rate is a key performance limiting factor that should be carefully considered in densification planning. This paper sheds light on the HO problem that appears in dense 5G networks and proposes an effective solution via topology aware HO skipping. Different skipping techniques are considered and compared with the conventional best connected scheme. To this end, the proposed schemes are validated via the average user rate in downlink single-tier and two-tier cellular networks, which are modeled using the Poisson point process and the Poisson cluster process, respectively. The proposed skipping schemes show up to 47% gains in the average throughput, which would maximize the benefit of network densification.","['Cellular networks', 'Trajectory', 'Throughput', 'Handover', 'Delays', 'Computer architecture']","['Downlink cellular networks', 'handover management', 'stochastic geometry', 'average throughput']"
"The urban traffic flow prediction is a significant issue in the intelligent transportation system. In consideration of nonlinear and spatial-temporal features of urban traffic data, we propose a deep hybrid neural network improved by greedy algorithm for urban traffic flow prediction with taxi GPS trace. The proposed deep neural network model first combines the convolutional neural network (CNN), which extracts the spatial features, with the long short term memory (LSTM), which captures the temporal information, to predict urban traffic flow. Then, the proposed model is trained by a greedy policy to short time consumption and improves accuracy when a network goes deeper. Experimental results with real taxis GPS trajectory data from Xi'an city show that the improved deep hybrid CNN-LSTM model can achieve higher prediction accuracy and shorter time consumption compared with existing methods.","['Global Positioning System', 'Neural networks', 'Trajectory', 'Predictive models', 'Feature extraction', 'Data models', 'Public transportation']","['Deep hybrid networks', 'greedy policy', 'trajectory data', 'urban traffic-flow prediction']"
"Software-Defined Network (SDN) has been developed to reduce network complexity through control and manage the whole network from a centralized location. Today, SDN is widely implemented in many data center's network environments. Nevertheless, emerging technology itself can lead to many vulnerabilities and threats which are still challenging for manufacturers to address it. Therefore, deploying Intrusion Detection Systems (IDSs) to monitor malicious activities is a crucial part of the network architecture. Although the centralized view of the SDN network creates new opportunities for the implementation of IDSs, the performance of these detection techniques relies on the quality of the training datasets. Unfortunately, there are no publicly available datasets that can be used directly for anomaly detection systems applied in SDN networks. The majority of the published studies use non-compatible and outdated datasets, such as the KDD'99 dataset. This manuscript aims to generate an attack-specific SDN dataset and it is publicly available to the researchers. To the best of our knowledge, our work is one of the first solutions to produce a comprehensive SDN dataset to verify the performance of intrusion detection systems. The new dataset includes the benign and various attack categories that can occur in the different elements of the SDN platform. Further, we demonstrate the use of our proposed dataset by performing an experimental evaluation using eight popular machine-learning-based techniques for IDSs.","['Intrusion detection', 'Training', 'Anomaly detection', 'Feature extraction', 'Protocols', 'Machine learning']","['Dataset', 'intrusion detection system (IDS)', 'OpenFlow', 'SDN', 'security', 'threat vectors', 'machine learning']"
"The novel coronavirus (COVID-19), declared by the World Health Organization (WHO) as a global pandemic, has brought with it changes to the general way of life. Major sectors of the world industry and economy have been affected and the Internet of Things (IoT) management and framework is no exception in this regard. This article provides an up to date survey on how a global pandemic such as COVID-19 has affected the world of IoT technologies. It looks at the contributions that IoT and associated sensor technologies have made towards virus tracing, tracking and spread mitigation. The associated challenges of deployment of sensor hardware in the face of a rapidly spreading pandemic have been looked into as part of this review article. The effects of a global pandemic on the evolution of IoT architectures and management have also been addressed, leading to the likely outcomes on future IoT implementations. In general, this article provides an insight into the advancement of sensor-based E-health towards the management of global pandemics. It also answers the question of how a global virus pandemic has shaped the future of IoT networks.","['Pandemics', 'COVID-19', 'Viruses (medical)', 'Monitoring', 'Internet of Things', 'Temperature measurement']","['Artificial intelligence', 'big data', 'COVID-19', 'data sharing', 'internet of things', 'pandemic management']"
"This paper proposes a novel single-dc-source multilevel inverter called Packed E-Cell (PEC) topology to achieve nine levels with noticeably reduced components count, while dc capacitors are actively balanced. The nine-level PEC (PEC9) is composed of seven active switches and two dc capacitors that are shunted by a four-quadrant switch to from the E-cell, and it makes use of a single dc link. With the proper design of the corresponding PEC9 switching states, the dc capacitors are balanced using the redundant charging/discharging states. Since the shunted capacitors are horizontally extended, both capacitors are simultaneously charged or discharged with the redundant states, so only the auxiliary dc-link voltage needs to be sensed and regulated to half of the input dc source voltage, and consequently, dc capacitors' voltages are inherently balanced to one quarter of the dc bus voltage. To this end, an active capacitor voltage balancing integrated to the level-shifted half-parabola carrier PWM technique has been designed based on the redundant charging/discharging states to regulate the dc capacitors voltages of PEC9. Furthermore, using the E-cell not only reduces components count but also the proposed topology permits multi ac terminal operation. Thus, five-level inverter operation can be achieved during the four-quadrant switch fault, which confers to the structure high reliability. The theoretical analysis as well as the experimental results are presented and discussed, showing the basic operation, multi-functionality, as well as the superior performance of the proposed novel PEC9 inverter topology.","['Capacitors', 'Inverters', 'Topology', 'Voltage control', 'Switches', 'Voltage measurement', 'Reliability']","['Nine-level Packed E-Cell (PEC)', 'single-dc source inverter', 'single auxiliary dc-link capacitors', 'multilevel converter', 'PUC converter', 'active rectifier', 'active filter', 'grid-connected converter']"
"In this paper, an improved Model Predictive Control (MPC) controller based on fuzzy adaptive weight control is proposed to solve the problem of autonomous vehicle in the process of path tracking. The controller not only ensures the tracking accuracy, but also considers the vehicle dynamic stability in the process of tracking, i.e., the vehicle dynamics model is used as the controller model. Moreover, the problem of driving comfort caused by the application of classical MPC controller when the vehicle is deviated from the target path is solved. This controller is mainly realized by adaptively improving the weight of the cost function in the classical MPC through the fuzzy adaptive control algorithm. A comparative study which compares the proposed controller with the pure-pursuit controller and the classical MPC controller is made: through the CarSim-Matlab/Simulink co-simulations, the results show that this controller presents better tracking performance than the latter ones considering both tracking accuracy and steering smoothness.","['Tires', 'Mathematical model', 'Vehicle dynamics', 'Wheels', 'Stability analysis', 'Target tracking', 'Cost function']","['Autonomous vehicles', 'path tracking', 'improved MPC controller', 'weight adaptive control']"
"The appearance of generative adversarial networks (GAN) provides a new approach and framework for computer vision. Compared with traditional machine learning algorithms, GAN works via adversarial training concept and is more powerful in both feature learning and representation. GAN also exhibits some problems, such as non-convergence, model collapse, and uncontrollability due to high degree of freedom. How to improve the theory of GAN and apply it to computer-vision-related tasks have now attracted much research efforts. In this paper, recently proposed GAN models and their applications in computer vision are systematically reviewed. In particular, we firstly survey the history and development of generative algorithms, the mechanism of GAN, its fundamental network structures, and theoretical analysis of the original GAN. Classical GAN algorithms are then compared comprehensively in terms of the mechanism, visual results of generated samples, and Frechet Inception Distance. These networks are further evaluated from network construction, performance, and applicability aspects by extensive experiments conducted over public datasets. After that, several typical applications of GAN in computer vision, including high-quality samples generation, style transfer, and image translation, are examined. Finally, some existing problems of GAN are summarized and discussed and potential future research topics are forecasted.","['Gallium nitride', 'Generative adversarial networks', 'Generators', 'Hidden Markov models', 'Computer vision', 'Training', 'Feature extraction']","['Deep learning', 'generative adversarial networks (GAN)', 'computer vision (CV)', 'image generation', 'style transfer', 'image inpainting']"
"This paper presents a substrate integrated waveguide (SIW) multibeam slot array operating at \sim 30 GHz for future 5G mobile terminal applications. The multibeam forming network is realized with a Butler matrix that is composed of hybrid couplers, crossovers, and phase shifters (135° and 0°). The crossovers are formed with two cascaded hybrid couplers. In the design of 135° and 0° phase shifters, the phase compensation technique is employed. The slot array is a 2 \times 4 type, in which each column has two slot elements that are longitudinally staggered with respect to one another (in half-wavelength). In addition, mutual couplings reduction techniques applied in the proposed slot array are also discussed. The SIW technique is adopted in case for the related components, as it can be highly integrated in mmWave circuits at low fabrication cost and has low profile characteristics. The overall dimension of the SIW multibeam slot array (including the Butler matrix feeding network) is 72 \times 27.4 \times 0.508 mm 3 , and the total area of the slot array is only 10.1\times 20.4 mm 2 . The measured 10 dB bandwidth was 28–32 GHz, and the measured gains at 30 GHz for each port were 10.8, 12.1, 12, and 11 dBi. The proposed slot array also possesses wide angle coverage of \sim 40^{\circ } with good steerable radiation.","['5G mobile communication', 'Millimeter wave communication', 'Substrates', 'Butler matrices', 'Phase shifters', 'Gain measurement', 'Mobile communication']","['5G', 'Butler matrix', 'mobile terminals', 'substrate integrated waveguide (SIW)', 'millimeter wave']"
"In this paper, a simple, miniature, and highly sensitive photonic crystal fiber (PCF)-based surface plasmon resonance (SPR) sensor is proposed. The target analyte and the plasmonic material are at the outer surface of the fiber making practical applications feasible. A 30-nm gold (Au) layer supports surface plasmons. A thin titanium dioxide (TiO 2 ) layer is used to assist adhesion of Au on the glass fiber. The fiber cross section is formed purely by circular-shaped holes simplifying the preform manufacturing process. A high-birefringence (hi-bi) fiber is obtained by means of an array of air holes at the center of the fiber. A finite element method (FEM) is employed to analyze the surface plasmon properties of the proposed PCF-SPR sensor. By optimizing the geometric parameters, a maximum wavelength sensitivity (WS) of 25 000 nm/RIU and an amplitude sensitivity (AS) of 1411 RIU -1 for a dielectric refractive index (RI) range of 1.33-1.38 are obtained. Moreover, an estimated maximum resolution of 4 × 10 -6 and a figure of merit (FOM) of 502 are obtained that ensures high detection accuracy of small refractive index (RI) changes. Owing to its sensitivity and simple architecture, the proposed sensor has potential application in a range of sensing application, including biosensing.","['Gold', 'Sensitivity', 'Dielectrics', 'Surface plasmons', 'Optical sensors']","['Surface plasmons', 'polarization', 'birefringence', 'resonance', 'plasmonics', 'optical sensing', 'sensors and actuators']"
"Electronic health records (EHRs) are providing increased access to healthcare data that can be made available for advanced data analysis. This can be used by the healthcare professionals to make a more informed decision providing improved quality of care. However, due to the inherent heterogeneous and imbalanced characteristics of medical data from EHRs, data analysis task faces a big challenge. In this paper, we address the challenges of imbalanced medical data about a brain tumor diagnosis problem. Morphometric analysis of histopathological images is rapidly emerging as a valuable diagnostic tool for neuropathology. Oligodendroglioma is one type of brain tumor that has a good response to treatment provided the tumor subtype is recognized accurately. The genetic variant, 1p-/19q-, has recently been found to have high chemosensitivity, and has morphological attributes that may lend it to automated image analysis and histological processing and diagnosis. This paper aims to achieve a fast, affordable, and objective diagnosis of this genetic variant of oligodendroglioma with a novel data mining approach combining a feature selection and ensemble-based classification. In this paper, 63 instances of brain tumor with oligodendroglioma are obtained due to prevalence and incidence of the tumor variant. In order to minimize the effect of an imbalanced healthcare data set, a global optimization-based hybrid wrapper-filter feature selection with ensemble classification is applied. The experiment results show that the proposed approach outperforms the standard techniques used in brain tumor classification problem to overcome the imbalanced characteristics of medical data.","['Tumors', 'Feature extraction', 'Data mining', 'Medical diagnostic imaging', 'Artificial neural networks']","['Brain tumor', 'morphological features', 'ANNIGMA', 'MRMR', 'feature selection', 'classification']"
"Recently, many countries have spent great efforts on wind power generation. Although there have been many methods in the field of wind power forecasting, the persistence statistics model based on historical data is still being challenged due to the randomness and uncontrollability in wind power. Hence, a more accurate and effective wind power forecasting method is still required. In this paper, a new forecasting method is proposed by combining stacked auto-encoders (SAE) and the back propagation (BP) algorithm. First, an SAE with three hidden layers is designed to extract the characteristics from the reference data sequence, and the subsequent loss function is used in the pre-training process to obtain the optimal initial connection weights of the deep network. Second, after adding one output layer to the stacked auto encoders, the BP algorithm is used to fine tune the weights of the whole network. To achieve the best network architecture, the particle swarm optimization is adopted to decide the number of neurons of the hidden layer and the learning rate of each auto encoder. Experimental results show that, for short-term wind power forecasting, the proposed method achieves more stable and effective performance than the existing BP neural network and support vector machines. The improvement in accuracy is 12% on average under different time steps.","['Forecasting', 'Predictive models', 'Wind power generation', 'Neurons', 'Feature extraction', 'Training', 'Wavelet analysis']","['Machine learning', 'particle swarm optimization', 'stacked auto-encoders', 'wind energy', 'wind power forecasting']"
"One of the challenges of Industry 4.0 is the creation of vertical networks that connect smart production systems with design teams, suppliers, and the front office. To achieve such a vision, information has to be collected from machines and products throughout a smart factory. Smart factories are defined as flexible and fully connected factories that are able to make use of constant streams of data from operations and production systems. In such scenarios, the arguably most popular way for identifying and tracking objects is by adding labels or tags, which have evolved remarkably over the last years: from pure hand-written labels to barcodes, QR codes, and RFID tags. The latest trend in this evolution is smart labels which are not only mere identifiers with some kind of internal storage, but also sophisticated context-aware tags with embedded modules that make use of wireless communications, energy efficient displays, and sensors. Therefore, smart labels go beyond identification and are able to detect and react to the surrounding environment. Moreover, when the industrial Internet of Things paradigm is applied to smart labels attached to objects, they can be identified remotely and discovered by other Industry 4.0 systems, what allows such systems to react in the presence of smart labels, thus triggering specific events or performing a number of actions on them. The amount of possible interactions is endless and creates unprecedented industrial scenarios, where items can talk to each other and with tools, machines, remote computers, or workers. This paper, after reviewing the basics of Industry 4.0 and smart labels, details the latest technologies used by them, their applications, the most relevant academic and commercial implementations, and their internal architecture and design requirements, providing researchers with the necessary foundations for developing the next generation of Industry 4.0 human-centered smart label applications.","['Industries', 'Production facilities', 'Real-time systems', 'Production systems', 'Smart manufacturing', 'Internet of Things']","['Smart labels', 'human-computer interface', 'smart objects', 'Industry 40', 'human-centered design', 'traceability', 'tracking', 'cyber-physical system', 'IoT', 'IIoT']"
"Cardiac arrhythmia is associated with abnormal electrical activities of the heart, which can be reflected by altered characteristics of electrocardiogram (ECG). Due to the simplicity and non-invasive nature, the ECG has been widely used for detecting arrhythmias and there is an urgent need for automatic ECG detection. Up to date, some algorithms have been proposed for automatic classification of cardiac arrhythmias based on the features of the ECG; however, their stratification rate is still poor due to unreliable features of signal characteristics or limited generalization capability of the classifier, and therefore, it remains a challenge for automatic diagnosis of arrhythmias. In this paper, we propose a new method for automatic classification of arrhythmias based on deep neural networks (DNNs). The two DNN models constitutive of residual convolutional modules and bidirectional long short-term memory (LSTM) layers are trained to extract features from raw ECG signals. The extracted features are concatenated to form a feature vector which is trained to do the final classification. The algorithm is evaluated based on the test set of China Physiological Signal Challenge (CPSC) dataset with F1 measure regarded as the harmonic mean between the precision and recall. The resulting overall F1 score is 0.806, FAF score is 0.914 for atrial fibrillation (AF), FBlock score is 0.879 for block, FPC and FST scores are 0.801 and 0.742 for premature contraction and ST-segment change, which demonstrates a good performance that may have potential practical applications.","['Electrocardiography', 'Feature extraction', 'Training', 'Neural networks', 'Classification algorithms', 'Heart', 'Databases']","['Cardiac arrhythmia', 'electrocardiogram (ECG)', 'deep neural networks (DNNs)', 'deep residual network', 'bidirectional long short-term memory (LSTM)']"
"Robust automatic pavement crack detection is critical to automated road condition evaluation. However, research on crack detection is still limited and pixel-level automatic crack detection remains a challenging problem, due to heterogeneous pixel intensity, complex crack topology, poor illumination condition, and noisy texture background. In this paper, we propose a novel approach for automatically detecting pavement cracks at pixel level, leveraging on multi-scale neighborhood information, and pixel intensity. Using pixel intensity information, a probabilistic generative model (PGM) based method is developed to calculate the probability of a crack for each pixel. This produces a probability map consisting of the probability of each pixel being part of the crack. We demonstrate that the neighborhoods of each pixel contain critical information for crack detection, and propose a support vector machine (SVM) based method to calculate the probability maps using information of multi-scale neighborhoods. We develop a fusion algorithm to merge the multiple probability maps, obtained from both PGM and SVM approaches, into a fused map, which can detect cracks with accuracy higher than any of the original probability maps. We also propose a weighted dilation operation that relies on the fused probability map to enhance the recognition of borderline pixels and improve the crack continuity without increasing the crack width improperly. Experimental results demonstrate that our algorithm achieves better performance in terms of precision, recall, f1-score, and receiver operating characteristic, in comparison with the state-of-the-art pavement crack detection algorithms.","['Roads', 'Probability', 'Support vector machines', 'Signal processing algorithms', 'Robustness', 'Topology', 'Surface cracks']","['Pavement crack detection', 'probability map', 'multi-scale neighborhoods', 'probabilistic generative mode', 'support vector machine']"
"In this paper, we propose an optimization framework of computation offloading and resource allocation for mobile-edge computing with multiple servers. Concretely, we aim to minimize the system-wide computation overhead by jointly optimizing the individual computation decisions, transmit power of the users, and computation resource at the servers. The crux of the problem lies in the combinatorial nature of multi-user offloading decisions, the complexity of the optimization objective, and the existence of inter-cell interference. To overcome these difficulties, we adopt a suboptimal approach by splitting the original problem into two parts: 1) computation offloading decision and 2) joint resource allocation. To enable distributed computation offloading, two matching algorithms are investigated. Moreover, the transmit power of offloading users is found using a bisection method with approximate inter-cell interference, and the computation resources allocated to offloading users is achieved via the duality approach. Simulation results validate that the proposed framework can significantly improve the percentage of offloading users and reduce the system overhead with respect to the existing schemes. Our results also show that the proposed framework performs close to the centralized heuristic algorithm with a small optimality gap.","['Servers', 'Resource management', 'Optimization', 'Interference', 'Games', 'Task analysis', 'Heuristic algorithms']","['Heterogeneous networks', 'matching theory', 'mobile edge computing', 'resource allocation']"
"Spread spectrum is a technique introduced for mitigating electromagnetic interference (EMI) problems in many class of circuits. In this paper, with particular emphasis on switching DC/DC converters, we consider the most common and most efficient known spreading techniques, looking for spreading parameters that ensure the highest EMI reduction and the lowest performance reduction in the circuit where the spreading is applied. The result is an interesting tradeoff not only between EMI reduction and performance drop, but also on the EMI reduction itself when considering different EMI victim models. The proposed analysis is supported by measurements on two switching DC/DC converters: 1) based on pulse-width modulation and 2) based on the resonant converter class.","['Electromagnetic interference', 'Frequency modulation', 'Spread spectrum management', 'Switching circuits', 'Switches', 'Electromagnetic compatibility']","['DC/DC converters', 'electromagnetic compatibility (EMC)', 'electromagnetic interference (EMI)']"
"Electrocardiograms (ECGs) play a vital role in the clinical diagnosis of heart diseases. An ECG record of the heart signal over time can be used to discover numerous arrhythmias. Our work is based on 15 different classes from the MIT-BIH arrhythmia dataset. But the MIT-BIH dataset is strongly imbalanced, which impairs the accuracy of deep learning models. We propose a novel data-augmentation technique using generative adversarial networks (GANs) to restore the balance of the dataset. Two deep learning approaches-an end-to-end approach and a two-stage hierarchical approach-based on deep convolutional neural networks (CNNs) are used to eliminate hand-engineering features by combining feature extraction, feature reduction, and classification into a single learning method. Results show that augmenting the original imbalanced dataset with generated heartbeats by using the proposed techniques more effectively improves the performance of ECG classification than using the same techniques trained only with the original dataset. Furthermore, we demonstrate that augmenting the heartbeats using GANs outperforms other common data augmentation techniques. Our experiments with these techniques achieved overall accuracy above 98.0%, precision above 90.0%, specificity above 97.4%, and sensitivity above 97.7% after the dataset had been balanced using GANs, results that outperform several other ECG classification methods.","['Electrocardiography', 'Feature extraction', 'Heart beat', 'Heart rate variability', 'Gallium nitride', 'Machine learning', 'Generative adversarial networks']","['Class imbalance', 'convolution neural networks (CNNs)', 'ECG classification', 'generative adversarial networks (GANs)']"
"The introduction of smart mobile devices has radically redesigned user interaction, as these devices are equipped with numerous sensors, making applications context-aware. To further improve user experience, most mobile operating systems and service providers are gradually shipping smart devices with voice controlled intelligent personal assistants, reaching a new level of human and technology convergence. While these systems facilitate user interaction, it has been recently shown that there is a potential risk regarding devices, which have such functionality. Our independent research indicates that this threat is not merely potential, but very real and more dangerous than initially perceived, as it is augmented by the inherent mechanisms of the underlying operating systems, the increasing capabilities of these assistants, and the proximity with other devices in the Internet of Things (IoT) era. In this paper, we discuss and demonstrate how these attacks can be launched, analysing their impact in real world scenarios.","['Androids', 'Humanoid robots', 'Operating systems', 'Mobile communication', 'Sensors', 'Security', 'Privacy']","['Security', 'voice recognition', 'mobile devices', 'Android permissions', 'voice assistants']"
"Research on 100% renewable energy systems is a relatively recent phenomenon. It was initiated in the mid-1970s, catalyzed by skyrocketing oil prices. Since the mid-2000s, it has quickly evolved into a prominent research field encompassing an expansive and growing number of research groups and organizations across the world. The main conclusion of most of these studies is that 100% renewables is feasible worldwide at low cost. Advanced concepts and methods now enable the field to chart realistic as well as cost- or resource-optimized and efficient transition pathways to a future without the use of fossil fuels. Such proposed pathways in turn, have helped spur 100% renewable energy policy targets and actions, leading to more research. In most transition pathways, solar energy and wind power increasingly emerge as the central pillars of a sustainable energy system combined with energy efficiency measures. Cost-optimization modeling and greater resource availability tend to lead to higher solar photovoltaic shares, while emphasis on energy supply diversification tends to point to higher wind power contributions. Recent research has focused on the challenges and opportunities regarding grid congestion, energy storage, sector coupling, electrification of transport and industry implying power-to-X and hydrogen-to-X, and the inclusion of natural and technical carbon dioxide removal (CDR) approaches. The result is a holistic vision of the transition towards a net-negative greenhouse gas emissions economy that can limit global warming to 1.5°C with a clearly defined carbon budget in a sustainable and cost-effective manner based on 100% renewable energy-industry-CDR systems. Initially, the field encountered very strong skepticism. Therefore, this paper also includes a response to major critiques against 100% renewable energy systems, and also discusses the institutional inertia that hampers adoption by the International Energy Agency and the Intergovernmental Panel on Climate Change, as well as possible negative connections to community acceptance and energy justice. We conclude by discussing how this emergent research field can further progress to the benefit of society.","['Renewable energy sources', 'Fuels', 'System analysis and design', 'Hydrogen', 'Jacobian matrices', 'Hydroelectric power generation', 'Wind power generation', 'Global warming']","['Climate safety', 'energy transition', 'power-to-X', '100% renewable energy', 'sector coupling']"
"Accurate short-term traffic forecasts help people choose transportation and travel time. Through the query data, many models for traffic flow prediction have neglected the temporal and spatial correlation of traffic flow, so that the prediction accuracy is limited by the accuracy of traffic data. This paper proposed a short-term traffic flow prediction model that combined the spatio-temporal analysis with a Gated Recurrent Unit (GRU). In the proposed prediction model, firstly, time correlation analysis and spatial correlation analysis were performed on the collected traffic flow data, and then the spatiotemporal feature selection algorithm was employed to define the optimal input time interval and spatial data volume. At the same time, the selected traffic flow data were extracted from the actual traffic flow data and converted into a two-dimensional matrix with spatio-temporal traffic flow information. The GRU was used to process the spatio-temporal feature information of the internal traffic flow of the matrix to achieve the purpose of prediction. Finally, the prediction results obtained by the proposed model were compared with the actual traffic flow data to verify the effectiveness of the model. The model proposed in this paper was compared with the convolutional neural network (CNN) model and the GRU model, and the results show that the proposed method outperforms both in accuracy and stability.","['Predictive models', 'Correlation', 'Data models', 'Neural networks', 'Roads', 'Prediction algorithms', 'Analytical models']","['Gated recurrent unit', 'spatio-temporal analysis', 'short-term traffic flow prediction', 'traffic engineering', 'urban road section']"
"In this article we introduce Simu5G, a new OMNeT++-based model library to simulate 5G networks. Simu5G allows users to simulate the data plane of 5G New Radio deployments, in an end-to-end perspective and including all protocol layers, making it a valuable tool for researchers and practitioners interested in the performance evaluation of 5G networks and services. We discuss the modelling of the protocol layers, network entities and functions, and validate our abstraction of the physical layer using 3GPP-based scenarios. Moreover, we show how Simu5G can be used to evaluate Multi-access Edge Computing (MEC) and Cellular Vehicle-to-everything (C-V2X) services offered through a 5G network.","['5G mobile communication', 'Object oriented modeling', 'Libraries', 'Protocols', 'Computational modeling', 'Performance evaluation', 'Real-time systems']","['Computer simulation', 'object-oriented modeling', 'computer networks', '5G mobile communication']"
"Tactile Internet (TI) is envisioned to create a paradigm shift from the content-oriented communications to steer/control-based communications by enabling real-time transmission of haptic information (i.e., touch, actuation, motion, vibration, surface texture) over Internet in addition to the conventional audiovisual and data traffics. This emerging TI technology, also considered as the next evolution phase of Internet of Things (IoT), is expected to create numerous opportunities for technology markets in a wide variety of applications ranging from teleoperation systems and Augmented/Virtual Reality (AR/VR) to automotive safety and eHealthcare towards addressing the complex problems of human society. However, the realization of TI over wireless media in the upcoming Fifth Generation (5G) and beyond networks creates various non-conventional communication challenges and stringent requirements in terms of ultra-low latency, ultra-high reliability, high data-rate connectivity, resource allocation, multiple access and quality-latency-rate tradeoff. To this end, this paper aims to provide a holistic view on wireless TI along with a thorough review of the existing state-of-the-art, to identify and analyze the involved technical issues, to highlight potential solutions and to propose future research directions. First, starting with the vision of TI and recent advances and a review of related survey/overview articles, we present a generalized framework for wireless TI in the Beyond 5G Era including a TI architecture, the main technical requirements, the key application areas and potential enabling technologies. Subsequently, we provide a comprehensive review of the existing TI works by broadly categorizing them into three main paradigms; namely, haptic communications, wireless AR/VR, and autonomous, intelligent and cooperative mobility systems. Next, potential enabling technologies across physical/Medium Access Control (MAC) and network layers are identified and discussed in detail. Also, security and privacy issues of TI applications are discussed along with some promising enablers. Finally, we present some open research challenges and recommend promising future research directions.","['5G mobile communication', 'Wireless communication', 'Reliability', 'Communication system security', 'Internet of Things', 'Haptic interfaces']","['Tactile internet', 'IoT', '5G', 'beyond 5G', 'haptic communications', 'augmented reality (AR)', 'virtual reality (VR)', 'ultra-reliable and low-latency communications (URLLC)']"
"Future smart classrooms that we envision will significantly enhance learning experience and seamless communication among students and teachers using real-time sensing and machine intelligence. Existing developments in engineering have brought the state-of-the-art to an inflection point, where they can be utilized as components of a smart classroom. In this paper, we propose a smart classroom system that consists of these components. Our proposed system is capable of making real-time suggestions to an in-class presenter to improve the quality and memorability of their presentation by allowing the presenter to make real-time adjustments/corrections to their non-verbal behavior, such as hand gestures, facial expressions, and body language. We base our suggested system components on existing research in affect sensing, deep learning-based emotion recognition, and real-time mobile-cloud computing. We provide a comprehensive study of these technologies and determine the computational requirements of a system that incorporates these technologies. Based on these requirements, we provide a feasibility study of the system. Although the state-of-the-art research in most of the components we propose in our system are advanced enough to realize the system, the main challenge lies in: 1) the integration of these technologies into a holistic system design; 2) their algorithmic adaptation to allow real-time execution; and 3) quantification of valid educational variables for use in algorithms. In this paper, we discuss current issues and provide future directions in engineering and education disciplines to deploy the proposed system.","['Real-time systems', 'Education', 'Engines', 'Machine learning', 'System analysis and design', 'Haptic interfaces', 'Visualization']","['Educational technology', 'emotion recognition', 'smart classroom', 'deep learning', 'real-time computing', 'mobile-cloud computing', 'meta-cognition']"
"In order to simplify the management of the traditional network, software-defined networking (SDN) has been proposed as a promising paradigm shift that decouples control plane and data plane, providing programmability to configure the network. With the deployment and the applications of SDN, researchers have found that the controller placement directly affects network performance in SDN. In this paper, the state of the art of controller placement problem is surveyed from the perspective of optimization objective. First, we introduce the overview of SDN and controller placement problem. Then, we classify this paper of controller placement problem into four aspects (latency, reliability, and cost and multi-objective) depending on their objective and analyze specific algorithms in different application scenarios. Finally, we identify some relevant open issues and research challenge to deal with in the future and conclude the controller placement problem.","['Control systems', 'Reliability', 'Heuristic algorithms', 'Process control', 'Optimization', 'Network architecture', 'Linear programming']","['Software-defined networking', 'controller placement problem', 'latency', 'reliability', 'cost', 'multi-objective']"
"Cloud gaming is a new way to deliver high-quality gaming experience to gamers anywhere and anytime. In cloud gaming, sophisticated game software runs on powerful servers in data centers, rendered game scenes are streamed to gamers over the Internet in real time, and the gamers use light-weight software executed on heterogeneous devices to interact with the games. Due to the proliferation of high-speed networks and cloud computing, cloud gaming has attracted tremendous attentions in both the academia and industry since late 2000's. In this paper, we survey the latest cloud gaming research from different aspects, spanning over cloud gaming platforms, optimization techniques, and commercial cloud gaming services. The readers will gain the overview of cloud gaming research and get familiar with the recent developments in this area.","['Cloud computing', 'Games', 'Distributed processing', 'Quality of service', 'Computer graphics', 'Video coding']","['Clouds', 'distributed computing', 'video coding', 'quality of service', 'computer graphics']"
"Elastic scaling and load balancing with efficient switch migration are critical to enable the elasticity of software-defined networking (SDN) controllers, but learning how to improve migration efficiency remains a difficult problem. To address this issue, a switch migration-based decision-making (SMDM) scheme is put forward that could be made aware of the load imbalance by a switch migration trigger metric; the migration efficiency model for this scheme is built to make a tradeoff between migration costs and the load balance rate. An efficiency-aware switch migration algorithm based on greedy method is designed to utilize the migration efficiency model and thus guide the choice of possible migration actions. We implement a proof of the scheme and present a numerical evaluation using Mininet emulator to demonstrate the effectiveness of our proposal.","['Switches', 'Load management', 'Load modeling', 'Scalability', 'Algorithm design and analysis', 'Decision making']","['Software-defined networking', 'switch migration', 'migration efficiency', 'migration cost', 'load balancing']"
"Dealing with air pollution presents a major environmental challenge in smart city environments. Real-time monitoring of pollution data enables local authorities to analyze the current traffic situation of the city and make decisions accordingly. Deployment of the Internet of Things-based sensors has considerably changed the dynamics of predicting air quality. Existing research has used different machine learning tools for pollution prediction; however, comparative analysis of these techniques is required to have a better understanding of their processing time for multiple datasets. In this paper, we have performed pollution prediction using four advanced regression techniques and present a comparative study to determine the best model for accurately predicting air quality with reference to data size and processing time. We have conducted experiments using Apache Spark and performed pollution estimation using multiple datasets. The Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) have been used as evaluation criteria for the comparison of these regression models. Furthermore, the processing time of each technique through standalone learning and through fitting the hyperparameter tuning on Apache Spark has also been calculated to find the best-fit model in terms of processing time and lowest error rate.","['Air pollution', 'Indexes', 'Machine learning', 'Smart cities']","['IoT', 'smart city', 'air quality index (AQI)', 'data mining', 'Apache Spark']"
"Diabetic retinopathy (DR) is a common eye disease and a significant cause of blindness in diabetic patients. Regular screening with fundus photography and timely intervention is the most effective way to manage the disease. The large population of diabetic patients and their massive screening requirements have generated interest in a computer-aided and fully automatic diagnosis of DR. Deep neural networks, on the other hand, have brought many breakthroughs in various tasks in the recent years. To automate the diagnosis of DR and provide appropriate suggestions to DR patients, we have built a dataset of DR fundus images that have been labeled by the proper treatment method that is required. Using this dataset, we trained deep convolutional neural network models to grade the severities of DR fundus images. We were able to achieve an accuracy of 88.72% for a four-degree classification task in the experiments. We deployed our models on a cloud computing platform and provided pilot DR diagnostic services for several hospitals; in the clinical evaluation, the system achieved a consistency rate of 91.8% with ophthalmologists, demonstrating the effectiveness of our work.","['Diabetes', 'Lesions', 'Task analysis', 'Retinopathy', 'Neural networks', 'Retina', 'Feature extraction']","['Diabetic retinopathy', 'automatic diagnosis', 'deep neural networks']"
"In this paper, we investigate the dual hesitant bipolar fuzzy multiple attribute decision making problems in which there exists a prioritization relationship over attributes. Then, motivated by the idea of Hamacher operations and prioritized aggregation operators, we have developed some Hamacher prioritized aggregation operators for aggregating dual hesitant bipolar fuzzy information: dual hesitant bipolar fuzzy Hamacher prioritized average operator, dual hesitant bipolar fuzzy Hamacher prioritized geometric operator, dual hesitant bipolar fuzzy Hamacher prioritized weighted average operator, dual hesitant bipolar fuzzy Hamacher prioritized weighted geometric operator. Then, we have utilized these operators to develop some approaches to solve the dual hesitant bipolar fuzzy multiple attribute decision making problems. Finally, a real-world example is then analyzed to illustrate the relevance and effectiveness of the proposed methodology.","['Fuzzy sets', 'Decision making', 'Computational modeling', 'Quantum computing', 'Economics']","['Multiple attribute decision making (MADM)', 'Bipolar fuzzy set', 'Dual hesitant bipolar fuzzy set', 'Dual hesitant bipolar fuzzy Hamacher prioritized weighted average (DHBFHPWA) operator', 'dual hesitant bipolar fuzzy Hamacher prioritized weighted geometric (DHBFHPWG) operator']"
"In today's increasingly rich material life, people are shifting their focus from the physical world to the spiritual world. In order to identify and care for people's emotions, human-machine interaction systems have been created. The currently available human-machine interaction systems often support the interaction between human and robot under the line-of-sight (LOS) propagation environment, while most communications in terms of human-to-human and human-to-machine are non-LOS (NLOS). In order to break the limitation of the traditional human-machine interaction system, we propose the emotion communication system based on NLOS mode. Specifically, we first define the emotion as a kind of multimedia which is similar to voice and video. The information of emotion can not only be recognized, but can also be transmitted over a long distance. Then, considering the real-time requirement of the communications between the involved parties, we propose an emotion communication protocol, which provides a reliable support for the realization of emotion communications. We design a pillow robot speech emotion communication system, where the pillow robot acts as a medium for user emotion mapping. Finally, we analyze the real-time performance of the whole communication process in the scene of a long distance communication between a mother-child users' pair, to evaluate the feasibility and effectiveness of emotion communications.","['Emotion recognition', 'Physiology', 'Man-machine systems', 'Robot sensing systems', 'Communication systems']","['Emotion communications', 'emotion communication protocol', 'Markov state transfer']"
"Although there are many attempts to build an optimal model for feature selection in Big Data applications, the complex nature of processing such kind of data makes it still a big challenge. Accordingly, the data mining process may be obstructed due to the high dimensionality and complexity of huge data sets. For the most informative features and classification accuracy optimization, the feature selection process constitutes a mandatory pre-processing phase to reduce dataset dimensionality. The exhaustive search for the relevant features is time-consuming. In this paper, a new binary variant of the wrapper feature selection grey wolf optimization and particle swarm optimization is proposed. The K-nearest neighbor classifier with Euclidean separation matrices is used to find the optimal solutions. A tent chaotic map helps in avoiding the algorithm from locked to the local optima problem. The sigmoid function employed for converting the search space from a continuous vector to a binary one to be suitable to the problem of feature selection. Cross-validation K-fold is used to overcome the overfitting issue. A variety of comparisons have been made with well-known and common algorithms, such as the particle swarm optimization algorithm, and the grey wolf optimization algorithm. Twenty datasets are used for the experiments, and statistical analyses are conducted to approve the performance and the effectiveness and of the proposed model with measures like selected features ratio, classification accuracy, and computation time. The cumulative features picked through the twenty datasets were 196 out of 773, as opposed to 393 and 336 in the GWO and the PSO, respectively. The overall accuracy is 90% relative to other algorithms ' 81.6 and 86.8. The total processing time for all datasets equals 184.3 seconds, wherein GWO and PSO equal 272 and 245.6, respectively.","['Optimization', 'Feature extraction', 'Classification algorithms', 'Particle swarm optimization', 'Data mining', 'Genetic algorithms', 'Data models']","['Particle swarm optimization (PSO)', 'grey wolf optimization (GWO)', 'data mining', 'big data analytics', 'feature selection']"
"IoT is becoming more common and popular due to its wide range of applications in various domains. They collect data from the real environment and transfer it over the networks. There are many challenges while deploying IoT in a real-world, varying from tiny sensors to servers. Security is considered as the number one challenge in IoT deployments, as most of the IoT devices are physically accessible in the real world and many of them are limited in resources (such as energy, memory, processing power and even physical space). In this paper, we are focusing on these resource-constrained IoT devices (such as RFID tags, sensors, smart cards, etc.) as securing them in such circumstances is a challenging task. The communication from such devices can be secured by a mean of lightweight cryptography, a lighter version of cryptography. More than fifty lightweight cryptography (plain encryption) algorithms are available in the market with a focus on a specific application(s), and another 57 algorithms have been submitted by the researchers to the NIST competition recently. To provide a holistic view of the area, in this paper, we have compared the existing algorithms in terms of implementation cost, hardware and software performances and attack resistance properties. Also, we have discussed the demand and a direction for new research in the area of lightweight cryptography to optimize balance amongst cost, performance and security.","['Cryptography', 'Security', 'Encryption', 'Software algorithms', 'Internet of Things', 'Random access memory', 'Software']","['IoT', 'lightweight', 'cryptography', 'sensors', 'RFID', 'smart cards']"
"As one of the key techniques determining the overall system performances, efficient and reliable algorithms for improving the classification accuracy of motor imagery (MI) based electroencephalography (EEG) signals are highly desired for the development of brain-computer interface (BCI) systems. In this study, we propose, for the first time to the best of our knowledge, a novel data adaptive empirical wavelet transform (EWT) based signal decomposition method for improving the classification accuracy of MI based EEG signals. Specifically, to reduce the system complexity and execution time, the proposed method selects 18 electrodes out of 118 to analyze the non-stationary and nonlinear EEG signal behaviors. Meanwhile, the method adopts the Welch power spectral density (PSD) analysis method for single mode selection out of the total 10 for each channel, and the Hilbert transform (HT) method for both instantaneous amplitude (IA) and instantaneous frequency (IF) signal components extraction for each selected mode. With seven commonly used machine-learning classifiers adopted, extensive experiments were conducted with the benchmark dataset IVa from BCI competition III to evaluate the performance of the proposed method. Results show that with the IA and IF component features being tested using the least-square support vector machine (LS-SVM) classifier, the EWT method achieves an average classification accuracy of 95.2% and 94.6% respectively, which is higher as compared with the existing methods. While for every participant, a classification accuracy of at least 80% could be achieved by employing a single feature only. Results also show that a combination of EWT and higher order statistics features, which contain both kurtosis and skewness of the extracted instantaneous components, help achieve a higher success rate. The better performances of EWT over those of the existing methods demonstrate the effectiveness and great potential of EWT for BCI system applications.","['Electroencephalography', 'Feature extraction', 'Task analysis', 'Transforms', 'Brain modeling', 'Pattern classification', 'Brain-computer interfaces']","['Brain-computer interface', 'motor imagery', 'electroencephalography', 'empirical wavelet transform', 'higher order statistics']"
"This paper presents a unique technique to enhance isolation between transmit/receive radiating elements in densely packed array antenna by embedding a metamaterial (MTM) electromagnetic bandgap (EMBG) structure in the space between the radiating elements to suppress surface currents that would otherwise contribute towards mutual coupling between the array elements. The proposed MTM-EMBG structure is a cross-shaped microstrip transmission line on which are imprinted two outward facing E-shaped slits. Unlike other MTM structures, there is no short-circuit grounding using via-holes. With this approach, the maximum measured mutual coupling achieved is -60 dB @ 9.18 GHz between the transmit patches (#1 & #2) and receive patches (#3 & #4) in a four-element array antenna. Across the antenna's measured operating frequency range of 9.12-9.96 GHz, the minimum measured isolation between each element of the array is 34.2 dB @ 9.48 GHz, and there is no degradation in radiation patterns. The average measured isolation over this frequency range is 47 dB. The results presented confirm the proposed technique is suitable in applications such as synthetic aperture radar and multiple-input multiple-output systems.","['Slabs', 'Mutual coupling', 'Microstrip antenna arrays', 'Antenna measurements', 'Photonic band gap', 'Substrates']","['Metamaterial', 'electromagnetic bandgap', 'array antennas', 'decoupling slab', 'mutual coupling', 'synthetic aperture radar', 'multiple-input multiple-output']"
"Fifth-generation (5G) and beyond networks are envisioned to provide multi-services with diverse specifications. Network slicing is identified as a key enabling technology to enable 5G networks with multi-services. Network slicing allows a transition from a network-as-an-infrastructure setup to a network-as-a-service to enable numerous 5G smart services with diverse requirements. Although several surveys and tutorials have discussed network slicing in detail, there is no comprehensive study discussing the taxonomy and requirements of network slicing. In this paper, we present and investigate key recent advances of network slicing towards enabling several Internet of Things (IoT) smart applications. A taxonomy is devised for network slicing using different parameters: key design principles, enablers, slicing resources levels, service function chaining schemes, physical infrastructures, and security. Furthermore, we discuss key requirements for network slicing to enable smart services. Finally, we present several open research challenges along with possible guidelines for network slicing.","['Network slicing', 'Taxonomy', '5G mobile communication', 'Internet of Things', 'Security', 'Network function virtualization', 'Cloud computing']","['5G', '6G', 'network slicing', 'software-defined networking', 'network function virtualization', 'Internet of Things']"
"Object detection is a significant issue in visual surveillance. Faster region-based convolutional neural network (R-CNN) is a typical object detection algorithm of deep learning; however, neither its generalization ability nor its detection accuracy of small object is high. In this paper, an effective object detection algorithm is proposed for the small and occluded objects, which is based on multi-layer convolution feature fusion (MCFF) and online hard example mining (OHEM). First, the candidate regions are generated with region proposal network optimized by MCFF. Then, an effective OHEM algorithm is employed to train the region-based ConvNet detector. The hard examples are automatically selected to improve training efficiency. The avoidance of invalid examples accelerates the convergence speed of the model training. The experiments are performed on KITTI data set in intelligent traffic scenario. The proposed method outperforms the popular methods, such as Faster R-CNN, Regionlets, in terms of the overall detection accuracy. Furthermore, our method is good at the detection of small and occluded objects.","['Object detection', 'Feature extraction', 'Convolution', 'Training', 'Automobiles', 'Microsoft Windows', 'Classification algorithms']","['Deep leaning', 'multi-layer convolution feature fusion', 'object detection', 'online hard example mining', 'region proposal network']"
"Real-time apple detection in orchards is one of the most effective ways of estimating apple yields, which helps in managing apple supplies more effectively. Traditional detection methods used highly computational machine learning algorithms with intensive hardware set up, which are not suitable for infield real-time apple detection due to their weight and power constraints. In this study, a real-time embedded solution inspired from “Edge AI” is proposed for apple detection with the implementation of YOLOv3-tiny algorithm on various embedded platforms such as Raspberry Pi 3 B+ in combination with Intel Movidius Neural Computing Stick (NCS), Nvidia's Jetson Nano and Jetson AGX Xavier. Data set for training were compiled using acquired images during field survey of apple orchard situated in the north region of Italy, and images used for testing were taken from widely used google data set by filtering out the images containing apples in different scenes to ensure the robustness of the algorithm. The proposed study adapts YOLOv3-tiny architecture to detect small objects. It shows the feasibility of deployment of the customized model on cheap and power-efficient embedded hardware without compromising mean average detection accuracy (83.64%) and achieved frame rate up to 30 fps even for the difficult scenarios such as overlapping apples, complex background, less exposure of apple due to leaves and branches. Furthermore, the proposed embedded solution can be deployed on the unmanned ground vehicles to detect, count, and measure the size of the apples in real-time to help the farmers and agronomists in their decision making and management skills.","['Real-time systems', 'Hardware', 'Artificial intelligence', 'Robots', 'Graphics processing units', 'Embedded systems', 'Training']","['Edge AI', 'machine learning', 'real-time embedded systems', 'object detection']"
"Improving the accuracy of power system load forecasting is important for economic dispatch. However, a load sequence is highly nonstationary and hence makes accurate forecasting difficult. In this paper, a method based on wavelet decomposition (WD) and a second-order gray neural network combined with an augmented Dickey–Fuller (ADF) test is proposed to improve the accuracy of load forecasting. First, the load sequence is decomposed by WD to reduce the nonstationary load sequence. Then, the ADF test is adopted as the test method for the stationary load sequence of each decomposed component after WD in which the test results determine the best WD level. Finally, because forecasting the wavelet details characterized by high frequencies is difficult owing to its fluctuation, a second-order gray forecasting model is used to forecast each component after WD. Furthermore, to obtain the optimum parameters of the second-order gray forecasting model, the neural network mapping approach is used to build the second-order gray neural network forecasting model. The simulation result of a real load sequence verifies that the method proposed in this paper can effectively improve the load-forecasting accuracy.","['Load modeling', 'Neural networks', 'Predictive models', 'Forecasting', 'Mathematical model', 'Load forecasting', 'Wavelet transforms']","['Augmented Dickey–Fuller test', 'load forecasting', 'neural network mapping', 'second-order gray neural network forecasting', 'stationary load sequence']"
"Smart cities are becoming a reality. Various aspects of modern cities are being automated and integrated with information and communication technologies to achieve higher functionality, optimized resources utilization, and management, and improved quality of life for the residents. Smart cities rely heavily on utilizing various software, hardware, and communication technologies to improve the operations in areas, such as healthcare, transportation, energy, education, logistics, and many others, while reducing costs and resources consumption. One of the promising technologies to support such efforts is the Cloud of Things (CoT). CoT provides a platform for linking the cyber parts of a smart city that are executed on the cloud with the physical parts of the smart city, including residents, vehicles, power grids, buildings, water networks, hospitals, and other resources. Another useful technology is Fog Computing, which extends the traditional Cloud Computing paradigm to the edge of the network to enable localized and real-time support for operating-enhanced smart city services. However, proper integration and efficient utilization of CoT and Fog Computing is not an easy task. This paper discusses how the service-oriented middleware (SOM) approach can help resolve some of the challenges of developing and operating smart city services using CoT and Fog Computing. We propose an SOM called SmartCityWare for effective integration and utilization of CoT and Fog Computing. SmartCityWare abstracts services and components involved in smart city applications as services accessible through the service-oriented model. This enhances integration and allows for flexible inclusion and utilization of the various services needed in a smart city application. In addition, we discuss the implementation and experimental issues of SmartCityWare and demonstrate its use through examples of smart city applications.","['Smart cities', 'Edge computing', 'Cloud computing', 'Monitoring', 'Intelligent sensors']","['Smart city', 'Cloud of Things', 'Internet of Things', 'cyber physical systems', 'middleware', 'service-oriented middleware', 'cloud computing', 'fog computing']"
"In the digital world of today, global security issues have given rise to video surveillance devices. Gait-based human recognition is an emerging behavioral biometric trait for intelligent surveillance monitoring because of its non-contact and non-cooperation with subjects. Other benefits of gait recognition in video surveillance are that it can be acquired at a distance and help to identify an object under low-resolution videos. This paper surveys extensively the current progress made towards vision-based human gait recognition. This paper discusses historical research that performs analysis of gait locomotion and provides information on how gait recognition can be performed. This paper describes measuring metrics that can be used to measure the performance of gait recognition model under verification and identification mode. This paper also provides an up-to-date review of existing studies on gait recognition representations (model based and model free). We also provide an extensive survey of available gait databases used in state-of-art gait recognition models, created since 1998. Furthermore, it offers insight into open research problems that help researchers to explore unripe areas in gait analysis, such as occlusion, view variations, and appearance changes in gait recognition. This paper also identifies the future perspectives in gait recognition and also outlines the proposed work.","['Gait recognition', 'Legged locomotion', 'Feature extraction', 'Sensors', 'Pattern recognition', 'Real-time systems', 'Face']","['Biometric', 'gait analysis', 'gait recognition', 'gait representation', 'pattern recognition', 'feature extraction']"
"In this paper, we report an effective cryptosystem aimed at securing the transmission of medical images in an Internet of Healthcare Things (IoHT) environment. This contribution investigates the dynamics of a 2-D trigonometric map designed using some well-known maps: Logistic-sine-cosine maps. Stability analysis reveals that the map has an infinite number of solutions. Lyapunov exponent, bifurcation diagram, and phase portrait are used to demonstrate the complex dynamic of the map. The sequences of the map are utilized to construct a robust cryptosystem. First, three sets of key streams are generated from the newly designed trigonometric map and are used jointly with the image components (R, G, B) for hamming distance calculation. The output distance-vector, corresponding to each component, is then Bit-XORed with each of the key streams. The output is saved for further processing. The decomposed components are again Bit-XORed with key streams to produce an output, which is then fed into the conditional shift algorithm. The Mandelbrot Set is used as the input to the conditional shift algorithm so that the algorithm efficiently applies confusion operation (complete shuffling of pixels). The resultant shuffled vectors are then Bit-XORed (Diffusion) with the saved outputs from the early stage, and eventually, the image vectors are combined to produce the encrypted image. Performance analyses of the proposed cryptosystem indicate high security and can be effectively incorporated in an IoHT framework for secure medical image transmission.","['Biomedical imaging', 'Encryption', 'Medical services', 'Streaming media', 'Stability analysis']","['Internet of health things', 'encryption', 'chaotic systems', 'dynamics analysis', 'lightweight security']"
"The integration of simultaneous wireless information and power transfer (SWIPT) and cooperative relay (CoR) techniques has evolved as a new phenomenon for the next-generation wireless communication system. CoR is used to get energy and spectral efficient network and to solve the issues of fading, path loss, shadowing, and smaller coverage area. Relay nodes are battery-constrained or battery-less devices. They need some charging systems externally as replacing or recharging of their batteries sometimes which are not feasible and convenient. Energy harvesting (EH) is the most cost-effective, suitable, and safer solutions to power up these relays. Among various types of the EH, SWIPT is the most prominent technique as it provides spectral efficiency by delivering energy and information to the relays at the same time. This paper reviews the combination of CoR and SWIPT. From basic to advanced architectures, applications and taxonomies of CoR and SWIPT are presented, various forms of resource allocation and relay selection algorithms are covered. The usage of CoR and SWIPT in the fifth-generation wireless networks is discussed. This paper focuses on the integral aspects of the CoR and SWIPT to other next-generation wireless communication systems and techniques such as multiple-input-multiple-output, wireless sensor network, cognitive radio, vehicular ad hoc network, non-orthogonal multiple access, beamforming technique, and the Internet of Things. Some open issues and future directions and challenges are given in this paper.","['Relays', 'Wireless communication', 'Wireless sensor networks', 'Batteries', '5G mobile communication', 'MIMO communication', 'Energy harvesting']","['Cooperative relay', 'SWIPT', 'energy harvesting', '5G', 'resource allocation', 'relay selection', 'IoT', 'next-generation wireless communications']"
"A novel water dense dielectric patch antenna (DDPA) fed by an L-shaped probe is proposed and investigated. In contrast to the water antennas in the literature, including the water monopole and the water dielectric resonator antenna, the operation mechanism of the proposed water DDPA is similar to the conventional metallic patch antenna. The antenna is excited in a mode like the TM 10 mode of the rectangular patch antenna. An L-shaped probe, which is widely used for the conventional patch antenna, is used to excite the water DDPA. A study on the bandwidth performance of the proposed design reveals that wide bandwidth can be achieved for the antenna by choosing a thick supporting substrate between the water patch and the ground plane. A prototype is fabricated to confirm the correctness of the design. An impedance bandwidth of 8%, maximum gain of 7.3 dBi, radiation efficiency up to 70%, and symmetrically unidirectional patterns with low backlobe and low cross polarization levels are obtained. Furthermore, owing to the transparency of the water patch, the proposed water DDPA can be conveniently integrated with the solar cells to realize a dual-function design. Measurements on the prototype demonstrate that the existence of the solar cells does not significantly affect the performance of the antenna and vice versa.","['Dielectrics', 'Patch antennas', 'Antenna measurements', 'Dielectric measurement', 'Photovoltaic cells', 'Bandwidth allocation', 'Liquids']","['Water patch', 'pure water', 'liquid antenna', 'dense dielectric patch antenna', 'L-probe']"
"Traditional waste management system operates based on daily schedule which is highly inefficient and costly. The existing recycle bin has also proved its ineffectiveness in the public as people do not recycle their waste properly. With the development of Internet of Things (IoT) and Artificial Intelligence (AI), the traditional waste management system can be replaced with smart sensors embedded into the system to perform real time monitoring and allow for better waste management. The aim of this research is to develop a smart waste management system using LoRa communication protocol and TensorFlow based deep learning model. LoRa sends the sensor data and Tensorflow performs real time object detection and classification. The bin consists of several compartments to segregate the waste including metal, plastic, paper, and general waste compartment which are controlled by the servo motors. Object detection and waste classification is done in TensorFlow framework with pre-trained object detection model. This object detection model is trained with images of waste to generate a frozen inference graph used for object detection which is done through a camera connected to the Raspberry Pi 3 Model B+ as the main processing unit. Ultrasonic sensor is embedded into each waste compartment to monitor the filling level of the waste. GPS module is integrated to monitor the location and real time of the bin. LoRa communication protocol is used to transmit data about the location, real time and filling level of the bin. RFID module is embedded for the purpose of waste management personnel identification.","['Waste management', 'Recycling', 'Monitoring', 'Machine learning', 'Object detection', 'Metals', 'Temperature sensors']","['Internet of Things', 'LoRa', 'object detection', 'smart waste management system', 'TensorFlow']"
"Oral cancer is a major global health issue accounting for 177,384 deaths in 2018 and it is most prevalent in low- and middle-income countries. Enabling automation in the identification of potentially malignant and malignant lesions in the oral cavity would potentially lead to low-cost and early diagnosis of the disease. Building a large library of well-annotated oral lesions is key. As part of the MeMoSA ® (Mobile Mouth Screening Anywhere) project, images are currently in the process of being gathered from clinical experts from across the world, who have been provided with an annotation tool to produce rich labels. A novel strategy to combine bounding box annotations from multiple clinicians is provided in this paper. Further to this, deep neural networks were used to build automated systems, in which complex patterns were derived for tackling this difficult task. Using the initial data gathered in this study, two deep learning based computer vision approaches were assessed for the automated detection and classification of oral lesions for the early detection of oral cancer, these were image classification with ResNet-101 and object detection with the Faster R-CNN. Image classification achieved an F1 score of 87.07% for identification of images that contained lesions and 78.30% for the identification of images that required referral. Object detection achieved an F1 score of 41.18% for the detection of lesions that required referral. Further performances are reported with respect to classifying according to the type of referral decision. Our initial results demonstrate deep learning has the potential to tackle this challenging task.","['Cancer', 'Lesions', 'Image classification', 'Machine learning', 'Cavity resonators', 'Image segmentation']","['Composite annotation', 'deep learning', 'image classification', 'object detection', 'oral cancer', 'oral potentially malignant disorders']"
"Sharing traffic information on the vehicular network can help in the implementation of intelligent traffic management, such as car accident warnings, road construction notices, and driver route changes to reduce traffic congestion earlier. In the future, in the case of autonomous driving, traffic information will be exchanged more frequently and more immediately. Once the exposed traffic incident is incorrect, the driving route will be misleading, and the driving response may be in danger. The blockchain ensures the correctness of data and tampers resistance in the consensus mechanism, which can solve such similar problems. This paper proposes a proof-of-event consensus concept applicable to vehicular networks rather than proof-of-work or proof-of-authority approaches. The traffic data are collected through the roadside units, and the passing vehicles will verify the correctness when receiving the event notification. In addition, a two-phase transaction on blockchain is introduced to send warning messages in appropriate regions and time periods. The simulation results show that the proposed mechanism can effectively feedback the correctness of traffic events and provide traceable events with trust verification.","['Blockchain', 'Vehicular ad hoc networks', 'Privacy', 'Protocols', 'Authentication', 'Accidents', 'Roads']","['Blockchain', 'event validation', 'proof-of-event consensus', 'trust verification', 'vehicular ad-hoc networks']"
"Brain-computer interfaces (BCIs) have enabled individuals to control devices, such as spellers, robotic arms, drones, and wheelchairs, but often these BCI applications are restricted to research laboratories. With the advent of virtual reality (VR) systems and the Internet of Things (IoT) we can couple these technologies to offer real-time control of a user's virtual and physical environment. Likewise, BCI applications are often single-use with user's having no control outside of the restrictions placed upon the applications at the time of creation. Therefore, there is a need to create a tool that allows users the flexibility to create and modularize aspects of BCI applications for control of IoT devices and VR environments. Using a popular video game engine, Unity, and coupling it with BCI2000, we can create diverse applications that give the end-user additional autonomy during the task at hand. We demonstrate the validity of controlling a Unity-based VR environment and several commercial IoT devices via direct neural interfacing processed through BCI2000.","['Task analysis', 'Games', 'Graphical user interfaces', 'Internet of Things', 'Brain-computer interfaces', 'Virtual reality', 'Electroencephalography']","['Brain computer interface', 'virtual reality', 'Internet of Things', 'Unity', 'sensorimotor rhythms']"
"V2X (Vehicle to everything) communications can be currently supported by standards based on IEEE 802.11p (e.g. DSRC or ITS-G5) or LTE-V2X (also known as Cellular V2X or C-V2X) technologies. There has been an intense debate in the community on which technology achieves best performance. However, existing studies do not take into account the variability present in the generation and size of V2X messages. This variability can significantly impact the operation and performance of the Medium Access Control (MAC). This study progresses the state of the art by conducting an in-depth evaluation of both technologies under different message traffic patterns. In particular, we consider aperiodic and periodic messages of constant or variable size based on the standardized ETSI Cooperative Awareness Messages (CAMs). This study considers different scenarios and possible configurations of IEEE 802.11p and LTE-V2X. We demonstrate that IEEE 802.11p can better cope with variations in the size and time interval between messages. We also demonstrate (and characterize) that the LTE-V2X sensing-based semi-persistent scheduling faces certain inefficiencies when transmitting aperiodic messages of variable size. These inefficiencies result in that IEEE 802.11p generally outperforms LTE-V2X when transmitting aperiodic messages of variable size except when the channel load is very low.","['Vehicle-to-everything', 'Rail to rail inputs', 'Cams', 'Sensors', 'Long Term Evolution', 'Safety']","['LTE-V2X', 'C-V2X', 'cellular V2X', 'IEEE 80211p', 'ITS-G5', 'DSRC', 'comparison', 'aperiodic', 'variable size', 'CAM']"
"Wireless Sensor Networks (WSNs) consist of several battery powered sensor nodes. The sensing coverage of the Field of Interest (FoI) is an important function of the sensor nodes in connected WSNs. A FoI is said to be covered if each point in the FoI is monitored by at least one sensor node. Due to small size, battery power supply, simple architecture, and light weight Operating System of the sensor nodes, maintaining the desired coverage of the FoI consists various issues and challenges in a connected WSN. This paper surveys the existing work done to address various issues and challenges for solving the coverage and connectivity problems in WSNs. Our discussion emphasis on sensing models, classification of coverage, research issues in WSNs and practical challenges in deployment of WSNs. We review a brief but complete overview of the various solutions of coverage problems in connected WSNs and describing insights into issues and challenges for research in this area.","['Wireless sensor networks', 'Monitoring', 'Sensors', 'Batteries', 'Probabilistic logic', 'Euclidean distance', 'Task analysis']","['Coverage', 'communication', 'monitoring', 'protocol designing', 'sensor nodes']"
"This paper investigates optical camera communication (OCC) technologies, targeting new spectrum, multiple-input-multiple-output diversity, transmission access, and novel architectures with augmented reality user experience for the extended 5G wireless network. It provides the current OCC research status and trend pertaining to these technologies, especially an inside view on the revision of IEEE 802.15.7-2011 known as the IEEE 802.15.7m (TG7m) Optical Wireless Communication Task Group. Such standardization activities have a major impact on the development of OCC technologies. In addition, it provides a detailed review of the related literature. Herein, OCC technologies are classified into five categories to elucidate their operations and technical characteristics. Furthermore, a concise performance analysis, numerical simulations, and some comparison of the results obtained for associated systems are presented, and the future directions of research and development are discussed.","['5G mobile communication', 'IEEE 802.15 Standard', 'Wireless communication', 'Optical fiber networks', 'Radio frequency', 'Cameras']","['5G network', 'optical spectrum', 'optical camera communication', 'OCC', 'IEEE 802.15.7m', 'TG7m', 'modulation', 'coding', 'performance analysis']"
"Ring roads have been widely built in many cities, especially in the central districts with excessively heavy traffic demands and frequently generated congestion. In order to improve the operations and reduce traffic delay on urban ring roads, this paper developed a coordinated signal control system for urban ring roads under vehicle-infrastructure connected environment. The speed guidance would be provided to motorists utilizing four sub-systems including detection, communication, signal control, and expected speed calculation in the system. The signal timing parameters such as cycle length, green split, and offset, would be adjusted based on the artificial bee colony-shuffled frog leaping algorithm. The proposed signal control system had been test using VISSIM simulation model and the simulation results showed that the average delay, number of stops, and queue length were significantly improved compared with the conventional traffic control system.","['Roads', 'Real-time systems', 'Green products', 'Traffic control', 'Optimization', 'Timing']","['Intelligent transportation system', 'vehicle-infrastructure connected environment', 'traffic signal control optimization']"
"Energy efficiency and sustainability are important factors to address in the context of smart cities. In this sense, smart metering and nonintrusive load monitoring play a crucial role in fighting energy thefts and for optimizing the energy consumption of the home, building, city, and so forth. The estimated number of smart meters will exceed 800 million by 2020. By providing near real-time data about power consumption, smart meters can be used to analyze electricity usage trends and to point out anomalies guaranteeing companies' safety and avoiding energy wastes. In literature, there are many proposals approaching the problem of anomaly detection. Most of them are limited because they lack context and time awareness and the false positive rate is affected by the change in consumer habits. This research work focuses on the need to define anomaly detection method capable of facing the concept drift, for instance, family structure changes; a house becomes a second residence, and so forth. The proposed methodology adopts long short term memory network in order to profile and forecast the consumers' behavior based on their recent past consumptions. The continuous monitoring of the consumption prediction errors allows us to distinguish between possible anomalies and changes (drifts) in normal behavior that correspond to different error motifs. The experimental results demonstrate the suitability of the proposed framework by pointing out an anomaly in a near real-time after a training period of one week.","['Anomaly detection', 'Energy consumption', 'Monitoring', 'Clustering algorithms', 'Smart grids', 'Smart meters', 'Training']","['Anomaly detection', 'concept drift', 'machine learning', 'smart grid', 'time series analysis']"
"Image encryption is an efficient visual technology to protect private images. This paper develops an image encryption algorithm utilizing the principles of the Josephus problem and the filtering technology. The encryption algorithm follows the classical diffusion and confusion structure. The principle of Josephus problem is used to shuffle the image pixels to different positions to achieve the confusion property. Using a randomly generated filter, the filtering technology can spread slight changes of the original image to all pixels of the cipher image to obtain diffusion property. The simulation results show that the developed image encryption algorithm is able to encrypt different kinds of images into cipher images with uniform distribution. The security analysis demonstrates that it has an extremely sensitive secret key, can resist various security attacks, and has a better performance than several advanced image encryption algorithms.","['Encryption', 'Digital images', 'Two dimensional displays', 'Chaos', 'Visualization']","['Cryptography', 'image encryption', 'image filtering', 'multimedia security', 'security analysis']"
Retracted.,[],[]
"One of the main features of adaptive systems is an oscillatory convergence that exacerbates with the speed of adaptation. Recently, it has been shown that closed-loop reference models (CRMs) can result in improved transient performance over their open-loop counterparts in model reference adaptive control. In this paper, we quantify both the transient performance in the classical adaptive systems and their improvement with CRMs. In addition to deriving bounds on L-2 norms of the derivatives of the adaptive parameters that are shown to be smaller, an optimal design of CRMs is proposed that minimizes an underlying peaking phenomenon. The analytical tools proposed are shown to be applicable for a range of adaptive control problems including direct control and composite control with observer feedback. The presence of CRMs in adaptive backstepping and adaptive robot control is also discussed. Simulation results are presented throughout this paper to support the theoretical derivations.","['Adaptation models', 'Customer relationship management', 'Transient analysis', 'Adaptive control', 'Oscillators', 'Mathematical model']","['Adaptive algorithms', 'adaptive algorithms', 'adaptive control', 'observers', 'closed-loop reference model']"
"Recognition of discriminative neural signatures and regions corresponding to emotions are important in understanding the neuron functional network underlying the human emotion process. Electroencephalogram (EEG) is a spatial discrete signal. In this paper, in order to extract the spatio-temporal characteristics and the inherent information implied by functional connections, a multichannel EEG emotion recognition method based on phase-locking value (PLV) graph convolutional neural networks (P-GCNN) is proposed. The basic idea of the proposed EEG emotion recognition method is using PLV-based brain network to model multi-channel EEG features as graph signals and then perform EEG emotion classification based on this model. Different from the traditional graph convolutional neural networks (GCNN) methods, the proposed P-GCNN method uses the PLV connectivity of EEG signals to determine the mode of emotional-related functional connectivity, which is used to represent the intrinsic relationship between EEG channels in different emotional states. On this basis, the neural network is trained to extract effective EEG emotional features. We conduct extensive experiments on the SJTU emotion EEG dataset (SEED) and DEAP dataset. The experimental results demonstrate that novel framework can improve the classification accuracy on both datasets, but not so effective on DEAP as on SEED, in which with 84.35% classification accuracy for SEED, and the average accuracies of 73.31%, 77.03% and 79.20% are, respectively, obtained for valence, arousal, and dominance classifications on the DEAP database.","['Prefetching', 'Approximation algorithms', 'Integer linear programming', 'Physical layer', 'Standards', 'Servers', 'Scheduling']","['EEG emotion recognition', 'phase-locking value', 'graph convolutional neural networks', 'brain network', 'functional connectivity']"
"The state-of-the-art machine learning approaches are based on classical von Neumann computing architectures and have been widely used in many industrial and academic domains. With the recent development of quantum computing, researchers and tech-giants have attempted new quantum circuits for machine learning tasks. However, the existing quantum computing platforms are hard to simulate classical deep learning models or problems because of the intractability of deep quantum circuits. Thus, it is necessary to design feasible quantum algorithms for quantum machine learning for noisy intermediate scale quantum (NISQ) devices. This work explores variational quantum circuits for deep reinforcement learning. Specifically, we reshape classical deep reinforcement learning algorithms like experience replay and target network into a representation of variational quantum circuits. Moreover, we use a quantum information encoding scheme to reduce the number of model parameters compared to classical neural networks. To the best of our knowledge, this work is the first proof-of-principle demonstration of variational quantum circuits to approximate the deep Q-value function for decision-making and policy-selection reinforcement learning with experience replay and target network. Besides, our variational quantum circuits can be deployed in many near-term NISQ machines.","['Quantum computing', 'Machine learning', 'Decision making', 'Learning (artificial intelligence)', 'Physics', 'Neural networks', 'Standards']","['Communication network', 'deep reinforcement learning', 'quantum machine learning', 'quantum information processing', 'variational quantum circuits', 'noisy intermediate scale quantum', 'quantum computing']"
"Local energy generation and peer to peer (P2P) energy trading in the local market can reduce the energy consumption cost, emission of harmful gases (as renewable energy sources are used to generate energy at user’s premises) and increase the smart grid resilience. However, local energy trading with peers can have trust and privacy issues. A centralized system can be used to manage this energy trading but it increases the overall cost of the system and also faces several issues. In this paper, to implement a hybrid P2P energy trading market, a blockchain-based system is proposed. It is fully decentralized and allows the market members to interact with each other and trade energy without involving a third party. Smart contracts play a very important role in the blockchain-based energy trading market. They contain all the necessary rules for energy trading. We have proposed three smart contracts to implement the hybrid electricity trading market. The market members interact with the main smart contract, which requests P2P and prosumer to grid smart contracts for further processing. The main objectives of this paper are to propose a model to implement an efficient hybrid energy trading market while reducing cost and peak to average ratio of electricity.","['Contracts', 'Smart grids', 'Privacy', 'Microgrids', 'Energy consumption', 'Peak to average power ratio']","['Blockchain', 'consumers', 'energy trading', 'load', 'PAR', 'power', 'prosumers', 'security']"
"Social distancing plays a pivotal role in preventing the spread of viral diseases illnesses such as COVID-19. By minimizing the close physical contact among people, we can reduce the chances of catching the virus and spreading it across the community. This two-part paper aims to provide a comprehensive survey on how emerging technologies, e.g., wireless and networking, artificial intelligence (AI) can enable, encourage, and even enforce social distancing practice. In this Part I, we provide a comprehensive background of social distancing including basic concepts, measurements, models, and propose various practical social distancing scenarios. We then discuss enabling wireless technologies which are especially effect- in social distancing, e.g., symptom prediction, detection and monitoring quarantined people, and contact tracing. The companion paper Part II surveys other emerging and related technologies, such as machine learning, computer vision, thermal, ultrasound, etc., and discusses open issues and challenges (e.g., privacy-preserving, scheduling, and incentive mechanisms) in implementing social distancing in practice.","['Social factors', 'Human factors', 'Wireless communication', 'COVID-19', 'Artificial intelligence', 'Urban areas']","['Social distancing', 'pandemic', 'COVID-19', 'wireless', 'networking', 'positioning systems', 'AI', 'machine learning', 'data analytics', 'localization', 'privacy-preserving', 'scheduling', 'incentive mechanism']"
"This paper presents the design and realization of a metasurface-based low-profile wideband Circularly Polarized (CP) patch antenna with high performance for Fifth-generation (5G) communication systems. The antenna consists of a modified patch, sandwiched between an array of 4 x 4 symmetrical square ring Metasurface (MTS) and a ground plane. Initially, the intrinsic narrow bandwidth of the conventional patch antenna is increased using a diagonal rectangular slot. For further performance enhancement, the additional resonances and CP radiations are achieved for wideband operation in terms of impedance and Axial Ratio (AR) by effective excitation of surface waves propagating along the MTS. The stacking of MTS on the modified patch without any air gap resulted in an overall compact size of 1.1λ0x 1.1λ0 x 0.093λ0. Simulated and measured results show that the MTS-based antenna offers a wide impedance bandwidth ranging from 24 - 34.1 GHz (34.7%) for |S11| <; -10 with a maximum gain of 11 dBic and a 3-dB AR bandwidth of 24.1 - 29.5 GHz (20.1 %). Moreover, the proposed antenna has a smooth gain response with a small variation in its gain (9.5 - 11 dBic) and a stable left-hand CP radiation in the desired frequency range. The operating bandwidth of this antenna is covering the proposed entire global millimeter-wave spectrum (24.2 - 29.5 GHz) for 5G communication systems.","['Patch antennas', 'Wideband', '5G mobile communication', 'Air gaps']","['Metasurface-based antenna', 'circular polarization', '5G technology', 'millimeter-wave']"
"Sentiment analysis and opinion mining in social networks present nowadays a hot topic of research. However, most of the state of the art works and researches on the automatic sentiment analysis and opinion mining of texts collected from social networks and microblogging websites are oriented toward the binary classification (i.e., classification into “positive”and “negative”) or the ternary classification (i.e., classification into “positive,”“negative,”and “neutral”) of texts. In this paper, we propose a novel approach that, in addition to the aforementioned tasks of binary and ternary classifications, goes deeper in the classification of texts collected from Twitter and classifies these texts into multiple sentiment classes. While in this paper, we limit our scope to seven different sentiment classes, the proposed approach is scalable and can be run to classify texts into more classes. We first introduce SENTA, our tool built to help users select out of a wide variety of features the ones that fit the most for their application, to run the classification, through an easy-to-use graphical user interface. We then use SENTA to run our own experiments of multiclass classification. Our experiments show that the proposed approach can reach up to 60.2% accuracy on the multi-class classification. Nevertheless, the approach proves to be very accurate in binary classification and ternary classification: in the former case, we reach an accuracy of 81.3% for the same data set used after removing neutral tweets, and in the latter case, we reached an accuracy of classification equal to 70.1%.","['Feature extraction', 'Tools', 'Twitter', 'Data mining', 'Sentiment analysis', 'Tagging']","['Twitter', 'sentiment analysis', 'machine learning']"
"Various attacks have emerged as the major threats to the success of a connected world like the Internet of Things (IoT), in which billions of devices interact with each other to facilitate human life. By exploiting the vulnerabilities of cheap and insecure devices such as IP cameras, an attacker can create hundreds of thousands of zombie devices and then launch massive volume attacks to take down any target. For example, in 2016, a record large-scale DDoS attack launched by millions of Mirai-injected IP cameras and smart printers blocked the accessibility of several high-profile websites. To date, the state-of-the-art defense systems against such attacks rely mostly on pre-defined features extracted from the entire flows or signatures. The feature definitions are manual, and it would be too late to block a malicious flow after extracting the flow features. In this work, we present an effective anomaly traffic detection mechanism, namely D-PACK, which consists of a Convolutional Neural Network (CNN) and an unsupervised deep learning model (e.g., Autoencoder) for auto-profiling the traffic patterns and filtering abnormal traffic. Notably, D-PACK inspects only the first few bytes of the first few packets in each flow for early detection. Our experimental results show that, by examining just the first two packets in each flow, D-PACK still performs with nearly 100% accuracy, while features an extremely low false-positive rate, e.g., 0.83%. The design can inspire the emerging efforts towards online anomaly detection systems that feature reducing the volume of processed packets and blocking malicious flows in time.","['Anomaly detection', 'Feature extraction', 'Deep learning', 'Internet of Things', 'Buildings', 'Telecommunication traffic', 'IP networks']","['IoT security', 'anomaly detection', 'convolutional neural network', 'autoendcoder', 'online DL-based anomaly detection']"
"Massive MIMO is one of the promising techniques to improve spectral efficiency and network performance for reaching its targeted multi-gigabit throughput in 5G systems. For 5G New Radio (NR) systems, one of the key differences compared to 4G systems is the utilization of high frequency millimeter wave (mmWave) bands in addition to sub-6GHz bands. To keep the complexity and implementation cost low, hybrid analog-digital beam-forming with large-scale antenna array has become a common design approach to address the issue of higher propagation loss as well as to improve spectral efficiency in mmWave communication in 5G NR. The 5G NR standard is designed to adapt to different beam-forming architecture and deployment scenarios. This paper provides the overview on beam management procedure according to the current 5G standardization progress. We discuss some major challenges of millimeter-wave communications encountered in the current 5G NR standard and present some expected enhancements considered for the future beyond-5G standard.","['5G mobile communication', 'Millimeter wave communication', 'MIMO communication', 'Antenna arrays']","['5G NR systems', 'beam management', 'physical layer', 'beyond 5G', 'hybrid beamforming', 'AI based beam management']"
"The emergence of new data handling technologies and analytics enabled the organization of big data in processes as an innovative aspect in wireless sensor networks (WSNs). Big data paradigm, combined with WSN technology, involves new challenges that are necessary to resolve in parallel. Data aggregation is a rapidly emerging research area. It represents one of the processing challenges of big sensor networks. This paper introduces the big data paradigm, its main dimensions that represent one of the most challenging concepts, and its principle analytic tools which are more and more introduced in the WSNs technology. The paper also presents the big data challenges that must be overcome to efficiently manipulate the voluminous data, and proposes a new classification of these challenges based on the necessities and the challenges of WSNs. As the big data aggregation challenge represents the center of our interest, this paper surveys its proposed strategies in WSNs.","['Big Data', 'Wireless sensor networks', 'Data aggregation', 'Tools', 'Clustering algorithms', 'Organizations']","['Big data', 'data aggregation', 'wireless sensor networks']"
"In this article, a comprehensive overview of the Crow Search Algorithm (CSA) is introduced with detailed discussions, which is intended to keep researchers interested in swarm intelligence algorithms and optimization problems. CSA is a new swarm intelligence algorithm recently developed, which simulates crow behavior in storing excess food and retrieving it when needed. In the optimization theory, the crow is the searcher, the surrounding environment is the search space, and randomly storing the location of food is a feasible solution. Among all food locations, the location where the most food is stored is considered to be the global optimal solution, and the objective function is the amount of food. By simulating the intelligent behavior of crows, CSA tries to find optimal solutions to various optimization problems. It has gained a considerable interest worldwide since its advantages like simple implementation, a few numbers of parameters, flexibility, etc. This survey introduces a comprehensive variant of CSA, including hybrid, modified, and multi-objective versions. Furthermore, based on the analyzed papers published in the literature by some publishers such as IEEE, Elsevier, and Springer, the comprehensive application scenarios of CSA such as power, computer science, machine learning, civil engineering have also been reviewed. Finally, the advantages and disadvantages of CSA have been discussed by conducting some comparative experiments with other similar published peers.","['Optimization', 'Particle swarm optimization', 'Heuristic algorithms', 'Classification algorithms', 'Genetic algorithms', 'Mathematical model']","['Crow search algorithm', 'CSA', 'swarm intelligence', 'meta-heuristics', 'optimization', 'nature-inspired algorithms']"
"In this paper, a distributed hierarchical control is proposed for ac microgrid, which could apply to both grid-connected (GC) mode and islanded (IS) mode as well as mode transitions. The control includes three control levels: 1) the basic droop control is adopted as the primary control; 2) the secondary control is based on the distributed control with a leaderâĂ""follower consensus protocol; and 3) the tertiary level is a mode-supervisory control, which manages the different control targets of four operation modes. Under the proposed control framework, the following targets are achieved: 1) the frequency/voltage recovery and accurate power sharing in IS mode; 2) flexible power flow regulation between utility-grid and microgrid in GC mode; 3) universal control strategy from GC to IS modes without control switching; and 4) smooth active-synchronization from IS mode to GC mode. In this sense, the proposed method can adapt to all four operation modes of microgrid. Compared with central-standard hierarchical control, the proposed method only requires local neighbor-to-neighbor interaction with a sparse distributed communication network. Thus, the scalability, flexibility, reliability, and robustness are greatly improved in practical application. In addition, stability analysis is added to facilitate the control parameter designs, and substantial simulation cases are provided to validate the control feasibility, link-failure-resiliency, and plug-and-play capability.","['Microgrids', 'Voltage control', 'Decentralized control', 'Frequency control', 'Synchronization', 'Communication networks', 'Power system stability']","['Distributed coordination', 'hierarchical control', 'microgrid', 'seamless transition']"
"Social Internet of Vehicles (SIoV) is a new paradigm that enables social relationships among vehicles by integrating vehicle-to-everything communications and social networking properties into the vehicular environment. Through the provision of diverse socially-inspired applications and services, the emergence of SIoV helps to improve the road experience, traffic efficiency, road safety, travel comfort, and entertainment along the roads. However, the computation performance for those applications have been seriously affected by resource-limited on-board units as well as deployment costs and workloads of roadside units. Under such context, an unmanned aerial vehicle (UAV)-assisted mobile edge computing environment over SIoV with a three-layer integrated architecture is adopted in this paper. Within this architecture, we explore the energy-aware dynamic resource allocation problem by taking into account partial computation offloading, social content caching, and radio resource scheduling. Particularly, we develop an optimization framework for total utility maximization by jointly optimizing the transmit power of vehicle and the UAV trajectory. To resolve this problem, an energy-aware dynamic power optimization problem is formulated under the constraint of the evolution law of energy consumption state for each vehicle. By considering two cases, i.e., cooperation and noncooperation among vehicles, we obtain the optimal dynamic power allocation of the vehicle with a fixed UAV trajectory via dynamic programming method. In addition, under the condition of fixed power, a search algorithm is introduced to derive the optimized UAV trajectory based on acceptable ground-UAV distance metric and the optimal offloaded data size of the vehicle. Simulation results are presented to demonstrate the effectiveness of the proposed framework over alternative benchmark schemes.","['Resource management', 'Unmanned aerial vehicles', 'Trajectory', 'Vehicle dynamics', 'Dynamic scheduling', 'Computer architecture', 'Optimization']","['Internet of Vehicles', 'social networks', 'unmanned aerial vehicles', 'mobile edge computing', 'resource allocation']"
"Faster-than-Nyquist (FTN) signaling can improve the bandwidth utilization. In this paper, we will provide a comprehensive survey on the topic. The history and the applications of FTN signaling are first introduced. Then, the basic principles and the system framework of FTN signaling are presented. Next, more details on transmitter and receiver optimization are discussed. Finally, the current research challenges on FTN signaling are identified and conclusions are provided.","['Bandwidth', 'Receivers', 'OFDM', 'Frequency-domain analysis', 'Transmitters', 'Communication systems', 'Modulation']","['Faster-than-Nyquist (FTN)', 'capacity analysis', 'transmitter design', 'receiver design']"
"Grasshopper Optimization Algorithm (GOA) is a recent swarm intelligence algorithm inspired by the foraging and swarming behavior of grasshoppers in nature. The GOA algorithm has been successfully applied to solve various optimization problems in several domains and demonstrated its merits in the literature. This paper proposes a comprehensive review of GOA based on more than 120 scientific articles published by leading publishers: IEEE, Springer, Elsevier, IET, Hindawi, and others. It provides the GOA variants, including multi-objective and hybrid variants. It also discusses the main applications of GOA in various fields such as scheduling, economic dispatch, feature selection, load frequency control, distributed generation, wind energy system, and other engineering problems. Finally, the paper provides some possible future research directions in this area.","['Optimization', 'Particle swarm optimization', 'Genetic algorithms', 'MIMICs', 'Education', 'Economics']","['Grasshopper optimization algorithm', 'GOA', 'meta-heuristics', 'optimization', 'population-based algorithm', 'swarm intelligence']"
"The brain is the largest and most complex structure in the central nervous system. It dominates all activities in the body, and the lesions in the human body are also reflected in the brain signal. In this paper, the image method is used to assist the brain signal to detect the human lesion. Due to the particularity of medical images, there is no common segmentation method for any medical image, and there is no objective standard to judge whether the segmentation is effective. Medical image segmentation technology is still a bottleneck restricting the development and the application of other related technologies in medical image processing. Based on the above reasons, this paper proposes an improved region growing algorithm based on the fuzzy theory and region growing algorithm. The algorithm is used to segment the medical images of the liver and chest X-ray of different human organs. The improved algorithm uses a threshold segmentation algorithm to assist in the automatic selection of seed points and improves the region growing rules, then morphological post-processing is used to improve the segmentation effect. The experimental results show that the improved region growing algorithm has better segmentation effect under two different organs, which proves that the algorithm has certain applicability, and its accuracy and segmentation quality are better than the traditional region growing algorithm. This algorithm combines the advantages of the threshold method and traditional region growing method. It is feasible in algorithm and has certain application value.","['Image segmentation', 'Liver', 'Medical diagnostic imaging', 'Clustering algorithms', 'Computed tomography', 'Cancer']","['Medical image segmentation', 'improved region growing algorithm', 'applicability method', 'brain signal']"
"The latest methods based on deep learning have achieved amazing results regarding the complex work of inpainting large missing areas in an image. But this type of method generally attempts to generate one single “optimal” result, ignoring many other plausible results. Considering the uncertainty of the inpainting task, one sole result can hardly be regarded as a desired regeneration of the missing area. In view of this weakness, which is related to the design of the previous algorithms, we propose a novel deep generative model equipped with a brand new style extractor which can extract the style feature (latent vector) from the ground truth. Once obtained, the extracted style feature and the ground truth are both input into the generator. We also craft a consistency loss that guides the generated image to approximate the ground truth. After iterations, our generator is able to learn the mapping of styles corresponding to multiple sets of vectors. The proposed model can generate a large number of results consistent with the context semantics of the image. Moreover, we evaluated the effectiveness of our model on three datasets, i.e., CelebA, PlantVillage, and MauFlex. Compared to state-of-the-art inpainting methods, this model is able to offer desirable inpainting results with both better quality and higher diversity. The code and model will be made available on https://github.com/vivitsai/PiiGAN .","['Feature extraction', 'Generative adversarial networks', 'Generators', 'Semantics', 'Training', 'Gallium nitride', 'Face']","['Deep learning', 'generative adversarial networks', 'image inpainting', 'diversity inpainting']"
"The development of IoT technologies and the massive admiration and acceptance of social media tools and applications, new doors of opportunity have been opened for using data analytics in gaining meaningful insights from unstructured information. The application of opinion mining and sentiment analysis (OMSA) in the era of big data have been used a useful way in categorizing the opinion into different sentiment and in general evaluating the mood of the public. Moreover, different techniques of OMSA have been developed over the years in different data sets and applied to various experimental settings. In this regard, this paper presents a comprehensive systematic literature review, aims to discuss both technical aspect of OMSA (techniques and types) and non-technical aspect in the form of application areas are discussed. Furthermore, this paper also highlighted both technical aspects of OMSA in the form of challenges in the development of its technique and non-technical challenges mainly based on its application. These challenges are presented as a future direction for research.","['Sentiment analysis', 'Big Data', 'Data mining', 'Social network services', 'Systematics', 'Intelligent sensors', 'Organizations']","['Opinion mining', 'sentiment analysis', 'big data', 'applications', 'opinionated data', 'social media', 'online social network']"
"This paper presents a novel method to address the actuator saturation for nonlinear hybrid systems by directly incorporating user-defined input bounds in a controller design. In particular, we consider the application of bipedal walking and show that our method [based on a quadratic programming (QP) implementation of a control Lyapunov function (CLF)-based controller] enables a gradual performance degradation while still continuing to walk under increasingly stringent input bounds. We draw on our previous work, which has demonstrated the effectiveness of the CLF-based controllers for stabilizing periodic gaits for biped walkers. This paper presents a framework, which results in more effective handling of control saturations and provides a means for incorporating a whole family of user-defined constraints into the online computation of a CLF-based controller. This paper concludes with an experimental validation of the main results on the bipedal robot MABEL, demonstrating the usefulness of the QP-based CLF approach for real-time robotic control.","['Actuators', 'Nonlinear systems', 'Torque control', 'Quadratic programming', 'Lyapunov methods', 'Hybrid systems', 'Real-time systems', 'Legged locomotion', 'Degradation']","['Quadratic programming', 'legged locomotion', 'Lyapunov methods']"
"A new 3-D chaotic dynamical system with a peanut-shaped closed curve of equilibrium points is introduced in this work. Since the new chaotic system has infinite number of rest points, the new chaotic model exhibits hidden attractors. A detailed dynamic analysis of the new chaotic model using bifurcation diagrams and entropy analysis is described. The new nonlinear plant shows multi-stability and coexisting convergent attractors. A circuit model using MultiSim of the new 3-D chaotic model is designed for engineering applications. The new multi-stable chaotic system is simulated on a field-programmable gate array (FPGA) by applying two numerical methods, showing results in good agreement with numerical simulations. Consequently, we utilize the properties of our chaotic system in designing a new cipher colour image mechanism. Experimental results demonstrate the efficiency of the presented encryption mechanism, whose outcomes suggest promising applications for our chaotic system in various cryptographic applications.","['Chaotic communication', 'Integrated circuit modeling', 'Encryption', 'Solid modeling', 'Mathematical model', 'Field programmable gate arrays']","['Chaos', 'chaotic systems', 'hidden attractors', 'circuit design', 'FPGA realization', 'image encryption', 'encryption analysis']"
"Blockchain technology enables users to verify, preserve, and synchronize the contents of a data sheet (a transaction ledger) replicated by multiple users. Blockchain technology has provided considerable advantages and incentives to industries in terms of enabling better services. This review aims to explore the benefits, challenges and functionalities that affect blockchain applications in different sectors. This article is constructed as a systematic literature review study. From 1976 articles, 168 final articles were selected and classified into three main dimensions, that is, benefits, challenges, and functionalities, in four different sectors: government, financial, manufacturing, and healthcare. The results were extracted and compared based on factors in three dimensions, which were categorized as benefits (informational, technological, economic, organizational, and strategic), challenges (technological, organizational, adoption, operational, and environmental and sustainability), and functionalities (point-to-point transmission, data ownership, data protection, and transaction processing). The results of this review study aim to support professionals, practitioners, and stakeholders who wish to implement and manage transformation projects related to blockchain in their sectors. Moreover, helping these possible blockchain users to understand the implied factors associated with blockchain would be beneficial for the decision-making processes of their organizations.","['Blockchain', 'Systematics', 'Security', 'Government', 'Protocols', 'Manufacturing', 'Safety']","['Blockchain technology', 'benefits', 'challenges', 'functionalities', 'government', 'finance', 'manufacturing', 'health care']"
"To avoid the complex process of explicit feature extraction in traditional facial expression recognition, a face expression recognition method based on a convolutional neural network (CNN) and an image edge detection is proposed. Firstly, the facial expression image is normalized, and the edge of each layer of the image is extracted in the convolution process. The extracted edge information is superimposed on each feature image to preserve the edge structure information of the texture image. Then, the dimensionality reduction of the extracted implicit features is processed by the maximum pooling method. Finally, the expression of the test sample image is classified and recognized by using a Softmax classifier. To verify the robustness of this method for facial expression recognition under a complex background, a simulation experiment is designed by scientifically mixing the Fer-2013 facial expression database with the LFW data set. The experimental results show that the proposed algorithm can achieve an average recognition rate of 88.56% with fewer iterations, and the training speed on the training set is about 1.5 times faster than that on the contrast algorithm.","['Feature extraction', 'Face recognition', 'Image edge detection', 'Face', 'Eigenvalues and eigenfunctions', 'Emotion recognition']","['Face expression recognition', 'convolutional neural network', 'edge computing', 'deep learning', 'image edge detection']"
"A massive use of social media platforms such as Twitter and Facebook by omnifarious organizations has increased the critical individual feedback on the situation, events, products, and services. However, sentiment classification plays an important role in the user's feedback evaluation. At present, deep learning such as long short-term memory (LSTM), gated recurrent unit (GRU), bidirectionally long short-term memory (BiLSTM) or convolutional neural network (CNN) are prevalently preferred in sentiment classification. Moreover, word embedding such as Word2Vec and FastText is closely examined in text for mapping closely related to the vectors of real numbers. However, both deep learning and word embedding methods have strengths and weaknesses. Combining the strengths of the deep learning models with that of word embedding is the key to high-performance sentiment classification in the field of natural language processing (NLP). In the present study, we propose a novel hybrid deep learning model that strategically combines different word embedding (Word2Vec, FastText, character-level embedding) with different deep learning methods (LSTM, GRU, BiLSTM, CNN). The proposed model extracts features of different deep learning methods of word embedding, combines these features and classifies texts in terms of sentiment. To verify the performance of the proposed model, several deep learning models called basic models were created to perform series of experiments. By comparing, the performance of the proposed model with that of past studies, the proposed model offers better sentiment classification performance.","['Deep learning', 'Feature extraction', 'Sentiment analysis', 'Numerical models', 'Twitter']","['Sentiment classification', 'Turkish tweets analysis', 'hybrid model', 'word embedding', 'deep learning', 'LSTM', 'CNN']"
"Autonomous driving is a crucial issue of the automobile industry, and research on lane change is its significant part. Previous works on the autonomous vehicle lane change mainly focused on lane change path planning and path tracking, but autonomous vehicle lane change decision making is rarely mentioned. Therefore, this paper establishes an autonomous lane change decision-making model based on benefit, safety, and tolerance by analyzing the factors of the autonomous vehicle lane change. Then, because of the multi-parameter and non-linearity of the autonomous lane change decision-making process, a support vector machine (SVM) algorithm with the Bayesian parameters optimization is adopted to solve this problem. Finally, we compare a lane change model based on rules with the proposed SVM model in the test set, and results illustrate that the SVM model performs better than the rule-based lane change model. Moreover, the real car experiment is carried out to verify the effectiveness of the decision model.","['Autonomous vehicles', 'Decision making', 'Support vector machines', 'Hidden Markov models', 'Safety', 'Trajectory']","['Autonomous vehicle', 'lane change decision making', 'support vector machine', 'Bayesian optimization', 'drivers’ habits']"
"In this paper, we present a machine learning classifier which is used for pedestrian detection based on XGBoost. Our approach, the Genetic Algorithm is introduced to optimize the parameter tuning process during training an XGBoost model. In order to improve the classification accuracy, HOG and LBP features are used to describe pedestrians in a way of tandem fusion, then input into GA-XGBoost classifier proposed in this paper to form a new static image pedestrian detection algorithm. The pedestrian feature extraction and machine learning are decoupled by storing the extracted pedestrian feature as feature files in the experiment, so that training can be exacuted many times and algorithms can be camparied conveniently. Experimental show that our pedestrian detection algorithm has improved the accuracy of pedestrian detection in the static image. The Area Under the ROC Curve (AUC) value reaches 0.9913.","['Feature extraction', 'Classification algorithms', 'Machine learning algorithms', 'Boosting', 'Histograms', 'Image color analysis', 'Genetic algorithms']","['Pedestrain detection', 'histogram of oriented gradient features (HOG)', 'local binary patterns (LBP) XGBoost classifier', 'genetic algorithm']"
"Existing work in energy demand side management focuses on the interaction between the utility grid and consumers. However, the previous technique is not focused on energy trading in local community of a renewable energy generation, distributed demand side management and not suitable for real-time environment. This paper presents a distributed demand side management system among multiple homes in community microgrid, with the integration of the internet of things smart meter and in the presence of renewable energy sources. The proposed energy consumption game is formulated for minimizing the cost of electricity in the individual home and the total cost of energy consumption in the whole community. The smart home users are playing game by optimizing their own daily energy consumption of appliances. The multiple participants include the self renewable generation of users, shared community microgrid and optional utility company. Each participant applies its best strategy to minimize energy consumption cost and users can maintain their own privacy of energy consumption. Moreover, the proposed scheme is distributed on blockchain, which provides a trusted communication medium between the participants. It enforces the autonomous monitoring of smart appliances and the billing of electricity consumption via smart contracts. Solidity smart contract is deployed to facilitate the execution of transactions without the involvement of third party in the smart community. Comparison of the results show that the proposed approach minimizes the total cost of energy consumption as well as each user's energy consumption cost.","['Home appliances', 'Microgrids', 'Energy consumption', 'Contracts', 'Privacy', 'Renewable energy sources']","['Distributed demand side management', 'community microgrid', 'appliances scheduling', 'smart home', 'Internet of Things', 'blockchain', 'smart contracts']"
"Since Bitcoin's debut in 2008, blockchain, the technology behind the cryptocurrency, has been gaining increasing scientific and industrial interest. Due to the technology's innate distributed and immutable features, the adoption of blockchains on supply chains is one of the most promising recent applications. In this survey, we review academic researches and implementations of distributed ledgers on supply chains. We present the current state of research on the subject and summarize the benefits and the challenges of the distributed organization and management of supply chains. Focusing on industrial practices and use cases, we discuss the technical characteristics and maturity of the various industrial projects. Our goal is to assess the applicability of blockchains in the supply chain domain and to provide a foundation for practitioners and researchers to direct their future projects towards improving the technology and its applications.","['Supply chains', 'Blockchain', 'Distributed ledger', 'Organizations', 'Bibliographies', 'Cryptocurrency']","['Blockchain', 'distributed ledger technology', 'implementations and use cases', 'supply chains']"
"For time and space constraints, 5G base stations will have more serious energy consumption problems in some time periods, so it needs corresponding sleep strategies to reduce energy consumption. Based on the analysis of 5G super dense base station network structure, through the analysis of current situation and user demand, a cluster sleep method based on genetic algorithm is constructed under the support of genetic algorithm, which can realize the dynamic matching of energy consumption in time domain and space, and the low load base station enters the sleep state. In order to verify the performance of the algorithm, the simulation network structure is built on the MATLAB platform, and the advantages of the algorithm in this study are obtained through comparative analysis, and the relevant test parameters are set for the technical performance analysis of this study. The research shows that the method proposed in this paper has a certain energy-saving effect, can meet the energy efficiency requirements of 5G ultra dense base station, and in the ultra dense base station group, the complexity can also meet the system operation requirements, which has a certain degree of practicality, and can provide reference for the follow-up related research.","['Base stations', 'Energy consumption', '5G mobile communication', 'Load modeling', 'Heuristic algorithms', 'Cellular networks']","['Internet of Things', 'collaborative network control', '5G base station', 'energy consumption', 'energy conservation']"
"Upper-limb amputation imposes significant burden on amputees thereby restricting them from fully exploring their environments during activities of daily living. The use of intelligent learning algorithm for electromyogram-pattern recognition (EMG-PR)-based control in upper-limb prostheses is considered as an important clinical option. Though the existing EMG-PR prostheses could discriminate multiple degrees of freedom (DOF) limb movements, their transition to clinically viable option is still being challenged by some confounding factors. Toward realizing a clinically viable multiple DOF prostheses, this paper first explored the principles and dynamics of the existing intelligently driven EMG-PR-based prostheses control scheme. Then, investigations on core issues including variation in muscle contraction force, electrode shift, and subject mobility affecting the existing EMG-PR prosthetic control scheme were reported. For instance, variation in muscle contraction force and subject mobility led to degradation in the performance of the EMG-PR controlled prostheses with approximately 17.00% and 8.98% error values, respectively, which are still challenging issues among others. Thus, this paper reports core issues and best practices with respect to intelligent EMG-PR controlled prosthesis, the major challenges in implementing adaptively robust control scheme and provides future research directions that may result in the clinical realization of intuitively dexterous multiple DOF EMG-PR-based prostheses in the near future.","['Muscles', 'Electrodes', 'Electromyography', 'Prosthetics', 'Pattern recognition', 'Wrist', 'Control systems']","['Amputees', 'electromyogram', 'pattern recognition', 'rehabilitation', 'upper-limb prostheses']"
"This paper surveys the optimization frameworks and performance analysis methods for large intelligent surfaces (LIS), which have been emerging as strong candidates to support the sixth-generation wireless physical platforms (6G). Due to their ability to adjust the behavior of interacting electromagnetic (EM) waves through intelligent manipulations of the reflections phase shifts, LIS have shown promising merits at improving the spectral efficiency of wireless networks. In this context, researchers have been recently exploring LIS technology in depth as a means to achieve programmable, virtualized, and distributed wireless network infrastructures. From a system level perspective, LIS have also been proven to be a low-cost, green, sustainable, and energy-efficient solution for 6G systems. This paper provides a unique blend that surveys the principles of operation of LIS, together with their optimization and performance analysis frameworks. The paper first introduces the LIS technology and its physical working principle. Then, it presents various optimization frameworks that aim to optimize specific objectives, namely, maximizing energy efficiency, sum-rate, secrecy-rate, and coverage. The paper afterwards discusses various relevant performance analysis works including capacity analysis, the impact of hardware impairments on capacity, uplink/downlink data rate analysis, and outage probability. The paper further presents the impact of adopting the LIS technology for positioning applications. Finally, we identify numerous exciting open challenges for LIS-aided 6G wireless networks, including resource allocation problems, hybrid radio frequency/visible light communication (RF-VLC) systems, health considerations, and localization.","['Optimization', 'Performance analysis', '6G mobile communication', 'Wireless networks', 'Wireless sensor networks', 'Surface waves']","['6G technology', 'large intelligent surfaces (LIS)', 'massive multiple-input multiple-output (mMIMO)', 'millimetre waves (mmWave) communication', 'wireless communication']"
"A traffic monitoring system is an integral part of Intelligent Transportation Systems (ITS). It is one of the critical transportation infrastructures that transportation agencies invest a huge amount of money to collect and analyze the traffic data to better utilize the roadway systems, improve the safety of transportation, and establish future transportation plans. With recent advances in MEMS, machine learning, and wireless communication technologies, numerous innovative traffic monitoring systems have been developed. In this article, we present a review of state-of-the-art traffic monitoring systems focusing on the major functionality-vehicle classification. We organize various vehicle classification systems, examine research issues and technical challenges, and discuss hardware/software design, deployment experience, and system performance of vehicle classification systems. Finally, we discuss a number of critical open problems and future research directions in an aim to provide valuable resources to academia, industry, and government agencies for selecting appropriate technologies for their traffic monitoring applications.","['Magnetic sensors', 'Monitoring', 'Detectors', 'Sensor systems', 'Transportation', 'Sensor phenomena and characterization']","['Intelligent transportation systems', 'traffic monitoring systems', 'vehicle classification']"
"Since the launch of Google Glass in 2014, smart glasses have mainly been designed to support micro-interactions. The ultimate goal for them to become an augmented reality interface has not yet been attained due to an encumbrance of controls. Augmented reality involves superimposing interactive computer graphics images onto physical objects in the real world. This survey reviews current research issues in the area of human-computer interaction for smart glasses. The survey first studies the smart glasses available in the market and afterwards investigates the interaction methods proposed in the wide body of literature. The interaction methods can be classified into hand-held, touch, and touchless input. This paper mainly focuses on the touch and touchless input. Touch input can be further divided into on-device and on-body, while touchless input can be classified into hands-free and freehand. Next, we summarize the existing research efforts and trends, in which touch and touchless input are evaluated by a total of eight interaction goals. Finally, we discuss several key design challenges and the possibility of multi-modal input for smart glasses.","['Smart glasses', 'Augmented reality', 'Intelligent sensors', 'Glass', 'Smart phones', 'Optical sensors']","['Input methods', 'smart glasses interaction', 'touch inputs', 'touchless input', 'wearable computing']"
"The next frontier towards truly ubiquitous connectivity is the use of Low Earth Orbit (LEO) small-satellite constellations to support 5G and Beyond-5G (B5G) networks. Besides enhanced mobile broadband (eMBB) and massive machine-type communications (mMTC), LEO constellations can support ultra-reliable communications (URC) with relaxed latency requirements of a few tens of milliseconds. Small-satellite impairments and the use of low orbits pose major challenges to the design and performance of these networks, but also open new innovation opportunities. This paper provides a comprehensive overview of the physical and logical links, along with the essential architectural and technological components that enable the full integration of LEO constellations into 5G and B5G systems. Furthermore, we characterize and compare each physical link category and explore novel techniques to maximize the achievable data rates.","['Satellite broadcasting', 'Low earth orbit satellites', 'Satellites', 'Orbits', '5G mobile communication', 'Propagation delay', 'Internet of Things']","['5G', 'beyond-5G', 'low Earth orbit (LEO)', 'radio access network', 'small-satellite constellations']"
"Since electricity plays a crucial role in countries' industrial infrastructures, power companies are trying to monitor and control infrastructures to improve energy management and scheduling. Accurate forecasting is a critical task for a stable and efficient energy supply, where load and supply are matched. This article discusses various algorithms and a new hybrid deep learning model which combines long short-term memory networks (LSTM) and convolutional neural network (CNN) model to analyze their performance for short-term load forecasting. The proposed model is called parallel LSTM-CNN Network or PLCNet. Two real-world data sets, namely “hourly load consumption of Malaysia ” as well as “daily power electric consumption of Germany”, are used to test and compare the presented models. To evaluate the tested models' performance, root mean squared error (RMSE), mean absolute percentage error (MAPE), and R-squared were used. In total, this article is divided into two parts. In the first part, different machine learning models, including the PLCNet, predict the next time step load. In the second part, the model's performance, which has shown the most accurate results in the first part, is discussed in different time horizons. The results show that deep neural networks models, especially PLCNet, are good candidates for being used as short-term prediction tools. PLCNet improved the accuracy from 83.17% to 91.18% for the German data and achieved 98.23% accuracy in Malaysian data, which is an excellent result in load forecasting.","['Load modeling', 'Predictive models', 'Load forecasting', 'Data models', 'Forecasting', 'Deep learning', 'Time series analysis']","['Electricity', 'smart grids', 'load consumption', 'short-term load forecasting', 'deep learning', 'time series', 'regression', 'convolutional neural networks', 'long short-term memory']"
"Deep Learning (DL) algorithms based on artificial neural networks have achieved remarkable success and are being extensively applied in a variety of application domains, ranging from image classification, automatic driving, natural language processing to medical diagnosis, credit risk assessment, intrusion detection. However, the privacy and security issues of DL have been revealed that the DL model can be stolen or reverse engineered, sensitive training data can be inferred, even a recognizable face image of the victim can be recovered. Besides, the recent works have found that the DL model is vulnerable to adversarial examples perturbed by imperceptible noised, which can lead the DL model to predict wrongly with high confidence. In this paper, we first briefly introduces the four types of attacks and privacy-preserving techniques in DL. We then review and summarize the attack and defense methods associated with DL privacy and security in recent years. To demonstrate that security threats really exist in the real world, we also reviewed the adversarial attacks under the physical condition. Finally, we discuss current challenges and open problems regarding privacy and security issues in DL.","['Security', 'Computational modeling', 'Privacy', 'Data models', 'Training', 'Training data', 'Face recognition']","['Deep learning', 'DL privacy', 'DL security', 'model extraction attack', 'model inversion attack', 'adversarial attack', 'poisoning attack', 'adversarial defense', 'privacy-preserving']"
"With the recent increased usage of video services, the focus has recently shifted from the traditional quality of service-based video delivery to quality of experience (QoE)-based video delivery. Over the past 15 years, many video quality assessment metrics have been proposed with the goal to predict the video quality as perceived by the end user. HTTP adaptive streaming (HAS) has recently gained much attention and is currently used by the majority of video streaming services, such as Netflix and YouTube. HAS, using reliable transport protocols, such as TCP, does not suffer from image artifacts due to packet losses, which are common in traditional streaming technologies. Hence, the QoE models developed for other streaming technologies alone are not sufficient. Recently, many works have focused on developing QoE models targeting HAS-based applications. Also, the recently published ITU-T Recommendation series P.1203 proposes a parametric bitstream-based model for the quality assessment of progressive download and adaptive audiovisual streaming services over a reliable transport. The main contribution of this paper is to present a comprehensive overview of recent and currently undergoing works in the field of QoE modeling for HAS. The HAS QoE models, influence factors, and subjective test methodologies are discussed, as well as existing challenges and shortcomings. The survey can serve as a guideline for researchers interested in QoE modeling for HAS and also discusses possible future work.","['Quality of experience', 'Streaming media', 'Adaptation models', 'Quality of service', 'Measurement', 'Solid modeling', 'Quality assessment']","['HTTP adaptive streaming', 'QoE modeling', 'TCP', 'video quality assessment']"
"Recent studies have shown that robust diets recommended to patients by Dietician or an Artificial Intelligent automated medical diet based cloud system can increase longevity, protect against further disease, and improve the overall quality of life. However, medical personnel are yet to fully understand patient-dietician’s rationale of recommender system. This paper proposes a deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol. This research framework is focused on implementing both machine and deep learning algorithms like, logistic regression, naive bayes, Recurrent Neural Network (RNN), Multilayer Perceptron (MLP), Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM). The medical dataset collected through the internet and hospitals consists of 30 patient’s data with 13 features of different diseases and 1000 products. Product section has 8 features set. The features of these IoMT data were analyzed and further encoded before applying deep and machine and learning-based protocols. The performance of various machine learning and deep learning techniques was carried and the result proves that LSTM technique performs better than other scheme with respect to forecasting accuracy, recall, precision, and F1 -measures. We achieved 97.74% accuracy using LSTM deep learning model. Similarly 98% precision, 99% recall and 99\%~F1 -measure for allowed class is achieved, and for not-allowed class precision is 89%, recall score is 73% and F1 Measure score is 80%.","['Diseases', 'Deep learning', 'Diabetes', 'Machine learning algorithms']","['Recommendation system', 'RNN', 'GRU', 'LSTM', 'IoMT', 'Naive Bayes logistic regression']"
"Security of medical media is important for patient safety and confidentiality. This paper proposes a framework for the chaos-based quantum encryption of healthcare images. In the framework, healthcare staff in one location send cipher images to the cloud. The healthcare staff in another location receives the images from the cloud. By decrypting the content of the images, the healthcare staff can assist users in a secure manner. This paper also proposes a novel approach for the efficient quantum image encryption of healthcare media. The proposed algorithm utilizes gray code and a chaotic map. The quantum image is scrambled by quantum gray code. Then, the scrambled quantum image is encrypted using a quantum XOR operation based on a key generator controlled by the logistic-sine map. The circuits of the proposed encryption/decryption algorithm are devised based on an NEQR quantum image representation. Numerical and simulation analyses show that the proposed quantum image encryption approach is robust, realizable, and has high efficiency compared with its classical counterpart.","['Encryption', 'Medical services', 'Quantum computing', 'Reflective binary codes', 'Biomedical imaging', 'Media']","['Quantum image encryption', 'chaotic systems', 'healthcare']"
"Human pose estimation localizes body keypoints to accurately recognizing the postures of individuals given an image. This step is a crucial prerequisite to multiple tasks of computer vision which include human action recognition, human tracking, human-computer interaction, gaming, sign languages, and video surveillance. Therefore, we present this survey article to fill the knowledge gap and shed light on the researches of 2D human pose estimation. A brief introduction is followed by classifying it as a single or multi-person pose estimation based on the number of people needed to be tracked. Then gradually the approaches used in human pose estimation are described before listing some applications and also flaws facing in pose estimation. Following that, a center of attention is given on briefly discussing researches with a significant effect on human pose estimation and examine the novelty, motivation, architecture, the procedures (working principles) of each model together with its practical application and drawbacks, datasets implemented, as well as the evaluation metrics used to evaluate the model. This review is presented as a baseline for newcomers and guides researchers to discover new models by observing the procedure and architecture flaws of existing researches.","['Pose estimation', 'Two dimensional displays', 'Machine learning', 'Computer architecture', 'Measurement', 'Three-dimensional displays', 'Elbow']","['Human pose estimation', 'pose estimation and action recognition', 'pose estimation survey', 'single and multi-person pose estimation']"
"The education industry around the globe is undergoing major transformations. Organizations, such as Coursera are advancing new business models for education. A number of major industries have dropped degrees from the job requirements. While the economics of higher education institutions are under threat in a continuing gloomy global economy, digital and lifelong learners are increasingly demanding new teaching and learning paradigms from educational institutions. There is an urgent need to transform teaching and learning landscape in order to drive global economic growth. The use of distance eTeaching and eLearning (DTL) is on the rise among digital natives alongside our evolution toward smart societies. However, the DTL systems today lack the necessary sophistication due to several challenges including data analysis and management, learner-system interactivity, system cognition, resource planning, agility, and scalability. This paper proposes a personalised Ubiquitous eTeaching & eLearning (UTiLearn) framework that leverages Internet of Things, big data, supercomputing, and deep learning to provide enhanced development, management, and delivery of teaching and learning in smart society settings. A proof of concept UTiLearn system has been developed based on the framework. A detailed design, implementation, and evaluation of the UTiLearn system, including its five components, are provided using 11 widely used datasets.","['Big Data', 'Smart cities', 'Computer aided instruction', 'Economics', 'Electronic learning']","['Big data', 'computational and artificial intelligence', 'distance learning', 'high performance computing', 'Internet of Things']"
"The purpose of this paper is to bestow the reader with a timely study of UAV cellular communications, bridging the gap between the 3GPP standardization status quo and the more forward-looking research. Special emphasis is placed on the downlink command and control (C&C) channel to aerial users, whose reliability is deemed of paramount technological importance for the commercial success of UAV cellular communications. Through a realistic side-by-side comparison of two network deployments – a present-day cellular infrastructure versus a next-generation massive MIMO system – a plurality of key facts are cast light upon, with the three main ones summarized as follows: 1) UAV cell selection is essentially driven by the secondary lobes of a base station’s radiation pattern, causing UAVs to associate to far-flung cells; 2) over a 10 MHz bandwidth, and for UAV heights of up to 300 m, massive MIMO networks can support 100 kbps C&C channels in 74% of the cases when the uplink pilots for channel estimation are reused among base station sites, and in 96% of the cases without pilot reuse across the network; and 3) supporting UAV C&C channels can considerably affect the performance of ground users on account of severe pilot contamination, unless suitable power control policies are in place.","['Unmanned aerial vehicles', 'MIMO communication', '3GPP', 'Cellular networks', 'Interference', 'Fading channels', 'Reliability']","['Unmanned aerial vehicles (UAVs)', 'command and control channel', 'cellular networks', 'massive MIMO', '3GPP']"
"With the rapid development and application of the mobile Internet, huge amounts of user data are generated and collected every day. How to take full advantages of these ubiquitous data is becoming the essential aspect of a recommender system. Collaborative filtering (CF) has been widely studied and utilized to predict the interests of mobile users and to make proper recommendations. In this paper, we first propose a framework of the CF recommender system based on various user data including user ratings and user behaviors. Key features of these two kinds of data are discussed. Moreover, several typical CF algorithms are classified as memory-based approaches and model-based approaches and compared. Two case studies are presented in an effort to validate the proposed framework.","['Internet', 'Mobile communication', 'Collaborative filtering', 'Recommender systems', 'Collaboration', 'Prediction algorithms', 'Classification algorithms']","['Mobile Internet', 'recommender system', 'collaborative filtering']"
"Wireless sensor networks (WSNs) often consist of hundreds of sensor nodes that may be deployed in relatively harsh and complex environments. In views of hardware cost, sensor nodes always adopt relatively cheap chips, which make these nodes become error-prone or faulty in the course of their operation. Natural factors and electromagnetic interference could also influence the performance of the WSNs. When sensor nodes become faulty, they may have died which means they cannot communicate with other members in the wireless network, they may be still alive but produce incorrect data, they may be unstable jumping between normal state and faulty state. To improve data quality, shorten response time, strengthen network security, and prolong network lifespan, many studies have focused on fault diagnosis. This survey paper classifies fault diagnosis methods in recent five years into three categories based on decision centers and key attributes of employed algorithms: centralized approaches, distributed approaches, and hybrid approaches. As all these studies have specific goals and limitations, this paper tries to compare them, lists their merits and limits, and propose potential research directions based on established methods and theories.","['Wireless sensor networks', 'Fault diagnosis', 'Monitoring', 'Sensors', 'Safety', 'Bandwidth']","['Wireless sensor networks (WSNs)', 'industrial wireless sensor network (IWSN)', 'fault diagnosis', 'reliability', 'lifetime']"
"In recent years, ship detection in satellite remote sensing images has become an important research topic. Most existing methods detect ships by using a rectangular bounding box but do not perform segmentation down to the pixel level. This paper proposes a ship detection and segmentation method based on an improved Mask R-CNN model. Our proposed method can accurately detect and segment ships at the pixel level. By adding a bottom-up structure to the FPN structure of Mask R-CNN, the path between the lower layers and the topmost layer is shortened, allowing the lower layer features to be more effectively utilized at the top layer. In the bottom-up structure, we use channel-wise attention to assign weights in each channel and use the spatial attention mechanism to assign a corresponding weight at each pixel in the feature maps. This allows the feature maps to respond better to the target’s features. Using our method, the detection and segmentation mAPs increased from 70.6% and 62.0% to 76.1% and 65.8%, respectively.","['Marine vehicles', 'Feature extraction', 'Image segmentation', 'Remote sensing', 'Satellites', 'Deep learning', 'Object detection']","['Computer vision', 'object detection', 'object segmentation', 'remote sensing']"
"Distributed Ledger Technologies (DLTs), like Blockchain, are characterized by features such as transparency, traceability, and security by design. These features make the adoption of Blockchain attractive to enhance information security, privacy, and trustworthiness in very different contexts. This paper provides a comprehensive survey and aims at analyzing and assessing the use of Blockchain in the context of Distributed Trust and Reputation Management Systems (DTRMS). The analysis includes academic research as well as initiatives undertaken in the business domain. The paper defines two taxonomies for both Blockchain and DTRMS and applies a Formal Concept Analysis. Such an approach allowed us to identify the most recurrent and stable features in the current scientific landscape and several important implications among the two taxonomies. The results of the analysis have revealed significant trends and emerging practices in the current implementations that have been distilled into recommendations to guide Blockchain's adoption in DTRMS systems.","['Peer-to-peer computing', 'Distributed ledger', 'Blockchain', 'Taxonomy', 'Trust management', 'Copyright protection', 'Internet of Things']","['Blockchain', 'distributed ledger technology', 'distributed reputation management system', 'distributed trust management system', 'formal concept analysis', 'security', 'taxonomy']"
"Wireless power transfer devices are becoming more relevant and widespread. Therefore, an article is devoted to a review, analysis and comparison of compensation topologies for an inductive power transfer. A new classification of topologies is developed. A lot of attention is paid to the problems of the physical fundamentals of compensation work, standards, safety, and five main topology requirements. It is determined, that topologies with the series primary compensating are the most effective in the IPT for charging devices among the four classical schemes. The series-parallel solution is recommended in case of the low output voltage, minimum size of a secondary side coil is achievable. The series-series solution does not depend on the magnetic coupling coefficient and the load on the resonance frequency. For the convenience of displaying and understanding the information, the comparison results are listed in the tables, graphs and dependencies. The main suitable topologies for a certain application are defined. The given conclusions provide a “one-stop” information source and a selection guide on the application of compensation topologies both in terms of devices and in terms of power level that is the main value of this paper. During literature analysis and recent trends in the market for wireless power transmission devices, the main possible further ways of developing topologies are underlined. First of all, it concerns increasing the frequency of resonance of compensation topologies, the use of multilevel / multi-pulse / multicoils structures, the study of existing high-frequency semiconductors and the development of the semiconductor and magnetic materials.","['Standards', 'Topology', 'Magnetic resonance', 'Wireless communication', 'Couplings', 'Electric vehicles']","['Wireless power transfer', 'inductive power transfer', 'compensation topology', 'requirement', 'classification', 'standards', 'application']"
"An accurate vision system to classify and analyze fruits in real time is critical for harvesting robots to be cost-effective and efficient. However, practical success in this area is still limited, and to the best of our knowledge, there is no research in the area of machine vision for date fruits in an orchard environment. In this work, we propose an efficient machine vision framework for date fruit harvesting robots. The framework consists of three classification models used to classify date fruit images in real time according to their type, maturity, and harvesting decision. In the classification models, deep convolutional neural networks are utilized with transfer learning and fine-tuning on pre-trained models. To build a robust vision system, we create a rich image dataset of date fruit bunches in an orchard that consists of more than 8000 images of five date types in different pre-maturity and maturity stages. The dataset has a large degree of variations that reflects the challenges in the date orchard environment including variations in angles, scales, illumination conditions, and date bunches covered by bags. The proposed date fruit classification models achieve accuracies of 99.01%, 97.25%, and 98.59% with classification times of 20.6, 20.7, and 35.9 msec for the type, maturity, and harvesting decision classification tasks, respectively.","['Machine vision', 'Robots', 'Task analysis', 'Deep learning', 'Computer architecture', 'Real-time systems', 'Image color analysis']","['Dates classification', 'maturity analysis', 'automated harvesting', 'deep learning', 'convolutional neural networks']"
"Accurately detecting Parkinson's disease (PD) at an early stage is certainly indispensable for slowing down its progress and providing patients the possibility of accessing to disease-modifying therapy. Towards this end, the premotor stage in PD should be carefully monitored. An innovative deep-learning technique is introduced to early uncover whether an individual is affected with PD or not based on premotor features. Specifically, to uncover PD at an early stage, several indicators have been considered in this study, including Rapid Eye Movement and olfactory loss, Cerebrospinal fluid data, and dopaminergic imaging markers. A comparison between the proposed deep learning model and twelve machine learning and ensemble learning methods based on relatively small data including 183 healthy individuals and 401 early PD patients shows the superior detection performance of the designed model, which achieves the highest accuracy, 96.45% on average. Besides detecting the PD, we also provide the feature importance on the PD detection process based on the Boosting method.","['Machine learning', ""Parkinson's disease"", 'Feature extraction', 'Biomarkers', 'Single photon emission computed tomography']","['Parkinson’s disease', 'deep learning', 'ensemble learning', 'early detection', 'premotor features', 'features importance']"
"Social Internet of Things (SIoT) supports many novel applications and networking services for the IoT in a more powerful and productive way. In this paper, we have introduced a hierarchical framework for feature extraction in SIoT big data using map-reduced framework along with a supervised classifier model. Moreover, a Gabor filter is used to reduce noise and unwanted data from the database, and Hadoop Map Reduce has been used for mapping and reducing big databases, to improve the efficiency of the proposed work. Furthermore, the feature selection has been performed on a filtered data set by using Elephant Herd Optimization. The proposed system architecture has been implemented using Linear Kernel Support Vector Machine-based classifier to classify the data and for predicting the efficiency of the proposed work. From the results, the maximum accuracy, specificity, and sensitivity of our work is 98.2%, 85.88%, and 80%, moreover analyzed time and memory, and these results have been compared with the existing literature.","['Internet of Things', 'Big Data', 'Task analysis', 'Feature extraction', 'Optimization', 'Electronic mail', 'Data models']","['Internet of Things', 'social Internet of Things', 'machine Learning', 'big data', 'feature selection']"
"This paper presents solutions for efficient multiplexing of ultra-reliable low-latency communications (URLLC) and enhanced mobile broadband (eMBB) traffic on a shared channel. This scenario presents multiple challenges in terms of radio resource scheduling, link adaptation, and inter-cell interference, which are identified and addressed throughout this paper. We propose a joint link adaptation and resource allocation policy that dynamically adjusts the block error probability of URLLC small payload transmissions in accordance with the instantaneous experienced load per cell. Extensive system-level simulations of the downlink performance show promising gains of this technique, reducing the URLLC latency from 1.3 to 1 ms at the 99.999% percentile, with less than 10% degradation of the eMBB throughput performance as compared with conventional scheduling policies. Moreover, an exhaustive sensitivity analysis is conducted to determine the URLLC and eMBB performance under different offered loads, URLLC payload sizes, and link adaptation and scheduling strategies. The presented results give valuable insights on the maximum URLLC offered traffic load that can be tolerated while still satisfying the URLLC requirements, as well as what conditions are more appropriate for dynamic multiplexing of URLLC and eMBB traffic in the upcoming 5G systems.","['5G mobile communication', 'Interference', 'Payloads', 'Adaptation models', 'Reliability', 'Downlink', 'OFDM']","['5G New Radio', 'link adaptation', 'scheduling', 'radio resource management', 'ultra-reliable low-latency communications']"
"Applications of perceptual image quality assessment (IQA) in image and video processing, such as image acquisition, image compression, image restoration, and multimedia communication, have led to the development of many IQA metrics. In this paper, a reliable full reference IQA model is proposed that utilize gradient similarity (GS), chromaticity similarity (CS), and deviation pooling (DP). By considering the shortcomings of the commonly used GS to model the human visual system (HVS), a new GS is proposed through a fusion technique that is more likely to follow HVS. We propose an efficient and effective formulation to calculate the joint similarity map of two chromatic channels for the purpose of measuring color changes. In comparison with a commonly used formulation in the literature, the proposed CS map is shown to be more efficient and provide comparable or better quality predictions. Motivated by a recent work that utilizes the standard DP, a general formulation of the DP is presented in this paper and used to compute a final score from the proposed GS and CS maps. This proposed formulation of DP benefits from the Minkowski pooling and a proposed power pooling as well. The experimental results on six data sets of natural images, a synthetic data set, and a digitally retouched dataset show that the proposed index provides comparable or better quality predictions than the most recent and competing state-of-the-art IQA metrics in the literature, it is reliable and has low complexity. The MATLAB source code of the proposed metric is available at https://dl.dropboxusercontent.com/u/74505502/MDSI.m.","['Reliability', 'Measurement', 'Indexes', 'Mathematical coding', 'Image coding', 'Image restoration']","['Image quality assessment', 'gradient similarity', 'chromaticity similarity', 'deviation pooling', 'synthetic image', 'human visual system']"
"Water is a precious resource that should be managed carefully. However, due to leakages in water distributed networks (WDNs), a large amount of water is lost each year that suggests the need for reliable and robust leak detection and localization system. This paper attempts to review the current technologies for leakage detection in WDN as well as several proposed intelligent methodologies (such as support vector machine, neural network, and convolution neural network) over the past few years. The current methodologies and their limitations are discussed. Uncertainties involved in the implementation of WDN leakage detection are also discussed, and several suggestions to overcome such uncertainties are provided for future implementations.","['Leak detection', 'Water resources', 'Pipelines', 'Soil', 'Monitoring', 'Acoustic emission']","['Water distribution networks', 'leakage', 'localization', 'review']"
"Fog computing is a paradigm that extends cloud computing to the edge of the network. It can provide computation and storage services to end devices in Internet of Things (IoT). Attribute-based cryptography is a well-known technology to guarantee data confidentiality and fine-grained data access control. However, its computational cost in encryption and decryption phase is linear with the complexity of policy. In this paper, we propose a secure and fine-grained data access control scheme with ciphertext update and computation outsourcing in fog computing for IoT. The sensitive data of data owner are first encrypted using attribute-based encryption with multiple policies and then outsourced to cloud storage. Hence, the user whose attributes satisfy the access policy can decrypt the ciphertext. Based on the attribute-based signature technique, authorized user whose attributes integrated in the signature satisfy the update policy can renew the ciphertext. Specifically, most of the encryption, decryption, and signing computations are outsourced from end devices to fog nodes, and thus, the computations for data owners to encrypt, end users to decrypt, re-encrypt, and sign are irrelevant to the number of attributes in the policies. The security analysis shows that the proposed scheme is secure against known attacks, and the experimental results show that the fog nodes perform most of the computation operations of encryption, decryption, and signing, and hence, the time of encryption for data owner, decryption, re-encryption, and signing for users is small and constant.","['Encryption', 'Access control', 'Edge computing', 'Cloud computing', 'Servers', 'Outsourcing']","['Internet of Things', 'fog computing', 'access control', 'data security', 'attribute based encryption', 'attribute based signature']"
"In this paper, a model for time-averaged realistic maximum power levels for the assessment of radio frequency (RF) electromagnetic field (EMF) exposure for the fifth generation (5G) radio base stations (RBS) employing massive MIMO is presented. The model is based on a statistical approach and developed to provide a realistic conservative RF exposure assessment for a significant proportion of all possible downlink exposure scenarios (95th percentile) in-line with requirements in a recently developed International Electrotechnical Commission standard for RF EMF exposure assessments of RBS. Factors, such as RBS utilization, time-division duplex, scheduling time, and spatial distribution of users within a cell are considered. The model is presented in terms of a closed-form equation. For an example scenario corresponding to an expected 5G RBS product, the largest realistic maximum power level was found to be less than 15% of the corresponding theoretical maximum. For far-field exposure scenarios, this corresponds to a reduction in RF EMF limit compliance distance with a factor of about 2.6. Results are given for antenna arrays of different sizes and for scenarios with beamforming in both azimuth and elevation.","['Radio frequency', '5G mobile communication', 'Antenna arrays', 'Downlink', 'MIMO', 'Azimuth', 'Base stations']","['5G mobile communication', 'EMF exposure', 'base stations', 'RF EMF compliance', 'massive MIMO', 'antenna arrays']"
"Breast cancer is one of the most common and deadliest cancers among women. Since histopathological images contain sufficient phenotypic information, they play an indispensable role in the diagnosis and treatment of breast cancers. To improve the accuracy and objectivity of Breast Histopathological Image Analysis (BHIA), Artificial Neural Network (ANN) approaches are widely used in the segmentation and classification tasks of breast histopathological images. In this review, we present a comprehensive overview of the BHIA techniques based on ANNs. First of all, we categorize the BHIA systems into classical and deep neural networks for in-depth investigation. Then, the relevant studies based on BHIA systems are presented. After that, we analyze the existing models to discover the most suitable algorithms. Finally, publicly accessible datasets, along with their download links, are provided for the convenience of future researchers.","['Breast cancer', 'Machine learning', 'Neural networks', 'Image analysis']","['Breast cancer', 'histopathology', 'convolutional neural networks', 'deep learning', 'image segmentation', 'image classification']"
"Integrated on-board battery chargers (OBCs) have been recently introduced as an optimal/elegant solution to increase electric vehicle (EV) market penetration as well as minimize overall EV cost. Unlike conventional off-board and on-board battery chargers, integrated OBCs exploit the existing propulsion equipment for battery charging without extra bulky components and/or dedicated infrastructure. OBCs are broadly categorized into three-phase and single-phase types with unidirectional or bidirectional power flow. This paper starts with surveying the main topologies introduced in the recent literature employing either induction or permanent magnet motors to realize fully integrated slow (single-phase) and fast (three-phase) on-board EV battery charging systems, with emphasis on topologies that entail no or minimum hardware reconfiguration. Although, permanent magnet (PM) motors with conventional double-layer distributed winding layouts have been deployed in most commercial EV motors, the non-overlapped fractional slot concentrated winding (FSCW) has been the prevailing choice in the most recent permanent magnet motor designs due to its outstanding operational merits. Hence, a thorough investigation of the impact different FSCW stator winding designs have on machine performance under the charging process is presented in this paper. To this end, the induced magnet losses, which represent a challenging demerit of the FSCW, have been used to compare different topologies under both propulsion and charging operation modes. Based on the introduced comparative study, the optimal slot/pole combinations that correspond to the best compromise under both operational modes have been highlighted.","['Power capacitors', 'Torque', 'Batteries', 'Windings', 'Battery chargers', 'Propulsion', 'Topology']","['Integrated chargers', 'on-board battery chargers (OBCs)', 'multiphase machines', 'fractional slot concentrated winding (FSCW)', 'battery charging', 'optimal slot/pole combinations', 'reviews']"
"With the rapid development of the Internet industry, sentiment analysis has grown into one of the popular areas of natural language processing (NLP). Through it, the implicit emotion in the text can be effectively mined, which can help enterprises or organizations to make an effective decision, and the explosive growth of data undoubtedly brings more opportunities and challenges to the sentiment analysis. At the same time, transfer learning has emerged as a new machine learning technique that uses the existing knowledge to solve different domain problems and produces state-of-the-art prediction results. Many scholars apply transfer learning to the field of the sentiment analysis. This survey summarizes the relevant research results of the sentiment analysis in recent years and focuses on the algorithms and applications of transfer learning in the sentiment analysis, and we look forward to the development trend of the sentiment analysis.","['Sentiment analysis', 'Analytical models', 'Deep learning', 'Computational modeling', 'Task analysis', 'Context modeling']","['Sentiment analysis', 'transfer learning', 'natural language processing']"
"In the past decades, many optimization methods have been devised and applied to job shop scheduling problem (JSSP) to find the optimal solution. Many methods assumed that the scheduling results were applied to static environments, but the whole environments in the real world are always dynamic. Moreover, many unexpected events such as machine breakdowns and material problems may be present to adversely affect the initial job scheduling. This work views JSSP as a sequential decision making problem and proposes to use deep reinforcement learning to cope with this problem. The combination of deep learning and reinforcement learning avoids handcraft features as used in traditional reinforcement learning, and it is expected that the combination will make the whole learning phase more efficient. Our proposed model comprises actor network and critic network, both including convolution layers and fully connected layer. Actor network agent learns how to behave in different situations, while critic network helps agent evaluate the value of statement then return to actor network. This work proposes a parallel training method, combining asynchronous update as well as deep deterministic policy gradient (DDPG), to train the model. The whole network is trained with parallel training on a multi-agent environment and different simple dispatching rules are considered as actions. We evaluate our proposed model on more than ten instances that are present in a famous benchmark problem library - OR library. The evaluation results indicate that our method is comparative in static JSSP benchmark problems, and achieves a good balance between makespan and execution time in dynamic environments. Scheduling score of our method is 91.12% in static JSSP benchmark problems, and 80.78% in dynamic environments.","['Job shop scheduling', 'Machine learning', 'Benchmark testing', 'Dynamic scheduling', 'Learning (artificial intelligence)', 'Training', 'Optimization']","['Job shop scheduling problem (JSSP)', 'deep reinforcement learning', 'actor-critic network', 'parallel training']"
"Recently, solar energy has been intensively employed in power systems, especially using the photovoltaic (PV) generation units. In this regard, this paper proposes a novel design of a fuzzy logic based algorithm for varying the step size of the incremental conductance (INC) maximum power point tracking (MPPT) method for PV. In the proposed method, a variable voltage step size is estimated according to the degree of ascent or descent of the power-voltage relation. For this purpose, a novel unique treatment is proposed based on introducing five effective regions around the point of maximum PV power. To vary the step size of the duty cycle, a fuzzy logic system is developed according to the locations of the fuzzy inputs regarding the five regions. The developed fuzzy inputs are inspired from the slope of the power-voltage relation, namely the current-voltage ratio and its derivatives whereas appropriate membership functions and fuzzy rules are designed. The benefit of the proposed method is that the MPPT efficiency is improved for varying the step size of the incremental conductance method, thanks to the effective coordination between the proposed fuzzy logic based algorithm and the INC method. The output DC power of the PV array and the tracking speed are presented as indices for illustrating the improvement achieved in MPPT. The proposed method is verified and tested through the simulation of a grid-connected PV system model. The simulation results reveal a valuable improvement in static and dynamic responses over that of the traditional INC method with the variation of the environmental conditions. Further, it enhances the output dc power and reduce the convergence time to reach the steady state condition with intermittent environmental conditions.","['Maximum power point trackers', 'Fuzzy logic', 'Photovoltaic systems', 'Power generation control']","['Maximum power point tracking', 'fuzzy logic', 'incremental conductance', 'PV system', 'dynamic responses']"
"To guarantee the ubiquitous and fully autonomous Internet connections in our daily life, the new technical challenges of mobile communications lie on the efficient utilization of resource and social information. To facilitate the innovation of the fifth generation (5G) networks, the cloud radio access network (RAN) and fog network have been proposed to respond newly emerging traffic demands. The cloud RAN functions more toward centralized resource management to achieve optimal transmissions. The fog network takes advantage of social information and edge computing to efficiently alleviate the end-to-end latency. In this paper, we conduct a comprehensive survey of these two network structures, and then investigate possible harmonization to integrate both for the diverse needs of 5G mobile communications. We analytically study the harmonization of cloud RAN and fog network from various points of view, including the cache of Internet contents, mobility management, and radio access control. The performance of transition between the cloud RAN and the fog network has been presented and the subsequent switching strategy has been proposed to ensure engineering flexibility and success.","['Cloud computing', 'Radio access networks', 'Mobile communication', 'Computer architecture', 'Social network services', 'Optimization']","['5G', 'fog network', 'cloud radio access network', 'RAN', 'heterogeneous network', 'edge computing', 'cache', 'radio resource management', 'mobility', 'mobile communications', 'vehicular network']"
"The field of artificial intelligence (AI) has shown an upward trend of growth in the 21st century (from 2000 to 2015). The evolution in AI has advanced the development of human society in our own time, with dramatic revolutions shaped by both theories and techniques. However, the multidisciplinary and fast-growing features make AI a field in which it is difficult to be well understood. In this paper, we study the evolution of AI at the beginning of the 21st century using publication metadata extracted from 9 top-tier journals and 12 top-tier conferences of this discipline. We find that the area is in the sustainable development and its impact continues to grow. From the perspective of reference behavior, the decrease in self-references indicates that the AI is becoming more and more open-minded. The influential papers/researchers/institutions we identified outline landmarks in the development of this field. Last but not least, we explore the inner structure in terms of topics’ evolution over time. We have quantified the temporal trends at the topic level and discovered the inner connection among these topics. These findings provide deep insights into the current scientific innovations, as well as shedding light on funding policies.","['Artificial intelligence', 'Conferences', 'Computer vision', 'Statistical analysis', 'Cognition', 'Collaboration', 'Market research']","['Artificial intelligence', 'data analytics', 'scientific impact', 'science of science', 'data science']"
"The complex detection background and lesion features make the automatic detection of dermoscopy image lesions face many challenges. The previous solutions mainly focus on using larger and more complex models to improve the accuracy of detection, there is a lack of research on significant intra-class differences and inter-class similarity of lesion features. At the same time, the larger model size also brings challenges to further algorithm application; In this paper, we proposed a lightweight skin cancer recognition model with feature discrimination based on fine-grained classification principle. The propose model includes two common feature extraction modules of lesion classification network and a feature discrimination network. Firstly, two sets of training samples (positive and negative sample pairs) are input into the feature extraction module (Lightweight CNN) of the recognition model. Then, two sets of feature vectors output from the feature extraction module are used to train the two classification networks and feature discrimination networks of the recognition model at the same time, and the model fusion strategy is applied to further improve the performance of the model, the proposed recognition method can extract more discriminative lesion features and improve the recognition performance of the model in a small amount of model parameters; In addition, based on the feature extraction module of the proposed recognition model, U-Net architecture, and migration training strategy, we build a lightweight semantic segmentation model of lesion area of dermoscopy image, which can achieve high precision lesion area segmentation end-to-end without complicated image preprocessing operation; The performance of our approach was appraised through widespread experiments comparative and feature visualization analysis, the outcome indicates that the proposed method has better performance than the start-of-the-art deep learning-based approach on the ISBI 2016 skin lesion analysis towards melanoma detection challenge dataset.","['Lesions', 'Feature extraction', 'Melanoma', 'Image recognition', 'Image segmentation', 'Skin', 'Training']","['Dermoscopy images', 'skin cancer detection', 'lightweight deep learning network', 'fine-grained feature']"
"In recent years, various food-safety issues have aroused public concern regarding safety in the food supply chain. Since grains are closely linked to human life and health, it is necessary to effectively manage information in the grain supply chain. The grain supply chain is characterized by a long life cycle, complex links, various hazards, and heterogeneous information sources. Problems with traditional traceability systems include easy data tampering, difficult hazardous-material information management, the “information isolated island” problem, and low traceability efficiency in the whole supply chain. Blockchain is a distributed computing paradigm characterized by decentralization, network-wide recording, security, and reliability. As such, it can reduce administrative costs and improve the efficiency of information management. Based on literature research and a field investigation of wheat-processing enterprises in Shandong Province, We analyze the operation process of grain supply chain. This study, therefore, proposed a new system architecture in the entire grain supply chain based on blockchain technology and designed a multimode storage mechanism that combines chain storage. This prototype system was tested and verified using actual cases and application scenarios. Compared to traditional systems, the proposed system is characterized by data security and reliability, information interconnection and intercommunication, real-time sharing of hazardous-material information, and dynamic and credible whole-process tracing. As such, this system is highly significant and has reference value for guaranteeing food quality and safety-process traceability.","['Supply chains', 'Blockchain', 'Information management', 'Hazards', 'Reliability']","['Blockchain', 'food safety', 'grain supply chain', 'hyperledger', 'smart contract']"
"Cyber-physical systems (CPS) are interconnected architectures that employ analog and digital components as well as communication and computational resources for their operation and interaction with the physical environment. CPS constitute the backbone of enterprise (e.g., smart cities), industrial (e.g., smart manufacturing), and critical infrastructure (e.g., energy systems). Thus, their vital importance, interoperability, and plurality of computing devices make them prominent targets for malicious attacks aiming to disrupt their operations. Attacks targeting cyber-physical energy systems (CPES), given their mission-critical nature within the power grid infrastructure, can lead to disastrous consequences. The security of CPES can be enhanced by leveraging testbed capabilities in order to replicate and understand power systems operating conditions, discover vulnerabilities, develop security countermeasures, and evaluate grid operation under fault-induced or maliciously constructed scenarios. Adequately modeling and reproducing the behavior of CPS could be a challenging task. In this paper, we provide a comprehensive overview of the CPS security landscape with an emphasis on CPES. Specifically, we demonstrate a threat modeling methodology to accurately represent the CPS elements, their interdependencies, as well as the possible attack entry points and system vulnerabilities. Leveraging the threat model formulation, we present a CPS framework designed to delineate the hardware, software, and modeling resources required to simulate the CPS and construct high-fidelity models that can be used to evaluate the system's performance under adverse scenarios. The system performance is assessed using scenario-specific metrics, while risk assessment enables the system vulnerability prioritization factoring the impact on the system operation. The overarching framework for modeling, simulating, assessing, and mitigating attacks in a CPS is illustrated using four representative attack scenarios targeting CPES. The key objective of this paper is to demonstrate a step-by-step process that can be used to enact in-depth cybersecurity analyses, thus leading to more resilient and secure CPS.","['Security', 'Power systems', 'Testing', 'Risk management', 'Analytical models', 'Software', 'Measurement']","['Cyber-physical systems', 'security', 'threat modeling', 'power grid', 'simulation', 'risk assessment', 'testbeds']"
"With the exponentially growing COVID-19 (coronavirus disease 2019) pandemic, clinicians continue to seek accurate and rapid diagnosis methods in addition to virus and antibody testing modalities. Because radiographs such as X-rays and computed tomography (CT) scans are cost-effective and widely available at public health facilities, hospital emergency rooms (ERs), and even at rural clinics, they could be used for rapid detection of possible COVID-19-induced lung infections. Therefore, toward automating the COVID-19 detection, in this paper, we propose a viable and efficient deep learning-based chest radiograph classification (DL-CRC) framework to distinguish the COVID-19 cases with high accuracy from other abnormal (e.g., pneumonia) and normal cases. A unique dataset is prepared from four publicly available sources containing the posteroanterior (PA) chest view of X-ray data for COVID-19, pneumonia, and normal cases. Our proposed DL-CRC framework leverages a data augmentation of radiograph images (DARI) algorithm for the COVID-19 data by adaptively employing the generative adversarial network (GAN) and generic data augmentation methods to generate synthetic COVID-19 infected chest X-ray images to train a robust model. The training data consisting of actual and synthetic chest X-ray images are fed into our customized convolutional neural network (CNN) model in DL-CRC, which achieves COVID-19 detection accuracy of 93.94% compared to 54.55% for the scenario without data augmentation (i.e., when only a few actual COVID-19 chest X-ray image samples are available in the original dataset). Furthermore, we justify our customized CNN model by extensively comparing it with widely adopted CNN architectures in the literature, namely ResNet, Inception-ResNet v2, and DenseNet that represent depth-based, multi-path-based, and hybrid CNN paradigms. The encouragingly high classification accuracy of our proposal implies that it can efficiently automate COVID-19 detection from radiograph images to provide a fast and reliable evidence of COVID-19 infection in the lung that can complement existing COVID-19 diagnostics modalities.","['Radiography', 'Lung', 'X-rays', 'Diseases', 'Computed tomography', 'Data models', 'Hospitals']","['COVID-19', 'convolutional neural network (CNN)', 'deep learning', 'generative adversarial network (GAN)', 'pneumonia']"
"The biggest contributor to global warming is energy production and use. Moreover, a push for electrical vehicle and other economic developments are expected to further increase energy use. To combat these challenges, electrical load forecasting is essential as it supports energy production planning and scheduling, assists with budgeting, and helps identify saving opportunities. Machine learning approaches commonly used for energy forecasting such as feedforward neural networks and support vector regression encounter challenges with capturing time dependencies. Consequently, this paper proposes Sequence to Sequence Recurrent Neural Network (S2S RNN) with Attention for electrical load forecasting. The S2S architecture from language translation is adapted for load forecasting and a corresponding sample generation approach is designed. RNN enables capturing time dependencies present in the load data and S2S model further improves time modeling by combining two RNNs: encoder and decoder. The attention mechanism alleviates the burden of connecting encoder and decoder. The experiments evaluated attention mechanisms with different RNN cells (vanilla, LSTM, and GRU) and with varied time horizons. Results show that S2S with Bahdanau attention outperforms other models. Accuracy decreases as forecasting horizon increases; however, longer input sequences do not always increase accuracy.","['Load forecasting', 'Load modeling', 'Decoding', 'Recurrent neural networks', 'Logic gates', 'Predictive models', 'Machine learning', 'Global warming']","['Attention mechanism', 'gated recurrent units', 'GRU', 'load forecasting', 'long short-term memory', 'LSTM', 'recurrent neural networks', 'sequence-to-sequence networks']"
"Currently, data generated by smart devices connected through the Internet is increasing relentlessly. An effective and efficient paradigm is needed to deal with the bulk amount of data produced by the Internet of Things (IoT). Deep learning and edge computing are the emerging technologies, which are used for efficient processing of huge amount of data with distinct accuracy. In this world of advanced information systems, one of the major issues is authentication. Several techniques have been employed to solve this problem. Face recognition is considered as one of the most reliable solutions. Usually, for face recognition, scale-invariant feature transforms (SIFT) and speeded up robust features (SURF) have been used by the research community. This paper proposes an algorithm for face detection and recognition based on convolution neural networks (CNN), which outperform the traditional techniques. In order to validate the efficiency of the proposed algorithm, a smart classroom for the student’s attendance using face recognition has been proposed. The face recognition system is trained on publically available labeled faces in the wild (LFW) dataset. The system can detect approximately 35 faces and recognizes 30 out of them from the single image of 40 students. The proposed system achieved 97.9% accuracy on the testing data. Moreover, generated data by smart classrooms is computed and transmitted through an IoT-based architecture using edge computing. A comparative performance study shows that our architecture outperforms in terms of data latency and real-time response.","['Face', 'Face recognition', 'Feature extraction', 'Convolution', 'Neural networks', 'Edge computing', 'Deep learning']","['CNN', 'face', 'attendance', 'RCNN', 'anchors', 'RPN', 'edge computing']"
"This paper proposes a distributed optimization algorithm for scheduling the energy consumption of multiple smart homes with distributed energy resources. In the proposed approach, the centralized optimization problem for home energy management is decomposed into a two-level optimization problem, corresponding to the local home energy management system (LHEMS) at the first level and the global home energy management system (GHEMS) at the second level. The controllable household appliances (e.g., air conditioner and washing machine) are scheduled in the LHEMS within the consumer's preferred appliance scheduling and comfort level, while the energy storage system and power trading between households are scheduled in the GHEMS. In the simulation study, the proposed distributed algorithm shows almost equivalent performance to the centralized algorithm in terms of the electricity cost and the consumer's comfort level. The impact of different network topologies on the proposed algorithm is also analyzed, and the result provides insight into the selection of the optimal network configuration in view of the consumer's electricity cost saving.","['Home appliances', 'Optimization', 'Energy management', 'Energy consumption', 'Smart homes', 'Scheduling', 'Schedules']","['Home energy management system (HEMS)', 'energy consumption scheduling', 'demand side management', 'distributed algorithm']"
"The ecological conditions in urban area are greatly changed during the process of industrialization and urbanization of China. The pressure-state-response (PSR) framework is the most popular method to evaluate the ecological quality by integrating a set of remote sensing and statistical indicators into one index through a weighting method. However, a completely remote-sensed ecological index (RSEI), integrating normalized difference vegetation index (NDVI), Wet, land surface temperature (LST), and the normalized differential build-up and bare soil index (NDBSI) through principal components analysis (PCA) method, has been proposed to assess the regional ecological quality. The publications about urban ecological evaluation by RSEI often focus on only one city or a certain area and there are few types of research on the ecological quality assessment by RSEI of 35 major cities in China. In this paper, we employed RSEI to monitor the changes in the ecological quality in China' 35 major cities. The results of RSEI were compared to that of PSR and stepwise regression method was applied to establish the quantitative relationship among RSEI, NDVI, Wet, NDBSI, and LST. The results show that there are 18 cities with ecological quality deteriorated, mainly located in the east and southwest of China (Shanghai, Guangzhou, Hongkong, Macao, Nanjing, Haikou, Shijiazhuang, and Xi'an), and 17 cities with better ecological quality, mainly located in the north and central area of China (Beijing, Tianjin, Shenzhen, Taipei, Fuzhou, Chongqing, and Jinan), from 1990 to 2015. The 3D-scatter plots of RSEI, NDVI, Wet, NDBSI, and LST demonstrate that the levels of very bad and bad mainly situate in where with a high density of built-up and low vegetation cover and soil water content. The PSR map, acquired from integrating 17 indicators, is quite similar to that of RSEI generated by merging only four remote-sensed indicators. This indicates that RSEI can be adopted to characterize regional ecological quality. Take the quantitative equation of Shanghai in 2015 as an example, every 1.46 decrement in NDBSI or each 3.72 increments in NDVI value can result in one increment in RSEI value and the ecological quality can be improved. Specifically, the expansion of the built-up area can lead to ecological degradation, and vegetation construction can promote eco-environmental quality.","['Urban areas', 'Indexes', 'Remote sensing', 'Land surface temperature', 'Soil', 'Ecosystems', 'Land surface']","['Ecological quality assessment', 'remote sensing-based ecological index (RSEI)', '35 major cities in China']"
"The extraction of features from the fully connected layer of a convolutional neural network (CNN) model is widely used for image representation. However, the features obtained by the convolutional layers are seldom investigated due to their high dimensionality and lack of global representation. In this study, we explore the uses of local description and feature encoding for deeply convolutional features. Given an input image, the image pyramid is constructed, and different pretrained CNNs are applied to each image scale to extract convolutional features. Deeply local descriptors can be obtained by concatenating the convolutional features in each spatial position. Hellinger kernel and principal component analysis (PCA) are introduced to improve the distinguishable capabilities of the deeply local descriptors. The Hellinger kernel causes the distance measure to be sensitive to small feature values, and the PCA helps reduce feature redundancy. In addition, two aggregate strategies are proposed to form global image representations from the deeply local descriptors. The first strategy aggregates the descriptors of different CNNs by Fisher encoding, and the second strategy concatenates the Fisher vectors of different CNNs. Experiments on two remote sensing image datasets illustrate that the Hellinger kernel, PCA, and two aggregate strategies improve classification performance. Moreover, the deeply local descriptors outperform the features extracted from fully connected layers.","['Feature extraction', 'Encoding', 'Kernel', 'Aggregates', 'Principal component analysis', 'Remote sensing', 'Convolutional neural networks']","['Convolutional neural networks (CNN)', 'image classification', 'local description', 'remote sensing']"
"The patient of Parkinson’s disease (PD) is facing a critical neurological disorder issue. Efficient and early prediction of people having PD is a key issue to improve patient’s quality of life. The diagnosis of PD specifically in its initial stages is extremely complex and time-consuming. Thus, the accurate and efficient diagnosis of PD has been a significant challenge for medical experts and practitioners. In order to tackle this issue and to accurately diagnosis the patient of PD, we proposed a machine-learning-based prediction system. In the development of the proposed system, the support vector machine (SVM) was used as a predictive model for the prediction of PD. The L1-norm SVM of features selection was used for appropriate and highly related features selection for accurate target classification of PD and healthy people. The L1-norm SVM produced a new subset of features from the PD dataset based on a feature weight value. For the validation of the proposed system, the $K$ -fold cross-validation method was used. In addition, the metrics of performance measures, such as accuracy, sensitivity, specificity, precision, F1 score, and execution time, were computed for model performance evaluation. The PD dataset was in this paper. The optimal accuracy achieved the best subset of the selected features that might be due to various contributions of the PD features. The experimental findings of this paper suggest that the proposed method can be used to accurately predict the PD and can be easily incorporated in healthcare for diagnosis purpose. Currently, the computer-based assisted predictive system is playing an important role to assist in PD recognition. In addition, the proposed approach fills in a gap on feature selection and classification using voice recordings data by properly matching the experimental design.","['Feature extraction', 'Support vector machines', 'Classification algorithms', 'Diseases', 'Machine learning algorithms', 'Machine learning', 'Measurement']","['Classification', 'feature selection', 'L1-norm support vector machine', 'Parkinson’s disease diagnosis', 'performance', 'voice recording']"
"The Internet of Musical Things (IoMusT) is an emerging research field positioned at the intersection of Internet of Things, new interfaces for musical expression, ubiquitous music, human-computer interaction, artificial intelligence, and participatory art. From a computer science perspective, IoMusT refers to the networks of computing devices embedded in physical objects (musical things) dedicated to the production and/or reception of musical content. Musical things, such as smart musical instruments or wearables, are connected by an infrastructure that enables multidirectional communication, both locally and remotely. We present a vision in which the IoMusT enables the connection of digital and physical domains by means of appropriate information and communication technologies, fostering novel musical applications and services. The ecosystems associated with the IoMusT include interoperable devices and services that connect musicians and audiences to support musician-musician, audience-musicians, and audience-audience interactions. In this paper, we first propose a vision for the IoMusT and its motivations. We then discuss five scenarios illustrating how the IoMusT could support: 1) augmented and immersive concert experiences; 2) audience participation; 3) remote rehearsals; 4) music e-learning; and 5) smart studio production. We identify key capabilities missing from today's systems and discuss the research needed to develop these capabilities across a set of interdisciplinary challenges. These encompass network communication (e.g., ultra-low latency and security), music information research (e.g., artificial intelligence for real-time audio content description and multimodal sensing), music interaction (e.g., distributed performance and music e-learning), as well as legal and responsible innovation aspects to ensure that future IoMusT services are socially desirable and undertaken in the public interest.","['Music', 'Instruments', 'Ecosystems', 'Internet of Things', 'Real-time systems', 'Sensors']","['Internet of Things', 'sound and music computing', 'ubiquitous music', 'mobile music', 'networked music performance', 'participatory art']"
"The Internet of Things (IoT) paradigm has integrated the sensor network silos to the Internet and enabled the provision of value-added services across these networks. These smart devices are now becoming socially conscious by following the social Internet of Things (SIoT) model that empowers them to create and maintain social relationships among them. The Social Internet of Vehicle (SIoV) is one application of SIoT in the vehicular domain that has evolved the existing intelligent transport system (ITS) and vehicular ad-hoc networks (VANETs) to the next phase of Intelligent by adding socializing aspect and constant connectivity. SIoV generates a massive amount of real-time data enriched with context and social relationship information about vehicles, drivers, passengers, and the surrounding environment. Therefore, the role of privacy management becomes essential in SIoV, as data is collected and stored at different layers of its architecture. The challenge of privacy is aggravated because the dynamic nature of SIoV poses a major threat in its adoption. Motivated by the need to address these aspects, this paper identifies the challenges involved in managing privacy in SIoV. Furthermore, the paper analyzes the privacy issues and factors that are essential to be considered for preserving privacy in SIoV environments from different perspectives including the privacy of a person, behavior and action, communication, data and image, thoughts and feelings, location and space, and association. In addition, the paper discusses the blockchain-based solutions to preserve privacy for SIoV.","['Privacy', 'Data privacy', 'Internet of Things', 'Blockchain', 'Vehicles', 'Computer architecture', 'Roads']","['Privacy management', 'blockchain', 'social Internet of Vehicles', 'Internet of Vehicles', 'social Internet of things', 'Internet of things']"
"The security of sensitive information is an urgent need in today's communication, principally in cloud and Internet of Things (IoT) environments. Therefore, a well-designed security mechanism should be carefully considered. This paper presents a new framework for secure information in fog cloud IoT. In the framework, the user in one location embeds his/her valuable data via the proposed quantum steganography protocol and uploads the covered data to the fog cloud. The intended receiver in another location accesses the data from the fog cloud and extracts the intended content via the proposed extraction approach. This paper also presents a novel quantum steganography protocol based on hash function and quantum entangled states. To the best of our knowledge, there is no prior quantum steganography protocol that authenticates an embedded secret message. In the suggested protocol, the hash function is utilized to authenticate embedded secret messages. The presented protocol is secure against well-known attacks, such as message, man-in-the-middle, and no-message attacks. In addition, it does not consume additional channels besides the proposed one to send a secret message or verify security. The proposed approach is nominated for use in fog and mobile edge computing.","['Protocols', 'Cloud computing', 'Quantum entanglement', 'Authentication', 'Reflective binary codes', 'Edge computing']","['Quantum steganography', 'authentication', 'Internet of Things', 'fog computing', 'cloud computing']"
"In the latest years, 3GPP has added short-range cellular-vehicle-to-anything (C-V2X) to the features of LTE and 5G to allow vehicles, roadside devices, and vulnerable users to directly exchange information using the same chipset as for classical long-range connections. C-V2X is based on the use of advanced physical layer techniques and orthogonal resources, and one of the main aspects affecting its performance is the way resources are allocated. Allocations can be either managed by the network or in a distributed way, directly by the nodes. The latter case, called Mode 4, is required in those situations where the network cannot be involved in the scheduling process, for example, due to a lack of coverage, but could also be adopted in order to reduce the processing burden of eNodeB. An algorithm, defined in the standards, makes nodes sense the medium, and identify the best time-frequency combination to allocate their messages. Focusing on C-V2X Mode 4, in this paper, we analyze the parameters of the algorithm designed by 3GPP and their impact on the system performance. Through simulations in different large-scale scenarios, we show that modifying some parameters have negligible effect, that the proper choice of others can indeed improve the quality of service, and that a group of parameters allows to tradeoff reliability with update delay. The provided results can also be exploited to guide the future work.","['3GPP', 'Resource management', 'Long Term Evolution', 'Time-frequency analysis', 'Interference']","['C-V2X', 'intelligent vehicles', 'vehicular and wireless technologies', 'wireless networks']"
"Since the advent of distributed ledger technologies, they have provided diverse opportunities in a wide range of application domains. This article brings a comprehensive review of the fundamentals of distributed ledger and its variants. Analyzing 185 publications, ranging from academic journals to industry websites, it provides a comparative analysis of 130 consensus algorithms using a novel architectural classification. The distribution of the reviewed algorithms is analyzed in terms of the proposed classification and different application domains, along with the applicability of each class among the top 10 platforms in the most prominent blockchain application domains. Additional conclusions are drawn from the evolution of consensus mechanisms, and the analysis concludes envisaging future prospects for consensus as an important part of distributed ledger technology.","['Distributed ledger', 'Blockchain', 'Consensus algorithm', 'Scalability', 'Distributed databases', 'Banking']","['Blockchain', 'distributed ledger technology', 'consensus mechanisms', 'cryptocurrency']"
"In this paper, we propose a hierarchical bidirectional Gated Recurrent Unit (GRU) network with attention for human emotion classification from continues electroencephalogram (EEG) signals. The structure of the model mirrors the hierarchical structure of EEG signals, and the attention mechanism is used at two levels of EEG samples and epochs. By paying different levels of attention to content with different importance, the model can learn more significant feature representation of EEG sequence which highlights the contribution of important samples and epochs to its emotional categories. We conduct the cross-subject emotion classification experiments on DEAP data set to evaluate the model performance. The experimental results show that in valence and arousal dimensions, our model on 1-s segmented EEG sequences outperforms the best deep baseline LSTM model by 4.2% and 4.6%, and outperforms the best shallow baseline model by 11.7% and 12% respectively. Moreover, with increase of the epoch's length of EEG sequences, our model shows more robust classification performance than baseline models, which demonstrates that the proposed model can effectively reduce the impact of long-term non-stationarity of EEG sequences and improve the accuracy and robustness of EEG-based emotion classification.","['Electroencephalography', 'Brain modeling', 'Logic gates', 'Feature extraction', 'Data models', 'Adaptation models', 'Deep learning']","['Hierarchical', 'bidirectional GRU', 'attention', 'EEG', 'emotion classification']"
"The device-to-device (D2D) communication paradigm in 5G networks provides an effective infrastructure to enable different smart city applications such as public safety. In future smart cities, dense deployment of wireless sensor networks (WSNs) can be integrated with 5G networks using D2D communication. D2D communication enables direct communication between nearby user equipments (UEs) using cellular or ad hoc links, thereby improving the spectrum utilization, system throughput, and energy efficiency of the network. In this paper, we propose a hierarchal D2D communication architecture where a centralized software-defined network (SDN) controller communicates with the cloud head to reduce the number of requested long-term evolution (LTE) communication links, thereby improving energy consumption. The concept of local and central controller enables our architecture to work in case of infrastructure damage and hotspot traffic situation. The architecture helps to maintain the communication between disaster victims and first responders by installing multi-hop routing path with the support of the SDN controller. In addition, we highlight the robustness and potential of our architecture by presenting a public safety scenario, where a part of the network is offline due to extraordinary events such as disaster or terrorist attacks.","['Smart cities', 'Energy efficiency', 'Public safety', '5G mobile communication']","['Software–defined', '5G networks', 'D2D', 'WSN', 'smart cities', 'public safety', 'Internet of things', 'spectrum efficiency', 'energy efficiency']"
"The vehicular ad-hoc networks (VANETs) is one of the most promising application in the communications of smart vehicles and the smart transportation systems. However, authentication and privacy of users are still two vital issues in VANETs. It is crucial to prevent internal vehicles from broadcasting the forged messages while preserving the privacy of vehicles against the tracking attack. Moreover, in the traditional mode, the transactional data storage provides no distributed and decentralized security, so that the third party initiates the dishonest behaviors possibly. In this paper, based on blockchain technique, we propose a traceable and decentralized the Internet of Vehicle system framework for communication among smart vehicles by employing of a secure access authentication scheme between vehicles and RoadSide Units (RSUs). On the one hand, this scheme allows that vehicles employ pseudonyms for Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) communications anonymously in the non-fully trusted environment. On the other hand, the transparency of vehicles in authentication and announcement is preformed efficiently by the blockchain technology. In addition, the transaction information is tamper-resistant that provides the distributed and decentralized property for the different cloud servers. With the help of Certificate Authority (CA) and the RoadSide Units (RSUs), our proposal achieves the conditional privacy to trace the real identity of the malicious vehicle in the anonymous announcements as well. Finally, through the theoretical analysis and simulations, our scheme is able to construct a secure and decentralized system framework of VANETs with accountability and privacy preservation.","['Blockchain', 'Authentication', 'Privacy', 'Peer-to-peer computing', 'Vehicular ad hoc networks']","['Blockchain-based', 'privacy-preserving', 'authentication', 'traceability', 'VANETs']"
"The negative impedance characteristics of a constant power load (CPL) can easily lead to the instability of the DC bus voltage. To improve the stability of the DC bus voltage, an adaptive backstepping sliding mode control strategy for a boost converter with the CPL in DC microgrid is proposed. First, to carry out the backstepping control, the zero dynamic stability of the system under different output functions is studied by using input-output exact feedback linearization theory. The model is transformed into a linear system in Brunovsky canonical form, which solves the nonlinear problem caused by the CPL and the non-minimum phase problem of the boost converter. Then, under the premise of ensuring large signal stability, an adaptive mechanism is introduced into the design of the backstepping sliding mode control. The adaptive backstepping sliding mode controller is designed by adaptively updating the switching gain in real time. Furthermore, the Lyapunov theory is used to prove the global asymptotic stability of the overall closed-loop system. Finally, the numerical simulation and experimental results show that the proposed control strategy has better dynamic regulation performance and stronger robustness compared with the conventional double closed-loop PI control method.","['Stability analysis', 'Microgrids', 'Power system stability', 'Backstepping', 'Sliding mode control', 'Asymptotic stability', 'Nonlinear systems']","['Constant power load', 'boost converter', 'exact feedback linearization', 'backstepping sliding mode control adaptive']"
"The relentless growth of wireless applications and data traffic continues to accentuate the long felt need for decentralized, self-managed, and cooperative network architectures. Enlightened by the power of blockchain technology, we propose a blockchain radio access network (B-RAN) architecture and develop decentralized, secure, and efficient mechanisms to manage network access and authentication among inherently trustless network entities. We further identify promising advanced functions made possible by adopting blockchain for open radio access networks. Our test results demonstrate the benefits of the B-RAN architecture. We also present a number of challenges and future research directions.","['Blockchain', 'Radio access networks', 'Smart contracts', 'Computer architecture', 'Wireless networks', 'Payloads']","['Blockchain', 'communication networks', 'decentralization', 'radio access network', 'wireless application protocol']"
"We propose a neural network architecture for detecting intrusions on the controller area network (CAN). The latter is the standard communication method between the electronic control units (ECUs) of automobiles. However, CAN lacks security mechanisms and it has recently been shown that it can be attacked remotely. Hence, it is desirable to monitor CAN traffic to detect intrusions. In order to find both, known and unknown intrusion scenarios, we consider a novel unsupervised learning approach which we call CANet. To our knowledge, this is the first deep learning based intrusion detection system (IDS) that naturally handles the data structure of the high dimensional CAN bus, where different message types are sent at different times. Our method is evaluated on real and synthetic CAN data. A comparison with previous machine learning based methods shows that CANet outperforms them by a significant margin. For reproducibility of the method, our synthetic data is publicly available.","['Neural networks', 'Payloads', 'Intrusion detection', 'Standards', 'Automobiles', 'Deep learning', 'Network architecture']","['CAN bus', 'deep learning', 'intrusion detection']"
"A novel and high-performance four-element ultra-wideband (UWB) multiple-input multipleoutput (MIMO) antenna is proposed in the paper. The proposed antenna is designed by using a novel integration technology of the symmetric layout, orthogonal structure, four-directional staircase-shaped decoupling, and multi-slit and multi-slot techniques. The mutual couplings among the antenna elements are significantly reduced by introducing the symmetric orthogonal and separated four-directional staircaseshaped structure. Furthermore, the antenna size is effectively miniaturized, and its impedance bandwidth is broadened by using a two-sided symmetric layout, partial and defected ground structure, the decoupling structure, and multi-slot and multi-slit techniques. Therefore, the antenna has the low-profile structure and a small dimension of 39mm×39mm×1.6mm. Moreover, the proposed antenna achieves triple band-notched characteristics by embedding different type slots and slits on the square radiating elements, default ground structure, and the decoupling structure, respectively. As a result, the antenna obtains the wider bandwidth of 2.30-13.75 GHz with the notched bands of 3.25-3.75 GHz, 5.08-5.90 GHz, and 7.06-7.95 GHz. The three notched bands are good in agreement with the existing interference bands of WiMAX (3.3-3.7 GHz), WLAN (5.15-5.875 GHz), and X-band (7.1-7.9 GHz), respectively. In addition, the proposed antenna also has a lower mutual coupling (<;-22dB), lower envelop correlation coefficient (ECC<;0.02, except for the three notched bands), high multiplexing efficiency (η mux >-3.0dB), stable gain, and quasi-omnidirectional radiation patterns at the entire impedance bandwidth. Therefore, a good tradeoff of the performance is obtained for the proposed antenna. The proposed antenna can be a good candidate for UWB-MIMO wireless communication applications, and especially for portable UWB-MIMO systems.","['Bandwidth', 'Slot antennas', 'Ultra wideband antennas', 'Mutual coupling', 'Layout', 'MIMO communication']","['UWB-MIMO antenna', 'symmetric orthogonal structure', 'multi-slot-multi-slit', 'high isolation', 'triple band-notched characteristics']"
"In view of the lack of feature complementarity between the feature layers of Single Shot MultiBox Detector (SSD) and the weak detection ability of SSD for small objects, we propose an improved SSD object detection algorithm based on Dense Convolutional Network (DenseNet) and feature fusion, which is called DF-SSD. On the basis of SSD, we design the feature extraction network DenseNet-S-32-1 with reference to the dense connection of DenseNet, and replace the original backbone network VGG-16 of SSD with DenseNet-S-32-1 to enhance the feature extraction ability of the model. In the part of multi-scale detection, a fusion mechanism of multi-scale feature layers is introduced to organically combine low-level visual features and high-level semantic features in the network structure. Finally, a residual block is established before the object prediction to further improve the model performance. We train the DF-SSD model from scratch. The experimental results show that our model DF-SSD with 300 × 300 input achieves 81.4% mAP, 79.0% mAP, and 29.5% mAP on PASCAL VOC 2007, VOC 2012, and MS COCO datasets, respectively. Compared with SSD, the detection accuracy of DF-SSD on VOC 2007 is improved by 3.1% mAP. DF-SSD requires only 1/2 parameters to SSD and 1/9 parameters to Faster RCNN. We inject more semantic information into DF-SSD, which makes it have advanced detection effect on small objects and objects with specific relationships.","['Feature extraction', 'Object detection', 'Semantics', 'Convolution', 'Detectors', 'Task analysis', 'Adaptation models']","['DenseNet', 'feature fusion', 'multi-scale object detection', 'SSD']"
"As industries become automated and connectivity technologies advance, a wide range of systems continues to generate massive amounts of data. Many approaches have been proposed to extract principal indicators from the vast sea of data to represent the entire system state. Detecting anomalies using these indicators on time prevent potential accidents and economic losses. Anomaly detection in multivariate time series data poses a particular challenge because it requires simultaneous consideration of temporal dependencies and relationships between variables. Recent deep learning-based works have made impressive progress in this field. They are highly capable of learning representations of the large-scaled sequences in an unsupervised manner and identifying anomalies from the data. However, most of them are highly specific to the individual use case and thus require domain knowledge for appropriate deployment. This review provides a background on anomaly detection in time-series data and reviews the latest applications in the real world. Also, we comparatively analyze state-of-the-art deep-anomaly-detection models for time series with several benchmark datasets. Finally, we offer guidelines for appropriate model selection and training strategy for deep learning-based time series anomaly detection.","['Anomaly detection', 'Time series analysis', 'Guidelines', 'Deep learning', 'Data models', 'Biological system modeling', 'Time factors']","['Anomaly detection', 'deep learning', 'fault diagnosis', 'industry applications', 'Internet-of-Things (IoT)', 'time series analysis']"
"Home automation systems have attracted considerable attention with the advancement of communications technology. A smart home (SH) is an Internet of Things (IoT) application that utilizes the Internet to monitor and control appliances using a home automation system. Lack of IoT technology usage, unfriendly user interface, limited wireless transmission range, and high costs are the limitations of existing home automation systems. Therefore, this study presents a cost-effective and hybrid (local and remote) IoT-based home automation system with a user-friendly interface for smartphones and laptops. A prototype called IoT@HoMe is developed with an algorithm to enable the monitoring of home conditions and automate the control of home appliances over the Internet anytime and anywhere. This system utilizes a node microcontroller unit (NodeMCU) as a Wi-Fi-based gateway to connect different sensors and updates their data to Adafruit IO cloud server. The collected data from several sensors (radio-frequency identification, ultrasonic, temperature, humidity, gas, and motion sensors) can be accessed via If This Then That (IFTTT) on users' devices (smartphones and/or laptops) over the Internet regardless of their location. A set of relays is used to connect the NodeMCU to homes under controlled appliances. The designed system is structured in a portable manner as a control box that can be attached for monitoring and controlling a real house. The proposed IoT-based system for home automation can easily and efficiently control appliances over the Internet and support home safety with autonomous operation. IoT@HoMe is a low cost and reliable automation system that reduces energy consumption and can notably provide convenience, safety, and security for SH residents.","['Home appliances', 'Internet of Things', 'Automation', 'Home automation', 'Monitoring', 'Sensors']","['Smart Home', 'IoT', 'NodeMCU', 'adafruit IO', 'MQTT', 'google assistant']"
"The vision of the Internet of Things (IoT) to interconnect and Internet-connect everyday people, objects, and machines poses new challenges in the design of wireless communication networks. The design of medium access control (MAC) protocols has been traditionally an intense area of research due to their high impact on the overall performance of wireless communications. The majority of research activities in this field deal with different variations of protocols somehow based on ALOHA, either with or without listen before talk, i.e., carrier sensing multiple access. These protocols operate well under low traffic loads and low number of simultaneous devices. However, they suffer from congestion as the traffic load and the number of devices increase. For this reason, unless revisited, the MAC layer can become a bottleneck for the success of the IoT. In this paper, we provide an overview of the existing MAC solutions for the IoT, describing current limitations and envisioned challenges for the near future. Motivated by those, we identify a family of simple algorithms based on distributed queueing (DQ), which can operate for an infinite number of devices generating any traffic load and pattern. A description of the DQ mechanism is provided and most relevant existing studies of DQ applied in different scenarios are described in this paper. In addition, we provide a novel performance evaluation of DQ when applied for the IoT. Finally, a description of the very first demo of DQ for its use in the IoT is also included in this paper.","['Internet of Things', 'Telecommunication traffic', 'Wireless communication', 'Media Access Protocol', 'Performance evaluation', 'Sensors', 'Wireless sensor networks']","['Communications technology', 'Internet of Things', 'cellular networks', 'machine-to-machine communications', '4G mobile communication', 'protocols', 'access protocols', 'Bluetooth', 'Zigbee', 'radio access networks', 'wireless communication', 'RFID tags']"
"Wireless communication systems play a very crucial role in modern society for entertainment, business, commercial, health and safety applications. These systems keep evolving from one generation to next generation and currently we are seeing deployment of fifth generation (5G) wireless systems around the world. Academics and industries are already discussing beyond 5G wireless systems which will be sixth generation (6G) of the evolution. One of the main and key components of 6G systems will be the use of Artificial Intelligence (AI) and Machine Learning (ML) for such wireless networks. Every component and building block of a wireless system that we currently are familiar with from our knowledge of wireless technologies up to 5G, such as physical, network and application layers, will involve one or another AI/ML techniques. This overview paper, presents an up-to-date review of future wireless system concepts such as 6G and role of ML techniques in these future wireless systems. In particular, we present a conceptual model for 6G and show the use and role of ML techniques in each layer of the model. We review some classical and contemporary ML techniques such as supervised and un-supervised learning, Reinforcement Learning (RL), Deep Learning (DL) and Federated Learning (FL) in the context of wireless communication systems. We conclude the paper with some future applications and research challenges in the area of ML and AI for 6G networks.","['6G mobile communication', '5G mobile communication', 'Artificial intelligence', 'Wireless networks', 'Resource management', 'Data models', 'Solid modeling']","['Fifth generation (5G)', 'sixth generation (6G)', 'artificial intelligence (AI)', 'machine learning (ML)', 'deep learning (DL)', 'reinforcement learning (RL)', 'federated learning (FL)']"
"Accurate channel models are essential to evaluate mobile communication system performance and optimize coverage for existing deployments. The introduction of various transmission frequencies for 5G imposes new challenges for accurate radio performance prediction. This paper compares traditional channel models to a channel model obtained using Deep Learning (DL)-techniques utilizing satellite images aided by a simple path loss model. Experimental measurements are gathered and compose the training and test set. This paper considers path loss modelling techniques offered by state-of-the-art stochastic models and a ray-tracing model for comparison and evaluation. The results show that 1) the satellite images offer an increase in predictive performance by ≈ 0.8 dB, 2) The model-aided technique offers an improvement of ≈ 1 dB, and 3) that the proposed DL model is capable of improving path loss prediction at unseen locations for 811 MHz with ≈ 1 dB and ≈ 4.7 dB for 2630 MHz.","['Predictive models', 'Computational modeling', 'Channel models', 'Mobile communication', 'Adaptation models', 'Satellite broadcasting', 'Propagation losses']","['5G mobile communication', 'channel models', 'wireless communication', 'computer vision', 'machine learning', 'supervised learning']"
"As a promising paradigm for the fifth generation wireless communication (5G) system, the fog radio access network (F-RAN) has been proposed as an advanced socially aware mobile networking architecture to provide high spectral efficiency (SE) while maintaining high energy efficiency (EE) and low latency. Recent advents are advocated to the performance analysis and radio resource allocation, both of which are fundamental issues to make F-RANs successfully rollout. This paper comprehensively summarizes the recent advances of the performance analysis and radio resource allocation in F-RANs. In particular, the advanced edge cache and adaptive model selection schemes are presented to improve SE and EE under maintaining a low latency level. The radio resource allocation strategies to optimize SE and EE in F-RANs are, respectively, proposed. A few open issues in terms of the F-RAN-based 5G architecture and the social-awareness technique are identified as well.","['Device-to-device communication', 'Mobile computing', '5G mobile communication', 'Resource management', 'Performance analysis', 'Radio access networks']","['Fog radio access networks (F-RANs)', '5G', 'socially-aware mobile networking', 'edge cache']"
"Unmanned aerial vehicles (UAVs) have found important applications in wireless communications due to their ability for on-demand and swift deployment, high mobility, and high probability of line-of-sight communication link with the ground. For UAV-enabled wireless communications, one of the main use cases is UAV relaying, where UAVs are deployed as flying relays in the sky to provide wireless connections between distant users that do not have reliable direct connectivity. This paper considers a general multiple UAV relaying system, where the information from a source node to a destination node is forwarded through multi-hop UAV relays. We aim to maximize the end-to-end throughput via joint UAV trajectory and transmit power optimization, subject to UAV mobility and collision avoidance constraints, the information-causality constraints, and the average and peak transmit power constraints of the source and UAV relays. The formulated problem is non-convex and challenging to solve, hence we propose an efficient iterative algorithm to obtain a suboptimal solution based on the alternating maximization and successive convex optimization techniques. Numerical results validate the effectiveness of the proposed algorithm as compared to three benchmark schemes with only transmit power allocation or trajectory optimization.","['Relays', 'Resource management', 'Unmanned aerial vehicles', 'Wireless communication', 'Trajectory optimization', 'Spread spectrum communication']","['UAV communication', 'multi-hop relaying', 'power allocation', 'trajectory optimization']"
"This paper proposes a new metaheuristic optimization algorithm based on ancient war strategy. The proposed War Strategy Optimization (WSO) is based on the strategic movement of army troops during the war. War strategy is modeled as an optimization process wherein each soldier dynamically moves towards the optimum value. The proposed algorithm models two popular war strategies, attack and defense strategies. The positions of soldiers on the battlefield are updated in accordance with the strategy implemented. To improve the algorithm’s convergence and robustness, a novel weight updating mechanism and a weak soldier’s relocation strategy are introduced. The proposed war strategy algorithm achieves good balance of the exploration and exploitation stages. A detailed mathematical model of the algorithm is presented. The efficacy of the proposed algorithm is tested on 50 benchmark functions and four engineering problems. The performance of the algorithm is compared with ten popular metaheuristic algorithms. The experimental results for various optimization problems prove the superiority of the proposed algorithm.","['Optimization', 'Classification algorithms', 'Metaheuristics', 'Heuristic algorithms', 'Search problems', 'Convergence', 'Particle swarm optimization']","['Metaheuristic', 'optimization', 'war strategy', 'swarm optimization']"
"Fog computing has emerged as a revolutionary paradigm to serve the massive data generated in the Internet of Things (IoT) environments. It can be considered a derivative of cloud computing that provides cloud-like services at the edge of the network. As such, it helps address the, often significant, issue of delays encountered when using cloud systems for the IoT. According to the literature, inefficient scheduling of user tasks in fog computing can actually result in higher delays than cloud computing. Hence, the real benefits of fog computing can only be obtained by applying effective job scheduling strategies. In fact, task scheduling is an NP-hard problem and requires optimal and efficient techniques to address issues of latency, response time, and the efficient resource utilization of resources available at the edge of the network. Given this, we propose a novel bio-inspired hybrid algorithm (NBIHA) which is a hybrid of modified particle swarm optimization (MPSO) and modified cat swarm optimization (MCSO). In the proposed scheme, the MPSO is used to schedule the tasks among fog devices and the hybrid of the MPSO and MCSO is used to manage resources at the fog device level. In the proposed approach, the resources are assigned and managed on the basis of the demand of incoming requests. The main objective of the proposed work is to reduce the average response time and to optimize resource utilization by efficiently scheduling the tasks and managing the fog resources available. The simulations are performed using iFogSim. The evaluation results show that the proposed approach (NBIHA) shows promising results in terms of energy consumption, execution time, and average response time in comparison to the state-of-the-art scheduling techniques.","['Cloud computing', 'Task analysis', 'Edge computing', 'Resource management', 'Processor scheduling', 'Internet of Things', 'Scheduling']","['Cloud computing', 'edge computing', 'fog computing', 'bio-inspired algorithms', 'task scheduling', 'resource management']"
"Over the past decade, blockchain technology has attracted tremendous attention from both academia and industry. The popularity of blockchains was originated from the concept of crypto-currencies to serve as a decentralized and tamper-proof transaction data ledger. Nowadays, blockchains as the key framework in the decentralized public data-ledger have been applied to a wide range of scenarios far beyond crypto-currencies, such as the Internet of Things, healthcare, and insurance. This survey aims to fill the gap between a large number of studies on blockchain networks, where game theory emerges as an analytical tool, and the lack of a comprehensive survey on the game theoretical approaches applied in blockchain-related issues. In this survey, we review the game models proposed to address common issues in the blockchain network. The focus is placed on security issues, e.g., selfish mining, majority attack and denial of service attack, issues regarding mining management, e.g., computational power allocation, reward allocation, and pool selection, as well as issues regarding blockchain economic and energy trading. Additionally, we discuss the advantages and disadvantages of these selected game theoretical models and solutions. Finally, we highlight important challenges and future research directions of applying game theoretical approaches to incentive mechanism design and the combination of blockchain with other technologies.","['Blockchain', 'Protocols', 'Games', 'Game theory', 'Cryptography', 'Peer-to-peer computing']","['Blockchain', 'game theory', 'mining management', 'security']"
"The development of a navigation system is one of the major challenges in building a fully autonomous platform. Full autonomy requires a dependable navigation capability not only in a perfect situation with clear GPS signals but also in situations, where the GPS is unreliable. Therefore, self-contained odometry systems have attracted much attention recently. This paper provides a general and comprehensive overview of the state of the art in the field of self-contained, i.e., GPS denied odometry systems, and identifies the out-coming challenges that demand further research in future. Self-contained odometry methods are categorized into five main types, i.e., wheel, inertial, laser, radar, and visual, where such categorization is based on the type of the sensor data being used for the odometry. Most of the research in the field is focused on analyzing the sensor data exhaustively or partially to extract the vehicle pose. Different combinations and fusions of sensor data in a tightly/loosely coupled manner and with filtering or optimizing fusion method have been investigated. We analyze the advantages and weaknesses of each approach in terms of different evaluation metrics, such as performance, response time, energy efficiency, and accuracy, which can be a useful guideline for researchers and engineers in the field. In the end, some future research challenges in the field are discussed.","['Global Positioning System', 'Wheels', 'Laser radar', 'Lasers', 'Satellite broadcasting', 'Simultaneous localization and mapping']","['Self-contained localization', 'wheel odometry', 'inertial odoemtry', 'laser odometry', 'visual-inertial odometry', 'filter-based', 'optimization-based', 'loosely-coupled', 'tightly-coupled', 'GPS-denied']"
"Restoring the interaction between disabled people and the 3-D physical world via a brain-computer interface (BCI) is an exciting topic. To this end, we designed a wearable BCI system based on the steady-state visual evoked potential (SSVEP), which enables 3-D navigation of quadcopter flight with immersive first-person visual feedback using a head-mounted device. In addition, to alleviate the user’s operational burden, this paper provides asynchronous switch control for the users. The transitional state due to head movement in an asynchronous BCI was isolated online and translated into hover to eliminate its influence. The experimental results in the physical environment showed that the subjects could accomplish the 3-D flight tasks accurately and smoothly using our system. In particular, in this paper, we proposed an information transfer rate metric that is suitable for the asynchronous task. We demonstrated the feasibility of using the head-mounted device and a proper control strategy to facilitate the portability and practicability of the SSVEP-based BCI system for its navigation utility.","['Resists', 'Three-dimensional displays', 'Visualization', 'Navigation', 'Steady-state', 'Headphones', 'Electroencephalography']","['Brain-computer interface (BCI)', 'quadcoptor', 'head-mounted device', 'steady-state visual evoked potential', 'wearable system']"
"A major challenge in biometrics is performing the test at the client side, where hardware resources are often limited. Deep learning approaches pose a unique challenge: while such architectures dominate the field of face recognition with regard to accuracy, they require elaborate, multi-stage computations. Recently, there has been some work on compressing networks for the purpose of reducing run time and network size. However, it is not clear that these compression methods would work in deep face nets, which are, generally speaking, less redundant than the object recognition networks, i.e., they are already relatively lean. We propose two novel methods for compression: one based on eliminating lowly active channels and the other on coupling pruning with repeated use of already computed elements. Pruning of entire channels is an appealing idea, since it leads to direct saving in run time in almost every reasonable architecture.","['Biometrics', 'Resource management', 'Face recognition', 'Image compression']","['Face recognition', 'neural network compression']"
"Cervical cancer, as the fourth most common cause of death from cancer among women, has no symptoms in the early stage. There are few methods to diagnose cervical cancer precisely at present. Support vector machine (SVM) approach is introduced in this paper for cervical cancer diagnosis. Two improved SVM methods, support vector machine-recursive feature elimination and support vector machine-principal component analysis (SVM-PCA), are further proposed to diagnose the malignant cancer samples. The cervical cancer data are represented by 32 risk factors and 4 target variables: Hinselmann, Schiller, Cytology, and Biopsy. All four targets have been diagnosed and classified by the three SVM-based approaches, respectively. Subsequently, we make the comparison among these three methods and compare our ranking result of risk factors with the ground truth. It is shown that SVM-PCA method is superior to the others.","['Support vector machines', 'Cervical cancer', 'Prediction algorithms', 'Principal component analysis', 'Pregnancy', 'Biopsy']","['Cervical cancer', 'data-driven', 'SVM classification', 'SVM-RFE', 'SVM-PCA']"
"Melanoma is the deadliest form of skin cancer. Distinguishing melanoma lesions from non-melanoma lesions has however been a challenging task. Many Computer Aided Diagnosis and Detection Systems have been developed in the past for this task. They have been limited in performance due to the complex visual characteristics of the skin lesion images which consists of inhomogeneous features and fuzzy boundaries. In this paper, we propose a deep learning-based method that overcomes these limitations for automatic melanoma lesion detection and segmentation. An enhanced encoder-decoder network with encoder and decoder sub-networks connected through a series of skip pathways which brings the semantic level of the encoder feature maps closer to that of the decoder feature maps is proposed for efficient learning and feature extraction. The system employs multi-stage and multi-scale approach and utilizes softmax classifier for pixel-wise classification of melanoma lesions. We devise a new method called Lesion-classifier that performs the classification of skin lesions into melanoma and non-melanoma based on results derived from pixel-wise classification. Our experiments on two well-established public benchmark skin lesion datasets, International Symposium on Biomedical Imaging(ISBI)2017 and Hospital Pedro Hispano (PH2), demonstrate that our method is more effective than some state-of-the-art methods. We achieved accuracy and dice coefficient of 95% and 92% on ISIC 2017 dataset and accuracy and dice coefficient of 95% and 93% on PH2 datasets.","['Lesions', 'Melanoma', 'Skin', 'Feature extraction', 'Image color analysis']","['Deep learning-based', 'encoding-decoding network', 'pixel-wise classification', 'melanoma', 'skin lesion', 'segmentation']"
"Detecting and controlling the diffusion of infectious diseases such as COVID-19 is crucial to managing epidemics. One common measure taken to contain or reduce diffusion is to detect infected individuals and trace their prior contacts so as to then selectively isolate any individuals likely to have been infected. These prior contacts can be traced using mobile devices such as smartphones or smartwatches, which can continuously collect the location and contacts of their owners by using their embedded localisation and communications technologies, such as GPS, Cellular networks, Wi-Fi, and Bluetooth. This paper evaluates the effectiveness of these technologies and determines the impact of contact tracing precision on the spread and control of infectious diseases. To this end, we have created an epidemic model that we used to evaluate the efficiency and cost (number of people quarantined) of the measures to be taken, depending on the smartphone contact tracing technologies used. Our results show that in order to be effective for the COVID-19 disease, the contact tracing technology must be precise, contacts must be traced quickly, and a significant percentage of the population must use the smartphone contact tracing application. These strict requirements make smartphone-based contact tracing rather ineffective at containing the spread of the infection during the first outbreak of the virus. However, considering a second wave, where a portion of the population will have gained immunity, or in combination with some other more lenient measures, smartphone-based contact tracing could be extremely useful.","['Infectious diseases', 'Sociology', 'Statistics', 'Stochastic processes', 'Adaptation models', 'Mobile handsets', 'COVID-19']","['Mobile computing', 'opportunistic networking', 'epidemic models', 'social networks', 'digital epidemiology']"
"Interference is one of the fundamental aspects that makes wireless communication challenging, which has attracted great research attention for decades. To solve this interference problem, many interference management (IM) techniques have been developed. Nevertheless, interference can also provide some benefits to wireless networks if it is properly utilized according to the latest research advances. Wireless signal can carry information as well as energy, and thus the redundant resource of interference can be exploited using energy harvesting (EH) to provide the power to support the operation of wireless nodes. In this paper, we provide a comprehensive survey on the research works of exploiting interference for wireless EH. Some fundamental aspects are first reviewed, including the receiver architecture, antenna dimension, network topology, and IM techniques, for wireless EH systems that exploit interference. Then, two IM techniques for wireless EH, beamforming optimization and interference alignment, are discussed in detail. In addition, several research issues are also presented, including the adversarial jamming signal and artificial noise for EH. Finally, some research challenges of exploiting interference for wireless EH are discussed.","['Interference', 'Energy harvesting', 'Receivers', 'Radio frequency', 'Wireless networks', 'Couplings']","['Beamforming optimization', 'interference alignment', 'interference management', 'power splitting', 'simultaneous wireless information and power transfer', 'time switching', 'wireless energy harvesting']"
"Because insulators provide electrical insulation and mechanical support for electric transmission lines, these components are of paramount importance to safe and reliable operations of power systems. However, insulators are often considered to be prone to different faults, e.g., bunch-drop, which demands a novel solution for accurate fault detection and fault location. Current research efforts have primarily focused on the bunch-drop fault of glass insulators, and the study of ceramic insulators has not been reported to date. To this end, this paper proposes an algorithmic solution for the bunch-drop fault detection for both glass and ceramic insulators based on spatial morphological features, which can be integrated into an unmanned aerial vehicle-based inspection system. Color models can be established based on the unique color features of both glass and ceramic insulators. Next, the target areas of the insulators can be identified according to the color determination combined with the insulator's spatial features. The target area is morphologically processed to highlight the fault location, and the rules are established based on the spatial feature differences between the insulators with and without faults. Consequently, the fault location can be accurately identified, and the coordinates can be determined. The performance of the proposed solution is evaluated in comparison with existing solutions. The numerical results demonstrate that the proposed solution can detect the bunch-drop faults of insulators with a better than average detection rate. In addition, the performance is assessed and validated in terms of robustness and real-time performance.","['Insulators', 'Image color analysis', 'Ceramics', 'Glass', 'Feature extraction', 'Fault detection', 'Fault diagnosis']","['Bunch-drop', 'color determination', 'fault detection', 'insulator', 'morphology', 'spatial features']"
"Recent years have witnessed the rapid development in the research topic of WiFi sensing that automatically senses human with commercial WiFi devices. Past work falls into two major categories, i.e., activity recognition and the indoor localization. The former work utilizes WiFi devices to recognize human daily activities such as smoking, walking, and dancing. The latter one, indoor localization, can be used for indoor navigation, location-based services, and through-wall surveillance. The key rationale behind WiFi sensing is that people behaviors can influence the WiFi signal propagation and introduce specific patterns into WiFi signals, called WiFi fingerprints, which can be further explored to identify human activities and locations. In this paper, we propose a novel deep learning framework for joint activity recognition and indoor localization task using WiFi channel state information (CSI) fingerprints. More precisely, we develop a system running standard IEEE 802.11n WiFi protocol and collect more than 1400 CSI fingerprints on 6 activities at 16 indoor locations. Then we propose a dual-task convolutional neural network with one-dimensional convolutional layers for the joint task of activity recognition and indoor localization. The experimental results and ablation study show that our approach achieves good performances in this joint WiFi sensing task. Data and code have been made publicly available at https://github.com/geekfeiw/apl .","['Wireless fidelity', 'Activity recognition', 'Task analysis', 'Convolutional neural networks', 'Fingerprint recognition', 'Clocks']","['CSI fingerprints', 'activity recognition', 'indoor localization', 'human–computer interaction', '1D convolutional neural networks']"
"This paper presents a fuzzy adaptive model predictive approach for load frequency control of an isolated micro grid. A generalized state space model of a typical isolated micro grid having controllable and uncontrollable generating power sources is derived, and the same has been utilized to predict the future output and control inputs for the micro grid frequency control. A centralized model predictive control (MPC) is implemented with a single input multi-output system model based on the controllable distributed energy resources in the micro grid. The parameter-driven MPC is made adaptable by dynamically adjusting its parameter Rw using fuzzy controller. The proposed fuzzy MPC employs a rule-based fuzzy controller to fuzzify the tuning parameter Rw present in the cost function of MPC, which plays an important role in minimizing the frequency deviation in the system. The closed loop system response obtained by the proposed fuzzy MPC has been found faster and adaptable for different scenarios in the system. The effectiveness has been evaluated with performance index integral time square error (ITSE) value and has been compared with MPC with constant tuning parameter value also with the proportional-integral controller response. Thus, the efficacy of using proposed fuzzy MPC in secondary load frequency control has been validated thereof.","['Frequency control', 'Microgrids', 'Predictive control', 'Load modeling', 'Predictive models', 'Fuel cells', 'Mathematical model']","['Load frequency control', 'fuzzy control', 'adaptive model predictive control']"
"Three-dimensional Digital Image Correlation (3D-DIC) is a non-contact optical-numerical technique for evaluating the dynamic mechanical behavior at the surface of structures and materials, including biological tissues. 3D-DIC can be used to extract shape and full-field displacements and strains with high resolution, at various length scales. While various commercial and academic 3D-DIC software exist, the field lacks 3D-DIC packages which offer straightforward calibration and data-merging solutions for multi-view analysis, which is particularly desirable in biomedical applications. To address these limitations, we present MultiDIC, an open-source MATLAB toolbox, featuring the first 3D-DIC software specifically dedicated to multi-view setups. MultiDIC integrates robust two-dimensional subset-based DIC software with specially tailored calibration procedures, to reconstruct the dynamic behavior of surfaces from multiple stereo-pairs. MultiDIC contains novel algorithms to automatically merge meshes from multiple stereopairs, and to compute and visualize 3D shape and full-field motion, deformation, and strain. User interfaces provide capabilities to perform 3D-DIC analyses without interacting with MATLAB syntax, while standalone functions also allow proficient MATLAB users to write custom scripts for specific experimental requirements. This paper discusses the challenges underlying multi-view 3D-DIC, details the proposed solutions, and describes the algorithms implemented in MultiDIC. The performance of MultiDIC is tested using a low-cost experimental system featuring a 360° 12-camera setup. The software and system are evaluated using measurement of a cylindrical object with known geometry subjected to rigid body motion and measurement of the lower limb of a human subject. The findings confirm that shape, motion, and fullfield deformations and strains can be accurately measured, and demonstrate the feasibility of MultiDIC in multi-view in-vivo biomedical applications.","['Cameras', 'Calibration', 'Strain', 'Three-dimensional displays', 'Distortion', 'Shape', 'Open source software']","['Biomedical image analysis', 'full-field 3-D deformation', 'material mechanical properties', 'open source software', 'skin shape and strain', 'soft tissue biomechanics', 'stereo-DIC', 'strain map']"
"This paper presents an open course in the University Network of Interactive Laboratories, which offers several virtual and remote laboratories on automatic control, accessible to anyone. All the details on one of these labs (a two electric coupled drives system that allows performing control practices in a 2 × 2 MIMO system with industrial applications) and the activities that can be performed with it are given. We use a low-cost solution for developing the virtual and remote labs shared in this open course, based on the use of a free authoring tool Easy Java/Javascript Simulations (EJsS) for building the laboratories' user interfaces and a cheap development platform board (BeagleBone Black). The virtual and remote labs are deployed into a free Learning Management System (Moodle) Web environment that facilitates their management and maintenance.","['Distance education', 'Remote laboratories', 'Control systems', 'Virtual laboratories', 'Engineering education']","['Distance education', 'Remote laboratories', 'Control engineering education', 'Control systems']"
"The evolution of traditional energy networks toward smart grids increases security vulnerabilities in the power system infrastructure. State estimation plays an essential role in the efficient and reliable operation of power systems, so its security is a major concern. Coordinated cyber-attacks, including false data injection (FDI) attack, can manipulate smart meters to present serious threats to grid operations. In this paper, a robust state estimation algorithm against FDI attack is presented. As a solution to mitigate such an attack, a new analytical technique is proposed based on the Markov chain theory and Euclidean distance metric. Using historical data of a set of trusted buses, a Markov chain model of the system normal operation is formulated. The estimated states are analyzed by calculating the Euclidean distance from the Markov model. States, which match the lower probability, are considered as attacked states. It is shown that the proposed method is able to detect malicious attack, which is undetectable by traditional bad data detection (BDD) methods. The proposed robust dynamic state estimation algorithm is built on a Kalman filter, and implemented on the massively parallel architecture of graphic processing unit using fine-grained parallel programming techniques. Numerical simulations demonstrate the efficiency and accuracy of the proposed mechanism.","['State estimation', 'Power system dynamics', 'Markov processes', 'Graphics processing units', 'Security', 'Robustness']","['Bad data detection', 'cyber-attack', 'false data injection', 'dynamic state estimation', 'graphic processing units', 'large-scale systems', 'Markov chain', 'parallel programming', 'SCADA', 'PMUs']"
"In the study of modern optics, the work of terahertz metamaterial absorbers is mostly multi-band perfect absorbers and ultra-wideband perfect absorbers. In contrast, in practical applications, metamaterial absorbers with adjustable resonance frequency or amplitude play an essential role in many forms. Here, we firstly designed an ultra-wideband terahertz metamaterial perfect absorber, achieving over 99% perfect absorption in the 6.6-8.9 THz range. Secondly, based on the absorber, phase change material VO 2 was added to improve the structure, and three tunable terahertz metamaterial absorbers based on VO 2 were designed, respectively realizing broadband movement and conversion between broadband and multi-band. Also, the terahertz absorber with dynamic tuning characteristics can flexibly control the absorption performance, providing an excellent platform for the realization of terahertz filtering, modulation, and so on.","['Absorption', 'Metamaterials', 'Vanadium', 'Periodic structures', 'Dielectrics', 'Electromagnetic scattering', 'Metals']","['Broadband', 'multiband', 'active tuned', 'vanadium dioxiderption', 'high quality factor']"
"As the world moves towards being increasingly dependent on computers and automation, building secure applications, systems and networks are some of the main challenges faced in the current decade. The number of threats that individuals and businesses face is rising exponentially due to the increasing complexity of networks and services of modern networks. To alleviate the impact of these threats, researchers have proposed numerous solutions for anomaly detection; however, current tools often fail to adapt to ever-changing architectures, associated threats and zero-day attacks. This manuscript aims to pinpoint research gaps and shortcomings of current datasets, their impact on building Network Intrusion Detection Systems (NIDS) and the growing number of sophisticated threats. To this end, this manuscript provides researchers with two key pieces of information; a survey of prominent datasets, analyzing their use and impact on the development of the past decade's Intrusion Detection Systems (IDS) and a taxonomy of network threats and associated tools to carry out these attacks. The manuscript highlights that current IDS research covers only 33.3% of our threat taxonomy. Current datasets demonstrate a clear lack of real-network threats, attack representation and include a large number of deprecated threats, which together limit the detection accuracy of current machine learning IDS approaches. The unique combination of the taxonomy and the analysis of the datasets provided in this manuscript aims to improve the creation of datasets and the collection of real-world data. As a result, this will improve the efficiency of the next generation IDS and reflect network threats more accurately within new datasets.","['Taxonomy', 'Intrusion detection', 'Mathematical model', 'Measurement', 'Tools', 'Feature extraction', 'Machine learning algorithms']","['Anomaly detection', 'datasets', 'intrusion detection systems', 'network attacks', 'network security', 'security threats', 'survey', 'taxonomy']"
"In healthcare management, a large volume of multi-structured patient data is generated from the clinical reports, doctor's notes, and wearable body sensors. The analysis of healthcare parameters and the prediction of the subsequent future health conditions are still in the informative stage. A cloud-enabled big data analytic platform is the best way to analyze the structured and unstructured data generated from healthcare management systems. In this paper, a probabilistic data collection mechanism is designed and the correlation analysis of those collected data is performed. Finally, a stochastic prediction model is designed to foresee the future health condition of the most correlated patients based on their current health status. Performance evaluation of the proposed protocols is realized through extensive simulations in the cloud environment, which gives about 98% accuracy of prediction, and maintains 90% of CPU and bandwidth utilization to reduce the analysis time.","['Hospitals', 'Data models', 'Big data', 'Diseases', 'Medica services', 'Cloud computing', 'Predictive models']","['Big data', 'cloud', 'healthcare', 'prediction']"
"Detecting and classifying the modulation scheme of the intercepted noisy low probability of intercept (LPI) radar signals in real time is a necessary survival technique required in the electronic warfare systems. Therefore, LPI radar waveform recognition technique (LWRT) has gained an increasing attention recently. In this paper, we propose a convolutional neural network (CNN)-based LWRT, where the input and hyperparameters of the CNN, such as the input size, number of filters, filter size, and number of neurons are designed based on various signal conditions to guarantee the maximum classification performance. In addition, we propose a sample averaging technique to efficiently reduce the large computational cost required when the intercept receiver needs to process a large amount of signal samples to improve the detection sensitivity. We demonstrate the performance of the proposed LWRT with numerous Monte Carlo simulations based on the simulation conditions used in the recent LWRTs introduced in the literature. It is testified that the proposed LWRT offers significant improvement, such as robustness to noise and recognition accuracy, over the recent LWRTs.","['Feature extraction', 'Binary phase shift keying', 'Signal to noise ratio', 'Receivers', 'Radar detection']","['Convolutional neural network', 'low probability of intercept', 'radar waveform recognition']"
"A novel ultra-wideband (UWB) multiple-input multiple-output (MIMO) Vivaldi antenna with dual band-notched characteristics is presented and fabricated. The antenna is comprised of an improved ground plane and two microstrip feeding lines with a compact size of 26\times 26 mm 2 . The evolutionary process of the antenna is given. By etching the T-shaped slot on the ground plane, the port isolation between individual antenna elements can be greatly increased. Meanwhile, by adding two split ring resonator (SRR) of different sizes next to the microstrip feed lines, dual notches can be achieved to filter the interfere of WLAN and X-band communication satellites. The notched mechanism is analyzed from the surface current distributions. The experimental results show that the impedance bandwidth of the designed MIMO antenna is from 2.9 to 11.6 GHz, along with two notched bands covering 5.3-5.8 GHz and 7.85-8.55 GHz, and the mutual coupling is less than -16 dB in the whole working bandwidth. The MIMO antenna has good radiation characteristics, stable gain, and very low envelop correlation coefficient (ECC <;0.02), which is suitable for UWB MIMO system applications. The idea in this paper also has a certain guiding significance for the study of band-notched MIMO Vivaldi antenna.","['MIMO communication', 'Ultra wideband antennas', 'Vivaldi antennas', 'Antenna measurements', 'Antenna radiation patterns', 'Microstrip']","['Band-notched', 'MIMO antenna', 'SRR', 'UWB', 'vivaldi antenna']"
"Sign language recognition aims to recognize meaningful movements of hand gestures and is a significant solution in intelligent communication between the deaf community and hearing societies. However, until now, the current dynamic sign language recognition methods still have some drawbacks with difficulties of recognizing complex hand gestures, low recognition accuracy for most dynamic sign language recognition, and potential problems in larger video sequence data training. In order to solve these issues, this paper presents a multimodal dynamic sign language recognition method based on a deep 3-dimensional residual ConvNet and bi-directional LSTM networks, which is named as BLSTM-3D residual network (B3D ResNet). This method consists of three main parts. First, the hand object is localized in the video frames in order to reduce the time and space complexity of network calculation. Then, the B3D ResNet automatically extracts the spatiotemporal features from the video sequences and establishes an intermediate score corresponding to each action in the video sequence after feature analysis. Finally, by classifying the video sequences, the dynamic sign language is accurately identified. The experiment is conducted on test datasets, including DEVISIGN_D dataset and SLR_Dataset. The results show that the proposed method can obtain state-of-the-art recognition accuracy (89.8% on the DEVISIGN_D dataset and 86.9% on SLR_Dataset). In addition, the B3D ResNet can effectively recognize complex hand gestures through larger video sequence data, and obtain high recognition accuracy for 500 vocabularies from Chinese hand sign language.","['Assistive technology', 'Gesture recognition', 'Video sequences', 'Dynamics', 'Shape', 'Trajectory', 'Feature extraction']","['Dynamic sign language recognition', 'bi-directional LSTM', 'residual ConvNet', 'video sequence']"
"Our research work describes a team of human Digital Twins (DTs), each tracking fitness-related measurements describing an athlete's behavior in consecutive days (e.g. food income, activity, sleep). After collecting enough measurements, the DT firstly predicts the physical twin performance during training and, in case of non-optimal result, it suggests modifications in the athlete's behavior. The athlete's team is integrated into SmartFit, a software framework for supporting trainers and coaches in monitoring and manage athletes' fitness activity and results. Through IoT sensors embedded in wearable devices and applications for manual logging (e.g. mood, food income), SmartFit continuously captures measurements, initially treated as the dynamic data describing the current physical twins' status. Dynamic data allows adapting each DT's status and triggering the DT's predictions and suggestions. The analyzed measurements are stored as the historical data, further processed by the DT to update (increase) its knowledge and ability to provide reliable predictions. Results show that, thanks to the team of DTs, SmartFit computes trustable predictions of the physical twins' conditions and produces understandable suggestions which can be used by trainers to trigger optimization actions in the athletes' behavior. Though applied in the sport context, SmartFit can be easily adapted to other monitoring tasks.","['Monitoring', 'Biomedical monitoring', 'Training', 'Manufacturing', 'Computational modeling', 'Medical services', 'Digital twin']","['Counterfactual explanations', 'digital twins', 'Internet of Things', 'machine learning', 'smart health', 'sociotechnical design', 'wearables']"
"This study presents a novel method to apply the RGB-D (Red Green Blue-Depth) sensors and fuse aligned RGB and NIR images with deep convolutional neural networks (CNN) for fruit detection. It aims to build a more accurate, faster, and more reliable fruit detection system, which is a vital element for fruit yield estimation and automated harvesting. Recent work in deep neural networks has led to the development of a state-of-the-art object detector termed Faster Region-based CNN (Faster R-CNN). A common Faster R-CNN network VGG16 was adopted through transfer learning, for the task of kiwifruit detection using imagery obtained from two modalities: RGB (red, green, blue) and Near-Infrared (NIR) images. Kinect v2 was used to take a bottom view of the kiwifruit canopy's NIR and RGB images. The NIR (1 channel) and RGB images (3 channels) were aligned and arranged side by side into a 6-channel image. The input layer of the VGG16 was modified to receive the 6-channel image. Two different fusion methods were used to extract features: Image-Fusion (fusion of the RGB and NIR images on input layer) and Feature-Fusion (fusion of feature maps of two VGG16 networks where the RGB and NIR images were input respectively). The improved networks were trained end-to-end using back-propagation and stochastic gradient descent techniques and compared to original VGG16 networks with RGB and NIR image input only. Results showed that the average precision (APs) of the original VGG16 with RGB and NIR image input only were 88.4% and 89.2% respectively, the 6-channel VGG16 using the Feature-Fusion method reached 90.5%, while that using the Image-Fusion method reached the highest AP of 90.7% and the fastest detection speed of 0.134 s/image. The results indicated that the proposed kiwifruit detection approach shows a potential for better fruit detection.","['Three-dimensional displays', 'Sensors', 'Feature extraction', 'Image sensors', 'Cameras', 'Neural networks', 'Image color analysis']","['Fruit detection', 'image alignment', 'information fusion', 'multi-modality faster R-CNN', 'RGB-D sensor']"
"Under the background of cyber-physical systems and Industry 4.0, intelligent manufacturing has become an orientation and produced a revolutionary change. Compared with the traditional manufacturing environments, the intelligent manufacturing has the characteristics as highly correlated, deep integration, dynamic integration, and huge volume of data. Accordingly, it still faces various challenges. In this paper, we summarize and analyze the current research status in both domestic and aboard, including industrial big data collection, modeling of the intelligent product lines based on ontology, the predictive diagnosis based on industrial big data, group learning of product line equipment and the product line reconfiguration of intelligent manufacturing. Based on the research status and the problems, we propose the research strategies, including acquisition schemes of industrial big data under the environment of intelligent, ontology modeling and deduction method based intelligent product lines, predictive diagnostic methods on production lines based on deep neural network, deep learning among devices based on cloud supplements and 3-D selforganized reconfiguration mechanism based on the supplements of cloud. In our view, this paper will accelerate the implementation of smart factory.","['Manufacturing', 'Big Data', 'Ontologies', 'Production facilities', 'Cloud computing', 'Data models', 'Machine learning']","['Industrial big data', 'smart factory', 'data analysis', 'cyber-physical systems']"
"The Fourth Industrial Revolution (Industry 4.0) is reshaping the construction industry and bringing it into an intelligent construction era. Emerging technologies, such as the Building Information Modelling, Internet of Things, big data, cloud computing, and artificial intelligence, have penetrated into all stages of the building life cycle and play a significant role. However, the major issue of intelligent construction is integrating multiple technologies to create more potential opportunities rather than their fragmented application. Considering the various special characteristics of the construction industry and the high heterogeneity of these technologies, their integration in the construction industry is challenging and requires in-depth investigations. This paper summarizes the Industry 4.0-related technologies involved in the construction industry based on an analysis of the characteristics of the industry. Further, this study presents a framework of a cyber-physical system to integrate these technologies and improve the overall capabilities of construction organization and management. A case study of the Xiong'an citizen service center is introduced to verify the technological feasibility and preliminary implementation effect of the proposed framework. As forward-looking research, the significance of this paper may also to inspire more efforts in this field.","['Construction industry', 'Buildings', 'Cyber-physical systems', 'Internet of Things', 'Monitoring', 'Solid modeling']","['Construction industry', 'industry 40', 'cyber-physical system']"
"The intrusion detection systems (IDSs) are essential elements when it comes to the protection of an ICT infrastructure. A misuse IDS is a stable method that can achieve high attack detection rates (ADR) while keeping false alarm rates under acceptable levels. However, the misuse IDSs suffer from the lack of agility, as they are unqualified to adapt to new and “unknown” environments. That is, such an IDS puts the security administrator into an intensive engineering task for keeping the IDS up-to-date every time it faces efficiency drops. Considering the extended size of modern networks and the complexity of big network traffic data, the problem exceeds the substantial limits of human managing capabilities. In this regard, we propose a novel methodology which combines the benefits of self-taught learning and MAPE-K frameworks to deliver a scalable, self-adaptive, and autonomous misuse IDS. Our methodology enables the misuse IDS to sustain high ADR, even if it is imposed on consecutive and drastic environmental changes. Through the utilization of deep-learning based methods, the IDS is able to grasp an attack's nature based on the generalized feature reconstructions stemming directly from the unknown environment and its unlabeled data. The experimental results reveal that our methodology can breathe new life into the IDS without the constant need for manually refreshing its training set. We evaluate our proposal under several classification metrics and demonstrate that the ADR of the IDS increases up to 73.37% in critical situations where a statically trained IDS is rendered totally ineffective.","['Intrusion detection', 'Task analysis', 'Deep learning', 'Training', 'Engines', 'Adaptive systems']","['Adaptive intrusion detection systems', 'artificial neural networks', 'deep learning', 'information systems security', 'MAPE-K', 'sparse auto encoders']"
"Millions of sensors are deployed to monitor the smart grid. They consume huge amounts of energy in the communication infrastructure. Therefore, the establishment of an energy-efficient medium access control (MAC) protocol for sensor nodes is challenging and urgently needed. The Quorum-based MAC protocol independently and adaptively schedules nodes' wake-up times and decreases idle listening and collisions, thereby increasing the network throughput and extending the network lifetime. A novel Quorum time slot adaptive condensing (QTSAC)-based MAC protocol is proposed for achieving delay minimization and energy efficiency for the wireless sensor networks (WSNs). Compared to previous protocols, the QTSAC-based MAC protocol has two main novelties: 1) It selects more Quorum time slots (QTSs) than previous protocols in the area that is far from the sink according to the energy consumption in WSNs to decrease the network latency and 2) It allocates QTSs only when data are transmitted to further decrease the network latency. Theoretical analyses and experimental results indicate that the QTSAS protocol can greatly improve network performance compared with existing Quorum-based MAC protocols. For intermediate-scale wireless sensor networks, the method that is proposed in this paper can enhance the energy efficiency by 24.64%-82.75%, prolong the network lifetime by 58%-27.31%, and lower the network latency by 3.59%-29.23%.","['Media Access Protocol', 'Wireless sensor networks', 'Energy efficiency', 'Intelligent sensors', 'Delays']","['Wireless sensor networks', 'quorum time slot condensing', 'network latency', 'energy efficiency', 'lifetime']"
"A design of an ultra-wideband eight-port multiple-input multiple-output (MIMO) antenna array in a smartphone with an open-slot metal frame for fifth-generation (5G) communications is presented. Each element is fed by a microstrip line with a tuning stub, consisting of a U-slot on the ground plane and an open slot on the metal frame. Each slot element on the ground only occupies an area of 15 x3 mm. The antenna array can operate in 3.3-6 GHz (S 11 <; -6 dB) that is ultra-wide bandwidth for the future 5G communications. The antenna array is manufactured and measured. Measured antenna isolation is higher than 11 dB without any decoupling structures applied. Moreover, measured radiation patterns, antenna efficiencies, and envelop correlation coefficients are also given in this paper. High agreement between the measured and simulated results is obtained, which means that the proposed antenna is promising in engineering application.","['Antenna arrays', 'MIMO communication', '5G mobile communication', 'Metals', 'Smart phones', 'Antenna measurements']","['5G communication', 'metal frame', 'MIMO antenna', 'smartphone', 'ultra-wideband']"
"An admissions system based on valid and reliable admissions criteria is very important to select candidates likely to perform well academically at institutions of higher education. This study focuses on ways to support universities in admissions decision making using data mining techniques to predict applicants' academic performance at university. A data set of 2,039 students enrolled in a Computer Science and Information College of a Saudi public university from 2016 to 2019 was used to validate the proposed methodology. The results demonstrate that applicants' early university performance can be predicted before admission based on certain pre-admission criteria (high school grade average, Scholastic Achievement Admission Test score, and General Aptitude Test score). The results also show that Scholastic Achievement Admission Test score is the pre-admission criterion that most accurately predicts future student performance. Therefore, this score should be assigned more weight in admissions systems. We also found that the Artificial Neural Network technique has an accuracy rate above 79%, making it superior to other classification techniques considered (Decision Trees, Support Vector Machines, and Naïve Bayes).","['Data mining', 'Decision making', 'Computer science', 'Education', 'Decision trees', 'Predictive models', 'Support vector machines']","['Data mining techniques', 'educational data mining', 'performance prediction', 'pre-admission criteria', 'student performance']"
"Featuring direct communications between two user equipments (UEs) without signal relay through a base station, 3GPP sidelink transmissions have manifested their crucial roles in the Long-Term Evolution (LTE) Advanced (LTE-A) for public safety and vehicle-to-everything (V2X) services. With this successful development in LTE-A, the evolution of sidelink transmissions continues in 3GPP New Radio (NR), which renders sidelink an inevitable component as well as downlink and uplink. Targeting at offering low latency, high reliability and high throughout V2X services for advanced driving use cases, a number of new sidelink functions not provided in the LTE-A are supported in NR, including the feedback channel, grant-free access, enhanced channel sensing procedure, and new control channel design. To fully comprehend these new functions, this paper therefore provides essential knowledge of 3GPP NR sidelink transmissions, including the physical layer structure, resource allocation mechanisms, resource sensing and selection procedures, synchronization, and quality-of-service (QoS) management. Furthermore, this paper also provides performance evaluation to assess the gains brought from the new control channel design. As NR sidelink transmissions have been regarded as a foundation to provide advanced services other than V2X in future releases (e.g., advanced relay), potential enhancements are also discussed to serve the urgent demand in corresponding normative works.","['3GPP', 'OFDM', 'Relays', 'Safety', 'Synchronization', 'Base stations', 'Uplink']","['3GPP NR', 'sidelink', 'V2X', 'fifth generation (5G) networks', 'device-to-device (D2D)']"
"Stress is an escalated psycho-physiological state of the human body emerging in response to a challenging event or a demanding condition. Environmental factors that trigger stress are called stressors. In case of prolonged exposure to multiple stressors impacting simultaneously, a person's mental and physical health can be adversely affected which can further lead to chronic health issues. To prevent stress-related issues, it is necessary to detect them in the nascent stages which are possible only by continuous monitoring of stress. Wearable devices promise real-time and continuous data collection, which helps in personal stress monitoring. In this paper, a comprehensive review has been presented, which focuses on stress detection using wearable sensors and applied machine learning techniques. This paper investigates the stress detection approaches adopted in accordance with the sensory devices such as wearable sensors, Electrocardiogram (ECG), Electroencephalography (EEG), and Photoplethysmography (PPG), and also depending on various environments like during driving, studying, and working. The stressors, techniques, results, advantages, limitations, and issues for each study are highlighted and expected to provide a path for future research studies. Also, a multimodal stress detection system using a wearable sensor-based deep learning technique has been proposed at the end.","['Stress', 'Heart rate variability', 'Resonant frequency', 'Wearable sensors', 'Heart rate', 'Skin', 'Frequency estimation']","['Mental stress detection', 'machine learning', 'physiological signals', 'wearable sensor', 'feature extraction']"
"In the past decade, sparse and low-rank recovery has drawn much attention in many areas such as signal/image processing, statistics, bioinformatics, and machine learning. To achieve sparsity and/or low-rankness inducing, the ℓ 1 norm and nuclear norm are of the most popular regularization penalties due to their convexity. While the ℓ 1 and nuclear norm are convenient as the related convex optimization problems are usually tractable, it has been shown in many applications that a nonconvex penalty can yield significantly better performance. In recent, nonconvex regularization-based sparse and low-rank recovery is of considerable interest and it in fact is a main driver of the recent progress in nonconvex and nonsmooth optimization. This paper gives an overview of this topic in various fields in signal processing, statistics, and machine learning, including compressive sensing, sparse regression and variable selection, sparse signals separation, sparse principal component analysis (PCA), large covariance and inverse covariance matrices estimation, matrix completion, and robust PCA. We present recent developments of nonconvex regularization based sparse and low-rank recovery in these fields, addressing the issues of penalty selection, applications and the convergence of nonconvex algorithms. Code is available at https://github.com/FWen/ncreg.git.","['Principal component analysis', 'Covariance matrices', 'Sparse matrices', 'Estimation', 'Optimization', 'Convergence', 'Machine learning']","['Sparse', 'low-rank', 'nonconvex', 'compressive sensing', 'regression', 'covariance matrix estimation', 'matrix completion', 'principal component analysis']"
"Cyber-security is the practice of protecting computing systems and networks from digital attacks, which are a rising concern in the Information Age. With the growing pace at which new attacks are developed, conventional signature based attack detection methods are often not enough, and machine learning poses as a potential solution. Adversarial machine learning is a research area that examines both the generation and detection of adversarial examples, which are inputs specially crafted to deceive classifiers, and has been extensively studied specifically in the area of image recognition, where minor modifications are performed on images that cause a classifier to produce incorrect predictions. However, in other fields, such as intrusion and malware detection, the exploration of such methods is still growing. The aim of this survey is to explore works that apply adversarial machine learning concepts to intrusion and malware detection scenarios. We concluded that a wide variety of attacks were tested and proven effective in malware and intrusion detection, although their practicality was not tested in intrusion scenarios. Adversarial defenses were substantially less explored, although their effectiveness was also proven at resisting adversarial attacks. We also concluded that, contrarily to malware scenarios, the variety of datasets in intrusion scenarios is still very small, with the most used dataset being greatly outdated.","['Machine learning', 'Malware', 'Perturbation methods', 'Intrusion detection', 'Computer security', 'Computational modeling', 'Machine learning algorithms']","['Cybersecurity', 'adversarial machine learning', 'intrusion detection', 'malware detection']"
"Crash injury severity prediction is a promising research target in traffic safety. Traditionally, various statistical methods were used for modeling crash injury severities. In recent years, machine learningbased methods are becoming popular due to their good predictive performance. However, the machine learning-based models are usually criticized as they perform like a black-box. In this paper, we aim at comparing the predictive performance, including prediction accuracy and estimation of variable importance, among various machine learning and statistical methods with distinct modeling logic for crash severity analysis. The crash severity, road geometry, and traffic flow data were collected at freeway diverge areas in Florida. We estimated two most commonly used statistical methods which were ordered probit (OP) model and multinomial logit model, and four popular machine learning methods, including K-Nearest Neighbor, Decision Tree, Random Forest (RF), and Support Vector Machine. The correct prediction rate for each crash severity level and the overall correct prediction rate were calculated. The results showed that the machine learning methods had higher predicting accuracy than the statistical methods, though they suffered from overfitting issue. The RF method had the best prediction in overall and severe crashes while OP was the weakest one. We compared variable importance on crash severity via perturbation-based sensitivity analyses. The results showed that the inferences of variable importance from different methods were not always consistent and should be paid careful attention.","['Computer crashes', 'Injuries', 'Machine learning', 'Analytical models', 'Predictive models', 'Support vector machines', 'Statistical analysis']","['Crash severity', 'statistical model', 'machine learning', 'accuracy', 'variable importance']"
"Continuous electrowetting (CEW) is demonstrated to be an effective actuation mechanism for reconfigurable radio frequency (RF) devices that use non-toxic liquid-metal tuning elements. Previous research has shown CEW is an efficient means of electrically inducing motion in a liquid-metal slug, but precise control of the slug's position within fluidic channels has not been demonstrated. Here, the precise positioning of liquid-metal slugs is achieved using CEW actuation in conjunction with channels designed to minimize the liquid-metal surface energy at discrete locations. This approach leverages the high surface tension of liquid metal to control its resting position with submillimeter accuracy. The CEW actuation and fluidic channel design were optimized to create reconfigurable RF devices. In addition, solutions for the reliable actuation of a gallium-based, non-toxic liquid-metal alloy (Galinstan) are presented that mitigate the tendency of the alloy to form a surface oxide layer capable of wetting to the channel walls, inhibiting motion. A reconfigurable slot antenna utilizing these techniques to achieve a 15.2% tunable frequency bandwidth is demonstrated.","['Actuators', 'Electrowetting', 'Radio frequency', 'Surface tension', 'Liquid metal', 'Fluids']","['Aperture antenna', 'electrowetting', 'frequency-reconfigurable', 'liquid metal', 'reconfigurable antenna', 'slot antenna']"
"Increasing attention has been paid to air quality monitoring with a rapid development in industry and transportation applications in the modern society. However, the existing air quality monitoring systems cannot provide satisfactory spatial and temporal resolutions of the air quality information with low costs in real time. In this paper, we propose a new method to implement the air quality monitoring system based on state-of-the-art Internet-of-Things (IoT) techniques. In this system, portable sensors collect the air quality information timely, which is transmitted through a low power wide area network. All air quality data are processed and analyzed in the IoT cloud. The completed air quality monitoring system, including both hardware and software, is developed and deployed successfully in urban environments. Experimental results show that the proposed system is reliable in sensing the air quality, which helps reveal the change patterns of air quality to some extent.","['Internet of things', 'Air quality', 'Atmospheric measurements', 'IEEE 802.15 Standard', 'Monitoring', 'Mobile sensors', 'Spatial resolution']","['Internet-of-Things (IoT)', 'air quality monitoring', 'PM2.5', 'LPWA', 'IEEE 802.15.4k']"
"Low-cost drones represent an emerging technology that opens the horizon for new smart Internet-of-Things (IoT) applications. Recent research efforts in cloud robotics are pushing for the integration of low-cost robots and drones with the cloud and the IoT. However, the performance of real-time cloud robotics systems remains a fundamental challenge that demands further investigation. In this paper, we present DroneTrack, a real-time object tracking system using a drone that follows a moving object over the Internet. The DroneTrack leverages the use of Dronemap planner (DP), a cloud-based system, for the control, communication, and management of drones over the Internet. The main contributions of this paper consist in: (1) the development and deployment of the DroneTrack, a real-time object tracking application through the DP cloud platform and (2) a comprehensive experimental study of the real-time performance of the tracking application. We note that the tracking does not imply computer vision techniques but it is rather based on the exchange of GPS locations through the cloud. Three scenarios are used for conducting various experiments with real and simulated drones. The experimental study demonstrates the effectiveness of the DroneTrack system, and a tracking accuracy of 3.5 meters in average is achieved with slow-speed moving targets.","['Cloud computing', 'Drones', 'Computer architecture', 'Real-time systems', 'Robot kinematics']","['Unmanned aerial vehicles', 'object tracking', 'cloud computing', 'Internet of Drones']"
"Process evaluation is widely accepted as an effective strategy to improve product quality and shorten its development cycle. However, there has been very little research on how to evaluate the process plan with the dynamic change of the machining condition and uncertain available manufacturing resources. This paper proposes a novel process evaluation method based on digital twin technology. Three core technologies embodied in the proposed method are illustrated in details: 1) real-time mapping mechanism between the collected data in machining and the process design information; 2) construction of the digital twin-based machining process evaluation (DT-MPPE) framework; and 3) process evaluation driven by digital twin data. To elaborate on how to apply the proposed method to the reality, we present a detailed implementation process of the proposed DT-MPPE method for the key parts of the marine diesel engine. Meanwhile, the future work to completely fulfill digital twin-based smart process planning for complex products is discussed.","['Machining', 'Manufacturing', 'Process planning', 'Real-time systems', 'Radiofrequency identification', 'Monitoring', 'Data models']","['Digital twin', 'process planning', 'process evaluation', 'mapping mechanism', 'digital twin data']"
"Transportation and locomotion mode recognition from multimodal smartphone sensors is useful for providing just-in-time context-aware assistance. However, the field is currently held back by the lack of standardized datasets, recognition tasks, and evaluation criteria. Currently, the recognition methods are often tested on the ad hoc datasets acquired for one-off recognition problems and with different choices of sensors. This prevents a systematic comparative evaluation of methods within and across research groups. Our goal is to address these issues by: 1) introducing a publicly available, large-scale dataset for transportation and locomotion mode recognition from multimodal smartphone sensors; 2) suggesting 12 reference recognition scenarios, which are a superset of the tasks we identified in the related work; 3) suggesting relevant combinations of sensors to use based on energy considerations among accelerometer, gyroscope, magnetometer, and global positioning system sensors; and 4) defining precise evaluation criteria, including training and testing sets, evaluation measures, and user-independent and sensor-placement independent evaluations. Based on this, we report a systematic study of the relevance of statistical and frequency features based on the information theoretical criteria to inform recognition systems. We then systematically report the reference performance obtained on all the identified recognition scenarios using a machine-learning recognition pipeline. The extent of this analysis and the clear definition of the recognition tasks enable future researchers to evaluate their own methods in a comparable manner, thus contributing to further advances in the field. The dataset and the code are available online. http://www.shl-dataset.org/.","['Transportation', 'Task analysis', 'Global Positioning System', 'Accelerometers', 'Mobile handsets', 'Magnetometers', 'Feature extraction']","['Activity recognition', 'feature selection', 'mobile sensing', 'multimodal sensor fusion', 'reference dataset', 'transportation mode recognition']"
"For a seamless deployment of the Internet of Things (IoT), there is a need for self-organizing solutions to overcome key IoT challenges that include data processing, resource management, coexistence with existing wireless networks, and improved IoT-wide event detection. One of the most promising solutions to address these challenges is via the use of innovative learning frameworks that will enable the IoT devices to operate autonomously in a dynamic environment. However, developing learning mechanisms for the IoT requires coping with unique IoT properties in terms of resource constraints, heterogeneity, and strict quality-of-service requirements. In this paper, a number of emerging learning frameworks suitable for IoT applications are presented. In particular, the advantages, limitations, IoT applications, and key results pertaining to machine learning, sequential learning, and reinforcement learning are studied. For each type of learning, the computational complexity, required information, and learning performance are discussed. Then, to handle the heterogeneity of the IoT, a new framework based on the powerful tools of cognitive hierarchy theory is introduced. This framework is shown to efficiently capture the different IoT device types and varying levels of available resources among the IoT devices. In particular, the different resource capabilities of IoT devices are mapped to different levels of rationality in cognitive hierarchy theory, thus enabling the IoT devices to use different learning frameworks depending on their available resources. Finally, key results on the use of cognitive hierarchy theory in the IoT are presented.","['Internet of things', 'Machine learning', 'Learning systems', 'Self-organizing networks', 'Wireless networks', 'Event detection', 'Resource management']","['Internet of things', 'machine learning', 'learning']"
"The use of new technologies to empower the social co-governance of food safety is a consensus in the theoretical and practical fields of food safety governance modernization. Based on the innovative features of the block chain such as non-tampering, consensus mechanism, and a smart contract, this paper proposes a new method to facilitate the achievement of the effect of social co-governance of food safety. Firstly, it provides a profound analysis of the causes of food safety problems and the drawbacks of traditional centralized supervision, and proposes a solution with decentralized features and the design process of smart contracts to realize the chaining and integration of finite credible data in the process of food circulation; secondly, it constructs a mathematical model through finite credible data on the chain and obtains the probabilistic consensus results of food safety through rigorous derivation; Finally, the scheme, model and algorithm are effectively practiced through the experimental environment of mature block chain platform and provincial food supervision platform. The example shows that the market failure problem in food safety can be greatly alleviated by the non-tampering feature of block chain; the consensus results formed by the credible data uploading, model construction and data derivation through smart contracts can greatly alleviate the problem of involution of government administrative supervision; and the social co-governance capacity of food safety can be improved through information sharing with the active synergy of multiple subjects of co-governance.","['Safety', 'Blockchains', 'Government', 'Smart contracts', 'Regulation', 'Distributed ledger', 'Bitcoin']","['Block chain', 'food safety', 'finite credible data', 'probability consensus', 'social co-governance']"
"Peak-load management is an important process that allows energy providers to reshape load profiles, increase energy efficiency, and reduce overall operational costs and carbon emissions. This paper presents an improved decision-tree-based algorithm to reduce the peak load in residential distribution networks by coordinated control of electric vehicles (EVs), photovoltaic (PV) units, and battery energy-storage systems (BESSs). The peak-load reduction is achieved by reading the domestic load in real time through a smart meter and taking appropriate coordinated action by a controller using the proposed algorithm. The proposed control algorithm was tested on a real distribution network using real load patterns and load dynamics, and validated in a laboratory experiment. Two types of EVs with fast and flexible charging capability, a PV unit, and BESSs were used to test the performance of the proposed control algorithm, which is compared with that of an artificial-neural-network technique. The results show that using the proposed method, the peak demand on the distribution grid can be reduced significantly, thereby greatly improving the load factor.","['Batteries', 'State of charge', 'Heuristic algorithms', 'Vehicle-to-grid', 'Real-time systems', 'Uncertainty']","['Electric vehicle', 'energy management', 'EV management', 'peak load management', 'peak shaving']"
"Melanoma is considered the most serious type of skin cancer. All over the world, the mortality rate is much high for melanoma in contrast with other cancer. There are various computer-aided solutions proposed to correctly identify melanoma cancer. However, the difficult visual appearance of the nevus makes it very difficult to design a reliable Computer-Aided Diagnosis (CAD) system for accurate melanoma detection. Existing systems either uses traditional machine learning models and focus on handpicked suitable features or uses deep learning-based methods that use complete images for feature learning. The automatic and most discriminative feature extraction for skin cancer remains an important research problem that can further be used to better deep learning training. Furthermore, the availability of the limited available images also creates a problem for deep learning models. From this line of research, we propose an intelligent Region of Interest (ROI) based system to identify and discriminate melanoma with nevus cancer by using the transfer learning approach. An improved k-mean algorithm is used to extract ROIs from the images. These ROI based approach helps to identify discriminative features as the images containing only melanoma cells are used to train system. We further use a Convolutional Neural Network (CNN) based transfer learning model with data augmentation for ROI images of DermIS and DermQuest datasets. The proposed system gives 97.9% and 97.4% accuracy for DermIS and DermQuest respectively. The proposed ROI based transfer learning approach outperforms existing methods that use complete images for classification.","['Feature extraction', 'Melanoma', 'Image color analysis', 'Shape', 'Skin']","['Melanoma detection', 'skin cancer detection', 'ROI', 'CNN', 'transfer learning']"
"Recent advances in the cyber-physical smart grid (CPSG) have enabled a broad range of new devices based on the information and communication technology (ICT). However, these ICT-enabled devices are susceptible to a growing threat of cyber-physical attacks. This paper performs a thorough review of the state-of-the-art cyber-physical security of the smart grid. By focusing on the physical layer of the CPSG, this paper provides an abstracted and unified state-space model, in which cyber-physical attack and defense models can be effectively generalized. The existing cyber-physical attacks are categorized in terms of their target components. We then discuss several operational and informational defense approaches that present the current state-of-the-art in the field, including moving target defense, watermarking, and data-driven approaches. Finally, we discuss challenges and future opportunities associated with the smart grid cyber-physical security.","['Security', 'Smart grids', 'Transmission line measurements', 'Servers', 'Control systems', 'Time measurement', 'Sensors']","['Cyber-physical power system', 'cyber-physical security', 'false data injection', 'dynamic watermarking', 'moving target defense']"
"This paper examines university students' intention to utilize e-learning. In this paper, we apply and use the theory of a technology acceptance model. We employ the structural equation modeling approach with a SmartPLS software to investigate students' adoption process. Findings indicate that the content of e-learning and self-efficacy has a positive impact and substantially associated with perceived usefulness and student satisfaction, which impact university students' intention to utilize e-learning. Although e-learning has gained acceptance in universities around the world, the study of the intention to use e-learning is still largely unexplored in Malaysia. The developed model is employed to explain the university student's intention to utilize e-learning. The study concludes that university students in Malaysia have positive perceptions toward e-learning and intend to practice it for educational purposes.","['Electronic learning', 'Mathematical model', 'Tools', 'Reliability', 'Training', 'Computational modeling']","['E-learning', 'technology acceptance model and higher education']"
"With the development of 5G and Internet of Vehicles technology, the possibility of remote wireless attack on an in-vehicle network has been proven by security researchers. Anomaly detection technology can effectively alleviate the security threat, as the first line of security defense. Based on this, this paper proposes a distributed anomaly detection system using hierarchical temporal memory (HTM) to enhance the security of a vehicular controller area network bus. The HTM model can predict the flow data in real time, which depends on the state of the previous learning. In addition, we improved the abnormal score mechanism to evaluate the prediction. We manually synthesized field modification and replay attack in data field. Compared with recurrent neural networks and hidden Markov model detection models, the results show that the distributed anomaly detection system based on HTM networks achieves better performance in the area under receiver operating characteristic curve score, precision, and recall.","['Anomaly detection', 'Automobiles', 'Hidden Markov models', 'Protocols', 'Data models', 'Intrusion detection']","['In-vehicle network security', 'real-time anomaly detection', 'HTM algorithm']"
"The cascaded H-bridge multilevel inverter (MLI) requires separate isolated dc sources to generate more than three voltage levels and to generate higher output voltage. This paper proposes a new MLI topology that requires only one dc source and is capable of generating seven voltage levels with triple voltage boosting gain. Three H-bridges are interconnected through two bidirectional voltage blocking switches to enable the integration of two switched-capacitors. Unlike the existing two-stage structure switched-capacitor-based MLI, the proposed MLI is a single-stage topology. It alleviates the voltage stress across switches such that low voltage stress of not more than the dc source voltage is ensured on all switches. In addition, capacitors voltage balancing is achieved automatically during operation. The operation of the proposed MLI is analyzed followed by verification through simulation and experimental test of a low power/voltage prototype.","['Topology', 'Stress', 'Inverters', 'Capacitors', 'Switches', 'Boosting', 'Prototypes']","['Multilevel inverter', 'single-stage', 'switched-capacitor', 'voltage boosting']"
"This paper presents a state-of-the-art analysis on the methods suitable for vehicle indoor localization and exploiting the RFID (Radio Frequency IDentification) technology. The survey describes three main categories of vehicle localization systems: (i) solutions exploiting only the RFID technology, (ii) sensor-fusion techniques combining data from RFID systems and proprioceptive sensors, and (iii) sensor-fusion techniques combing RFID data with those of other exteroceptive sensors in addition to the RFID system itself. For each method, implementation and methodological details are discussed, by highlighting the applied RFID technology, namely passive HF-RFID, passive UHF-RFID, or any other RFID system. Also, the employed RFID parameters, i.e., tag EPC, RSSI or backscattered phase, are discussed. The survey focuses on the achievable localization performance, also accounting for infrastructure-deployment costs together with complexity and maintenance overhead. Positioning, tracking, navigation and simultaneous localization and mapping (SLAM) issues are here considered. The analysis highlights pros and cons of each method, together with the main challenges and perspectives of RFID-based solutions for vehicle localization.","['Location awareness', 'Radiofrequency identification', 'Sensors', 'Sensor systems', 'Simultaneous localization and mapping', 'Sensor fusion', 'Trajectory']","['Autonomous vehicle', 'data fusion', 'exteroceptive sensors', 'localization', 'navigation', 'proprioceptive sensors', 'RFID', 'robot', 'tracking', 'sensor fusion', 'SLAM', 'UGV']"
"Smart city sensing calls for crowdsensing via mobile devices that are equipped with various built-in sensors. As incentivizing users to participate in distributed sensing is still an open research issue, the trustworthiness of crowdsensed data is expected to be a grand challenge if this cloud-inspired recruitment of sensing services is to be adopted. Recent research proposes reputation-based user recruitment models for crowdsensing; however, there is no standard way of identifying adversaries in smart city crowdsensing. This paper adopts previously proposed vote-based approaches, and presents a thorough performance study of vote-based trustworthiness with trusted entities that are basically a subset of the participating smartphone users. Those entities are called trustworthy anchors of the crowdsensing system. Thus, an anchor user is fully trustworthy and is fully capable of voting for the trustworthiness of other users, who participate in sensing of the same set of phenomena. Besides the anchors, the reputations of regular users are determined based on vote-based (distributed) reputation. We present a detailed performance study of the anchor-based trustworthiness assurance in smart city crowdsensing through simulations, and compare it with the purely vote-based trustworthiness approach without anchors, and a reputation-unaware crowdsensing approach, where user reputations are discarded. Through simulation findings, we aim at providing specifications regarding the impact of anchor and adversary populations on crowdsensing and user utilities under various environmental settings. We show that significant improvement can be achieved in terms of usefulness and trustworthiness of the crowdsensed data if the size of the anchor population is set properly.","['Smart cities', 'Recruitment', 'Intelligent sensors', 'Social factors', 'Statistics', 'Crowdsourcing', 'Smart phones', 'Sensors', 'Social network services']","['Crowdsensing', 'reputation', 'sensing as a service', 'smart cities', 'smart city sensing', 'smartphone sensing', 'truthfulness']"
"Ant Lion Optimizer (ALO) is a recent novel algorithm developed in the literature that simulates the foraging behavior of a Ant lions. Recently, it has been applied to a huge number of optimization problems. It has many advantages: easy, scalable, flexible, and have a great balance between exploration and exploitation. In this comprehensive study, many publications using ALO have been collected and summarized. Firstly, we introduce an introduction about ALO. Secondly, we categorized the recent versions of ALO into 3 Categories mainly Modified, Hybrid and Multi-Objective. we also introduce the applications in which ALO has been applied such as power, Machine Learning, Image processing problems, Civil Engineering, Medical, etc. The review paper is ended by giving a conclusion of the main ALO foundations and providing some suggestions & possible future directions that can be investigated.","['Optimization', 'Classification algorithms', 'Particle swarm optimization', 'Business', 'Object recognition', 'Information systems', 'Machine learning']","['Ant lion optimizer', 'antlion', 'ALO', 'swarm intelligence', 'SI', 'meta-heuristics', 'optimization', 'nature-inspired algorithms']"
"This paper surveys the literature related to the evolution of cellular communications as a key enabling technology for fundamental operations of smart grid neighborhood area networks (NANs). The latest releases of the LTE standard, representing the recent advancements in cellular technology, offer significant benefits to the modernization of the aging power distribution grid compared with other communication technologies. However, since LTE was not originally designed for smart grid applications, important challenges remain unsolved before it can efficiently support advanced NAN functionalities. This survey identifies the limitations of LTE and provides a comprehensive review of the most relevant proposed architectural and protocol enhancements for the communication infrastructure associated with smart grid NANs that can be found in the literature to date. As device-to-device (D2D) communications in LTE standards are a promising technology for reducing delay and boost reliability, this paper dwells on the potential gains that can be achieved by enabling direct communication using cellular networks, and also discusses in detail LTE-D2D applicability in representative NAN use cases in the power distribution grid. We conclude by stating open issues and providing research directions for future research in the field. This paper constitutes the first comprehensive survey of proposed LTE-enhancement and D2D solutions for smart grid NANs.","['Smart grids', 'Distributed databases', 'Cellular networks', 'Substations', 'Long Term Evolution', 'Power distribution', 'Neighborhod area networks']","['Smart Grid', 'Distribution Network', 'Cellular', 'LTE', 'Device-to-Device', 'Microgrid', 'Substation Automation']"
"In this paper, we propose a new approach to detect Deepfakes generated through the generative adversarial network (GANs) model via an algorithm called DeepVision to analyze a significant change in the pattern of blinking, which is a voluntary and spontaneous action that does not require conscious effort. Human eye blinking pattern has been known to significantly change according to the person's overall physical conditions, cognitive activities, biological factors, and information processing level. For example, an individual's gender or age, the time of day, or the person's emotional state or degree of alertness can all influence the pattern. As a result, Deepfakes can be determined through integrity verification by tracking significant changes in the eye blinking patterns in deepfakes by means of a heuristic method based on the results of medicine, biology, and brain engineering research, as well as machine learning and various algorithms based on engineering and statistical knowledge. This means we can perform integrity verification through tracking significant changes in the eye blinking pattern of a subject in a video. The proposed method called DeepVision is implemented as a measure to verify an anomaly based on the period, repeated number, and elapsed eye blink time when eye blinks were continuously repeated within a very short period of time. DeepVision accurately detected Deepfakes in seven out of eight types of videos (87.5% accuracy rate), suggesting we can overcome the limitations of integrity verification algorithms performed only on the basis of pixels.","['Gallium nitride', 'Detectors', 'Visualization', 'Target tracking', 'Machine learning', 'Generative adversarial networks', 'Biology']","['Cyber security', 'deep-fake', 'GANs', 'deep learning']"
"Underwater acoustic sensor networks (UW-ASNs) have recently been proposed for exploring the underwater resources and gathering the scientific data from the aquatic environments. UW-ASNs are faced with different challenges, such as high propagation delay, low bandwidth, and high energy consumption. However, the most notable challenge is perhaps how to efficiently forward the packets to the surface sink by considering the energy constrained sensor devices. The opportunistic routing concept may provide an effective solution for the UW-ASNs by the cooperation of the relay nodes to forward the packets to the surface sink. In this paper, the energy consumption problem is addressed and an energy-efficient cooperative opportunistic routing (EECOR) protocol is proposed to forward the packets toward the surface sink. In the EECOR protocol, a forwarding relay set is firstly determined by the source node based on the local information of the forwarder and then, a fuzzy logic-based relay selection scheme is applied to select the best relay based on considering the energy consumption ratio and the packet delivery probability of the forwarder. In the UW-ASNs, most of the energy is wasted due to the collisions amongst sensor nodes during the packet transmission. To alleviate the packet collisions problem, we have designed a holding timer for each of the forwarder to schedule the packets transmission toward the surface sink. We have performed our extensive simulations of the EECOR protocol on the Aqua-sim platform and compared with existing routing protocols in terms of average packet delivery ratio, average end-to-end delay, average energy consumption, and average network lifetime.","['Relays', 'Routing', 'Routing protocols', 'Energy consumption', 'Acoustics', 'Sea surface']","['Energy consumption ratio', 'forwarding relay set', 'fuzzy logic', 'holding timer', 'packet delivery probability', 'opportunistic routing']"
"With the advent of new technologies and the fast pace of human life, patients today require a sophisticated and advanced smart healthcare framework that is tailored to suit their individual health requirements. Along with 5G and state-of-the-art smart Internet of Things (IoT) sensors, edge computing provides intelligent, real-time healthcare solutions that satisfy energy consumption and latency criteria. Earlier surveys on smart healthcare systems were centered on cloud and fog computing architectures, security, and authentication, and the types of sensors and devices used in edge computing frameworks. They did not focus on the healthcare IoT applications deployed within edge computing architectures. The first purpose of this study is to analyze the existing and evolving edge computing architectures and techniques for smart healthcare and recognize the demands and challenges of different application scenarios. We examine edge intelligence that targets health data classification with the tracking and identification of vital signs using state-of-the-art deep learning techniques. This study also presents a comprehensive analysis of the use of cutting-edge artificial intelligence-based classification and prediction techniques employed for edge intelligence. Even with its many advantages, edge intelligence poses challenges related to computational complexity and security. To offer a higher quality of life to patients, potential research recommendations for improving edge computing services for healthcare are identified in this study. This study also offers a brief overview of the general usage of IoT solutions in edge platforms for medical treatment and healthcare.","['Medical services', 'Computer architecture', 'Intelligent sensors', 'Sensors', 'Edge computing', 'Internet of Things', 'Cloud computing']","['Internet of Things', 'smart healthcare', 'artificial intelligence', 'edge computing', 'fog computing']"
"A millimeter-wave (mm-Wave) multiple input multiple output (MIMO) antenna operating at 24 GHz (ISM band), suitable for wearable applications, is proposed in this paper. The proposed MIMO antenna consists of two elements, designed with an edge-to-edge distance of 5.14 mm, backed by a 5 × 5 cell electromagnetic bandgap (EBG) structure. The antenna is fabricated on a flexible Rogers 6002 material (ϵ r =$ 2.94, tanδ = 0.0012, thickness = 0.254 mm). The proposed antenna retains its performance when bent along the x-axis and y-axis. The performance of the antenna in term of s-parameters and radiation properties is studied in free space as well as on a human phantom. Good impedance matching of the antenna at the resonating frequency (24 GHz) is observed when it is bent and when worn on the body. The introduction of the EBG improves the gain by 1.9 dBi, reduces the backward radiation by 8 dB, reduces the power density on the back towards the body from > 200 W/m 2 to <; 10 W/m 2 , and also enhances the 10 dB bandwidth by 100 MHz. The antenna possesses a low envelope correlation coefficient (ECC) of 0.24, high diversity gain (DG) of 9.7 dB, reasonable multiplexing efficiency of -0.684 dB and a good peak gain of 6 dBi at 24 GHz. The proposed antenna is suitable for wearable applications at mm-Wave range due to its simple geometry and good performance in bending and on-body worn scenarios.","['Antennas', 'Periodic structures', 'Metamaterials', 'MIMO communication', 'Permittivity', 'Permeability', 'Gain']","['Wearable antenna', 'on-body antenna', 'mm-Wave antenna', 'MIMO s-parameters']"
"Energy consumption is one of the constraints in wireless sensor networks (WSNs). The routing protocols are the hot areas to address quality-of-service (QoS) related issues, viz., energy consumption, network lifetime, network scalability, and packet overhead. The key issue in WSN is that these networks suffer from the packet overhead, which is the root cause of more energy consumption and degrade the QoS in sensor networks. In WSN, there are several routing protocols, which are used to enhance the performance of the network. Out of those protocols, dynamic source routing (DSR) protocol is more suitable in terms of small energy density, but sometimes when the mode of a node changes from active to sleep, the efficiency decreases as the data packets need to wait at the initial point, where the packet has been sent and this increases the waiting time and end-to-end delay of the packets, which leads to increase in energy consumption. Our problem is to identify the dead nodes and to choose another suitable path so that the data transmission becomes smoother and less energy gets conserved. In order to resolve these issues, we propose directional transmission-based energy aware routing protocol named PDORP. The proposed protocol PDORP has the characteristics of both power efficient gathering sensor information system and DSR routing protocols. In addition, hybridization of genetic algorithm and bacterial foraging optimization is applied to proposed routing protocol to identify energy efficient optimal paths. The performance analysis, comparison through a hybridization approach of the proposed routing protocol, gives better result comprising less bit error rate, less delay, less energy consumption, and better throughput, which leads to better QoS and prolong the lifetime of the network. Moreover, the computation model is adopted to evaluate and compare the performance of the both routing protocols using soft computing techniques.","['Routing protocols', 'Wireless sensor networks', 'Routing', 'Optimization', 'Energy consumption', 'Energy efficiency']","['Wireless sensor networks', 'DSR', 'PEGASIS', 'PDORP', 'OD-PRRP', 'LEACH', 'optimization', 'hybridization', 'computation model']"
"Energy Internet, as a major trend in power system, can provide an open framework for integrating equipment of energy generation, transmission, storage, consumption, and so on, so that global energy can be managed and controlled efficiently by information and communication technologies. In this paper, we focus on the coordinated management of renewable and traditional energy, which is a typical issue on energy connections. We consider a conventional power system consisting of the utility company, the energy storage company, the microgrid, and electricity users. First, we formulate the energy management problem as a three-stage Stackelberg game, and every player in the electricity market aims to maximize its individual payoff while guaranteeing the system reliability and satisfying users' electricity demands. We employ the backward induction method to solve the three-stage non-cooperative game problem, and give the closed-form expressions of the optimal strategies for each stage. Next, we study the big data-based power generation forecasting techniques, and introduce a scheme of the wind power forecasting, which can assist the microgrid to make strategies. Furthermore, we prove the properties of the proposed energy management algorithm including the existence and uniqueness of Nash equilibrium and Stackelberg equilibrium. Simulation results show that accurate prediction results of wind power is conducive to better energy management.","['Energy management', 'Microgrids', 'Uncertainty', 'Optimization', 'Internet', 'Companies', 'Forecasting']","['Energy internet', 'Stackelberg game', 'microgrid energy management', 'wind power forecasting']"
"The CRISPR/Cas9 system is a creative and innovative gene editing biotechnology tool in genetic engineering. Although several achievements have been attained using the CRISPR/Cas9 system, it is still a challenge to avoid off-target effects and improve the editing efficacy. Previous efforts on evaluating the efficacy and designing the guide RNA mainly focused on DNA properties. However, some DNA features have not been characterized but can be reflected by protein properties, such as the disorder features and the sequence conservation. In this paper, we provided a computational framework to identify important features related to the efficacy of CRISPR/Cas9 focusing on the properties of the proteins encoded by the target DNA fragments. The feature selection method, maximal-relevance-minimal-redundancy, was adopted to analyze these features. And incremental feature selection together with support vector machine, were employed to extract optimal features, on which an optimal classifier can be constructed. As a result, 152 important features were extracted, with which an optimal classifier based on support vector machine was built. This classifier obtained the highest MCC value of 0.355. Finally, a series of detailed biological analyses were performed on the optimal features. From the results, we found that some key factors may differentially affect the binding activity of sgRNAs to their targets. Among them, the disorder status of the target protein sequences was found to be a major factor that is related to the efficacy of sgRNAs, suggesting the DNA features associated with the protein disorder status could also affect the CRISPR/Cas9 efficacy.","['Proteins', 'DNA', 'Feature extraction', 'Genomics', 'Bioinformatics', 'Biotechnology', 'Support vector machines']","['CRISPR/Cas9 system', 'sgRNAs', 'maximal-relevance-minimal-redundancy', 'incremental feature selection', 'protein disorder']"
"Underwater localization is used as a key element in most applications of underwater communications. Despite the global positioning system (GPS) receivers are usually employed in terrestrial wireless sensor networks, they cannot be exploited for underwater localization. In fact, GPS signals are highly attenuated by the water, by being unusable to a depth of more than a couple of meters, and cannot propagate underwater, especially, in the case of the salt water. In place of RF signals, acoustic signals are the most common mode of communication, and the so-called underwater acoustic sensor networks attracted a significant interest due to their great impact on ocean monitoring and exploration. Hydroacoustics, as the study and application of sound in water, is the foundation of underwater localization, but the existing available methods, classified in range-based versus range-free techniques, are affected by several open problems and research challenges. Therefore, an accurate range-based algorithm for localization needs to be developed, and the demand for expeditiously employing the energy of the sensor nodes is still remaining a distinct feature for underwater wireless sensor networks. Because of these argues, an improved interpretation for underwater localization is presented, by first presenting a general localization algorithm, and afterward deploying the ordinary, beacon nodes in order to find the error and accuracy of sensor localization. After that, we present two localization algorithms named as distance-based and angle-based algorithms. We consider a realistic case, where sensor nodes are not time synchronized and the sound speed in water is unknown. The simulation results exhibit that our algorithms compensate for time synchronization, estimate the mean errors in localization and achieve good localization accuracy.","['Wireless sensor networks', 'Underwater acoustics', 'Global Positioning System', 'Direction-of-arrival estimation', 'Estimation', 'Monitoring']","['Wireless sensor networks (WSNs)', 'underwater sensor networks (USNs)', 'underwater acoustic sensor networks (UASNs)', 'underwater localization']"
"The robustness and computational load are the key challenges in motor imagery (MI) based on electroencephalography (EEG) signals to decode for the development of practical brain-computer interface (BCI) systems. In this study, we propose a robust and simple automated multivariate empirical wavelet transform (MEWT) algorithm for the decoding of different MI tasks. The main contributions of this study are four-fold. First, the multiscale principal component analysis method is utilized in the preprocessing module to obtain robustness against noise. Second, a novel automated channel selection strategy is proposed and then is further verified with comprehensive comparisons among three different strategies for decoding channel combination selection. Third, a sub-band alignment method by utilizing MEWT is adopted to obtain joint instantaneous amplitude and frequency components for the first time in MI applications. Four, a robust correlation-based feature selection strategy is applied to largely reduce the system complexity and computational load. Extensive experiments for subject-specific and subject independent cases are conducted with the three-benchmark datasets from BCI competition III to evaluate the performances of the proposed method by employing typical machine-learning classifiers. For subject-specific case, experimental results show that an average sensitivity, specificity and classification accuracy of 98% was achieved by employing multilayer perceptron neural networks, logistic model tree and least-square support vector machine (LS-SVM) classifiers, respectively for three datasets, resulting in an improvement of upto 23.50% in classification accuracy as compared with other existing method. While an average sensitivity, specificity and classification accuracy of 93%, 92.1% and 91.4% was achieved for subject independent case by employing LS-SVM classifier for all datasets with an increase of up to 18.14% relative to other existing methods. Results also show that our proposed algorithm provides a classification accuracy of 100% for subjects with small training size in subject-specific case, and for subject independent case by employing a single source subject. Such satisfactory results demonstrate the great potential of the proposed MEWT algorithm for practical MI EEG signals classification.","['Electroencephalography', 'Feature extraction', 'Wavelet transforms', 'Task analysis', 'Decoding', 'Principal component analysis']","['Electroencephalography', 'multiscale principal component analysis', 'brain-computer interface', 'multivariate empirical wavelet transform']"
"With the development of social networks, a large variety of approaches have been developed to define users' personalities based on their social activities and language use habits. Particular approaches differ with regard to different machine learning algorithms, data sources, and feature sets. The goal of this paper is to investigate the predictability of the personality traits of Facebook users based on different features and measures of the Big 5 model. We examine the presence of structures of social networks and linguistic features relative to personality interactions using the my Personality project data set. We analyze and compare four machine learning models and perform the correlation between each of the feature sets and personality traits. The results for the prediction accuracy show that even if tested under the same data set, the personality prediction system built on the XGBoost classifier outperforms the average baseline for all the feature sets, with a highest prediction accuracy of 74.2%. The best prediction performance was reached for the extra version trait by using the individual social network analysis features set, which achieved a higher personality prediction accuracy of 78.6%.","['Facebook', 'Feature extraction', 'Linguistics', 'Correlation', 'Predictive models', 'Psychology']","['Big 5', 'feature analysis', 'predicting personality', 'social behavior', 'social networks']"
"Electronic health records (EHRs) contain patient diagnostic records, physician records, and records of hospital departments. For heart failure, we can obtain mass unstructured data from EHR time series. By analyzing and mining these time-based EHRs, we can identify the links between diagnostic events and ultimately predict when a patient will be diagnosed. However, it is difficult to use the existing EHR data directly, because they are sparse and non-standardized. Thus, this paper proposes an effective and robust architecture for heart failure prediction. The main contribution of this paper is to predict heart failure using a neural network (i.e., to predict the possibility of cardiac illness based on patient's electronic medical data). Specifically, we employed one-hot encoding and word vectors to model the diagnosis events and predicted heart failure events using the basic principles of a long short-term memory network model. Evaluations based on a real-world data set demonstrate the promising utility and efficacy of the proposed architecture in the prediction of the risk of heart failure.","['Heart', 'Predictive models', 'Logic gates', 'Time series analysis', 'Data models', 'Neural networks', 'Numerical models']","['Electronic health records', 'heart failure', 'risk prediction']"
"This paper presents a significant change in current electric power grid response and recovery schemes by developing a framework for proactive recovery of electric power assets with the primary objective of resiliency enhancement. Within the proposed framework, which can potentially present the next generation decision-making tool for proactive recovery, several coordinated models will be developed including: 1) the outage models to indicate the impact of hurricanes on power system components; 2) a stochastic pre-hurricane crew mobilization model for managing resources before the event; and 3) a deterministic post-hurricane recovery model for managing resources after the event. Proposed models will be extended to ensure applicability to a variety of electric power grids with different technologies and regulatory issues. The theoretical and practical implications of the developed models will push the research frontier of proactive response and recovery schemes in electric power grids, while its flexibility will support application to a variety of infrastructures, in response to a wide range of extreme weather events and natural disasters.","['Power system restoration', 'Power system reliability', 'Power grids', 'Disasters', 'Smart grids', 'Resiliency', 'Next generation networking', 'Hurricanes', 'Meteorology', 'Stochastic processes']","['Natural disaster', 'recovery', 'resiliency', 'restoration', 'smart grid']"
"The use of large-size antenna arrays to implement pencil-beam forming techniques is becoming a key asset to cope with the very high throughput density requirements and high path-loss of future millimeter-wave (mm-wave) gigabit-wireless applications. Suboptimal beamforming (BF) strategies based on search over discrete set of beams (steering vectors) are proposed and implemented in present standards and applications. The potential of fully adaptive advanced BF strategies that will become possible in the future, thanks to the availability of accurate localization and powerful distributed computing, is evaluated in this paper through system simulation. After validation and calibration against mm-wave directional indoor channel measurements, a 3-D ray tracing model is used as a propagation-prediction engine to evaluate performance in a number of simple, reference cases. Ray tracing itself, however, is proposed and evaluated as a real-time prediction tool to assist future BF techniques.","['Ray tracing', 'Antenna arrays', 'Array signal processing', 'Computational modeling', 'Beam steering', 'Millimeter wave technology', 'Performance evaluation', 'Predictive models']","['MIMO', 'beamforming', 'ray tracing', 'millimeter-wave propagation', 'channel measurements']"
"As the last link of an integrated future energy system, the smart home energy management system (HEMS) is critical for a prosumer to intelligently and conveniently manage the use of their domestic appliances, renewable energies (RES) generation, energy storage system (ESS), and electric vehicle (EV). In this paper, we propose a holistic model to center the preference of users when scheduling the involved physical equipment of different natures. Further, a dedicatedly designed charging and discharging strategy for both the ESS and EV considering their capital cost is proposed to integrate them into the HEMS for providing a better flexibility and economic advantages as well as to prolong the life of the batteries. Based on the mixed integer linear programming (MILP) and the proposed model, the energy schedule of the smart home can be derived to guarantee both the lowest cost and the comfort for the users. An illustrative case study is employed to demonstrate the effectiveness of the proposed method.","['Home appliances', 'Smart homes', 'Energy management', 'Energy storage', 'Temperature distribution', 'Electric vehicles', 'Water heating']","['Smart home', 'energy management', 'MILP', 'smart grid']"
"The automobile companies are focusing on recent technologies such as growing Hydrogen (H2) and Fuel Cell (FC) Vehicular Power Train (VPT) to improve the Tank-To-Wheel (TTW) efficiency. Benefits, the lower cost, `Eco' friendly, zero-emission and high-power capacity, etc. In the power train of fuel cell vehicles, the DC-DC power converters play a vital role to boost the fuel cell stack voltage. Hence, satisfy the demand of the motor and transmission in the vehicles. Several DC-DC converter topologies have proposed for various vehicular applications like fuel cell, battery, and renewable energy fed hybrid vehicles etc. Most cases, the DC-DC power converters are viable and cost-effective solutions for FC-VPT with reduced size and increased efficiency. This article describes the state-of-the-art in unidirectional non-isolated DC-DC Multistage Power Converter (MPC) topologies for FC-VPT application. The paper presented the comprehensive review, comparison of different topologies and stated the suitability for different vehicular applications. This article also discusses the DC-DC MPC applications more specific to the power train of a small vehicle to large vehicles (bus, trucks etc.). Further, the advantages and disadvantages pointed out with the prominent features for converters. Finally, the classification of the DC-DC converters, its challenges, and applications for FC technology is presented in the review article as state-of-the-art in research.","['Fuel cells', 'DC-DC power converters', 'Batteries', 'Fuel cell vehicles', 'Topology', 'Renewable energy sources']","['DC-DC converter', 'fuel cell vehicles', 'multistage power converter', 'non-isolated', 'power electronics', 'unidirectional converters', 'vehicular power train']"
"Software-defined networking (SDN) is an emerging network architecture that promises to simplify network management, improve network resource utilization, and boost evolution and innovation in traditional networks. The SDN allows the abstraction and centralized management of the lower-level network functionalities by decoupling the network logic from the data forwarding devices into the logically centralized distributed controllers. However, this separation introduces new scalability and performance challenges in large-scale networks of dynamic traffic and topology conditions. Many research studies have represented that centralization and maintaining the global network visibility over the distributed SDN controller introduce scalability concern. This paper surveys the state-of-the-art proposed techniques toward minimizing the control to data planes communication overhead and controllers’ consistency traffic to enhance the OpenFlow-SDN scalability in the context of logically centralized distributed SDN control plane architecture. The survey mainly focuses on four issues, including logically centralized visibility, link-state discovery, flow rules placement, and controllers’ load balancing. In addition, this paper discusses each issue and presents an updated and detailed study of existing solutions and limitations in enhancing the OpenFlow-SDN scalability and performance. Moreover, it outlines the potential challenges that need to be addressed further in obtaining adaptive and scalable OpenFlow-SDN flow control.","['Scalability', 'Control systems', 'Pipeline processing', 'Data centers', 'Resource management', 'Distributed databases', 'Computer architecture']","['SDN', 'OpenFlow', 'controller', 'scalability', 'global network view', 'flow rules placement', 'centralized flow control', 'load balancing', 'discovery protocol']"
"Detection of Alzheimer's disease (AD) from neuroimaging data such as MRI through machine learning has been a subject of intense research in recent years. The recent success of deep learning in computer vision has progressed such research. However, common limitations with such algorithms are reliance on a large number of training images, and the requirement of careful optimization of the architecture of deep networks. In this paper, we attempt solving these issues with transfer learning, where the state-of-the-art VGG architecture is initialized with pre-trained weights from large benchmark datasets consisting of natural images. The network is then fine-tuned with layer-wise tuning, where only a pre-defined group of layers are trained on MRI images. To shrink the training data size, we employ image entropy to select the most informative slices. Through experimentation on the ADNI dataset, we show that with the training size of 10 to 20 times smaller than the other contemporary methods, we reach the state-of-the-art performance in AD vs. NC, AD vs. MCI, and MCI vs. NC classification problems, with a 4% and a 7% increase in accuracy over the state-of-the-art for AD vs. MCI and MCI vs. NC, respectively. We also provide a detailed analysis of the effect of the intelligent training data selection method, changing the training size, and changing the number of layers to be fine-tuned. Finally, we provide class activation maps (CAM) that demonstrate how the proposed model focuses on discriminative image regions that are neuropathologically relevant and can help the healthcare practitioner in interpreting the model's decision-making process.","['Training', 'Computer architecture', 'Training data', 'Convolution', 'Feature extraction', ""Alzheimer's disease""]","['Deep learning', 'transfer learning', 'convolutional neural network', 'Alzheimer’s']"
"There are a growing number of people who hold accounts on social media platforms (SMPs) but hide their identity for malicious purposes. Unfortunately, very little research has been done to date to detect fake identities created by humans, especially so on SMPs. In contrast, many examples exist of cases where fake accounts created by bots or computers have been detected successfully using machine learning models. In the case of bots these machine learning models were dependent on employing engineered features, such as the “friend-to-followers ratio.”These features were engineered from attributes, such as “friend-count”and “follower-count,”which are directly available in the account profiles on SMPs. The research discussed in this paper applies these same engineered features to a set of fake human accounts in the hope of advancing the successful detection of fake identities created by humans on SMPs.","['Twitter', 'Electronic mail', 'Filtering', 'Support vector machines', 'Computational modeling', 'Feature extraction']","['Big data', 'bots', 'data science', 'fake accounts', 'fake identities', 'identity deception', 'social media', 'veracity']"
"Bluetooth low energy (BLE)-based indoor localization has attracted increasing interests for its low-cost, low-power consumption, and ubiquitous availability in mobile devices. In this paper, a novel denoising autoencoder-based BLE indoor localization (DABIL) method is proposed to provide high-performance 3-D positioning in large indoor places. A deep learning model, called denoising autoencoder, is adopted to extract robust fingerprint patterns from received signal strength indicator measurements, and a fingerprint database is constructed with reference locations in 3-D space, rather than traditional 2-D plane. Field experiments show that 3-D space fingerprinting can effectively increase positioning accuracy, and DABIL performs the best in terms of both horizontal accuracy and vertical accuracy, comparing with a traditional fingerprinting method and a deep learning-based method. Moreover, it can achieve stable performance with incomplete beacon measurements due to unpredictable BLE beacon lost.","['Noise reduction', 'Three-dimensional displays', 'Databases', 'Wireless fidelity', 'Robustness', 'Wireless communication', 'Receivers']","['Bluetooth low energy', 'indoor localization', 'fingerprinting', 'denoising autoencoder']"
"Simultaneous wireless information and power transfer (SWIPT) and multi-carrier non-orthogonal multiple access (MC-NOMA) are promising technologies for future fifth generation and beyond wireless networks due to their potential capabilities in energy-efficient and spectrum-efficient system designs, respectively. In this paper, the joint downlink resource allocation problem for a SWIPT-enabled MC-NOMA system with time switching-based receivers is investigated, where pattern division multiple access (PDMA) technique is employed. We focus on minimizing the total transmit power of the system while satisfying the quality-of-service requirements of each user in terms of data rate and harvested power. The corresponding optimization problem is a non-convex and a mixed integer programming problem which is difficult to solve. Different from the conventional iterative searching-based algorithms, we propose an efficient deep learning-based approach to determine an approximated optimal solution. Specifically, we employ a typical class of deep learning model, namely, deep belief network (DBN), where the detailed procedure of the developed approach consists of three parts, i.e., data preparation, training, and running. The simulation results demonstrate that the proposed DBN-based approach can achieve similar performance of power consumption to the exhaustive search method. Furthermore, the results also confirm that MC-NOMA with PDMA outperforms MC-NOMA with sparse code multiple access, single-carrier non-orthogonal multiple access, and orthogonal frequency division multiple access in terms of power consumption in SWIPT-enabled systems.","['NOMA', 'Resource management', 'Receivers', 'Wireless networks', 'Minimization', '5G mobile communication']","['Non-orthogonal multiple access (NOMA)', 'simultaneous wireless information and power transfer (SWIPT)', 'machine learning']"
"Cloud-based healthcare service with the Internet of Healthcare Things (IoHT) is a model for healthcare delivery for urban areas and vulnerable population that utilizes the digital communications and the IoHT to provide flexible opportunities to transform all the health data into workable, personalized health insights, and help attain wellness outside the traditional hospital setting. This model of healthcare Web services acts like a living organism, taking advantage of the opportunities afforded by running in cloud infrastructure to connect patients and providers anywhere and anytime to improve the quality of care, with the IoHT, acting as a central nervous system for this model that measures patients' vital statistics, constantly logging their health data, and report any abnormalities to the relevant healthcare provider. However, it is crucial to preserve the privacy of patients while utilizing this model so as to maintain their satisfaction and trust in the offered services. With the increasing number of cases for privacy breaches of healthcare data, different countries and corporations have issued privacy laws and regulations to define the best practices for the protection of personal health information. The health insurance portability and accountability act and the privacy principles established by the Organization for Economic Cooperation and Development (OECD) are examples of such regulation frameworks. In this paper, we assert that utilizing the cloud-based healthcare services to generate accurate health insights are feasible, while preserving the privacy of the end-users' sensitive health information, which will be residing on a clear form only on his/her own personal gateway. To support this claim, the personal gateways at the end-users' side will act as intermediate nodes (called fog nodes) between the IoHT devices and the cloud-based healthcare services. In such solution, these fog nodes will host a holistic privacy middleware that executes a two-stage concealment process within a distributed data collection protocol that utilizes the hierarchical nature of the IoHT devices. This will unburden the constrained IoHT devices from performing intensive privacy preserving processes. Additionally, the proposed solution complies with one of the common privacy regulation frameworks for fair information practice in a natural and functional way-which is OECD privacy principles. We depicted how the proposed approach can be integrated into a scenario related to preserving the privacy of the users' health data that is utilized by a cloud-based healthcare recommender service in order to generate accurate referrals. Our holistic approach induces a straightforward solution with accurate results, which are beneficial to both end-users and service providers.","['Cloud computing', 'Medical services', 'Data privacy', 'Data models', 'Logic gates', 'Privacy', 'Internet of things', 'Patient monitoring']","['Internet of healthcare things', 'cloud based healthcare services', 'holistic privacy']"
"Obtrusive sleep apnea (OSA) is one of the most important sleep disorders because it has a direct adverse impact on the quality of life. Intellectual deterioration, decreased psychomotor performance, behavior, and personality disorders are some of the consequences of OSA. Therefore, a real-time monitoring of this disorder is a critical need in healthcare solutions. There are several systems for OSA detection. Nevertheless, despite their promising results, these systems not guiding their treatment. For these reasons, this research presents an innovative system for both to detect and support of treatment of OSA of elderly people by monitoring multiple factors such as sleep environment, sleep status, physical activities, and physiological parameters as well as the use of open data available in smart cities. Our system architecture performs two types of processing. On the one hand, a pre-processing based on rules that enables the sending of real-time notifications to responsible for the care of elderly, in the event of an emergency situation. This pre-processing is essentially based on a fog computing approach implemented in a smart device operating at the edge of the network that additionally offers advanced interoperability services: technical, syntactic, and semantic. On the other hand, a batch data processing that enables a descriptive analysis that statistically details the behavior of the data and a predictive analysis for the development of services, such as predicting the least polluted place to perform outdoor activities. This processing uses big data tools on cloud computing. The performed experiments show a 93.3% of effectivity in the air quality index prediction to guide the OSA treatment. The system's performance has been evaluated in terms of latency. The achieved results clearly demonstrate that the pre-processing of data at the edge of the network improves the efficiency of the system.","['Sleep apnea', 'Monitoring', 'Biomedical monitoring', 'Real-time systems', 'Computer architecture', 'Big Data', 'Sensors']","['Internet-of-Things', 'big data', 'interoperability', 'sleep monitoring', 'health monitoring', 'open data', 'fog computing', 'cloud computing']"
"The global concern with power quality is increasing due to the penetration of renewable energy (RE) sources to cater the energy demands and meet de-carbonization targets. Power quality (PQ) disturbances are found to be more predominant with RE penetration due to the variable outputs and interfacing converters. There is a need to recognize and mitigate PQ disturbances to supply clean power to the consumer. This article presents a critical review of techniques used for detection and classification PQ disturbances in the utility grid with renewable energy penetration. The broad perspective of this review paper is to provide various concepts utilized for extraction of the features to detect and classify the PQ disturbances even in the noisy environment. More than 220 research publications have been critically reviewed, classified and listed for quick reference of the engineers, scientists and academicians working in the power quality area.","['Power quality', 'Monitoring', 'Renewable energy sources', 'Feature extraction', 'Wavelet analysis', 'Wavelet packets', 'Wavelet domain']","['Artificial intelligence', 'power quality disturbances', 'international standards of power quality monitoring', 'signal processing', 'renewable energy sources', 'noise']"
"The continuous improvements in the area of medical imaging, makes the patient monitoring a crucial concern. The internet of things (IoT) embedded in a medical technologies to collect data from human body through sensors, wireless connectivity etc. The junction of medicine and IT like medical informatics will transform healthcare, curbing cost, make more efficient, and saving lives. Various computerized techniques are implemented in the area of Artificial Intelligence (AI) for the application of medical imaging to diagnose the infected regions in the images and videos such as WCE and pathology. The famous stomach infections are ulcer, polyp, and bleeding. Stomach cancer is the most common infection and a leading cause of human deaths worldwide. In the USA, since 2019, a total of 27,510 new cases are reported including 17,230 men and 10,230 women. While the number of deaths is 11,140 consists of 6,800 men and 4,340 women. The manual diagnosis of these stomach infections is a difficult and agitated process therefore it is required to design a fully automated system using AI. In this article, we presented a fully automated system for stomach infection recognition based on deep learning features fusion and selection. In this design, ulcer images are assigned manually and support to a saliency-based method for ulcer detection. Later, pre-trained deep learning model named VGG16 is employing and re-trained using transfer learning. Features of re-trained model are extracted from two consecutive fully connected layers and fused by array-based approach. Besides, the best individuals are selected through the metaheuristic approach name PSO along mean value-based fitness function. The selected individuals are finally recognized through Cubic SVM. The experiments are conducted on Private collected dataset and achieved an accuracy of 98.4%, which is best as compared to existing state-of-the-art techniques.","['Feature extraction', 'Stomach', 'Cancer', 'Image color analysis', 'Hemorrhaging', 'Support vector machines', 'Gastrointestinal tract']","['Stomach diseases', 'WCE', 'saliency estimation', 'deep learning', 'features selection', 'features classification']"
"The Distributed Denial of Service (DDoS) attack has seriously impaired network availability for decades and still there is no effective defense mechanism against it. However, the emerging Software Defined Networking (SDN) provides a new way to reconsider the defense against DDoS attacks. In this paper, we propose two methods to detect the DDoS attack in SDN. One method adopts the degree of DDoS attack to identify the DDoS attack. The other method uses the improved K-Nearest Neighbors (KNN) algorithm based on Machine Learning (ML) to discover the DDoS attack. The results of the theoretical analysis and the experimental results on datasets show that our proposed methods can better detect the DDoS attack compared with other methods.","['Denial-of-service attack', 'Computer crime', 'IP networks', 'Protocols', 'Servers', 'Software', 'Computer architecture']","['DDoS attack', 'traffic behavior', 'software defined networking', 'gain value']"
"There are some problems in the photovoltaic microgrid system due to the solar irradiance-change environment, such as power fluctuation, which leads to larger power imbalance and affects the stable operation of the microgrid. Aiming at the problems of power mismatch loss under partial shading in photovoltaic microgrid systems, this paper proposed a distributed maximum power point tracking (DMPPT) approach based on an improved sparrow search algorithm (ISSA). First, used the center of gravity reverse learning mechanism to initialize the population, so that the population has a better spatial solution distribution; Secondly, the learning coefficient was introduced in the location update part of the discoverer to improve the global search ability of the algorithm; Simultaneously used the mutation operator to improve the position update of the joiner and avoid the algorithm falling into the local extreme value. The results of the model in Matlab showed that the ISSA can track the maximum power point(MPP) more accurately and quickly than the perturbation observation method (P&O) and the particle swarm optimization (PSO) algorithm, and had good steady-state performance.","['Solar power generation', 'Photovoltaic systems', 'Statistics', 'Sociology', 'Microgrids', 'Power supplies', 'Multichip modules']","['Distributed maximum power point tracking', 'photovoltaic microgrid', 'sparrow search algorithm', 'spatial solution distribution', 'steady-state']"
"To research the problems of the rolling bearing fault diagnosis under different noises and loads, a dual-input model based on a convolutional neural network (CNN) and long-short term memory (LSTM) neural network is proposed. The model uses both time domain and frequency domain features to achieve end-to-end fault diagnosis. One-dimensional convolutional and pooling layers are utilized to extract the spatial features and retain the sequence features of the data. In addition, an LSTM layer is employed to extract the sequence features. Finally, a dense layer is applied for fault classification. To enhance recognition accuracy under different noises and loads, three techniques are applied to the proposed model, including taking time-frequency domain signals as input, using the CNN-LSTM model, and adopting the mini-batch and batch normalization methods. The Case Western Reserve University and Drivetrain Diagnostics Simulator data sets are used to construct experiments under different conditions, including varying loads and different noises. The proposed model can achieve a high fault recognition rate under variable load and noise conditions as well as satisfactory anti-noise and load adaptability.","['Feature extraction', 'Fault diagnosis', 'Convolution', 'Data mining', 'Data models', 'Logic gates', 'Rolling bearings']","['Time-frequency features', 'CNN', 'LSTM', 'bearing fault diagnosis', 'anti-noise and variable load adaptation']"
"Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a totally good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though diversity plays an important role in the machine learning process, there is no systematical analysis of the diversification in the machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work. Our analysis provides a deeper understanding of the diversity technology in machine learning tasks and hence can help design and learn more effective models for real-world applications.","['Machine learning', 'Data models', 'Training data', 'Task analysis', 'Training', 'Diversity methods', 'Supervised learning']","['Diversity', 'training data', 'model learning', 'inference', 'supervised learning', 'active learning', 'unsupervised learning', 'posterior regularization']"
"Financial and economic news is continuously monitored by financial market participants. According to the efficient market hypothesis, all past information is reflected in stock prices and new information is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive or negative sentiments from news is very important for investment decision-making by traders, portfolio managers and investors. Sentiment analysis models can provide an efficient method for extracting actionable signals from the news. However, financial sentiment analysis is challenging due to domain-specific language and unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied to specific domains such as finance. To overcome these challenges, we design an evaluation platform which we use to assess the effectiveness and performance of various sentiment analysis approaches, based on combinations of text representation methods and machine-learning classifiers. We perform more than one hundred experiments using publicly available datasets, labeled by financial experts. We start the evaluation with specific lexicons for sentiment analysis in finance and gradually build the study to include word and sentence encoders, up to the latest available NLP transformers. The results show improved efficiency of contextual embeddings in sentiment analysis compared to lexicons and fixed word and sentence encoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers produce comparable results to their larger teacher models, which makes them suitable for use in production environments.","['Sentiment analysis', 'Feature extraction', 'Analytical models', 'Machine learning', 'Dictionaries', 'Semantics']","['Sentiment analysis', 'finance', 'natural language processing', 'text representations', 'deep-learning', 'encoders', 'word embedding', 'sentence embedding', 'transfer-learning', 'transformers', 'survey']"
"Landslide inventories are in high demand for risk assessment of this natural hazard, particularly in tropical mountainous regions. This research designed residual networks for landslide detection using spectral (RGB bands) and topographic information (altitude, slope, aspect, curvature). Recent studies indicate that deep learning methods such as convolutional neural networks (CNN) improve landslide mapping results compared to traditional machine learning. But the effects of network architecture designs and data fusion remain largely underexplored in landslide detection. We compared a one-layer CNN with two of its deeper counterparts and residual networks with two fusion strategies (layer stacking and feature-level fusion) to detect landslides in Cameron Highlands, Malaysia. Sixteen different maps were created using proposed methods and evaluated in separate training and testing sub-areas based on overall accuracy, F1-score, and mean intersection over union (mIOU) metrics. When layer stacking is used as a fusion approach, none of the network designs improved landslide detection results. However, our findings showed that when using feature-level fusion, results could be enhanced with the same network designs. Residual networks performed best improving F1-score and mIOU by 0.13 and 12.96%, respectively, using feature-level fusion rather than layer stacking. CNN models also enhanced the detection outcome with the same fusion approach. On single modality datasets, models' performance varies according to input data, highlighting the effects of input data on network architecture selection. In general, residual networks found to converge faster and generalize better to test areas than other models tested in this research.","['Terrain factors', 'Feature extraction', 'Remote sensing', 'Training', 'Deep learning', 'Testing']","['Landslide detection', 'deep learning', 'convolutional neural network', 'GIS', 'residual networks', 'remote sensing']"
"This paper provides 28- and 73-GHz urban omnidirectional propagation large-scale path loss data measured in downtown New York City during the summers of 2012 and 2013, and 38 GHz data measured in downtown Austin in the summer of 2011. The data provided herein may be used by antenna, propagation, and communications researchers for emerging mobile and/or backhaul millimeter-wave (mmWave) system analyses. This paper also presents measurement layout maps with transmitter and receiver locations and GPS coordinates, so that anyone may create similar or new measurements and models, or may perform further processing, such as with ray-tracers and modeling tools, in addition to studying mmWave system performance. Using the data provided herein, large-scale path loss models using a standard close-in 1 meter free-space reference distance are provided for each of the three frequency bands.","['Millimeter wave communication', '5G mobile communication', 'Loss measurement', 'Channel estimation', 'Microcell networks']","['mmWave', '5G', '28 GHz', '38 GHz', '73 GHz', 'propagation', 'path loss', 'outage', 'omnidirectional modelsrun']"
"The primary challenge of a cost-effective and low-complexity near-field millimeter-wave (mmWave) imaging system is to achieve high resolution with a few antenna elements as possible. Multiple-input multiple-output (MIMO) radar using simultaneous operation of spatially diverse transmit and receive antennas is a good candidate to increase the number of available degrees of freedom. On the other hand, higher integration complexity of extremely dense transceiver electronics limits the use of MIMO only solutions within a relatively large imaging aperture. Hybrid concepts combining synthetic aperture radar (SAR) techniques and sparse MIMO arrays present a good compromise to achieve short data acquisition time and low complexity. However, compared with conventional monostatic sampling schemes, image reconstruction methods for MIMO-SAR are more complicated. In this paper, we propose a high-resolution mmWave imaging system combining 2-D MIMO arrays with SAR, along with a novel Fourier-based image reconstruction algorithm using sparsely sampled aperture data. The proposed algorithm is verified by both simulation and processing real data collected with our mmWave imager prototype utilizing commercially available 77-GHz MIMO radar sensors. The experimental results confirm that our complete solution presents a strong potential in high-resolution imaging with a significantly reduced number of antenna elements.","['MIMO communication', 'Antenna arrays', 'Imaging', 'Apertures', 'Radar imaging', 'Image reconstruction', 'Synthetic aperture radar']","['Millimeter-wave radar (mmWave)', 'near-field radar imaging', 'synthetic aperture radar (SAR)', 'frequency-modulated continuous-wave (FMCW)', 'multiple-input multiple-output (MIMO) radar', 'IWR1443 mmWave sensors']"
"Distributed Energy Resources (DERs) are being integrated into the power market by customers rather than large scale energy suppliers, thereby slowly transforming the centralized, unidirectional market to a decentralized, bidirectional market and transitioning customers into prosumers. Various system architectures are used in the real field to coordinate the energy distribution in the micro/ mini-grids integrated with DERs, all of which have their strengths, weaknesses and challenges. Peer-to-peer (P2P) is an emerging architecture in the field of electrical energy trading and Distributed Generation (DG) management that can be applied in local energy markets. This paper focuses on P2P energy trading, with an in-depth discussion on its various operating algorithms, their principles, characteristics, features and scope through state of art review on P2P. Furthermore, the energy system of Nepal is used as a case study in this paper, and the micro/mini-grids of Nepal and their associated challenges, constraints and opportunities for improvement are discussed. Finally, an energy trading model is proposed to address the problems occurring in the specific case of Nepalese energy market.","['Peer-to-peer computing', 'Computer architecture', 'Decentralized control', 'Power markets', 'Sociology', 'Statistics']","['Distributed generation resources', 'energy trading', 'micro-grid', 'mini-grid', 'peer-to-peer']"
"With the development of mobile Internet technology and the popularity of intelligent mobile terminals, the data traffic load of mobile client users on the smart campus network platform has surged. How to reduce the data traffic of the smart campus network platform is an urgent problem to be solved. First, this paper discussed the key technologies of smart campus network teaching platform under the background of the 5G network, expounded the critical technologies of the transport layer of the Internet of Things (IoT) technology, and analyzed from the development perspective of the IoT platform. Second, by investigating the online classroom data of five types of colleges and universities in China and comparing the advantages and disadvantages of online classroom teaching and traditional classroom teaching, it is found that the number of online courses in colleges and universities has exploded in the second half of 2017. Next, this paper analyzed the demand of smart campus online teaching platform under the background of the 5G network, thus established an online teaching platform based on the four initiatives operation model (government-led, college sponsor, teacher subject, and academic director). Finally, this paper adopted the improved VIRE localization algorithm to obtain the specific location information of the student users in the classroom and, then, compared with the error obtained by the VIRE algorithm, and the error of the improved VIRE algorithm is smaller. In the process of obtaining information, the 5G network technology is used for data transmission, which can shorten the check-in time and can improve the positioning accuracy.","['Education', '5G mobile communication', 'Internet of Things', 'Cloud computing', 'Information processing', 'Logic gates', 'Multimedia communication']","['5G network', 'smart campus', 'online teaching platform', 'improved VIRE location algorithm']"
"A large community of research has been developed in recent years to analyze social media and social networks, with the aim of understanding, discovering insights, and exploiting the available information. The focus has shifted from conventional polarity classification to contemporary application-oriented fine-grained aspects such as, emotions, sarcasm, stance, rumor, and hate speech detection in the user-generated content. Detecting a sarcastic tone in natural language hinders the performance of sentiment analysis tasks. The majority of the studies on automatic sarcasm detection emphasize on the use of lexical, syntactic, or pragmatic features that are often unequivocally expressed through figurative literary devices such as words, emoticons, and exclamation marks. In this paper, we propose a deep learning model called sAtt-BLSTM convNet that is based on the hybrid of soft attention-based bidirectional long short-term memory (sAtt-BLSTM) and convolution neural network (convNet) applying global vectors for word representation (GLoVe) for building semantic word embeddings. In addition to the feature maps generated by the sAtt-BLSTM, punctuation-based auxiliary features are also merged into the convNet. The robustness of the proposed model is investigated using balanced (tweets from benchmark SemEval 2015 Task 11) and unbalanced (approximately 40000 random tweets using the Sarcasm Detector tool with 15000 sarcastic and 25000 non-sarcastic messages) datasets. An experimental study using the training- and test-set accuracy metrics is performed to compare the proposed deep neural model with convNet, LSTM, and bidirectional LSTM with/without attention and it is observed that the novel sAtt-BLSTM convNet model outperforms others with a superior sarcasm-classification accuracy of 97.87% for the Twitter dataset and 93.71% for the random-tweet dataset.","['Sentiment analysis', 'Feature extraction', 'Deep learning', 'Convolution', 'Neural networks', 'Semantics', 'Twitter']","['Sarcasm', 'deep learning', 'attention', 'social data']"
"The new culture of networked systems that offer everywhere accessible services has given rise to various types of security tradeoffs. In fact, with the evolution of physical systems that keep getting integrated with cyber frameworks, cyber threats have far more critical effects as they get reflected on the physical environment. As a result, the issue of security of cyber physical systems requires a special holistic treatment. In this paper, we study the tradeoff between security, safety, and availability in such systems and demonstrate these concepts on implantable medical devices as a case study. We discuss the challenges and constraints associated with securing such systems and focus on the tradeoff between security measures required for blocking unauthorized access to the device and the safety of the patient in emergency situations where such measures must be dropped to allow access. We analyze the up to date proposed solutions and discuss their strengths and limitations.","['Access control', 'Physical layer', 'Medical devices', 'Computer security', 'Safety', 'Implants', 'Cyber-physical systems']","['Access Control', 'Cyber Physical Systems', 'Implantable Medical Devices', 'Security Vs', 'Safety']"
"Weed identification in vegetable plantation is more challenging than crop weed identification due to their random plant spacing. So far, little work has been found on identifying weeds in vegetable plantation. Traditional methods of crop weed identification used to be mainly focused on identifying weed directly; however, there is a large variation in weed species. This paper proposes a new method in a contrary way, which combines deep learning and image processing technology. Firstly, a trained CenterNet model was used to detect vegetables and draw bounding boxes around them. Afterwards, the remaining green objects falling out of bounding boxes were considered as weeds. In this way, the model focuses on identifying only the vegetables and thus avoid handling various weed species. Furthermore, this strategy can largely reduce the size of training image dataset as well as the complexity of weed detection, thereby enhancing the weed identification performance and accuracy. To extract weeds from the background, a color index-based segmentation was performed utilizing image processing. The employed color index was determined and evaluated through Genetic Algorithms (GAs) according to Bayesian classification error. During the field test, the trained CenterNet model achieved a precision of 95.6%, a recall of 95.0%, and a F_{1} score of 0.953, respectively. The proposed index −19R + 24G −2B ≥ 862 yields high segmentation quality with a much lower computational cost compared to the wildly used ExG index. These experiment results demonstrate the feasibility of using the proposed method for the ground-based weed identification in vegetable plantation.","['Deep learning', 'Agriculture', 'Image color analysis', 'Training', 'Image segmentation', 'Indexes', 'Image processing']","['Weed identification', 'deep learning', 'image processing', 'genetic algorithms', 'color index']"
"The existing approaches for fuzzy soft sets decision-making are mainly based on different types of level soft sets. How to deal with such kinds of fuzzy soft sets decision-making problems via decreasing the uncertainty resulting from human's subjective cognition is still an open issue. To address this issue, a hybrid method for utilizing fuzzy soft sets in decision-making by integrating a fuzzy preference relations analysis based on the belief entropy with the Dempster-Shafer evidence theory is proposed. The proposed method is composed of four procedures. First, we measure the uncertainties of parameters by leveraging the belief entropy. Second, with the fuzzy preference relations analysis, the uncertainties of parameters are modulated by making use of the relative reliability preference of parameters. Third, an appropriate basic probability assignment in terms of each parameter is generated on the modulated uncertainty degrees of parameters basis. Finally, we adopt Dempster's combination rule to fuse the independent parameters into an integrated one; thus, the best one can be obtained based on the ranking candidate alternatives. In order to validate the feasibility and effectiveness of the proposed method, a numerical example and a medical diagnosis application are implemented. From the experimental results, it is demonstrated that the proposed method outperforms the related methods, because the uncertainty resulting from human's subjective cognition can be reduced; meanwhile, the decision-making level can also be improved with better performance.","['Uncertainty', 'Decision making', 'Entropy', 'Cognition', 'Measurement uncertainty', 'Medical diagnosis', 'Tools']","['Fuzzy soft set', 'decision making', 'Dempster–Shafer evidence theory', 'belief entropy', 'fuzzy preference relations', 'belief function', 'variance of entropy', 'medical diagnosis']"
"In recent years, unmanned aerial vehicles (UAVs) have gained popularity for various applications and services in both the military and civilian domains. Multiple UAVs can carry out complex tasks efficiently when they are organized as an ad hoc network, where wireless communication is essential for cooperation and collaboration between UAVs and the ground station. Due to rapid mobility and highly dynamic topology, designing a routing protocol for UAV networks is a challenging task. As the number of UAVs increases, a hierarchical routing called clustering is necessarily required to provide scalability because clustering schemes ensure the basic level of system performance such as throughput, end-to-end delay, and energy efficiency. For approximately a half-decade, several survey articles have been reported on topology-based routing and position-based routing for UAV networks. To the best of the authors’ knowledge, however, there is no survey on cluster-based routing in the literature. In this paper, cluster-based routing protocols for UAV networks are extensively surveyed and qualitatively compared in terms of outstanding features, characteristics, competitive advantages, and limitations. Furthermore, open research issues and challenges on cluster-based routing are discussed.","['Routing protocols', 'Routing', 'Ad hoc networks', 'Drones', 'Network topology', 'Topology']","['Unmanned aerial vehicle', 'drone', 'unmanned aerial vehicle network', 'flying ad hoc network', 'routing protocol', 'clustering algorithm', 'scalability']"
"Energy is a vital resource for human activities and lifestyle, powering important everyday infrastructures and services. Currently, pollutant and non-renewable sources, such as fossil fuels, remain the main source of worldwide consumed energy. The environmental impact of their exploitation has boosted research and investments in alternative, clean and renewable sources, including photovoltaic and wind-based systems. As a whole, buildings are one of the major energy consumption sectors. Hence, improving energy efficiency in buildings will result in economical and environmental gains. In the case of households, home energy management systems are mainly used for monitoring real-time consumption and to schedule appliance operations so that the energy bill could be minimised, or according to another specific criterion. This work aims to survey the most recent literature on home energy management systems, providing an aggregated and unified perspective in the context of residential buildings. In addition, an updated literature list regarding commonly managed household appliances and scheduling objectives are included. Physical and operational constraints, and how they are addressed by home energy management systems along with security issues are also discussed.","['Home appliances', 'Optimal scheduling', 'Smart homes', 'Energy consumption']","['Energy efficiency', 'home energy management systems', 'household appliance models', 'load management', 'optimal scheduling', 'smart homes', 'security']"
"The recent state of the art innovations in technology enables the development of low-cost sensor nodes with processing and communication capabilities. The unique characteristics of these low-cost sensor nodes such as limited resources in terms of processing, memory, battery, and lack of tamper resistance hardware make them susceptible to clone node or node replication attack. The deployment of WSNs in the remote and harsh environment helps the adversary to capture the legitimate node and extract the stored credential information such as ID which can be easily re-programmed and replicated. Thus, the adversary would be able to control the whole network internally and carry out the same functions as that of the legitimate nodes. This is the main motivation of researchers to design enhanced detection protocols for clone attacks. Hence, in this paper, we have presented a systematic literature review of existing clone node detection schemes. We have also provided the theoretical and analytical survey of the existing centralized and distributed schemes for the detection of clone nodes in static WSNs with their drawbacks and challenges.","['Cloning', 'Wireless sensor networks', 'Systematics', 'Law', 'Bibliographies', 'Security']","['Wireless sensor networks (WSNs)', 'clone attack', 'clone attack detection schemes', 'systematic literature review (SLR)']"
"Deep Learning has been widely applied to problems in detecting various network attacks. However, no cases on network security have shown applications of various deep learning algorithms in real-time services beyond experimental conditions. Moreover, owing to the integration of high-performance computing, it is necessary to apply systems that can handle large-scale traffic. Given the rapid evolution of web-attacks, we implemented and applied our Artificial Intelligence-based Intrusion Detection System (AI-IDS). We propose an optimal convolutional neural network and long short-term memory network (CNN-LSTM) model, normalized UTF-8 character encoding for Spatial Feature Learning (SFL) to adequately extract the characteristics of real-time HTTP traffic without encryption, calculating entropy, and compression. We demonstrated its excellence through repeated experiments on two public datasets (CSIC-2010, CICIDS2017) and fixed real-time data. By training payloads that analyzed true or false positives with a labeling tool, AI-IDS distinguishes sophisticated attacks, such as unknown patterns, encoded or obfuscated attacks from benign traffic. It is a flexible and scalable system that is implemented based on Docker images, separating user-defined functions by independent images. It also helps to write and improve Snort rules for signature-based IDS based on newly identified patterns. As the model calculates the malicious probability by continuous training, it could accurately analyze unknown web-attacks.","['Intrusion detection', 'Feature extraction', 'Machine learning', 'Real-time systems', 'Wireless sensor networks', 'Payloads']","['Computer networks', 'intrusion detection', 'neural networks', 'large-scale systems', 'intelligent systems', 'real time systems', 'security', 'CNN-LSTM']"
"In this correspondence, we present an accurate Magnetic Resonance (MR) image Super-Resolution (SR) method that uses a Very Deep Residual network (VDR-net) in the training phase. By applying 2D Stationary Wavelet Transform (SWT), we decompose each Low Resolution (LR)-High Resolution (HR) example image pair into its low-frequency and high-frequency subbands. These LR-HR subbands are used to train the VDR-net through the input and output channels. The trained parameters are then used to generate residual subbands of a given LR test image. The obtained residuals are added with their LR subbands to produce the SR subbands. Finally, we attempt to maintain the intrinsic structure of images by implementing the Gaussian edge-preservation step on the SR subbands. Our extensive experimental results show that the proposed MR-SR method outperforms the existing methods in terms of four different objective metrics and subjective quality.","['Training', 'Image edge detection', 'Interpolation', 'Image reconstruction', 'Deep learning', 'Encoding', 'Dictionaries']","['Deep learning', 'edge-preservation', 'MR imaging', 'residual network', 'stationary wavelet decomposition', 'super-resolution']"
"Thanks to the rapid development in mobile vehicles and wireless technologies, the Internet of Vehicles (IoV) has become an attractive application that can provide a large number of mobile services for drivers. Vehicles can be informed of the mobile position, direction, speed, and other real-time information of nearby vehicles to avoid traffic jams and accidents. However, the environments of IoV could be dangerous in the absence of security protections. Due to the openness and self-organization of IoV, there are enormous malicious attackers. To guarantee the safety of mobile services, we propose an effective decentralized authentication mechanism for IoV on the basis of the consensus algorithm of blockchain technology. The simulation under the veins framework is carried out to verify the feasibility of the scheme in reducing the selfish behavior and malicious attacks in IoV.","['Blockchain', 'Authentication', 'Servers', 'Internet', 'Encryption', 'Privacy']","['Blockchain', 'Internet of Vehicles', 'security and privacy', 'consensus algorithm']"
"In this paper, based on outdoor microcellular channel measurements at 32 GHz for 5G radio systems, a comprehensive channel modeling, simulation, and validation are performed. The directional-scan-sounding measurements using a horn antenna rotated with an angular step at the receiver are carried out, which constitutes a virtual array to form a single-input multiple-output radio channel. The directional- and omni-directional path-loss models are developed by using close-in and floating-intercept methods. Non-parametric and parametric methods are applied to extract large-scale channel parameters (LSPs). The non-parametric method is based on the definition of a channel parameter, whereas the parametric method is derived by the space-alternating generalized expectation-maximization (SAGE) algorithm, which can de-embed an antenna pattern. It is found that the LSPs in the angular domain are significantly different by using the two methods; however, the LSPs in the delay domain almost stay the same. By comparing the LSPs with the parameter table at 32 GHz with 3GPP standard, it is found that 3GPP LSPs should be corrected at the International Telecommunications Union-assigned millimeter wave (mmWave) frequencies for 5G. In this paper, the channel simulation is implemented by using the quasi-deterministic radio channel generator (QuaDRiGa) platform recommended by 3GPP. By comparing the LSPs with the simulated and measured results, it is found that QuaDRiGa is a good platform at the mmWave band, even if it is originally developed for channel simulation below 6 GHz. The results of this paper are important and useful in the simulations and design of future 5G radio systems at 32 GHz.","['Antenna measurements', 'Horn antennas', '5G mobile communication', 'Frequency measurement', '3GPP', 'Receiving antennas', 'Decision support systems']","['mmWave', '32 GHz', 'channel measurement', 'direction-scan-sounding', 'path-loss', 'SAGE', 'QuaDRiGa', 'simulation', 'validation']"
"Advanced metering infrastructure (AMI) is becoming a vital part of utility distribution networks, allowing the development of smart cities. AMI consists of smart electric, gas, and water meters, and the devices are very limited in terms of battery, processing power, and memory. The deployment and operational needs of energy-constrained network infrastructures in smart water and gas metering systems require the use of routing mechanisms that consider energy consumption, minimize energy use, and prolong network lifetime. An efficient routing metric is needed for energy-constrained devices. In this paper, we propose an energy- and congestion-aware routing metric for smart meter networks to be deployed in smart cities. The proposed metric is an adaptive parent node selection mechanism that considers the residual energy and queue utilization of neighboring nodes. Minimizing power consumption will enhance network lifetime. The proposed scheme was evaluated with the Cooja Simulator 3.0 using random and grid topology. The simulation results show greater network performance in terms of average power consumption and packet delivery ratio.","['Routing', 'Measurement', 'Smart cities', 'Routing protocols', 'Smart grids', 'Meters', 'Batteries']","['Low power and lossy networks', 'smart city', 'smart grid', '802.15.4', 'advance metering infrastructure (AMI)', 'IoT', '6LoWPAN']"
"In this paper, energy-efficient power allocation (PA) is investigated for a multiple-input multiple-output non-orthogonal multiple access system with multiple users in a cluster. To ensure the quality of service (QoS) for the users, a minimum rate requirement is pre-defined for each user. Because of the QoS requirement, it is first necessary to determine whether the considered energy-efficiency (EE) maximization problem is feasible or not, by comparing the total transmit power with the required power for satisfying the QoS of the users. If feasible, a closed-form solution is provided for the corresponding sum rate maximization problem, and on this basis, the EE maximization problem is solved by applying non-convex fractional programming. Otherwise, a low-complexity user admission scheme is proposed, which admits users one by one following the ascending order of the required power for satisfying the QoS. Numerical results are presented to validate the effectiveness of the proposed energy-efficient PA strategy and user admission scheme.","['NOMA', 'Quality of service', 'Resource management', 'Complexity theory', 'MIMO communication', 'Silicon carbide', 'Receivers']","['Non-orthogonal multiple access (NOMA)', 'multiple-input multiple-output (MIMO)', 'energy efficiency (EE)', 'user admission', 'power allocation (PA)', 'quality-of-service (QoS)']"
"Epilepsy is a very common neurological disease that has affected more than 65 million people worldwide. In more than 30 % of the cases, people affected by this disease cannot be cured with medicines or surgery. However, predicting a seizure before it actually occurs can help in its prevention; through therapeutic intervention. Studies have observed that abnormal activity inside the brain begins a few minutes before the start of a seizure, which is known as preictal state. Many researchers have tried to find a way for predicting this preictal state of a seizure but an effective prediction in terms of high sensitivity and specificity still remains a challenge. The current study, proposes a seizure prediction system that employs deep learning methods. This method includes preprocessing of scalp EEG signals, automated features extraction; using convolution neural network and classification with the support of vector machines. The proposed method has been applied on 24 subjects of scalp EEG dataset of CHBMIT resulting in successfully achieving an average sensitivity and specificity of 92.7% and 90.8% respectively.","['Electroencephalography', 'Feature extraction', 'Scalp', 'Machine learning', 'Prediction methods', 'Support vector machines', 'Electrodes']","['Epilepsy prediction', 'seizures', 'preictal state', 'scalp EEG', 'intracranial EEG', 'deep learning', 'CNN']"
"In addition to being a well-liked form of recreation, escape rooms have drawn the attention of educators due to their ability to foster teamwork, leadership, creative thinking, and communication in a way that is engaging for students. As a consequence, educational escape rooms are emerging as a new type of learning activity under the promise of enhancing students’ learning through highly engaging experiences. These activities consist of escape rooms that incorporate course materials within their puzzles in such a way that students are required to master these materials in order to succeed. Although several studies have reported on the use of escape rooms in a wide range of disciplines, prior research falls short of addressing the use of educational escape rooms for teaching programming, one of the most valuable skills of the twenty-first century that students often have difficulties grasping. This paper reports on the use of an educational escape room in a programming course at a higher education institution and provide, for the first time, insights on the instructional effectiveness of using educational escape rooms for teaching programming. The results of this paper show that appropriate use of educational escape rooms can have significant positive impacts on student engagement and learning in programming courses. These results also suggest that students prefer these activities over traditional computer laboratory sessions. Finally, another novel contribution of this paper is a set of recommendations and proposals for educators in order to help them create effective educational escape rooms for teaching programming.","['Programming profession', 'Education', 'Teamwork', 'Buildings', 'Investment']","['Computer science education', 'educational escape rooms', 'educational technology', 'engineering education']"
"E-learning has reshaped traditional education into more flexible and efficient learning in developed nations. However, e-learning remains underutilized and in the rudimentary stages of development in developing countries. Therefore, understanding the critical factors behind the adoption and acceptance of technology is a prime concern in developing countries like Pakistan. This paper provides and examines the adoption and acceptance baseline for e-learning systems by incorporating critical external factors in the technology acceptance model. A conceptual model-the Pakistan E-Learning Adoption Model-is proposed in the context of higher education. Data were collected from 354 learners at the Virtual University of Pakistan and structural equation modeling was employed to test the research hypotheses. The empirical investigation indicates that computer self-efficacy, Internet experience, enjoyment, and system characteristics are significant predictors of perceived ease of use, while system characteristics are a strong predictor of perceived usefulness. Moreover, the subjective norm is not found to be significant for perceived usefulness. The findings provide practical implications for policy makers, practitioners, and developers in successful e-learning systems implementation.","['Electronic learning', 'Context', 'Computational modeling', 'Context modeling', 'Computers', 'Mathematical model']","['Critical success factors for adoption', 'e-learning adoption', 'e-learning adoption in Pakistan', 'TAM']"
"Machine-to-machine communication over long-term evolution advanced (LTE-A) network has emerged as a new communication paradigm to support a variety of applications of Internet of Things. One of the most effective techniques to accommodate a large volume of machine type communication (MTC) devices in LTE-A is clustering where devices (nodes) are grouped into number of clusters and forward their traffics to the base station (e.g., LTE eNodeB) through some special nodes called cluster heads (CHs). In many applications, the CHs change location with time that causes variation in distances between neighboring CHs. When these distances increase, the performance of data transmission may degrade. To address this issue, we propose to employ intermediate non-CH nodes as relays between neighboring CHs. Our solution covers many aspects from relay selection to cooperative formation to meet the user's QoS requirements. As the number of total relay plays a significant role in cooperative communications, we first design a rateless-coded-incremental-relay selection algorithm based on greedy techniques to guarantee the required data rate with a minimum cost. After that, we develop both source-feedback and non-source-feedback-based fountain coded cooperative communication protocols to facilitate the data transmission between two neighbor CHs. Numerical results are presented to demonstrate the performance of these protocols with different relay selection methods under Rayleigh fading channel. It shows that the proposed source-feedback-based protocol outperforms its non-source-feedbackprotocol counterpart in terms of a variety of metrics.","['Internet of things', 'Machine-to-machine communications', 'Cooperative communication', 'Relays', 'Protocols', 'Base stations', 'Data communication']","['Internet of things', 'fountain codes', 'machine to machine communication', 'cooperative communications']"
"A full-bridge LLC resonant converter with series-parallel connected transformers for an onboard battery charger of electric vehicles is proposed, which can realize zero voltage switching turn-on of power switches and zero current switching turn-off of rectifier diodes. In this converter, two same small transformers are employed instead of the single transformer in the traditional LLC resonant converter. The primary windings of these two transformers are series-connected to obtain equal primary current, while the secondary windings are parallel-connected to be provided with the same secondary voltage, so the power can be automatically balanced. Series-connection can reduce the turns of primary windings. Parallel-connection can reduce the current stress of the secondary windings and the conduction loss of rectifier diodes. Compared with the traditional LLC resonant converter with single transformer under same power level, the smaller low-profile cores can be used to reduce the transformers loss and improve heat dissipation. In this paper, the operating principle, steady state analysis, and design of the proposed converter are described, simulation and experimental prototype of the proposed LLC converter is established to verify the effectiveness of the proposed converter.","['Resonant converters', 'Windings', 'Zero voltage switching', 'Rectifiers', 'Magnetic resonance', 'Capacitors']","['Series-parallel connected', 'full-bridge LLC resonant converter', 'dc-dc power conversion', 'on-board charger']"
"Reconfigurable intelligent surface (RIS) is considered to be an energy-efficient approach to reshape the wireless environment for improved throughput. Its passive feature greatly reduces the energy consumption, which makes RIS a promising technique for enabling the future smart city. Existing beamforming designs for RIS mainly focus on optimizing the spectral efficiency for single carrier systems. Meanwhile, complicated bit/power allocation on different spatial domain subchannels needs to be designed for better bit error rate (BER) performance in conventional singular value decomposition-based beamforming. To avoid this, in this paper, we propose a geometric mean decomposition-based beamforming for RIS-assisted millimeter wave (mmWave) hybrid MIMO systems. In this way, multiple parallel data streams in the spatial domain can be considered to have the same channel gain, so that the better BER can be achieved without sophisticated bit/power allocation. Moreover, by exploiting the common angular-domain sparsity of mmWave massive MIMO channels over different subcarriers, a simultaneous orthogonal matching pursuit algorithm is utilized to obtain the optimal multiple beams from an oversampling 2D-DFT codebook. Besides, by only leveraging the angle of arrival and angle of departure associated with the line of sight (LoS) channels, we further design the phase shifters for RIS by maximizing the array gain for LoS channel. Simulation results show that the proposed scheme can achieve better BER performance than conventional approaches. Our work is an initial attempt to discuss the broadband beamforming for RIS-assisted mmWave massive MIMO with the hybrid architecture.","['Array signal processing', 'Matching pursuit algorithms', 'OFDM', 'Massive MIMO', 'Bit error rate', 'Wideband']","['Reconfigurable intelligent surface (RIS)', 'geometric mean decomposition', 'simultaneous orthogonal matching pursuit', 'hybrid beamforming', 'mmWave', 'massive MIMO']"
"High-gain DC/DC converters with high efficiency are needed in dc microgrid owed to the low voltage of power sources, e.g., photovoltaic-cell and fuel-cell. This paper proposed a new high-gain double-duty-triple-mode (DDTM) converter for dc-microgrid applications. The proposed DDTM converter operates in three modes to achieve higher voltage gain without utilizing transformer, coupled inductor, voltage multiplier, and multiple voltage lifting techniques, e.g., triple, quadruple voltage lift. The modes of operation of the converter are controlled through three switches with two distinct duty ratios (double duty) to achieve wide range duty ratio. The operating principle, voltage gain analysis, and efficiency analysis of the proposed converter are discussed in detail and to show its benefits comparison is provided with the existing high-gain converters. The boundary operating condition for continuous conduction mode (CCM) and discontinuous conduction mode (DCM) is presented. The prototype of the proposed converters with 500-W power is implemented in the laboratory and experimentally investigated, which validate the performance and feasibility of the proposed converter. Due to double duty control, the proposed converter can be controlled in different ways and the thorough discussion on controlling of the converter is provided as a future scope.","['Inductors', 'Capacitors', 'Switches', 'Microgrids', 'Semiconductor diodes', 'High-voltage techniques']","['DC/DC', 'double duty', 'high gain converter', 'dc microgrid', 'transformer-less', 'triple mode', 'wide duty range']"
"Mobile edge computing (MEC) and non-orthogonal multiple access (NOMA) have been considered as the promising techniques to address the explosively growing computation-intensive applications and accomplish the requirement of massive connectivity in the fifth-generation networks. Moreover, since the computing resources of the edge server are limited, the computing load of the edge server needs to be effectively alleviated. In this paper, by exploiting device-to-device (D2D) communication for enabling user collaboration and reducing the edge server's load, we investigate the D2D-assisted and NOMA-based MEC system. In order to minimize the weighted sum of the energy consumption and delay of all users, we jointly optimize the computing resource, power, and channel allocations. Regarding the computing resource allocation, we propose an adaptive algorithm to find the optimal solution. Regarding the power allocation, we present a novel power allocation algorithm based on the particle swarm optimization (PSO) for the single NOMA group comprised of multiple cellular users. Then, for the matching group comprised of a NOMA group and D2D pairs, we theoretically derive the interval of optimal power allocation and propose a PSO-based algorithm to solve it. Regarding the channel allocation, we propose a one-to-one matching algorithm based on the Pareto improvement and swapping operations and extend the one-to-one matching algorithm to a many-to-one matching scenario. Finally, we propose a scheduling-based joint computing resource, power, and channel allocations algorithm to achieve the joint optimization. The simulation results show that the proposed solution can effectively reduce the weighted sum of the energy consumption and delay of all users.","['NOMA', 'Device-to-device communication', 'Task analysis', 'Servers', 'Resource management', 'Channel allocation', 'Energy consumption']","['Mobile edge computing (MEC)', 'non-orthogonal multiple access (NOMA)', 'device-to-device (D2D) communications', 'power allocation', 'and channel allocation']"
"Cyber-attacks are evolving at a disturbing rate. Data breaches, ransomware attacks, crypto-jacking, malware and phishing attacks are now rampant. In this era of cyber warfare, the software industry is also growing with an increasing number of software being used in all domains of life. This evolution has added to the problems of software vendors and users where they have to prevent a wide range of attacks. Existing watermark detection solutions have a low detection rate in the software. In order to address this issue, this paper proposes a novel blind Zero code based Watermark detection approach named KeySplitWatermark, for the protection of software against cyber-attacks. The algorithm adds watermark logically into the code utilizing the inherent properties of code and gives a robust solution. The embedding algorithm uses keywords to make segments of the code to produce a key-dependent on the watermark. The extraction algorithms use this key to remove watermark and detect tampering. When tampering increases to a certain user-defined threshold, the original software code is restored making it resilient against attacks. KeySplitWatermark is evaluated on tampering attacks on three unique samples with two distinct watermarks. The outcomes show that the proposed approach reports promising results against cyber-attacks that are powerful and viable. We compared the performance of our proposal with state-of-the-art works using two different software codes. Our results depict that KeySplitWatermark correctly detects watermarks, resulting in up to 15.95 and 17.43 percent reduction in execution time on given code samples with no increase in program size and independent of watermark size.","['Watermarking', 'Software algorithms', 'Heuristic algorithms', 'Malware', 'Software protection']","['Cyber-attacks', 'watermarking', 'software', 'algorithm', 'blind detection', 'attack models', 'security']"
"The atom-bond connectivity (ABC) index is one of the most actively studied degree-based graph invariants, which are found in a vast variety of chemical applications. For a simple graph $G$ , it is defined as $ABC(G)=\sum _{uv \in E(G)} ({({d(u)+d(v)-2})/({d(u) d(v)})})^{1/2}$ , where $d(v)$ denotes the degree of a vertex $v$ of $G$ . Recently in [17] graphs with $n$ vertices, $2n-4$ and $2n-3$ edges, and maximum $ABC$ index were characterized. Here, we consider the next, more complex case, and characterize the graphs with $n$ vertices, $2n-2$ edges, and maximum $ABC$ index.","['Indexes', '3G mobile communication', 'Chemicals', 'STEM', 'Information science', 'Mathematics', 'Physics']","['Atom–bond connectivity index', 'ABC index', 'extremal graph']"
"Electrification of the transportation sector can play a vital role in reshaping smart cities. With an increasing number of electric vehicles (EVs) on the road, deployment of well-planned and efficient charging infrastructure is highly desirable. Unlike level 1 and level 2 charging stations, level 3 chargers are super-fast in charging EVs. However, their installation at every possible site is not techno-economically justifiable because level 3 chargers may cause violation of critical system parameters due to their high power consumption. In this paper, we demonstrate an optimized combination of all three types of EV chargers for efficiently managing the EV load while minimizing installation cost, losses, and distribution transformer loading. Effects of photovoltaic (PV) generation are also incorporated in the analysis. Due to the uncertain nature of vehicle users, EV load is modeled as a stochastic process. Particle swarm optimization (PSO) is used to solve the constrained nonlinear stochastic problem. MATLAB and OpenDSS are used to simulate the model. The proposed idea is validated on the real distribution system of the National University of Sciences and Technology (NUST) Pakistan. Results show that an optimized combination of chargers placed at judicious locations can greatly reduce cost from 3.55 million to 1.99 million, daily losses from 787kWh to 286kWh and distribution transformer congestion from 58% to 22% when compared to scenario of optimized placement of level 3 chargers for 20% penetration level in commercial feeders. In residential feeder, these statistics are improved from 2.52 to 0.81 million, from 2167kWh to 398kWh and from 106% to 14%, respectively. It is also realized that the integration of PV improves voltage profile and reduces the negative impact of EV load. Our optimization model can work for commercial areas such as offices, university campuses, and industries as well as residential colonies.","['Charging stations', 'Load modeling', 'Planning', 'Mathematical model', 'Electric vehicle charging', 'Photovoltaic systems']","['Charging stations placement', 'distribution system', 'electric vehicles (EVs)', 'optimization']"
"This paper proposes the application of a dynamic voltage restorer (DVR) to enhance the power quality and improve the low voltage ride through (LVRT) capability of a three-phase medium-voltage network connected to a hybrid distribution generation system. In this system, the photovoltaic (PV) plant and the wind turbine generator (WTG) are connected to the same point of common coupling (PCC) with a sensitive load. The WTG consists of a DFIG generator connected to the network via a step-up transformer. The PV system is connected to the PCC via a two-stage energy conversion (dc-dc converter and dc-ac inverter). This topology allows, first, the extraction of maximum power based on the incremental inductance technique. Second, it allows the connection of the PV system to the public grid through a step-up transformer. In addition, the DVR based on fuzzy logic controller is connected to the same PCC. Different fault condition scenarios are tested for improving the efficiency and the quality of the power supply and compliance with the requirements of the LVRT grid code. The results of the LVRT capability, voltage stability, active power, reactive power, injected current, and dc link voltage, speed of turbine, and power factor at the PCC are presented with and without the contribution of the DVR system.","['Hybrid power systems', 'Reactive power', 'Photovoltaic systems', 'Power system stability', 'Doubly fed induction generators']","['Active power', 'DC-link voltage DFIG', 'dynamic voltage restorer', 'LVRT', 'power factor', 'photovoltaic', 'voltage stability', 'reactive power']"
"State of health (SOH) monitoring and remaining useful life (RUL) prediction are the key to ensuring the safe use of lithium-ion batteries. However, the commonly used models are inefficient in predicting accuracy and do not have the ability to capture local regeneration of battery cells. In this paper, a temporal convolutional network (TCN) based SOH monitoring model framework of lithium-ion batteries is proposed. Causal convolution and dilated convolution techniques are used in the model to improve the ability of the model to capture local capacity regeneration, thus improving the overall prediction accuracy of the model. Residual connection and dropout technologies are used to improve the training speed of the model and avoid overfitting in deep network. The empirical mode decomposition (EMD) technology is used to denoise the offline data in RUL prediction, so as to avoid RUL prediction errors caused by local regeneration. The proposed model is verified on two kinds of datasets and the results show that it has the ability to capture local regeneration phenomena in Lithium-ion batteries. Compared with the commonly used models, it has higher accuracy and stronger robustness in SOH monitoring and RUL prediction.","['Predictive models', 'Integrated circuit modeling', 'Lithium-ion batteries', 'Monitoring', 'Feature extraction', 'Battery charge measurement']","['Lithium-ion battery', 'state of health', 'remaining useful life', 'local capacity regeneration', 'temporal convolutional network']"
"Researchers have collected Twitter data to study a wide range of topics. This growing body of literature, however, has not yet been reviewed systematically to synthesize Twitter-related papers. The existing literature review papers have been limited by constraints of traditional methods to manually select and analyze samples of topically related papers. The goals of this retrospective study are to identify dominant topics of Twitter-based research, summarize the temporal trend of topics, and interpret the evolution of topics withing the last ten years. This study systematically mines a large number of Twitter-based studies to characterize the relevant literature by an efficient and effective approach. This study collected relevant papers from three databases and applied text mining and trend analysis to detect semantic patterns and explore the yearly development of research themes across a decade. We found 38 topics in more than 18,000 manuscripts published between 2006 and 2019. By quantifying temporal trends, this study found that while 23.7% of topics did not show a significant trend (P = 0.05), 21% of topics had increasing trends and 55.3% of topics had decreasing trends that these hot and cold topics represent three categories: application, methodology, and technology. The contributions of this paper can be utilized in the growing field of Twitter-based research and are beneficial to researchers, educators, and publishers.","['Twitter', 'Market research', 'Text mining', 'Bibliographies', 'Systematics', 'Data collection', 'Semantics']","['Literature review', 'social media', 'survey', 'text mining', 'topic modeling', 'Twitter']"
"Although the virtual inertia algorithm can be used to enhance the inertia of microgrid system, the strong coupling and low precision always limit its popularization and application. Therefore, a novel virtual inertia control strategy is proposed in this paper. Combining with the potential inertia advantages of virtual synchronous generator (VSG) technology, the poor compatibility between the virtual inertia principle and the energy storage control algorithm is analyzed in detail. In order to improve the control precision, this paper focuses on the analysis of frequency response characteristics of alternating current (ac) side and then regulates the ac frequency more directly and accurately by the virtual inertia generated from the energy storage device and the grid-connected inverter. Thus, additional droop characteristic, particular control algorithm of energy storage device, and power given module are designed, respectively, to make the system provide virtual inertia power support actively under multi disturbance operation. The novel virtual inertia control strategy can effectively deal with all kinds of wind speed and ac load mutation and restrain the frequency variation on ac side. Finally, the correctness and feasibility of the proposed scheme are verified by the simulation results.","['Rotors', 'Microgrids', 'Energy storage', 'Generators', 'Inverters', 'Kinetic energy', 'Frequency control']","['Virtual synchronous generator', 'virtual inertia', 'energy storage device', 'frequency stability', 'microgrid']"
"Recently, with the tremendous development of crypto-currencies, distributed ledger technology (DLT) (e.g., blockchain) has attracted significant attention. The traditional Internet was originally design to handle the exchange of information. With DLT, we will have the Internet of value. Although, DLT has a great potential to create new foundations for our economic and social systems, the existing DLT has a number of drawbacks (e.g., scalability) that prevent it from being used as a generic platform for distributed ledger across the globe. In this paper, we present a novel virtualization approach to address the challenges in the existing DLT systems. Specifically, in the proposed virtualization for DLT (vDLT), the underlying resources (e.g., hardware, compute, storage, network, and so on) are abstracted. By providing a logical view of resources, vDLT can significantly improve the performance, facilitate system evolution, and simplify DLT management and configuration. Several use cases of vDLT are presented to illustrate the effectiveness of the proposed vDLT.","['Virtualization', 'Internet', 'Computer architecture', 'Hardware', 'Software', 'Cryptography']","['Distributed ledger technology (DLT)', 'blockchain', 'directed acyclic graph (DAG)', 'virtualization']"
"The post-pandemic future will offer tremendous opportunity and challenge from transformation of the human experience linking physical, digital and biological worlds: 6G should be based on a new architecture to fully realize the vision to connect the worlds. We explore several novel architecture concepts for the 6G era driven by a decomposition of the architecture into platform, functions, orchestration and specialization aspects. With 6G, we associate an open, scalable, elastic, and platform agnostic het-cloud, with converged applications and services decomposed into micro-services and serverless functions, specialized architecture for extreme attributes, as well as open service orchestration architecture. Key attributes and characteristics of the associated architectural scenarios are described. At the air-interface level, 6G is expected to encompass use of sub-Terahertz spectrum and new spectrum sharing technologies, air-interface design optimized by AI/ML techniques, integration of radio sensing with communication, and meeting extreme requirements on latency, reliability and synchronization. Fully realizing the benefits of these advances in radio technology will also call for innovations in 6G network architecture as described.","['Computer architecture', 'Cloud computing', '5G mobile communication', 'Sensors', 'Microprocessors', 'Technological innovation', 'Industries']","['6G', 'architecture', 'B5G', 'cellular communication', 'convergence', 'orchestration', 'sub-networks', 'wireless networks']"
"Internet of Things security is attracting a growing attention from both academic and industry communities. Indeed, IoT devices are prone to various security attacks varying from Denial of Service (DoS) to network intrusion and data leakage. This paper presents a novel machine learning (ML) based security framework that automatically copes with the expanding security aspects related to IoT domain. This framework leverages both Software Defined Networking (SDN) and Network Function Virtualization (NFV) enablers for mitigating different threats. This AI framework combines monitoring agent and AI-based reaction agent that use ML-Models divided into network patterns analysis, along with anomaly-based intrusion detection in IoT systems. The framework exploits the supervised learning, distributed data mining system and neural network for achieving its goals. Experiments results demonstrate the efficiency of the proposed scheme. In particular, the distribution of the attacks using the data mining approach is highly successful in detecting the attacks with high performance and low cost. Regarding our anomaly-based intrusion detection system (IDS) for IoT, we have evaluated the experiment in a real Smart building scenario using one-class SVM. The detection accuracy of anomalies achieved 99.71%. A feasibility study is conducted to identify the current potential solutions to be adopted and to promote the research towards the open challenges.","['Machine learning', 'Intrusion detection', 'Internet of Things', 'Computer security', 'Software']","['Internet of Things', 'security', 'artificial intelligence', 'SDN', 'NFV', 'orchestration and MANO']"
"The Industrial Internet of Things (IIoT) brings together many sensors, machines, industrial applications, databases, services, and people at work. The IIoT is improving our lives in several ways including smarter cities, agriculture, and e-healthcare, etc. Although the IIoT shares several characteristics with the consumer IoT, different cybersecurity mechanisms are adopted for both networks. Unlike consumer IoT solutions that are used by an individual user for a single purpose, IIoT solutions tend to be integrated into larger operational systems. As a result, IIoT security solutions require additional planning and awareness to ensure the security and privacy of the system. In this paper, different cybersecurity attacks such as denial of service (DoS), malicious operation, malicious control, data type probing, spying, scan, and wrong setup are predicted by applying machine learning techniques. To predict the aforementioned attacks, a novel lightweight random neural network (RaNN)-based prediction model has been proposed in this article. To investigate the performance of the RaNN-based prediction model, several evaluation parameters such as accuracy, precision, recall, and F1 score were calculated and compared with the traditional artificial neural network (ANN), support vector machine (SVM) and decision tree (DT). The evaluation results show that the proposed RaNN model achieves an accuracy of 99.20% for a learning rate of 0.01, with a prediction time of 34.51 milliseconds. Other performance parameters such as the precision, recall, and F1 score were 99.11%, 99.13%, and 99.20%, respectively. The proposed scheme improves the attack detection accuracy by an average of 5.65% compared to that of state-of-the-art machine learning schemes for IoT security.","['Neural networks', 'Machine learning', 'Internet of Things', 'Support vector machines', 'Computer security', 'Industries']","['Artificial neural network', 'cybersecurity', 'industrial Internet of Things', 'random neural network', 'support vector machine']"
"Among the tenets of Smart Manufacturing (SM) or Industry 4.0 (I4.0), digital twin (DT), which represents the capabilities of virtual representations of components and systems, has been cited as the biggest technology trend disrupting engineering and design today. DTs have been in use for years in areas such as model-based process control and predictive maintenance, however moving forward a framework is needed that will support the expected pervasiveness of DT technology in the evolution of SM or I4.0. A set of requirements for a DT framework has been derived from analysis of DT definitions, DTs in use today, expected DT applications in the near future, and longer-term DT trends and the DT vision in SM. These requirements include elements of re-usability, interoperability, interchangeability, maintainability, extensibility, and autonomy across the entire DT lifecycle. A baseline framework for DT technology has been developed that addresses many aspects of these requirements and enables the addressing of the requirements more fully through additional specification. The baseline framework includes a definition of a DT and an object-oriented (O-O) architecture for DTs that defines generalization, aggregation and instantiation of DT classes. Case studies using and extending the baseline framework illustrate its advantages in supporting DT solutions and trends in SM.","['Digital twin', 'Market research', 'Industries', 'Smart manufacturing', 'Process control', 'Predictive models']","['Digital twin', 'industry 40', 'modeling', 'prediction', 'smart manufacturing']"
"Internet of Things (IoT) is an integration of the Sensor, Embedded, Computing, and Communication technologies. The purpose of the IoT is to provide seamless services to anything, anytime at any place. IoT technologies play a crucial role everywhere, which brings the fourth revolution of disruptive technologies after the internet and Information and Communication Technology (ICT). The Research & Development community has predicted that the impact of IoT will be more than the internet and ICT on society, which improves the well-being of society and industries. Addressing the predominant system-level design aspects like energy efficiency, robustness, scalability, interoperability, and security issues result in the use of a potential IoT system. This paper presents the current state of art of the functional pillars of IoT and its emerging applications to motivate academicians and researches to develop real-time, energy-efficient, scalable, reliable, and secure IoT applications. This paper summarizes the architecture of IoT, with the contemporary status of IoT architectures. Highlights of the IoT system-level issues to develop more advanced real-time IoT applications have been discussed. Millions of devices exchange information using different communication standards, and interoperability between them is a significant issue. This paper provides the current status of the communication standards and application layer protocols used in IoT with the detailed analysis. The computing paradigms like Cloud, Cloudlet, Fog, and Edge computing facilitate IoT with various services like data offloading, resource and device management, etc. In this paper, an exhaustive analysis of Edge Computing in IoT with different edge computing architectures and existing status are deliberated. The widespread adoption of IoT in society has resulted in privacy and security issues. This paper emphasizes on analyzing the security challenges, privacy and security threats, conventional mitigation techniques, and further scope for IoT security. The features like fewer memory footprints, scheduling, real-time task execution, fewer interrupt, and thread switching latency of Real-Time Operating Systems (RTOS) enables the development of time critical IoT applications. Also, this review offers the analysis of the RTOS's suitable for IoT with the current status and networking stack. Finally, open research issues in IoT system development are discussed.","['Internet of Things', 'Security', 'Computer architecture', 'Cloud computing', 'Protocols', 'Communication standards', 'Privacy']","['IoT', 'pillars of IoT', 'emerging IoT applications', 'IoT application requirements', 'IoT architecture', 'IoT application layer protocols', 'computing paradigms (edge fog cloudlets & cloud)', 'privacy & security', 'platforms for IoT']"
"Two turn-key surface potential-based compact models are developed to simulate multigate transistors for integrated circuit (IC) designs. The BSIM-CMG (common-multigate) model is developed to simulate double-, triple-, and all-around-gate FinFETs and it is selected as the world's first industry-standard compact model for the FinFET. The BSIM-IMG (independent-multigate) model is developed for independent double-gate, ultrathin body (UTB) transistors, capturing the dynamic threshold voltage adjustment with back gate bias. Starting from long-channel devices, the basic models are first obtained using a Poisson-carrier transport approach. The basic models agree with the results of numerical two-dimensional device simulators. The real-device effects then augment the basic models. All the important real-device effects, such as short-channel effects (SCEs), quantum mechanical confinement effects, mobility degradation, and parasitics are included in the models. BSIM-CMG and BSIM-IMG have been validated with hardware silicon-based data from multiple technologies. The developed models also meet the stringent quality assurance tests expected of production level models.","['Integrated circuit modeling', 'FinFETs', 'Logic gates', 'Computational modeling', 'Integrated circuits', 'MOSFETs', 'Transistors', 'Double-gate FETs']","['Double-gate FET', 'FinFET', 'integrated circuit modeling', 'MOSFET compact model', 'RF FinFET', 'short-channel effects', 'SPICE', 'triple-gate FET', 'UTB-SOI', 'UTBB-SOI']"
"In this paper, a multi-objective, multi-level model is proposed for active distribution system expansion planning with high-penetration renewable energy sources (RESs) and energy storage systems (ESSs). To optimize the planning of RESs, ESSs, and distribution networks cooperatively, a three-level optimization method is adopted based on the leader–follower strategy of hierarchic optimizations. In this model, the upper level and the middle-level serve to model the planning problems from different perspectives of multi-stakeholders; the lower level serves to model the operation aspect of ESSs. The multi-level model enables us to integrate operation optimization into a planning model and achieve the collaborative optimization of them in different time-scales. The multi-scenario tools and K-means clustering are adopted to deal with the uncertainties and capture the time-variable nature of RESs and load demand. In order to balance the multiple objectives of costs reduction, reliability improvement, and RES penetration promotion, a modified Pareto-based particle swarm optimization is employed to solve the proposed optimization problem. Finally, results obtained by case studies are presented and discussed, where the availability and the effectiveness of the proposed planning model are verified.","['Planning', 'Indexes', 'Optimization', 'Load modeling', 'Renewable energy sources', 'Energy storage', 'Reactive power']","['Active distribution system', 'multi-level optimization', 'Pareto optimization', 'distribution network planning', 'renewable energy source']"
"This paper presents a novel algorithm for the estimation of heart rate variability (HRV) features using 24-GHz continuous-wave Doppler radar with quadrature architecture. The proposed algorithm combines frequency and time domain analysis for high-accuracy estimation of beat-to-beat intervals (BBIs). Initially, band pass filtered in-phase (I) and quadrature (Q) radar components are fused into a single combined signal that contains information on the heartbeats. Its frequency domain analysis is used for coarse heart rate estimation. At the same time, the combined signal is processed using a filter bank containing narrowband band pass filters with different center frequencies. One of the band pass filter outputs is selected as the valid output based on the coarse heart rate estimation. Zero crossings in the resulting filter bank output signal represent heartbeats that are used to extract the BBIs. Finally, four HRV features are calculated from the BBIs. The algorithm is tested on real data obtained from recordings on ten human subjects. The mean relative error of extracted BBIs compared to electrocardiogram (ECG) measurement is in the 1.02-2.07% range. Furthermore, two time-domain and two frequency domain HRV features were calculated from the BBIs. The obtained results show a high level of agreement between radar-extracted and ECG-extracted HRV features. Low computation complexity makes this algorithm suitable for real-time monitoring.","['Doppler radar', 'Heart rate variability', 'Estimation', 'Heart beat', 'Feature extraction', 'Real-time systems']","['Band pass filters', 'beat-to-beat intervals (BBI)', 'chirp Z-transform', 'Doppler radar', 'frequency domain analysis', 'heart rate variability (HRV)', 'noncontact vital signs monitoring', 'real-time processing']"
"Wireless networks have evolved from 1G to 4G networks, allowing smart devices to become important tools in daily life. The 5G network is a revolutionary technology that can change consumers' Internet use habits, as it creates a truly wireless environment. It is faster, with better quality, and is more secure. Most importantly, users can truly use network services anytime, anywhere. With increasing demand, the use of bandwidth and frequency spectrum resources is beyond expectations. This paper found that the frequency spectrum and network information have considerable relevance; thus, spectrum utilization and channel flow interactions should be simultaneously considered. We considered that software defined radio (SDR) and software defined networks (SDNs) are the best solution. We propose a cross-layer architecture combining SDR and SDN characteristics. As the simulation evaluation results suggest, the proposed architecture can effectively use the frequency spectrum and considerably enhance network performance. Based on the results, suggestions are proposed for follow-up studies on the proposed architecture.","['Bandwidth', 'Hardware', 'Protocols', 'Control systems', 'Monitoring', 'Software radio', 'Computer architecture']","['Fifth generation network', 'software defined networks', 'software defined radio']"
"Internet of Things (IoT) technology is prospering and entering every part of our lives, be it education, home, vehicles, or healthcare. With the increase in the number of connected devices, several challenges are also coming up with IoT technology: heterogeneity, scalability, quality of service, security requirements, and many more. Security management takes a back seat in IoT because of cost, size, and power. It poses a significant risk as lack of security makes users skeptical towards using IoT devices. This, in turn, makes IoT vulnerable to security attacks, ultimately causing enormous financial and reputational losses. It makes up for an urgent need to assess present security risks and discuss the upcoming challenges to be ready to face the same. The undertaken study is a multi-fold survey of different security issues present in IoT layers: perception layer, network layer, support layer, application layer, with further focus on Distributed Denial of Service (DDoS) attacks. DDoS attacks are significant threats for the cyber world because of their potential to bring down the victims. Different types of DDoS attacks, DDoS attacks in IoT devices, impacts of DDoS attacks, and solutions for mitigation are discussed in detail. The presented review work compares Intrusion Detection and Prevention models for mitigating DDoS attacks and focuses on Intrusion Detection models. Furthermore, the classification of Intrusion Detection Systems, different anomaly detection techniques, different Intrusion Detection System models based on datasets, various machine learning and deep learning techniques for data pre-processing and malware detection has been discussed. In the end, a broader perspective has been envisioned while discussing research challenges, its proposed solutions, and future visions.","['Internet of Things', 'Security', 'Intrusion detection', 'Denial-of-service attack', 'Systematics', 'Deep learning', 'Machine vision']","['Anomaly detection', 'DDoS attacks', 'deep learning', 'machine learning', 'Internet of Things', 'intrusion detection system']"
"Unmanned aerial vehicle (UAV) and intelligent reflecting surface (IRS) are anticipated to be widely applied for improving the spectrum and energy efficiency in the forthcoming wireless communication systems. To take full advantages of IRS-assisted UAV system, both beamforming and UAV's trajectory should be optimally designed. In this paper, we consider a challenging scenario where there are one UAV and several IRSs. For the IRSs-assisted UAV system, we formulate the problem as maximizing the received power at the ground user by jointly optimizing active beamforming at the UAV, passive beamforming at the IRSs, and UAV's trajectory over a given flying time. An efficient framework is proposed so that the joint optimization problem can be decomposed into three subproblems, which can be iteratively optimized individually. In particular, a closed-form expression is derived for updating the phase shifts of the reflecting elements, which helps develop a low-complexity algorithm. Numerical results show that our scheme outperforms other benchmark schemes, which corroborates the feasibility and effectiveness of our proposed algorithm.","['Array signal processing', 'Unmanned aerial vehicles', 'Wireless communication', 'Trajectory optimization', 'Downlink']","['UAV communication', 'intelligent reflecting surface', 'beamforming', 'trajectory optimization']"
"Factories use many manufacturing processes that consume a lot of energy and highly contribute to greenhouse gas emissions. The introduction of the concept of Industrial Internet in USA and Industry 4.0 in Europe offers many opportunities to reduce energy consumption in these factories. Introducing and utilizing smart techniques for the applications pertinent to manufacturing processes within the Industry 4.0 domain can offer many benefits for reducing energy consumption in smart factories. This paper investigates and discusses these opportunities and benefits. This paper also discusses the roles of Industry 4.0 technologies in enabling these opportunities. Consequently, introducing these capabilities will help significantly reduce both production costs and greenhouse gas emissions. This paper then provides a benefit analysis that shows the advantages of such leverage. In addition, this paper offers an enabling architecture and its components that include a cyber-physical system manufacturing services' layer, a fog manufacturing services' layer, a cloud manufacturing services' layer, and a blockchain-based service-oriented middleware to support such opportunities.","['Industries', 'Manufacturing processes', 'Smart manufacturing', 'Energy efficiency', 'Energy consumption']","['Industry 4.0', 'Industrial Internet', 'energy efficiency', 'smart factory', 'cyber-physical system', 'fog computing', 'cloud computing', 'blockchain', 'service-oriented middleware']"
"Coordinated multi-point (CoMP) is a key feature for mitigating inter-cell interference, improve system throughput, and cell edge performance. However, CoMP implementation requires complex beamforming/scheduling design, increased backhaul bandwidth, additional pilot overhead, and precise synchronization. Cooperation needs to be limited to a few cells only due to this imposed overhead and complexity. Hence, small CoMP clusters will need to be formed in the network. In this paper, we first present a self-organizing, user-centric CoMP clustering algorithm in a control/data plane separation architecture, proposed for 5G to maximize spectral efficiency (SE) for a given maximum cluster size. We further utilize this clustering algorithm and introduce a novel two-stage re-clustering algorithm to reduce high load on cells in hotspot areas and improve user satisfaction. Stage-1 of the algorithm utilizes maximum cluster size metric to introduce additional capacity in the system. A novel re-clustering algorithm is introduced in stage-2 to distribute load from highly loaded cells to neighboring cells with less load for multi-user joint transmission CoMP case. We show that unsatisfied users due to high load can be significantly reduced with minimal impact on SE.","['Computer architecture', 'Microprocessors', 'Clustering algorithms', 'ALgorithm design and analysis', 'Bandwidth allocation', 'Inter-cell Interference', 'Throughput', 'Load management']","['Cooperative communication', 'mobile communication', 'clustering algorithms', 'cellular networks']"
"As a paradigm to recover unknown entries of a matrix from partial observations, low-rank matrix completion (LRMC) has generated a great deal of interest. Over the years, there have been lots of works on this topic, but it might not be easy to grasp the essential knowledge from these studies. This is mainly because many of these works are highly theoretical or a proposal of new LRMC technique. In this paper, we give a contemporary survey on LRMC. In order to provide a better view, insight, and understanding of potentials and limitations of the LRMC, we present early scattered results in a structured and accessible way. Specifically, we classify the state-of-the-art LRMC techniques into two main categories and then explain each category in detail. We next discuss the issues to be considered when one considers using the LRMC techniques. These include intrinsic properties required for the matrix recovery and how to exploit a special structure in the LRMC design. We also discuss the convolutional neural network (CNN)-based LRMC algorithms exploiting the graph structure of a low-rank matrix. Furthermore, we present the recovery performance and the computational complexity of state-of-the-art LRMC techniques. Our hope is that this paper will serve as a useful guide for practitioners and non-experts to catch the gist of the LRMC.","['Motion pictures', 'Euclidean distance', 'Image reconstruction', 'Data centers', 'Minimization', 'Radio communication']","['Low-rank matrices', 'matrix completion', 'recommendation system', 'nuclear norm minimization', 'graph model']"
"A unified and reconfigurable multifunctional transceiver for future integrated data-fusion services of radar sensing and radio communication (RadCom) is studied and developed in this paper. This proposed alternative of the state-of-the-art architectures presents an unprecedented integration of all radar sensing and RadCom functions together in a time-division platform. Furthermore, it is capable of offering a positioning function of both moving and static objects with an enhanced resolution in ranging in addition to providing a greater capability of data communication. The design and the performance incompatibilities between radar and radio systems are explored and investigated. A systematic top-bottom approach is presented, which involves the step-by-step methodology, building block design considerations, and the system level simulation. With the purpose of validating the proposed scheme, a low-frequency prototype around the FCC-commissioned dedicated short range communication (DSRC) band is developed, and its performance is evaluated. Since such a unified transceiver can find applications in intelligent transportation infrastructures, the system demonstrator is designed and examined according to the desired specifications of future automotive radar networks. Through various system level measurements, the proposed scheme has demonstrated attractive features in connection with both radar and radio functions. With the radar mode, the added ability of angle detection and the improved range resolution against the previously demonstrated version make the system suitable for driving assistance applications. With the radio mode, the system demonstrator has proved a great capability of communication at a data rate of 25 Mb/s.","['Transceivers', 'Sensors', 'Radio communication', 'Radar applications', 'Distance measurement', 'Data communication', 'Radar sensing', 'Short range communication', 'Data fusion', 'Data communication', 'Intelligent transportation systems', 'Intelligent vehicles']","['Intelligent transportation system (ITS)', 'multifunctional transceiver', 'software-defined system', 'positioning technique', 'radar sensing', 'radio communication', 'RF vehicular technology']"
"In this paper, improved single- and multi-objective Harris Hawks Optimization algorithms, called IHHO and MOIHHO, respectively are proposed and applied for determining the optimal placement of distribution generation (DG) in the radial distribution systems. Harris Hawks optimizer (HHO) is a new inspired meta-heuristic optimization technique that is mainly based on the intelligence behavior of the Harris hawks in chasing prey. The IHHO and MOIHHO are applied for determining the optimal size and location of DG at different operating power factors (p.f) with the aim of minimizing the total active power loss, reducing the voltage deviation (VD), and increasing the voltage stability index (VSI) considering the operational constraints of distribution system. In IHHO, the performance of the conventional HHO algorithm is improved using the rabbit location instead of the random location. In MOIHHO, grey relation analysis is applied for identifying the best compromise solution among the non-dominance Pareto solutions. To verify the effectiveness of the proposed algorithms, IEEE 33-bus and IEEE 69-bus radial distribution systems are used, and the obtained results are compared with those obtained by other optimization techniques. The results prove the efficiency of the proposed algorithms in terms of best solutions obtained so far for the single- and multi-objective scenarios.","['Optimization', 'Rabbits', 'Linear programming', 'Resource management', 'Indexes', 'Genetic algorithms', 'Stability criteria']","['Harris hawks optimizer', 'single- and multi-objective optimization', 'DG placement', 'distribution systems', 'power loss reduction', 'voltage deviation', 'voltage stability index']"
"An autonomous underwater vehicle (AUV) is an economical and safe tool that is well-suited for search, investigation, identification, and salvage operations on the sea floor. Path planning technology, which primarily includes modeling methods and path search algorithms, is an important technology for AUVs. In recent years, the AUV path planning technology has rapidly developed. Compared with land robots, AUVs must endure complex underwater environments and consider various factors, such as currents, water pressure, and topography. Challenges exist in terms of online obstacle avoidance, three-dimensional environment path planning, and the robustness of the algorithms. Adapting a complex environment and finding a suitable path planning method comprise the main problem that must be solved. In this paper, we summarize the principles, advantages, and disadvantages of modeling and path search technologies for AUVs. The most prominent feature of this paper is to summarize the improvement methods of various technical shortcomings and improve the original methods, such as dynamic obstacle avoidance, optimization path, coverage, and processing speed. In addition to summarizing the characteristics of each algorithm, this paper intuitively demonstrates the experimental environment, the real-time nature, the path planning range of the AUV, and so on. We also discuss the application scenarios of various modeling and path search technologies for AUVs. In addition, we discuss the challenges of AUVs and the direction of future research.","['Path planning', 'Oceans', 'Solid modeling', 'Heuristic algorithms', 'Computational modeling', 'Three-dimensional displays', 'Planning']","['AUV', 'path planning', 'model building', 'path search']"
"The face, an important part of the body, conveys a lot of information. When a driver is in a state of fatigue, the facial expressions, e.g., the frequency of blinking and yawning, are different from those in the normal state. In this paper, we propose a system called DriCare, which detects the drivers' fatigue status, such as yawning, blinking, and duration of eye closure, using video images, without equipping their bodies with devices. Owing to the shortcomings of previous algorithms, we introduce a new face-tracking algorithm to improve the tracking accuracy. Further, we designed a new detection method for facial regions based on 68 key points. Then we use these facial regions to evaluate the drivers' state. By combining the features of the eyes and mouth, DriCare can alert the driver using a fatigue warning. The experimental results showed that DriCare achieved around 92% accuracy.","['Vehicles', 'Fatigue', 'Face', 'Target tracking', 'Face recognition', 'Real-time systems', 'Correlation']","['convolutional neural network', 'fatigue detection', 'feature location', 'face tracking']"
"Similar to all mobile communication networks, synchronization in the time-frequency domain is a fundamental step that allows a fifth-generation (5G) new radio (NR) user equipment (UE) to properly receive and transmit its data. Due to the wide range of frequencies that are defined for the 5G NR systems, the corresponding synchronization procedure becomes critical and presents many challenges, especially for the applications that would need accurate oscillators to reduce the large values of the frequency offset. In this paper, we present and detail the 5G NR physical layer. Then, we describe the required synchronization procedure for 5G NR. And finally, we present the main challenges and issues within the 5G NR synchronization.","['5G mobile communication', 'OFDM', 'Synchronization', 'Amplitude modulation', 'Physical layer', '3GPP', 'Time-frequency analysis']","['5G NR systems', 'beam management', 'physical layer', 'frequency offset', 'time offset', 'synchronization procedure']"
"The interest in fractional-order (FO) control can be traced back to the late nineteenth century. The growing tendency towards using fractional-order proportional-integral-derivative (FOPID) control has been fueled mainly by the fact that these controllers have additional “tuning knobs” that allow coherent adjustment of the dynamics of control systems. For instance, in certain cases, the capacity for additional frequency response shaping gives rise to the generation of control laws that lead to superior performance of control loops. These fractional-order control laws may allow fulfilling intricate control performance requirements that are otherwise not in the span of conventional integer-order control systems. However, there are underpinning points that are rarely addressed in the literature: (1) What are the particular advantages (in concrete figures) of FOPID controllers versus conventional, integer-order (IO) PID controllers in light of the complexities arising in the implementation of the former? (2) For real-time implementation of FOPID controllers, approximations are used that are indeed equivalent to high-order linear controllers. What, then, is the benefit of using FOPID controllers? Finally, (3) What advantages are to be had from having a near-ideal fractional-order behavior in control practice? In the present paper, we attempt to address these issues by reviewing a large portion of relevant publications in the fast-growing FO control literature, outline the milestones and drawbacks, and present future perspectives for industrialization of fractional-order control. Furthermore, we comment on FOPID controller tuning methods from the perspective of seeking globally optimal tuning parameter sets and how this approach can benefit designers of industrial FOPID control. We also review some CACSD (computer-aided control system design) software toolboxes used for the design and implementation of FOPID controllers. Finally, we draw conclusions and formulate suggestions for future research.","['Patents', 'Technological innovation', 'Process control', 'Tools', 'Control systems', 'PD control', 'Tuning']","['Fractional calculus', 'fractional-order PID control', 'industrial applications', 'frequency-domain analysis', 'optimal tuning', 'fractional control implementation']"
"The diversification of wireless network traffic attack characteristics has led to the problems what traditional intrusion detection technology with high false positive rate, low detection efficiency, and poor generalization ability. In order to enhance the security and improve the detection ability of malicious intrusion behavior in a wireless network, this paper proposes a wireless network intrusion detection method based on improved convolutional neural network (ICNN). First, the network traffic data is characterized and preprocessed, then modeled the network intrusion traffic data by ICNN. The low-level intrusion traffic data is abstractly represented as advanced features by CNN, which extracted autonomously the sample features, and optimizing network parameters by stochastic gradient descent algorithm to converge the model. Finally, we conducted a sample test to detect the intrusion behavior of the network. The simulation results show that the method proposed in our paper has higher detection accuracy and true positive rate together with a lower false positive rate. The test results on the test set KDDTest + in our paper show that compared with the traditional models, the detection accuracy is 8.82% and 0.51% higher than that of LeNet-5 and DBN, respectively, and the recall rate is 4.24% and 1.16% higher than that of LeNet-5 and RNN, respectively, while the false positive rate is lower than the other three types of models. It also has a big advantage compared to the IDABCNN and NIDMBCNN methods.","['Intrusion detection', 'Training', 'Convolutional neural networks', 'Feature extraction', 'Wireless networks', 'Convolution', 'Backpropagation']","['Wireless network intrusion detection', 'security', 'convolutional neural network']"
"Human facial expressions change with different states of health; therefore, a facial-expression recognition system can be beneficial to a healthcare framework. In this paper, a facial-expression recognition system is proposed to improve the service of the healthcare in a smart city. The proposed system applies a bandlet transform to a face image to extract sub-bands. Then, a weighted, center-symmetric local binary pattern is applied to each sub-band block by block. The CS-LBP histograms of the blocks are concatenated to produce a feature vector of the face image. An optional feature-selection technique selects the most dominant features, which are then fed into two classifiers: a Gaussian mixture model and a support vector machine. The scores of these classifiers are fused by weight to produce a confidence score, which is used to make decisions about the facial expression's type. Several experiments are performed using a large set of data to validate the proposed system. Experimental results show that the proposed system can recognize facial expressions with 99.95% accuracy.","['Medical services', 'Databases', 'Smart cities', 'Speech', 'Emotion recognition', 'Support vector machines', 'Speech recognition']","['Smart cities', 'health monitoring', 'facial expression', 'CS-LBP', 'SVM', 'GMM', 'bandlet transform']"
"This paper presents a novel application of a grey wolf optimizer (GWO) to improve the low voltage ride through (LVRT) capability and the maximum power point tracking (MPPT) of a grid-connected permanent-magnet synchronous generator driven directly by a variable-speed wind turbine (DD-PMSG-VSWT). The LVRT capability and MPPT enhancements are achieved by the optimal tuning of eight proportional-integral (PI) controllers in the cascaded control of the machine-side converter and the grid-side inverter, simultaneously. An online optimization is used and achieved by minimizing the integral-squared error of the error inputs of the PI controllers that are controlling dc link voltage, generated real power, and terminal voltages of the PMSG and the grid. The symmetrical and asymmetrical faults for testing the optimum gain parameters are simulated and examined using PSCAD/EMTDC. The obtained results of the optimum values of the GWO algorithm are compared with those attained using the optimum values of the genetic algorithm and the simplex method.","['Voltage control', 'Wind turbines', 'Generators', 'Integrated circuit modeling', 'Optimization', 'Wind power generation', 'Genetic algorithms']","['Grey wolf optimizer', 'permanent magnet synchronous generator', 'proportional integral controller', 'grid-connection', 'wind turbine']"
"Internet of things (IoT) is revolutionizing this world with its evolving applications in various aspects of life such as sensing, healthcare, remote monitoring, and so on. Android devices and applications are working hand to hand to realize dreams of the IoT. Recently, there is a rapid increase in threats and malware attacks on Android-based devices. Moreover, due to extensive exploitation of the Android platform in the IoT devices creates a task challenging of securing such kind of malware activities. This paper presents a novel framework that combines the advantages of both machine learning techniques and blockchain technology to improve the malware detection for Android IoT devices. The proposed technique is implemented using a sequential approach, which includes clustering, classification, and blockchain. Machine learning automatically extracts the malware information using clustering and classification technique and store the information into the blockchain. Thereby, all malware information stored in the blockchain history can be communicated through the network, and therefore any latest malware can be detected effectively. The implementation of the clustering technique includes calculation of weights for each feature set, the development of parametric study for optimization and simultaneously iterative reduction of unnecessary features having small weights. The classification algorithm is implemented to extract the various features of Android malware using naive Bayes classifier. Moreover, the naive Bayes classifier is based on decision trees for extracting more important features to provide classification and regression for achieving high accuracy and robustness. Finally, our proposed framework uses the permissioned blockchain to store authentic information of extracted features in a distributed malware database blocks to increase the run-time detection of malware with more speed and accuracy, and further to announce malware information for all users.","['Malware', 'Feature extraction', 'Blockchain', 'Machine learning', 'Decision trees', 'Data mining', 'Clustering algorithms']","['Android malware detection', 'blockchain', 'Internet of Things (IoT)', 'clustering', 'secure machine learning']"
"Traditional traceability system has problems of centralized management, opaque information, untrustworthy data, and easy generation of information islands. To solve the above problems, this paper designs a traceability system based on blockchain technology for storage and query of product information in supply chain of agricultural products. Leveraging the characteristics of decentralization, tamper-proof and traceability of blockchain technology, the transparency and credibility of traceability information increased. A dual storage structure of “database + blockchain” on-chain and off-chain traceability information is constructed to reduce load pressure of the chain and realize efficient information query. Blockchain technology combined with cryptography is proposed to realize the safe sharing of private information in the blockchain network. In addition, we design a reputation-based smart contract to incentivize network nodes to upload traceability data. Furthermore, we provide performance analysis and practical application, the results show that our system improves the query efficiency and the security of private information, guarantees the authenticity and reliability of data in supply chain management, and meets actual application requirements.","['Blockchain', 'Agricultural products', 'Supply chains', 'Safety', 'Production', 'Smart contracts', 'Memory']","['Blockchain', 'traceability', 'on-chain and off-chain', 'agricultural products']"
"Blockchain technology has been known as the underlying technology of cryptocurrencies, but nowadays it is further considered as a functional technology for improving existing technologies and creating new applications previously never practical. In this paper, we are focused on utilizing blockchain technology to introduce a new ID as a service (IDaaS) for digital identity management. The proposed blockchain-based ID as a service (BIDaaS) is explained with one practical example that shows how the proposed BIDaaS works as an identity and authentication management infrastructure for mobile users of a mobile telecommunication company.","['Mobile communication', 'Authentication', 'Public key', 'Peer-to-peer computing', 'Companies', 'Bitcoin']","['Blockchain', 'IDaaS', 'identity', 'authentication']"
"We propose channel charting (CC), a novel framework in which a multi-antenna network element learns a chart of the radio geometry in its surrounding area. The channel chart captures the local spatial geometry of the area so that points that are close in space will also be close in the channel chart and vice versa. CC works in a fully unsupervised manner, i.e., learning is only based on channel state information (CSI) that is passively collected at a single point in space, but from multiple transmit locations in the area over time. The method then extracts channel features that characterize large-scale fading properties of the wireless channel. Finally, the channel charts are generated with tools from dimensionality reduction, manifold learning, and deep neural networks. The network element performing CC may be, for example, a multi-antenna base-station in a cellular system and the charted area in the served cell. Logical relationships related to the position and movement of a transmitter, e.g., a user equipment (UE), in the cell, can then be directly deduced from comparing measured radio channel characteristics to the channel chart. The unsupervised nature of CC enables a range of new applications in UE localization, network planning, user scheduling, multipoint connectivity, hand-over, cell search, user grouping, and other cognitive tasks that rely on CSI and UE movement relative to the base station, without the need of information from global navigation satellite systems.","['Geometry', 'Manifolds', 'Transmitters', 'Feature extraction', 'Wireless communication', 'Dimensionality reduction', 'Global navigation satellite system']","['Autoencoders', 'deep learning', 'dimensionality reduction', 'localization', 'machine learning', 'manifold learning massive multiple-input multiple-output (MIMO)', 'Sammon’s mapping']"
"Dual active bridge (DAB) dc-dc converters have several attractive features including auto-adjust bidirectional power flow, wide voltage gain range, and zero voltage switching (ZVS)-on capability. Various applications based on DAB including solid-state transformer in power grids and traction, energy storage system, and electric vehicle on-board chargers have been proposed by academics. Nevertheless, industrial applications based on DABs are still seldom mainly due to the circulating current and loss of ZVS problems under certain load and voltage gain conditions. There is an intensive research effort underway to solve these problems recently. This paper presents the state-of-the-art view in the cause of circulating current and loss of ZVS and surveys the solutions to these problems.","['Bridge circuits', 'Zero voltage switching', 'Switches', 'Switching loss', 'Inductors', 'Voltage control', 'Energy storage']","['Circulating current', 'dc-dc converter', 'dual active bridge', 'reactive power', 'ZVS-on']"
"With the exponential growth in the number of insecure devices, the impact of Distributed Denial-of-Service (DDoS) attacks is growing rapidly. Existing DDoS mitigation schemes are facing obstacles due to low flexibility, lack of resources, and high cost. The new emerging technologies, such as blockchain, introduce new opportunities for low-cost, efficient and flexible DDoS attacks mitigation across multiple domains. In this paper, we propose a blockchain-based approach, called Cochain-SC, which combines two levels of mitigation, intra-domain and inter-domain DDoS mitigation. For intra-domain, we propose an effective DDoS mitigation method in the context of software defined networks (SDN); it consists of three schemes: (1) Intra Entropy-based scheme (I-ES) to measure, using sFlow, the randomness of data inside the domain; (2) Intra Bayes-based scheme (I-BS) to classify, based on entropy values, illegitimate flows; and (3) Intra-domain Mitigation (I-DM) scheme to effectively mitigate illegitimate flows inside the domain. For inter-domain, we propose a collaborative DDoS mitigation scheme based on blockchain; it uses the concept of smart contracts (i.e., Ethereum's smart contracts) to facilitate the collaboration among SDN-based domains (i.e., Autonomous System: AS) to mitigate DDoS attacks. For this aim, we design a novel and secure scheme that allows multiple SDN-based domains to securely collaborate and transfer attack information in a decentralized manner. Combining intra- and inter-domain DDoS mitigation, Cochain-SC allows an efficient mitigation along the path of an ongoing attack and an effective mitigation near the origin of the attack. This allows reducing the enormous cost of forwarding packets, across multiple domains, which consist mostly of useless amplified attack traffic. To the best of our knowledge, Cochain-SC is the first scheme that proposes to deal with both intra-domain and inter-domain DDoS attacks mitigation combining SDN, blockchain and smart contract. The implementation of Cochain-SC is deployed on Ethereum official test network Ropsten. Moreover, we conducted extensive experiments to evaluate our proposed approach; the experimental results show that Cochain-SC achieves flexibility, efficiency, security, cost effectiveness, and high accuracy in detecting illegitimate flows, making it a promising approach to mitigate DDoS attacks.","['Computer crime', 'Collaboration', 'Blockchain', 'Smart contracts', 'Entropy']","['DDoS', 'entropy', 'Bayes classifier', 'SDN', 'intra-domain mitigation', 'inter-domain collaboration', 'blockchain technology', 'smart contracts']"
"Mobile edge computing (MEC) is expected to be an effective solution to deliver virtual reality (VR) videos over wireless networks. In contrast to previous computation-constrained MEC, which reduces the computation-resource consumption at the mobile device by increasing the communication-resource consumption, we develop a communications-constrained MEC framework to reduce communication-resource consumption by fully exploiting the computation and caching resources at the mobile VR device in this paper. Specifically, according to a task modularization, the MEC server only delivers the components which have not been stored in the VR device, and then the VR device uses the received components and other cached components to construct the task, yielding low communication cost but high delay. The MEC server also computes the task by itself to reduce the delay, however, it consumes more communication-resource due to the delivery of entire task. Therefore, we propose a task scheduling strategy to decide which computation model should the MEC server operates to minimize the communication-resource consumption under the delay constraint. Finally, the tradeoffs among communications, computing, and caching are also discussed, and we analytically find that given a target communication-resource consumption, the transmission rate is inversely proportional to the computing ability of mobile VR device.","['Task analysis', 'Servers', 'Mobile handsets', 'Videos', 'Delays', 'Processor scheduling', 'Wireless communication']","['Mobile edge computing', 'virtual reality', 'communications-computing-caching tradeoffs']"
"Under the background of global energy conservation, the energy hub (EH)-based integrated energy system is becoming the transition direction of future energy structure. In this paper, we study the cooperative economic scheduling problem for multiple neighboring integrated energy systems on the basis of EH. Different with the traditional non-cooperative mode where each EH operates individually, these EHs constitute a cooperative community and can share energy among them. Considering the autonomy and self-interest of different EHs, the coordinated management problem is modeled as a bargaining cooperative game, where involved EHs will bargain with each other about the exchanged energy and the associated payments. The bargaining solution can achieve a fair and Pareto-optimal balance among the objective functions of different EHs. A distributed optimization is applied to find the bargaining solution of the cooperative system, to guarantee the autonomous scheduling and information privacy of EHs. Numerical studies demonstrate the effectiveness of the bargaining-based cooperative economic scheduling framework, and also show the improvement of benefits of the community system.","['Cogeneration', 'Natural gas', 'Thermal loading', 'Games', 'Furnaces', 'Economics', 'Energy storage']","['Cooperative game', 'distributed approach', 'energy hub', 'energy trading', 'multiple energy system', 'Nash bargaining']"
"Information and communication technologies are permeating all aspects of industrial and manufacturing systems, expediting the generation of large volumes of industrial data. This paper surveys the recent literature on data management as it applies to networked industrial environments and identifies several open research challenges for the future. As a first step, we extract important data properties (volume, variety, traffic, and criticality) and identify the corresponding data enabling technologies of diverse fundamental industrial use cases, based on practical applications. Second, we provide a detailed outline of recent industrial architectural designs with respect to their data management philosophy (data presence, data coordination, and data computation) and the extent of their distributiveness. Then, we conduct a holistic survey of the recent literature from which we derive a taxonomy of the latest advances in industrial data enabling technologies and data centric services, spanning all the way from the field level deep in the physical deployments, up to the cloud and applications level. Finally, motivated by the rich conclusions of this critical analysis, we identify interesting open challenges for future research. The concepts presented in this paper thematically cover the largest part of the industrial automation pyramid layers. Our approach is multidisciplinary, as the selected publications were drawn from two fields; the communications, networking and computation field, and the industrial, manufacturing, and automation field. This paper can help the readers to deeply understand how data management is currently applied in networked industrial environments, and select interesting open research opportunities to pursue.","['Automation', 'Manufacturing', 'Production', 'Robot sensing systems', 'Service robots']","['Data management', 'industrial networks', 'manufacturing', 'Industry 4.0']"
"To reduce the increasingly congestion in cities, it is essential for intelligent transportation system (ITS) to accurately forecast the short-term traffic flow to identify the potential congestion sites. In recent years, the emerging deep learning method has been introduced to design traffic flow predictors, such as recurrent neural network (RNN) and long short-term memory (LSTM), which has demonstrated its promising results. In this paper, different from existing work, we study the temporal convolutional network (TCN) and propose a deep learning framework based on TCN model for short-term city-wide traffic forecast to accurately capture the temporal and spatial evolution of traffic flow. Moreover, we design the model with the Taguchi method to develop an optimized structure of the TCN model, which not only reduces the number of experiments, but also yields high accuracy of forecasting results. With the real-world traffic flow data collected from highways in Birmingham City of U.K., we compare our model with four deep learning based models including LSTM models, GRU models, SAE models, DeepTrend and CNN-LSTM models in terms of the mean absolute error (MAE) and mean relative error (MRE) regarding the actual flow data. The experimental results demonstrate that our framework achieves the state-of-art performance with superior accuracy in short-term traffic flow forecasting.","['Forecasting', 'Data models', 'Deep learning', 'Predictive models', 'Urban areas', 'Training', 'Neural networks']","['Deep learning', 'temporal convolutional networks', 'short-term forecasting']"
"Personal health records (PHRs) are private and vital assets for every patient. There have been introduced many works on various aspects of managing and organizing the PHR so far. However, there is an uncertain remaining issue for the role of PHR in emergencies. In a traditional emergency access system, the patient cannot give consent to emergency staff for accessing his/her PHR. Moreover, there is no secured record management of patient's PHR, which reveals highly confidential personal information, such as what happened, when, and who has access to such information. This paper proposes an emergency access control management system (EACMS) based on permissioned blockchain hyperledger fabric and hyperledger composer. In the proposed system, we defined some rules using the smart contracts for emergency condition and time duration for the emergency access PHR data items that patient can assign some limitations for controlling the PHR permissions. We analyzed the performance of our proposed framework by implementing it through the hyperledger composer based on the response time, privacy, security, and accessibility. The experiments confirm that our framework provides better efficiency compared with the traditional emergency access system.","['Blockchain', 'Peer-to-peer computing', 'Medical services', 'Access control', 'Fabrics', 'Organizations']","['Personal health record', 'emergency access', 'access authorization', 'blockchain', 'hyperledger fabric', 'hyperledger composer', 'privacy & security']"
"Accurate electric load forecasting is critical not only in preventing wasting electricity production but also in facilitating the reasonable integration of clean energy resources. Hybridizing the variational mode decomposition (VMD) method, the chaotic mapping mechanism, and improved meta-heuristic algorithm with the support vector regression (SVR) model is crucial to preventing the premature problem and providing satisfactory forecasting accuracy. To solve the boundary handling problem of the cuckoo search (CS) algorithm in the cuckoo birds' searching processes, this investigation proposes a simple method, called the out-bound-back mechanism, to help those out-bounded cuckoo birds return to their previous (the most recent iteration) optimal location. The proposed self-recurrent (SR) mechanism, inspired from the combination of Jordan's and Elman's recurrent neural networks, is used to collect comprehensive and useful information from the training and testing data. Therefore, the self-recurrent mechanism is hybridized with the SVR-based model. Ultimately, this investigation presents the VMD-SR-SVRCBCS model, by hybridizing the VMD method, the SVR model with the self-recurrent mechanism, the Tent chaotic mapping function, the out-bound-back mechanism, and the cuckoo search algorithm. Two real-world datasets are used to demonstrate that the proposed model has greater forecasting accuracy than other models.","['Load modeling', 'Predictive models', 'Forecasting', 'Load forecasting', 'Data models', 'Birds', 'Support vector machines']","['Support vector regression', 'variational mode decomposition', 'self-recurrent mechanism', 'tent chaotic mapping function', 'out-bound-back mechanism', 'cuckoo search algorithm']"
"The emerging technology breakthrough of the Internet of Things (IoT) is expected to offer promising solutions for indoor/outdoor healthcare, which may contribute significantly to human health and well-being. In this paper, we investigated the technologies of healthcare service applications in telemedicine architecture. We aimed to resolve a series of healthcare problems on the frequent failures in telemedicine architecture through IoT solutions, particularly the failures of wearable body sensors (Tier 1) and a medical center server (Tier 3). For improved generalisability, we demonstrated an effective research approach, the fault-tolerant framework on mHealth or the so-called FTF-mHealth-IoT in the context of IoT, to resolve essential problems in current investigations on healthcare services. First, we propose a risk local triage algorithm known as the risk-level localization triage (RLLT), which can exclude the control process of patient triage from the medical center by using mHealth and can warn about failures related to wearable sensors. RLLT performs this initial step towards detecting a patient's emergency case and then identifying the healthcare service package of the risk-level. Second, according to the risk-level package, our framework can aid decision makers in hospital selection through multi-criteria decision making (MCDM). Accordingly, mHealth can connect directly with the servers of distributed hospitals to ascertain available healthcare services for the risk-level package in those hospitals. The time of arrival of the patient at the hospital (TAH) is considered for each hospital to reach a final decision and select the appropriate institution in case of medical center failure. This paper used two datasets. The first dataset involved 572 patients with chronic heart disease. Their triage levels were evaluated using our RLLT algorithm. The second dataset included hospital healthcare services with two levels of availability within distributed hospitals to show variety when testing the proposed framework. The former dataset is an actual dataset of services collected from 12 hospitals located in the capital Baghdad, which represents the maximum level of availability. The latter is an assumption dataset of the services within the 12 hospitals located in the capital Kuala Lumpur, which represents the minimum level of availability. Subsequently, the hospitals were prioritized using a unique MCDM method for estimating small power consumption, namely, the analytic hierarchy process (AHP), based on a crossover between the “healthcare services package/TAH” of each hospital and the “hospital list”. The results showed that the AHP is effective for solving hospital selection problems within mHealth. The implications of this study support the patients, organizations, and medical staff in a modern lifestyle.","['Hospitals', 'Telemedicine', 'Servers', 'Wearable sensors', 'Fault tolerance']","['Telemedicine', 'Internet of thing', 'healthcare', 'triage', 'hospital selection', 'medical centre failure']"
"High frequency and high efficiency operation is one of the premier interests in the signal and energy conversion applications. The wide bandgap GaN based devices possess superior properties and have demonstrated exceeding performance than Si or GaAs devices. In order to further exploit the potential of GaN electronics, monolithic power integration is proposed. Firstly, this paper discusses the structure and properties of GaN power devices to explain the choice of lateral integration in the view of GaN power ICs. Then the state-of-the-art performance of GaN power integration in two major application areas is reviewed, which are the microwave power amplification and DC-DC power conversion. The GaN power integration technologies in MMIC platforms are summarized in terms of the gate length, operation frequency and power added efficiency of ICs. On the other hand, the smart GaN power IC platforms have boosted the development of DC-DC power converters. Demonstrations of high frequency (>1 MHz) and high efficiency (>95 %) converters with various kinds of integration technology and topology are reviewed. Lastly novel integration schemes and methods are introduced to stimulate new thoughts on GaN power integration road.","['Gallium nitride', 'HEMTs', 'Logic gates', 'Integrated circuits', 'High frequency', 'Power conversion', 'Aluminum gallium nitride']","['GaN', 'HEMT', 'high frequency', 'power conversion', 'power integration']"
"Traditional intelligent fault diagnosis works well when the labeled training data (source domain) and unlabeled testing data (target domain) are drawn from the same distribution. However, in many real-world applications, the working conditions can vary between training and testing time. In this paper, we address the issues of intelligent fault diagnosis when the data at training and testing time do not come from the same distribution as a domain adaptation problem using domain adaptive convolutional neural networks (DACNN). Our proposed DACNN consists of three parts: a source feature extractor, a target feature extractor, and a label classifier. We adopt a two-stage training process to obtain strong fault-discriminative and domain-invariant capacity. First, we obtain fault-discriminative features by pre-training the source feature extractor with labeled source training examples to minimize the label classifier error. Then, in the domain adaptive fine-tuning stage, we train the target feature extractor to minimize the squared maximum mean discrepancy between the output of the source and target feature extractor, such that the instances sampled from the source and target domains have similar distributions after the mapping. Furthermore, to enable training efficiency in domain adaptation, the layers between the source and target feature extractors in our DACNN are partially untied during the training stage. Experiments on the bearing and gearbox fault data showed that DACNN can achieve high fault diagnosis precision and recall under different working conditions, outperforming other intelligent fault diagnosis methods. We also demonstrate the ability to visualize the learned features and the networks to better understand the reasons behind the remarkable performance of our proposed model.","['Employee welfare', 'Feature extraction', 'Fault diagnosis', 'Training', 'Testing', 'Adaptation models', 'Vibrations']","['Convolutional neural networks', 'domain adaptation', 'deep learning', 'intelligent fault diagnosis', 'transfer learning']"
"The infrastructure of wireless sensor networks (WSN) is structured in an ad-hoc manner and organized nodes reporting the events to the Base Station (BS). A WSN is integrated with smart technologies to develop fast Internet of Things (IoT) communications among different applications. Recently, many researchers proposed their solutions to optimize IoT data transmissions in an energy efficient manner with cost effective support. However, most of the solutions have focused on the design and development of static topologies and overlooked the dynamic structure of mobile sensor nodes. Furthermore, due to limited constraints of sensor nodes with open accessibility of wireless communications medium, data protection against malicious activities need to be redesign with the least network overheads. Therefore, the contribution of this article is to propose an intrusion prevention framework for mobile IoT devices with its integration to WSN so that to provide data security with improved network delivery ratio. The proposed framework is composed of two sub-components. Firstly, non-overlapping and autonomously organized clusters are generated and maintained the clusters' stability based on the uncertainty principle. Secondly, end-to-end secure and multi-hop routing paths are developed based on the blockchain architecture. The simulation results demonstrate a significant improvement when compared to existing solutions in terms of different network metrics.","['Routing', 'Wireless sensor networks', 'Robot sensing systems', 'Data security', 'Reliability', 'Blockchain']","['Blockchain', 'intrusion prevention', 'mobile IoT', 'data privacy', 'security']"
"Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML models used in the identification of anomalies. Finally, we present 22 different datasets that are applied in experiments on anomaly detection, as well as many other general datasets. In addition, we observe that unsupervised anomaly detection has been adopted by researchers more than other classification anomaly detection systems. Detection of anomalies using ML models is a promising area of research, and there are a lot of ML models that have been implemented by researchers. Therefore, we provide researchers with recommendations and guidelines based on this review.","['Anomaly detection', 'Machine learning', 'Intrusion detection', 'Systematics', 'Training', 'Bibliographies', 'Analytical models']","['Anomaly detection', 'machine learning', 'security and privacy protection']"
"Multilevel thresholding is an important approach for image segmentation which has drawn much attention during the past few years. The Tsallis entropy method is implemented for its effectiveness and simplicity. Although it is efficient and gives an excellent result in the case of bi-level thresholding, its evaluation becomes complexity when the number of thresholds increases. To overcome the problem, the metaheuristic algorithms are applied in this search area for searching the optimal thresholds. In this paper, a modified grasshopper optimization algorithm (GOA) is adopted to render multilevel Tsallis cross entropy more practical and reduce the complexity. The Levy flight algorithm is employed to modify the original GOA and balance the exploration and exploitation of the GOA. Experiments are conducted between five state-of-the-art metaheuristic algorithms and the proposed one. In addition, the proposed approach is compared with thresholding techniques depending on between-class variance (Otsu) method and the Renyi entropy function. Both real life images and plant stomata images are used in the experiments to test the performance of the algorithms involved. Qualitative experimental results show that the proposed segmentation approach has a fewer iterations and a higher segmentation accuracy.","['Image segmentation', 'Entropy', 'Optimization', 'Thresholding (Imaging)', 'Color', 'Search problems', 'Complexity theory']","['Multi-threshold color image segmentation', 'Tsallis entropy method', 'grasshopper optimization algorithm', 'Levy flight']"
"Multi-access Edge Computing (MEC) is a key solution that enables operators to open their networks to new services and IT ecosystems to leverage edge-cloud benefits in their networks and systems. Located in close proximity from the end users and connected devices, MEC provides extremely low latency and high bandwidth while always enabling applications to leverage cloud capabilities as necessary. In this article, we illustrate the integration of MEC into a current mobile networks' architecture as well as the transition mechanisms to migrate into a standard 5G network architecture. We also discuss SDN, NFV, SFC and network slicing as MEC enablers. Then, we provide a state-of-the-art study on the different approaches that optimize the MEC resources and its QoS parameters. In this regard, we classify these approaches based on the optimized resources and QoS parameters (i.e., processing, storage, memory, bandwidth, energy and latency). Finally, we propose an architectural framework for a MEC-NFV environment based on the standard SDN architecture.","['5G mobile communication', 'Network slicing', 'Computer architecture', 'Optimization', 'Quality of service', 'Edge computing', 'Bandwidth']","['5G', 'multi-access edge computing', 'network function virtualization', 'network slicing', 'service function chaining', 'software defined networking']"
"This paper develops a recent methodology based on social spider optimizer (SSO) to determine the optimal sizing of a hybrid renewable energy sources (RESs) integrated microgrid (MG). It comprises photovoltaic (PV), wind turbine (WT), battery, diesel generator (DG), and inverter. The cost of energy (COE) is proposed as fitness function. The objective of the proposed SSO is to determine three design variables which are number of PV panels, number of WT, and number of battery autonomy days such that COE is minimized. Additionally, an energy management strategy is presented. Loss of power supply probability (LPSP) is considered to confirm the reliability of operation. The selection of SSO is due to its simplicity in construction and requiring less controlling parameters. The proposed MG is installed in a remote area at Aljouf region in the northern of Kingdom of Saudi Arabia. Annual data of irradiance, wind speed, and temperature are recorded. The SSO results are compared to Harris Hawks optimizer (HHO), Grey Wolf Optimizer (GWO), Multi-Verse Optimizer (MVO), Antlion Optimizer (ALO), and Whale Optimization Algorithm (WOA). The results obtained show that the proposed approach provides the best optimal configuration of hybrid RESs compared to HHO, GWO, MVO, ALO and WOA with COE of 0.1349 /kWh and LPSP of 0.01714. Moreover, sensitivity analysis with sizing different topologies of MG including PV/Battery/DG, WT/Battery/DG, and PV/WT/Battery/DG is presented. The best COEs are obtained via SSO achieving 0.2180 /kWh for the first topology and 0.2161$/kWh for the second architecture. Furthermore, sensitivity analysis is also presented to investigate the effect of design variables on COE. The experimental results confirm the superiority of the proposed approach in designing reliable and costless microgrid.","['Microgrids', 'Batteries', 'Load modeling', 'Generators', 'Energy management', 'Reliability', 'Wind speed']","['Optimal sizing of hybrid RESs', 'microgrid', 'social spider optimization']"
"The energy consumption by non-residential consumers in China accounts for a significant proportion of the total energy consumption in the society. Thus, accurate non-residential load forecasting plays an increasingly essential role in the future grid planning and operation. In this paper, a method based on LSTM recurrent neural network is proposed to predict the load of non-residential consumers using multiple correlated sequence information. First, the k-means is employed to analyze the daily load curves of non-residential consumers, classify and mine the consumer’s energy consumption behavior patterns. Then, the Spearman correlation coefficient is applied to investigate the time correlation under multiple time series for non-residential consumers. It is found that there exist multiple related time sequences such as adjacent time points, the same time points in adjacent days, and the same day in adjacent weeks among data samples for a specific consumer. Therefore, a non-residential load forecasting framework based on multiple sequence LSTM recurrent neural networks is presented. The proposed framework is tested on a real data set, which contains 48 non-residential consumers’ energy consumption data in China, and outperforms the other load forecasting approaches. Experiment results show that this method can effectively utilize the multiple sequence information, and successfully capture the dependencies among these sequences.","['Load forecasting', 'Energy consumption', 'Correlation', 'Industries', 'Load modeling', 'Autoregressive processes', 'Recurrent neural networks']","['Short-term non-residential load forecasting', 'recurrent neural network (RNN)', 'long short-term memory (LSTM)', 'spearman correlation coefficient']"
"Highly developed drone technology enables the use of drones in a wide variety of areas. However, those drones are mainly used in the unmanned aerial vehicles. We believe that underwater drones will become a big research topic and find a market in the near future. We developed an underwater drone with a 360° panoramic camera acting as the “eye”of the drone. The designs are based on the open-source hardware and will be shared as an open-source for contributing to the innovation of manufacturing including drone. The function of the 360° panoramic camera is generated by correcting the images taken by two fisheye lenses. The underwater drone was designed by extending the Raspberry Pi compute module, the frame was designed by OpenSCAD, and the printed circuit board was designed by MakePro. As for the application of the underwater drone, we focused on fish recognition for investigating fish species in a natural lake to help protect the original environment. Fish recognition is based on deep learning, which is the biggest topic in the artificial intelligence research field today. Experimental results show that the function of the underwater drone achieved at diving in the leak automatically. The 360° panoramic images were generated correctly. Fish recognition achieved 87% accuracy by deep learning.","['Unmanned underwater vehicles', 'Drones', 'Machine learning', 'Cameras', 'Open source software', 'Image generation', 'Hardware']","['360-degree panoramic image', 'underwater-drone', 'fish recognition', 'deep learning', 'open source hardware']"
"As a kind of green, clean and renewable energy, wind power generation has been widely utilized in various countries in the world. With the rapid development of wind energy, it is also facing prominent problems. Because wind power generation is intermittent, unstable and stochastic, it has caused serious difficulties for power grid dispatch. At present, the important method to solve this problem is to predict wind speed and wind power. Grey model is suitable for uncertain systems with poor information and needs less operation data, so it can be used for wind speed and wind power prediction. However, the traditional grey system model has the disadvantage of low prediction accuracy. Therefore, firstly the GM (1,1) for wind speed prediction is improved by background value optimization in this paper. In order to comprehensively reveal the inherent uncertainty of wind speed random series, the fractional order grey system models with different orders are constructed. Secondly, in order to overcome the shortcoming of single grey model, each grey model is effectively united, and a combination prediction model based on neural network is presented. The two NWP outputs, i.e. ECMWF and GRAPES-MESO, have been added to the prediction model for reducing the uncertainty. The structure parameters of the neural network are optimized by trial and error. Thirdly, the support vector regression model is established to fit the scatter operation data of wind speed-power, and the parameters of the model are optimized by the particle swarm algorithm. Then the power prediction value is obtained by the fitted wind speed-power relationship and the corresponding result of the grey combination model for wind speed prediction. Finally, wind speed and wind power are predicted based on the actual operation data. In addition, the prediction model based on ARIMA is also constructed as a benchmark model. The results show that the proposed grey combination model improves the prediction accuracy.","['Predictive models', 'Wind power generation', 'Wind speed', 'Data models', 'Computational modeling', 'Support vector machines', 'Prediction algorithms']","['Grey model', 'background value', 'support vector regression', 'fractional order', 'particle swarm algorithm', 'wind speed prediction', 'wind power prediction', 'combination model']"
"A novel coplanar waveguide-fed rectenna with high efficiency is proposed and implemented in this paper for 2.45-GHz Bluetooth/ wireless local area network applications. The antenna has compact dimensions of 18 mm × 30 mm, which is simulated and manufactured using a low-cost FR4 substrate with a thickness of 1.6 mm. A tuning stub technique with rectangular slots is used for better impedance matching and enhancing the impedance bandwidth of the antenna with a peak gain of 5.6 dB. The proposed novel antenna for RF energy harvesting applications exhibits dipolelike radiation pattern in H-plane and omnidirectional pattern in E-plane with improved radiation efficiency. Single-stage Cockcroft-Walton rectifier with L-shaped impedance-matching network is designed in advance design system and fabricated on FR4 substrate. The dc output of the rectenna is measured as 3.24 V with a load resistance of 5 kΩ. A simulated peak conversion efficiency of 75.5% is attained, whereas the measured one is observed to be 68% with an input signal power of 5 dBm at 2.45 GHz.","['Slot antennas', 'Energy harvesting', 'Radio frequency', 'Antenna feeds', 'Bandwidth', 'Antenna measurements']","['Rectennas', 'printed antennas', 'Wi-Fi', 'WLAN', 'ultrawideband', 'wireless energy harvesting']"
"Traditional wireless sensor networks (WSNs) face the problem of a limited-energy source, typically batteries, resulting in the need for careful and effective utilization of the energy source. However, inevitable energy depletion will eventually disturb the operation of a WSN. Energy harvesting (EH) technology is acquiring particular interest, because it has the potential to provide a continuous energy supply in battery-powered WSNs. Solar energy is the most effective environmental energy for EH-WSNs because of its high energy intensity, which comes from a non-controllable source. Therefore, the prediction of future energy availability is a critical issue, as the amount of the harvestable energy may vary over time. In this paper, a novel solar energy prediction algorithm with Q-learning, called Q-learning-based solar energy prediction (QL-SEP), is proposed. Q-learning is an effective way of predicting future actions based on past observations. The distinctive feature of QL-SEP is that not only past days' observations but also the current weather conditions are considered for prediction. The performance of QL-SEP is simulated in this paper using real-world measurements obtained from a solar panel in comparison with the state-of-art approaches.","['Wireless sensor networks', 'Media Access Protocol', 'Solar energy', 'Prediction algorithms', 'Batteries', 'Energy states', 'Energy harvesting']","['Energy harvesting', 'prediction algorithms', 'solar energy', 'wireless sensor networks']"
"Thanks to advances in electric wheelchair design, persons with motor impairments due to diseases, such as amyotrophic lateral sclerosis (ALS), have tools to become more independent and mobile. However, an electric wheelchair generally requires considerable skill to learn how to use and operate. Moreover, some persons with motor disabilities cannot drive an electric wheelchair manually (even with a joystick), because they lack the physical ability to control their hand movement (such is the case with people with ALS). In this paper, we propose a novel system that enables a person with motor disability to control a wheelchair via eye-gaze and to provide a continuous, real-time navigation in unknown environments. The system comprises a Permobile M400 wheelchair, eye tracking glasses, a depth camera to capture the geometry of the ambient space, a set of ultrasound and infrared sensors to detect obstacles with low proximity that are out of the field of view for the depth camera, a laptop placed on a flexible mount for maximized comfort, and a safety off switch to turn off the system whenever needed. First, a novel algorithm is proposed to support continuous, real-time target identification, path planning, and navigation in unknown environments. Second, the system utilizes a novel N-cell grid-based graphical user interface that adapts to input/output interfaces specifications. Third, a calibration method for the eye tracking system is implemented to minimize the calibration overheads. A case study with a person with ALS is presented, and interesting findings are discussed. The participant showed improved performance in terms of calibration time, task completion time, and navigation speed for a navigation trips between office, dining room, and bedroom. Furthermore, debriefing the caregiver has also shown promising results: the participant enjoyed higher level of confidence driving the wheelchair and experienced no collisions through all the experiment.","['Wheelchair', 'Electric wheelchairs', 'Navigation', 'Real-time systems', 'Calibration', 'Gaze tracking', 'Cameras', 'Graphical user interfaces', 'Biomedical equipment', 'Environmental factors']","['Eye gaze tracking', 'eye gaze calibration', 'wheelchair control system', 'grid-based graphical user interface', 'unknown environment tracking']"
"With the increasing capacity of new energy in the power system, new energy cannot provide support for the system frequency directly. This characteristic of new energy affects the frequency stability of the power system. Therefore the control strategy of a virtual synchronous generator (VSG) is proposed to improve the frequency stability of the system. An adaptive virtual inertia control strategy based on an improved bang-bang control strategy for a micro-grid is presented. On one hand, it can make full use of the variability of virtual inertia to reduce dynamic frequency deviation. On the other hand, the steady-state interval of frequency and the steady-state inertia are set to improve the system frequency stability. Then the stability analysis of the value range of the virtual inertia is performed by the small signal model of the VSG for the micro-grid. Meanwhile, the ranges of virtual inertia and steady-state inertia are determined. Finally, Matlab/Simulink is applied to accomplish simulation experiments to compare various virtual inertia control strategies. The results indicate the effectiveness of the proposed strategy.","['Steady-state', 'Power system stability', 'Stability analysis', 'Frequency control', 'Inverters', 'Bang-bang control', 'Impedance']","['Adaptive virtual inertia', 'bang-bang control strategy', 'micro-grid', 'virtual synchronous generator']"
"The online telemedicine systems are helpful since they provide timely and effective healthcare services. Such online healthcare systems are usually based on sophisticated and advanced wearable and wireless sensor technologies. A rapid technological growth has improved the scope of many remote health monitoring systems. Here, the researchers employed a cloud-based remote monitoring system for observing the health status of the patients after monitoring their heart rate variability. This system was developed after considering many factors like the ease of application, costs, accuracy, and the data security. Furthermore, this system was also conceptualized to act as an interface between the patients and the healthcare providers, thus ensuring a two-way communication between them. The major aim of this paper was to provide the best healthcare monitoring services to the people living in the remote areas, which was otherwise very difficult owing to the small doctor-to-patient ratio. The researchers also analyzed their monitoring system using two different databases. First comes from MIT Physionet database i.e., the MIT-BIH sinus rhythm and the MIT-St. Petersburg. While the second database was collected after monitoring 30 people who were asked to use these wearable sensors. After analyzing the performance of the proposed scheme, the obtained results for accuracy, sensitivity, and specificity were 99.02%, 98.78%, and 99.17%, respectively. The achieved results concluded that the proposed system was quite reliable, robust, and valuable. Also, the data analysis revealed that this system was very convenient and ensured data security. In addition, this developed monitoring system generated warning messages, directed towards the patients and the doctors, during some critical situation.","['Electrocardiography', 'Heart rate variability', 'Monitoring', 'Medical services', 'Biomedical monitoring']","['Telemedicine', 'cloud computing', 'IoT', 'ECG', 'HRV analyzing', 'QRS', 'homomorphic encryption']"
"This paper presents an automatic wearable electrocardiogram (ECG) classification and monitoring system with stacked denoising autoencoder (SDAE). We use a wearable device with wireless sensors to obtain the ECG data, and send these ECG data to a computer with Bluetooth 4.2. Then, these ECG data are classified by the automatic cardiac arrhythmia classification system. First, the ECG feature representation is learned by the SDAE with sparsity constraint. Then, the softmax regression is used to classify the ECG beats. In the fine-tuning phase, an active learning is added to improve the performance. In the active learning phase, we use the method that relies on the deep neural networks posterior probabilities to associate confidence measures to select the most informative samples. Breaking-ties and modified breaking-ties methods are used to select the most informative samples. We validate the proposed method on the well-known MIT-BIH arrhythmia database and ECG data obtained from the wearable device. We follow the recommendations of the Association for the Advancement of Medical Instrumentation for class labeling and results presentation. The results show that the classification performance of our proposed approach outperforms the most of the state-of-the-art methods.","['Electrocardiography', 'Biomedical monitoring', 'Feature extraction', 'Databases', 'Support vector machines', 'Noise reduction', 'Neural networks']","['Stacked denoising autoencoder', 'wearable device', 'active learning', 'breaking-ties', 'modified breaking-ties']"
"The leading causes of death worldwide are chronic illnesses suchlike diabetes, Heart Disease (HD), cancer as well as chronic respiratory malady. It is remarkably intricate to diagnose HD with disparate symptoms or features. With the augmentation in popularity of smart wearable gadgets, a chance to render an Internet of Things (IoT) solution has turned out to be more. Unfortunately, the survival rates are low for the people suffering from sudden heart attacks. Consequently, a patient monitoring scheme intended for heart patients utilizing IoT centered Deep Learning Modified Neural Network (DLMNN) is proposed to assist in the HD diagnosis, and medication is given accordingly. This proposed technique is executed via `3' steps: I) Authentication, ii) Encryption, and iii) Classification. First, by utilizing the substitution cipher (SC) together with the SHA-512, the heart patient of the specific hospital is authenticated. Subsequently, the wearable IoT sensor device, which is fixed to the patient's body, concurrently transmits the sensor data to the cloud. This sensor data is encrypted and securely transmitted to the cloud utilizing the PDH-AES technique. After that, the encrypted data is finally decrypted, and by employing the DLMNN classifier, the classification is done. The classified outcomes comprise `2'types of data: i) normal and ii) abnormal. It denotes the patient's heart condition and if the outcome is abnormal, an alert text is passed to the physician for treating the patient. The investigational outcomes are estimated and the DLMNN for HD diagnosis shows improvement as compared to existing algorithms. Additionally, the proposed PDH-AES used in support of secure data transmission results in the highest level of security i.e. 95.87%, and it is achieved in the lowest time for encryption along with decryption when weighted against the existent AES.","['Heart', 'Prediction algorithms', 'Biomedical monitoring', 'Cardiac arrest', 'Cloud computing']","['Disease prediction', 'healthcare monitoring system', 'Internet of Things (IoT)', 'advanced encryption standard (AES)', 'modified Huffman algorithm (MHA)', 'deep learning modified neural network (DLMNN)', 'Cuttlefish optimization algorithm (CFOA)']"
"With the rapid development in the field of medical image encryption, researchers analyzed a number of encryption algorithms based on chaotic systems. But there is a difficulty lies, i.e., small key space and weak security in 1-D chaotic cryptosystems. To overcome this difficulty, an alternative security model was proposed in this paper. This paper investigated highly secure medical images with a couple of subkeys, initially where a couple of subkeys are given by utilizing chaotic logistic and tent maps. As per the chaotic (C-function) process, the security was investigated like diffusion as well as confusion. Based on the initial conditions, different random numbers were generated for each map from chaotic maps. Adaptive grasshopper optimization algorithm with PSNR and correlation coefficient fitness function was proposed to choose the optimal secret and public key of the system among the random numbers. The reason behind choosing adaptive process is to enhance high-security investigation of the current proposed model compared to the existing methods. At last, the proposed strategy results were compared with existing security methods and literary works, but found to be high performing.","['Encryption', 'Biomedical imaging', 'Chaotic communication', 'Optimization']","['Chaotic maps', 'encryption', 'grasshopper optimization', 'medical images', 'optimal key', 'PSNR', 'security', 'tent map']"
"The enormous growth of wireless data traffic in recent years has made the millimeter-wave (mm-wave) technology as a good fit for high-speed communication systems. Extensive works are continuing from the device to system, to the radio architecture, to the network to support the communication in mm-wave frequency ranges. To support this extensive high data rate, beam forming is found to be the key-enabling technology. Hence, an array antenna design is an extremely important issue. The beam-forming arrays are chosen to achieve the desired link capacity considering the high path loss and atmospheric loss at mm-wave frequencies and also to increase the coverage of the mm-wave communication system. There are diverse design challenges of the array due to the small size, use of large numbers of antennas in close vicinity, integration with radio-frequency (RF) front ends, hardware constraints, and so on. This paper focuses on the evolution and development of mm-wave array antenna and its implementation for wireless communication and numerous other related areas. The scope of the discussion is extended on the reported works in every sphere of mm-wave antenna array design, including the selection of antenna elements, array configurations, feed mechanism, integration with front-end circuitry to understand the effects on system performance, and the underlying reason of it. The new design aspects and research directions are unfolded as a result of this discussion.","['Phased arrays', 'Arrays', 'Antenna feeds', 'Linear antenna arrays', 'Wireless communication']","['Mm-wave communication', 'antenna array design', 'array configuration', 'feed mechanism', 'RF circuit']"
"Grey wolf optimization (GWO) algorithm is a new population-oriented intelligence algorithm, which is originally proposed to solve continuous optimization problems inspired from the social hierarchy and hunting behaviors of grey wolves. It has been proved that GWO can provide competitive results compared with some well-known meta-heuristics. This paper aims to employ the GWO to deal with two combinatorial optimization problems in the manufacturing field: job shop and flexible job shop scheduling cases. The effectiveness of GWO algorithm on the two problems can give an idea about its possible application on solving other scheduling problems. For the discrete characteristics of the scheduling solutions, we developed a kind of discrete GWO algorithm with the objective of minimizing the maximum completion time (makespan). In the proposed algorithm, searching operator is designed based on the crossover operation to maintain the algorithm work directly in a discrete domain. Then an adaptive mutation method is introduced to keep the population diversity and avoid premature convergence. In addition, a variable neighborhood search method is embedded to further enhance the exploration. To evaluate the effectiveness, the discrete GWO algorithm is compared with other published algorithms in the literature for the two scheduling cases. Experimental results demonstrate that our algorithm outperforms other algorithms for the scheduling problems under study.","['Job shop scheduling', 'Optimization', 'Particle swarm optimization', 'Sociology', 'Statistics']","['Job shop', 'flexible job shop', 'makespan', 'discrete grey wolf optimization', 'genetic operator', 'variable neighborhood search']"
"Effectively managing the healthcare supply chain (HCSC) process is crucial for healthcare providers not only during pandemics such as COVID-19 but also in their normal operations. Despite significant advances in new technologies and treatment options providers still suffer from poor procurement, ordering, forecasting, and distribution practices. Group Purchasing Organizations (GPOs) are an important stakeholder in HCSC and benefit providers with cost savings, volume discounts, and vendor selection. However, the current GPO contract process is time-consuming and lacks efficiency. Hence, our proposed solution integrates blockchain technology and decentralized storage to promote transparency, streamlines communication with stakeholders, and minimize the procurement timeline while avoiding pricing discrepancies and inaccuracies. Our solution connects all the stakeholders such as manufacturer, GPO, distributor, and provider using Ethereum network. In this paper, we propose a blockchain solution using smart contracts to automate the GPO contract process. We propose a generic framework for contracting process in the HCSC with detailed algorithms depicting various interactions among HCSC stakeholders. The smart contract code was developed and tested using Remix IDE and the code is publicly shared via Github. We discuss various security risks and present detailed cost analysis of various transactions incurred by the stakeholders. Our analysis demonstrates that the proposed blockchain-based solution is economically feasible as only a minimal transaction fee is expended by the stakeholders in the distributed network.","['Medical services', 'Contracts', 'Blockchain', 'Stakeholders', 'Supply chains', 'Procurement', 'Vaccines']","['Blockchain', 'Ethereum', 'security analysis', 'blockchain applications', 'group purchasing organizations', 'healthcare supply chain']"
"In fifth-generation (5G) communications, millimeter wave (mmWave) is one of the key technologies to increase the data rate. To overcome this technology’s poor propagation characteristics, it is necessary to employ a number of antennas and form narrow beams. It becomes crucial then, especially for initial access, to attain fine beam alignment between a next generation NodeB (gNB) and a user equipment (UE). The current 5G New Radio (NR) standard, however, adopts an exhaustive search-based beam sweeping, which causes time overhead of a half frame for initial beam establishment. In this paper, we propose a deep learning-based beam selection, which is compatible with the 5G NR standard. To select a mmWave beam, we exploit sub-6 GHz channel information. We introduce a deep neural network (DNN) structure and explain how we estimate a power delay profile (PDP) of a sub-6 GHz channel, which is used as an input of the DNN. We then validate its performance with real environment-based 3D ray-tracing simulations and over-the-air experiments with a mmWave prototype. Evaluation results confirm that, with support from the sub-6 GHz connection, the proposed beam selection reduces the beam sweeping overhead by up to 79.3 %.","['5G mobile communication', 'Hidden Markov models', 'Channel models', 'Machine learning', 'Delays', 'Antenna arrays', 'Array signal processing']","['5G NR', '6G', 'mmWave', 'beamforming', 'deep learning', 'beam selection', 'ultra-low latency']"
"Federated learning (FL) has received considerable attention with the development of mobile internet technology, which is an emerging framework to train a deep learning model from decentralized data. Modern mobile devices often have access to rich but privacy-sensitive data, and computational abilities are often limited because of the hardware restriction. In previous works based on federated averaging (FedAvg) algorithm, mobile devices need to perform lots of calculations, and it is time-consuming in the process of global communication. Inspired by edge computing, we proposed edge federated learning (EdgeFed), which separates the process of updating the local model that is supposed to be completed independently by mobile devices. The outputs of mobile devices are aggregated in the edge server to improve the learning efficiency and decrease the global communication frequency. Empirical experiments demonstrate that our proposed EdgeFed has advantages in different bandwidth scenarios. Especially, by offloading part of the calculations from mobile clients to the edge server, the computational cost of the mobile devices and the global communication expense can be simultaneously reduced as compared to FedAvg.","['Servers', 'Mobile handsets', 'Training', 'Computational modeling', 'Edge computing', 'Performance evaluation', 'Collaborative work']","['Federated learning', 'deep learning', 'federated averaging', 'edge computing', 'edge federated learning']"
"Cybersecurity is a fast-evolving discipline that is always in the news over the last decade, as the number of threats rises and cybercriminals constantly endeavor to stay a step ahead of law enforcement. Over the years, although the original motives for carrying out cyberattacks largely remain unchanged, cybercriminals have become increasingly sophisticated with their techniques. Traditional cybersecurity solutions are becoming inadequate at detecting and mitigating emerging cyberattacks. Advances in cryptographic and Artificial Intelligence (AI) techniques (in particular, machine learning and deep learning) show promise in enabling cybersecurity experts to counter the ever-evolving threat posed by adversaries. Here, we explore AI's potential in improving cybersecurity solutions, by identifying both its strengths and weaknesses. We also discuss future research opportunities associated with the development of AI techniques in the cybersecurity field across a range of application domains.","['Computer crime', 'Machine learning', 'Malware']","['Artificial intelligence', 'cybersecurity', 'cyberattacks', 'machine learning']"
"It is demonstrated numerically that a metamaterial-inspired, low profile (height approximately λ/80), electrically small (ka = 0.45) Huygens source antenna can be designed to radiate at 300 MHz in its broadside direction with a high radiation efficiency and a large front-to-back ratio. Two electrically small, near-field resonant parasitic (NFRP) antennas are first designed. Both are based on a coax-fed dipole antenna. An electric dipole response is obtained by combining it with a tunable Egyptian axe dipole (EAD) NFRP element. A magnetic dipole response is obtained by spatially loading the driven dipole with tunable, extruded capacitively loaded loop (CLL) NFRP elements. The driven dipole and the EAD and CLL NFRP elements are combined together and retuned to achieve a broadside radiating Huygens source antenna. Two different designs, one with two CLL elements and one with four, are obtained, and their performance characteristics are compared.","['Dipole antennas', 'Magnetic resonance', 'Copper', 'Antenna accessories', 'Bandwidth']","['Directivity', 'electrically small antennas', 'Huygens source', 'metamaterial-inspired antennas']"
"Secure and efficient lightweight user authentication protocol for mobile cloud computing becomes a paramount concern due to the data sharing using Internet among the end users and mobile devices. Mutual authentication of a mobile user and cloud service provider is necessary for accessing of any cloud services. However, resource constraint nature of mobile devices makes this task more challenging. In this paper, we propose a new secure and lightweight mobile user authentication scheme for mobile cloud computing, based on cryptographic hash, bitwise XOR, and fuzzy extractor functions. Through informal security analysis and rigorous formal security analysis using random oracle model, it has been demonstrated that the proposed scheme is secure against possible well-known passive and active attacks and also provides user anonymity. Moreover, we provide formal security verification through ProVerif 1.93 simulation for the proposed scheme. Also, we have done authentication proof of our proposed scheme using the Burrows-Abadi-Needham logic. Since the proposed scheme does not exploit any resource constrained cryptosystem, it has the lowest computation cost in compare to existing related schemes. Furthermore, the proposed scheme does not involve registration center in the authentication process, for which it is having lowest communication cost compared with existing related schemes.","['Mobile communication', 'Cloud computing', 'Authentication', 'Cryptography', 'Mobile handsets', 'Computational modeling']","['Remote mobile user authentication', 'distributed mobile cloud computing', 'user anonymity', 'user biometrics', 'random oracle', 'BAN logic', 'ProVerif simulation']"
"Non-orthogonal multiple access (NOMA) has been conceived as a breakthrough technology for the fifth generation (5G) wireless networks. With imperfect channel state information (ICSI) taken into account, we study an NOMA-based downlink amplify-and-forward (AF) relaying network under Nakagami-m fading in this paper. First, we investigate the system outage behavior, and close-form expressions for the exact and tight lower bounds of the outage probability are attained, respectively. By further evaluating the outage probability at the high SNR region, it is observed that an error floor exists in the outage probability due to the presence of ICSI. Finally, numerical results are presented to demonstrate the validity of our analysis and show the advantages of NOMA over conventional orthogonal multiple access. Moreover, simulation results verify that the optimal relay location for NOMA should be close to the source node.","['NOMA', 'Downlink', 'Signal to noise ratio', 'Relays', 'Interference', 'Rayleigh channels', 'Performance evaluation', 'Nakagami fading channels', 'Channel state estimation']","['Relaying networks', 'non-orthogonal multiple access (NOMA)', 'outage probability', 'Nakagami-m fading', 'imperfect channel state information (ICSI)']"
"In this paper, we develop a comprehensive statistical framework to characterize and model large-scale unmanned aerial vehicle-enabled post-disaster recovery cellular networks. In the case of natural or man-made disasters, the cellular network is vulnerable to destruction resulting in coverage voids or coverage holes. Drone-based small cellular networks (DSCNs) can be rapidly deployed to fill such coverage voids. Due to capacity and back-hauling limitations on drone small cells (DSCs), each coverage hole requires a multitude of DSCs to meet the shortfall coverage at a desired quality-of-service. Moreover, ground users also tend to cluster in hot-spots in a post-disaster scenario. Motivated by this fact, we consider the clustered deployment of DSCs around the site of a destroyed BS. Joint consideration partially operating BSs and deployed DSCs yields a unique topology for such public safety networks. Borrowing tools from stochastic geometry, we develop a statistical framework to quantify the down-link performance of a DSCN. Our proposed clustering mechanism extends the traditional Matern and Thomas cluster processes to a more general case, where cluster size is dependent upon the size of the coverage hole. We then employ the newly developed framework to find closed-form expressions (later verified by Monte-Carlo simulations) to quantify the coverage probability, area spectral efficiency, and the energy efficiency for the down-link mobile user. Finally, we explore several design parameters (for both of the adopted cluster processes) that address optimal deployment of the network (i.e., number of drones per cluster, drone altitudes, and transmit power ratio between the traditional surviving base stations and the drone base stations).","['Cellular networks', 'Drones', 'Safety', 'Stochastic processes', 'Base stations', 'Communication networks']","['Drones', 'stochastic geometry', 'unmanned aerial vehicles', 'coverage probability', 'Poisson cluster processes']"
"In this work, we present Point Transformer, a deep neural network that operates directly on unordered and unstructured point sets. We design Point Transformer to extract local and global features and relate both representations by introducing the local-global attention mechanism, which aims to capture spatial point relations and shape information. For that purpose, we propose SortNet, as part of the Point Transformer, which induces input permutation invariance by selecting points based on a learned score. The output of Point Transformer is a sorted and permutation invariant feature list that can directly be incorporated into common computer vision applications. We evaluate our approach on standard classification and part segmentation benchmarks to demonstrate competitive results compared to the prior work.","['Shape', 'Transformers', 'Three-dimensional displays', 'Standards', 'Task analysis', 'Feature extraction', 'Computer vision']","['3D point processing', 'artificial neural networks', 'computer vision', 'feedforward neural networks', 'transformer']"
"This study aims to propose an effective intelligent model for predicting entrepreneurial intention, which can provide a reasonable reference for the formulation of talent training programs and the guidance of entrepreneurial intention of students. The prediction model is mainly based on the kernel extreme learning machine (KELM) optimized by the improved Harris hawk's optimizer (HHO). In order to obtain better parameters and feature subsets, the Gaussian barebone (GB) strategy is introduced to improve the HHO algorithm, so as to strengthen the optimization ability for tuning parameters of KELM and identifying the compact feature subsets. Then, an optimal KELM model (GBHHO-KELM) is established according to the obtained optimal parameters and feature subsets to predict the entrepreneurial intention of students. In the experiment, GBHHO is compared with the other nine well-known methods in 30 CEC 2014 benchmark problems. The experimental findings suggest that the proposed GBHHO method is significantly superior to the existing methods in most problems. At the same time, GBHHO-KELM is compared with other machine learning methods in the prediction of entrepreneurial intention. The experimental results indicate that the proposed GBHHO-KELM can achieve better classification performance and higher stability in accordance with the four metrics. Therefore, we can conclude that the GBHHO-KELM model is expected to be an effective tool for the prediction of entrepreneurial intention.","['Entrepreneurship', 'Kernel', 'Predictive models', 'Employment', 'Training', 'Engineering profession', 'Mathematical model']","['Harris hawks optimization', 'global optimization', 'swarm intelligence', 'entrepreneurial intention', 'kernel extreme learning machine']"
"This paper presents a thorough review of transmitarray devices particularly aiming antenna beamsteering, gathering some of the most relevant solutions published by the scientific community in the field. First, the background for realizing 1-D and 2-D antenna beamsteering with a transmitarray is introduced. Subsequently, several examples of unit-cells for transmitarray implementation and complete transmitarray designs presented in the literature are outlined. Each solution is analyzed in detail, identifying the nature of its layout, e.g., based on microstrip patches, frequency selective surfaces (FSS), or metamaterials (MMs), and the method employed to enable electronic reconfigurability, e.g., p-i-n diodes, varactor diodes, or microelectromechanical systems (MEMS). In addition, some models with the capability of controlling the wavefront polarization modes are also included herein since these are the base of hybrid transmitarrays, i.e., transmitarray with both electronic beamsteering and polarization control. Finally, all the models are compared against each other in order to highlight their benefits and limitations, summarizing their main characteristics, such as the frequency of operation and bandwidth, insertion loss, physical dimensions, and maximum beamsteering range, when available.","['Transmitting antennas', 'Phased arrays', 'P-i-n diodes', 'Microstrip antenna arrays', 'Linear antenna arrays', 'Microstrip']","['Antenna', 'beamsteering', 'beamforming', 'metamaterials', 'polarization', 'transmitarray']"
"Automated recognition of human activities or actions has great significance as it incorporates wide-ranging applications, including surveillance, robotics, and personal health monitoring. Over the past few years, many computer vision-based methods have been developed for recognizing human actions from RGB and depth camera videos. These methods include space-time trajectory, motion encoding, key poses extraction, space-time occupancy patterns, depth motion maps, and skeleton joints. However, these camera-based approaches are affected by background clutter and illumination changes and applicable to a limited field of view only. Wearable inertial sensors provide a viable solution to these challenges but are subject to several limitations such as location and orientation sensitivity. Due to the complementary trait of the data obtained from the camera and inertial sensors, the utilization of multiple sensing modalities for accurate recognition of human actions is gradually increasing. This paper presents a viable multimodal feature-level fusion approach for robust human action recognition, which utilizes data from multiple sensors, including RGB camera, depth sensor, and wearable inertial sensors. We extracted the computationally efficient features from the data obtained from RGB-D video camera and inertial body sensors. These features include densely extracted histogram of oriented gradient (HOG) features from RGB/depth videos and statistical signal attributes from wearable sensors data. The proposed human action recognition (HAR) framework is tested on a publicly available multimodal human action dataset UTD-MHAD consisting of 27 different human actions. K-nearest neighbor and support vector machine classifiers are used for training and testing the proposed fusion model for HAR. The experimental results indicate that the proposed scheme achieves better recognition results as compared to the state of the art. The feature-level fusion of RGB and inertial sensors provides the overall best performance for the proposed system, with an accuracy rate of 97.6%.","['Feature extraction', 'Cameras', 'Wearable sensors', 'Sensor fusion', 'Sensor phenomena and characterization', 'Three-dimensional displays']","['Dense HOG', 'depth sensor', 'feature-level fusion', 'human action recognition', 'inertial sensor', 'RGB camera']"
"Ever-increasing demands for portable and flexible communications have led to rapid growth in networking between unmanned aerial vehicles often referred to as flying ad-hoc networks (FANETs). Existing mobile ad hoc routing protocols are not suitable for FANETs due to high-speed mobility, environmental conditions, and terrain structures. In order to overcome such obstacles, we propose a combined omnidirectional and directional transmission scheme, together with dynamic angle adjustment. Our proposed scheme features hybrid use of unicasting and geocasting routing using location and trajectory information. The prediction of intermediate node location using 3-D estimation and directional transmission toward the predicted location, enabling a longer transmission range, allows keeping track of a changing topology, which ensures the robustness of our protocol. In addition, the reduction in path re-establishment and service disruption time to increase the path lifetime and successful packet transmissions ensures the reliability of our proposed strategy. Simulation results verify that our proposed scheme could significantly increase the performance of flying ad hoc networks.","['Routing protocols', 'Ad hoc networks', 'Routing', 'Unmanned aerial vehicles', 'Robustness', 'Peer-to-peer computing']","['FANET', 'routing protocol', 'directional transmission', 'route setup', 'average path lifetime', 'dynamic angle adjustment']"
"Vehicular ad-hoc networks (VANETs) play an important role in intelligent transportation systems for improving security and efficiency. However, due to dynamic characteristics of the vehicular environment, routing remains a significant challenge in the VANETs. While single-layer routing protocols based on the traditional layered open systems interconnection (OSI) model are readily available, they often do not make use of important parameters at the lower three layers of the OSI model when making routing decision. Hence, for making optimal routing decision to gain superior network performance, there is a need to design cross-layer routing that allows information exchange between layers. In this article, a survey of the existing single-layer and cross-layer routing techniques in VANETs is presented, emphasizing on cross-layer routing protocols that utilize information at the physical, medium access control and network layers as routing parameters. An overview and challenges of routing are given, followed by a brief discussion of single-layer routing with more focus on geographic routing. Cross-layer routing protocols are then discussed in detail. The article then elaborates on some advantages and disadvantages of the existing routing approaches, cross-layer routing parameter selection and cross-layer design issues. Finally, some open research challenges in developing efficient routing protocols in the VANETs are highlighted.","['Routing', 'Routing protocols', 'Vehicular ad hoc networks', 'Open systems', 'Safety', 'Media Access Protocol']","['Cross-layer design', 'routing protocols', 'single-layer', 'vehicular ad-hoc networks (VANETs)']"
"This study presents a computationally efficient deep learning model for binary sentiment classification, which aims to decide the sentiment polarity of people's opinions, attitudes, and emotions expressed in written text. To achieve this, we exploited three widely practiced datasets based on public opinions about movies. We utilized merely one bidirectional long short-term memory (BiLSTM) layer along with a global pooling mechanism and achieved an accuracy of 80.500%, 85.780%, and 90.585% on MR, SST2 and IMDb datasets, respectively. We concluded that the performance metrics of our proposed approach are competitive with the recently published models, having comparatively complex architectures. Also, it is inferred that the proposed single-layered BiLSTM based architecture is computationally efficient and can be recommended for real-time applications in the field of sentiment analysis.","['Machine learning', 'Sentiment analysis', 'Feature extraction', 'Computer architecture', 'Task analysis', 'Support vector machines', 'Computational modeling']","['Bidirectional long short-term memory', 'deep learning', 'long-term dependencies', 'natural language processing', 'sentiment analysis']"
"Meta-heuristic algorithm has been a research hotspot in solving the optimal solution of large-scale functions. However, meta-heuristic algorithms are prone to fall into local optimum problems, such as the recently proposed dolphin swarm algorithm (DSA). To solve this problem, in this study, the quantum search algorithm is introduced into DSA. In addition, to test the performance of the proposed quantum dolphin swarm algorithm (QDSA), six commonly used large-scale functions (e.g. Rotated hyper-ellipsoid function) are taken as examples. Furthermore, some advanced algorithms (e.g. whale optimization algorithm (WOA)) are used for comparison. The results show that the ability of QDSA to obtain global optimal solution is obviously improved compared with DSA, and the performance of QDSA is superior to other algorithms considered for comparison. Finally, it can be concluded that such a novel meta-heuristic algorithm may help to improve the problem of solving the optimal solution of large-scale functions.","['Optimization', 'Dolphins', 'Particle swarm optimization', 'Mathematical model', 'Search problems', 'Whales', 'Heuristic algorithms']","['Quantum search algorithm', 'dolphin swarm algorithm', 'large-scale function optimization']"
"Given a financial time series such as S\&P~500 , or any historical data in stock markets, how can we obtain useful information from recent transaction data to predict the ups and downs at the next moment? Recent work on this issue shows initial evidence that machine learning techniques are capable of identifying (non-linear) dependency in the stock market price sequences. However, due to the high volatility and non-stationary nature of the stock market, forecasting the trend of a financial time series remains a big challenge. In this paper, we introduced a new method to simplify noisy-filled financial temporal series via sequence reconstruction by leveraging motifs (frequent patterns), and then utilize a convolutional neural network to capture spatial structure of time series. The experimental results show the efficiency of our proposed method in feature learning and outperformance with 4%–7% accuracy improvement compared with the traditional signal process methods and frequency trading patterns modeling approach with deep learning in stock trend prediction.","['Time series analysis', 'Market research', 'Hidden Markov models', 'Predictive models', 'Feature extraction', 'Stock markets', 'Forecasting']","['Trend prediction', 'convolutional neural network', 'financial time series', 'motif extraction']"
"Drones have expanded from military operations to performing a broad range of civilian applications. As drone usage increases, humans will interact with such systems more often, therefore, it is important to achieve a natural human-drone interaction. Although some knowledge can be derived from the field of human-robot interaction, drones can fly in a 3D space, which essentially changes how humans can interact with them, making human-drone interaction a field of its own. This paper is the first survey on the emerging field of human-drone interaction focusing on multi-rotor systems, providing an overview of existing literature and the current state of the art in the field. This work begins with an analysis and comparison of the drone models that are commonly used by end-users and researchers in the field of human-drone interaction. Following, the current state of the field is discussed, including the roles of humans in HDI, innovative control methods, remaining aspects of interaction, and novelty drone prototypes and applications. This paper concludes by presenting a discussion of current challenges and future work in the field of human-drone interaction.","['Drones', 'FAA', 'Analytical models', 'User interfaces', 'Aircraft', 'Cognitive science', 'Prototypes']","['Drone', 'human-computer interaction', 'human-drone interaction', 'human-in-the-loop', 'human-robot interaction', 'unmanned aerial vehicle']"
"Wind energy is a kind of sustainable energy with strong uncertainty. With a large amount of wind power injected into the power grid, it will inevitably affect the security, stability and economic operation of the power grid. High-precision wind power spot prediction and fluctuation interval information can provide more adequate decision-making support for grid scheduling and optimization. Hence, this paper proposes a K-Means-long short-term memory (K-Means-LSTM) network model for wind power spot prediction, and a nonparametric kernel density estimation (KDE) model with bandwidth optimization for wind power probabilistic interval prediction. The long short-term memory (LSTM) network has a strong memory function, which can establish the correlation between the data before and after, so as to improve the prediction accuracy. The K-Means clustering method forms different clusters of wind power impact factors to generate a new LSTM sub-prediction model. The optimization of the bandwidth in the nonparametric KDE is implemented by the mean integrated squared error criterion. In addition, a part of the dataset is deliberately demarcated from the wind power historical dataset to generate reasonable wind power prediction errors. The simulation results show that the proposed K-Means-LSTM network model has higher prediction accuracy than the back propagation (BP) neural networks, Elman neural networks, support vector regression (SVR) and LSTM network models. Compared with the KDE model with random bandwidth and the Gaussian distribution model, the bandwidth optimization model proposed in this paper has more narrow prediction intervals with higher interval coverage rates.","['Wind power generation', 'Predictive models', 'Wind speed', 'Probabilistic logic', 'Optimization', 'Bandwidth']","['Wind power prediction', 'Kernel density estimation', 'long short-term memory', 'K-means clustering', 'probabilistic interval prediction']"
"The rapid advancements in computing, storage, communications, and networking technologies have enabled the creation of Digital Twins (DTs). A DT is a digital representation of a real-world physical component, product, or equipment. A DT can be used for 3-D design, testing, simulation, and prototyping prior to the manufacturing of the physical component. Once a physical component is in operation, a DT can be used for configuration, monitoring, diagnostics, and prognostics. It is expected that DTs will gain significant attention in the foreseeable future, and will play a key role in Industry 4.0. However, today's approaches, systems, and technologies leveraged for the creation of DTs are mostly centralized and fall short of providing trusted data provenance, audit, and traceability. Also, data related to transactions, logs, and history are not secure or tamper-proof. In this paper, we propose a blockchain-based creation process of DTs to guarantee secure and trusted traceability, accessibility, and immutability of transactions, logs, and data provenance. Our proposed approach uses smart contracts to govern and track transactions initiated by participants involved in the creation of DTs. Our approach also employs decentralized storage of interplanetary file systems to store and share DTs data. Moreover, we present details on our system design and architecture, implementation, and algorithms. Furthermore, we provide security and cost analysis, and show how our approach fulfills the requirements of DTs process creation. We make the smart contract code for creating DTs publicly available on Github.","['Contracts', 'Industries', 'Stakeholders', 'Testing', 'Monitoring', 'History']","['Digital twins', 'blockchain', 'Ethereum', 'smart contracts', 'security', 'Industry 4.0']"
"Brain-computer interface (BCI) has become extremely popular in recent decades. It gained its significance from the intention of helping paralyzed people communicate with the external environment. One of the major challenges facing BCI systems is obtaining reliable classification accuracy of motor imagery (MI) mental tasks. In this paper, a novel CSP\AM-BA-SVM approach is proposed using bio-inspired algorithms for feature selection and classifier optimization to improve classification accuracy of the MI-BCI systems. The proposed approach applies optimum selection of time interval for each subject. The features are extracted from EEG signal using the common spatial pattern (CSP). Binary CSP is extended to multi-class problems by utilizing one-vs-one strategy. This paper introduces applying a hybrid attractor metagene (AM) algorithm along with the Bat optimization algorithm (BA) to select the most discriminant CSP features and optimize SVM parameters. The efficacy of the proposed approach was examined using three data sets. The proposed approach has achieved 78.55% accuracy and 0.71 mean kappa for BCI Competition IV data set 2a, 86.6% accuracy and 0.82 mean kappa for BCI Competition III data set IIIa, and 85% for the binary class BCI Competition III data set IVa. For multi-class data sets, the proposed approach outperforms winners of BCIC IV, 2a and BCIC III, IIIa with kappa 0.14 and 0.17, respectively. For binary class BCIC III, IVa, it performed slightly better than existing studies in the literature by ≈ 0.5%. The proposed CSP\AM-BA-SVM transcends the traditional CSP\SVM approach and other existing studies.","['Feature extraction', 'Electroencephalography', 'Support vector machines', 'Training', 'Synchronous motors', 'Task analysis', 'Band-pass filters']","['Attractor metagene algorithm', 'Bat algorithm', 'brain computer interface', 'motor imagery', 'support vector machines']"
"In recent years, intelligent fault diagnosis technology with the deep learning algorithm has been widely used in the manufacturing industry for substituting time-consuming human analysis method to enhance the efficiency of fault diagnosis. The rolling bearing as the connection between the rotor and support is the crucial component in rotating equipment. However, the working condition of the rolling bearing is under changing with complex operation demand, which will significantly degrade the performance of the intelligent fault diagnosis method. In this paper, a new deep transfer model based on Wasserstein distance guided multi-adversarial networks (WDMAN) is proposed to address this problem. The WDMAN model exploits complex feature space structures to enable the transfer of different data distributions based on multiple domain critic networks. The essence of our method is learning the shared feature representation by minimizing the Wasserstein distance between the source domain and target domain distribution in an adversarial training way. The experiment results demonstrate that our model outperforms the state-of-the-art methods on rolling bearing fault diagnosis under different working conditions. The t-distributed stochastic neighbor embedding (t-SNE) technology is used to visualize the learned domain invariant feature and investigate the transferability behind the great performance of our proposed model.","['Fault diagnosis', 'Rolling bearings', 'Data models', 'Wavelength division multiplexing', 'Convolution', 'Employee welfare', 'Training']","['Transfer learning', 'fault diagnosis', 'convolutional neural network', 'multi-adversarial networks']"
"The world is consuming large amounts of energy in various forms like electric energy and mechanical energy. Since the electrical energy is an important factor for the development of the world, many researchers tried to generate electricity from renewable energy sources collected by sensors in order to overcome the shortage of electrical energy for household appliances and industrial areas. In this paper, we develop Internet-of-Things (IoT) based system to generate electrical energy from multiple sensors for household appliances and industrial areas. Different sensors namely piezoelectric sensor, body heat to electric converter and solar panel are utilized and connected to the power storage circuit for generation of electrical energy. Two different Artificial Intelligence (AI) models such as Artificial Neural Network (ANN), Adaptive Network based Fuzzy Inference System (ANFIS) are utilized for the total power generated from renewable energy resources. Validation is done through the statistical parameters such as Root Mean Square Error (RMSE) and R2 coefficient of correlation. Result outcome from the models shows that ANN performance is better than ANFIS.","['Renewable energy sources', 'Artificial neural networks', 'Artificial intelligence', 'Intelligent sensors', 'Home appliances', 'Sensor systems']","['Internet of Things', 'artificial intelligence', 'piezoelectricity', 'sensors', 'energy types', 'human body heat dissipation', 'optimization of renewal and non-renewal energies']"
"Technical progress in the open-source self replicating rapid prototyper (RepRap) community has enabled a distributed form of additive manufacturing to expand rapidly using polymer-based materials. However, the lack of an open-source metal alternative and the high capital costs and slow throughput of proprietary commercialized metal 3-D printers has severely restricted their deployment. The applications of commercialized metal 3-D printers are limited to only rapid prototyping and expensive finished products. This severely restricts the access of the technology for small and medium enterprises, the developing world and for use in laboratories. This paper reports on the development of a open-source metal 3-D printer. The metal 3-D printer is controlled with an open-source micro-controller and is a combination of a low-cost commercial gas-metal arc welder and a derivative of the Rostock, a deltabot RepRap. The bill of materials, electrical and mechanical design schematics, and basic construction and operating procedures are provided. A preliminary technical analysis of the properties of the 3-D printer and the resultant steel products are performed. The results of printing customized functional metal parts are discussed and conclusions are drawn about the potential for the technology and the future work necessary for the mass distribution of this technology.","['Printers', 'Three dimensional displays', 'Open source hardware', 'Fabrication', 'Scientific instruments', 'Manufacturing processes']","['3-D printing', 'additive manufacturing', 'distributed manufacturing', 'metal processing', 'MIG welding', 'open-source', 'open-source electronics', 'open-source hardware', 'personal fabrication', 'printing', 'rapid prototyping', 'scientific hardware', 'scientific instruments']"
"The number of older people in western countries is constantly increasing. Most of them prefer to live independently and are susceptible to fall incidents. Falls often lead to serious or even fatal injuries which are the leading cause of death for elderlies. To address this problem, it is essential to develop robust fall detection systems. In this context, we develop a machine learning framework for fall detection and daily living activity recognition. We use acceleration and angular velocity data from two public databases to recognize seven different activities, including falls and activities of daily living. From the acceleration and angular velocity data, we extract time- and frequency-domain features and provide them to a classification algorithm. In this paper, we test the performance of four algorithms for classifying human activities. These algorithms are the artificial neural network (ANN), $K$ -nearest neighbors (KNN), quadratic support vector machine (QSVM), and ensemble bagged tree (EBT). New features that improve the performance of the classifier are extracted from the power spectral density of the acceleration. In the first step, only the acceleration data are used for activity recognition. Our results reveal that the KNN, ANN, QSVM, and EBT algorithms could achieve overall accuracy of 81.2%, 87.8%, 93.2%, and 94.1%, respectively. The accuracy of fall detection reaches 97.2% and 99.1% without any false alarms for the QSVM and EBT algorithms, respectively. In a second step, we extract features from the autocorrelation function and the power spectral density of both the acceleration and the angular velocity data, which improves the classification accuracy. By using the proposed features, we could achieve overall accuracy of 85.8%, 91.8%, 96.1%, and 97.7% for the KNN, ANN, QSVM, and EBT algorithms, respectively. The accuracy of fall detection reaches 100% for both the QSVM and EBT algorithms without any false alarm, which is the best achievable performance.","['Feature extraction', 'Acceleration', 'Angular velocity', 'Activity recognition', 'Legged locomotion', 'Machine learning', 'Biomedical monitoring']","['Fall detection', 'activity recognition', 'machine learning', 'acceleration data', 'angular velocity data', 'feature extraction']"
"The main task of future networks is to build, as much as possible, intelligent networking architectures for intellectualization, activation, and customization. Software-defined networking (SDN) technology breaks the tight coupling between the control plane and the data plane in the traditional network architecture, making the controllability, security, and economy of network resources into a reality. As one of the important actualization methods of artificial intelligence (AI), machine learning (ML), combined with SDN architecture will have great potential in areas, such as network resource management, route planning, traffic scheduling, fault diagnosis, and network security. This paper presents the network applications combined with SDN concepts based on ML from two perspectives, namely the perspective of ML algorithms and SDN network applications. From the perspective of ML algorithms, this paper focuses on the applications of classical ML algorithms in SDN-based networks, after a characteristic analysis of algorithms. From the other perspective, after classifying the existing network applications based on the SDN architecture, the related ML solutions are introduced. Finally, the future development of the ML algorithms and SDN concepts is discussed and analyzed. This paper occupies the intersection of the AI, big data, computer networking, and other disciplines; the AI itself is a new and complex interdisciplinary field, which causes the researchers in this field to often have different professional backgrounds and, sometimes, divergent research purposes. This paper is necessary and helpful for researchers from different fields to accurately master the key issues.","['Classification algorithms', 'Numerical models', 'Software defined networking', 'Machine learning', 'Computer architecture', 'Prediction algorithms']","['Artificial intelligence', 'machine learning', 'network management', 'software-defined networking']"
"Cloud computing has become a widely exploited research area in academia and industry. Cloud computing benefits both cloud services providers (CSPs) and consumers. The security challenges associated with cloud computing have been widely studied in the literature. This systematic literature review (SLR) is aimed to review the existing research studies on cloud computing security, threats, and challenges. This SLR examined the research studies published between 2010 and 2020 within the popular digital libraries. We selected 80 papers after a meticulous screening of published works to answer the proposed research questions. The outcomes of this SLR reported seven major security threats to cloud computing services. The results showed that data tampering and leakage were among the highly discussed topics in the chosen literature. Other identified security risks were associated with the data intrusion and data storage in the cloud computing environment. This SLR’s results also indicated that consumers’ data outsourcing remains a challenge for both CSPs and cloud users. Our survey paper identified the blockchain as a partnering technology to alleviate security concerns. The SLR findings reveal some suggestions to be carried out in future works to bring data confidentiality, data integrity, and availability.","['Cloud computing', 'Security', 'Computational modeling', 'Information technology', 'Law', 'Cloud computing security', 'Authentication']","['Auditing', 'cloud computing', 'cloud models', 'decryption', 'encryption', 'malicious behavior', 'intrusion', 'secured communication']"
"Mobile ad hoc networks (MANETs) are self-organizing nodes in a mobile network that collaborate to form dynamic network architecture to establish connections. In MANET, data must traverse several intermediary nodes before reaching its destination. There must be security in place to prevent hostile nodes from accessing this data. Multiple methods were suggested in literature for securing routing; these techniques tackle different aspects of security. In order to enhance fault tolerance, wireless network multipath routing is typically used instead of the original single path routing. The routing protocol Genetic Algorithm with Hill climbing (GAHC) described in this article shows a hybrid GA-Hill Climbing algorithm that picks the optimal route in multipath. Prior to this in the beginning, the Improved fuzzy C-means algorithm method was built on density peak, and cluster heads (CHs) were chosen in a predicted manner, based on recent, indirect, and direct trust. The computation is based worth nodes are at the trust threshold found in addition. Even CHs take part in the alternate paths, the blend of all the many paths from these Cluster Heads that chooses the optimal route, which is based on the predicted hybrid protocol, as well as the optimum route’s aggregate features such as throughput, latency, and connection. This suggested technique requires a minimum amount of energy of 0.10 m joules and a small amount of delay time of 0.004 msec, which also yields a maximum throughput of 0.85 bits per second, a maximum detection rate of 91 percent and maximum packet delivery ratio of 89percent. The suggested approach was put through the paces with the selective packet dropping attack.","['Routing', 'Routing protocols', 'Mobile ad hoc networks', 'Security', 'Throughput', 'Genetic algorithms', 'Clustering algorithms']","['MANET', 'genetic algorithm (GA)', 'cluster heads (CHs)', 'hill climbing (HC)', 'selective packet dropping attack']"
"Nowadays, the importance of achieving and maintaining a high standard of data quality is widely recognized by both practitioners and researchers. Based on its impact on businesses, the quality of data is commonly viewed as a valuable asset. The literature comprises various techniques for defining, assessing, and improving data quality. However, requirements for data and their quality vary between organizations. Due to this variety, choosing suitable methods that are advantageous for the data quality of an organization or in a particular context can be challenging. This paper surveys data quality frameworks in a comparative way regarding the definition, assessment, and improvement of data quality with a focus on methodologies that are applicable in a wide range of business environments. To aid the decision process concerning the suitability of these methods, we further provide a decision guide to data quality frameworks. This guidance aims to help narrow down possible choices for data quality methodologies based on a number of specified criteria.","['Data integrity', 'Standards organizations', 'Organizations', 'Decision making', 'Data warehouses']","['Data quality assessment', 'data structures', 'decision making', 'information management', 'quality management']"
"In a blockchain-based system, data and the consensus-based process of recording and updating them over distributed nodes are central to enabling the trustless multi-party transactions. Thus, properly understanding what and how the data are stored and manipulated ultimately determines the degree of utility, performance, and cost of a blockchain-based application. While blockchains enhance the quality of the data by providing a transparent, immutable, and consistent data store, the technology also brings new challenges from a data management perspective. In this paper, we analyse blockchains from the viewpoint of a developer to highlight important concepts and considerations when incorporating a blockchain into a larger software system as a data store. The work aims to increase the level of understanding of blockchain technology as a data store and to promote a methodical approach in applying it to large software systems. First, we identify the common architectural layers of a typical software system with data stores and conceptualise each layer in blockchain terms. Second, we examine the placement and flow of data in blockchain-based applications. Third, we explore data administration aspects for blockchains, especially as a distributed data store. Fourth, we discuss the analytics of blockchain data and trustable data analytics enabled by blockchain. Lastly, we examine the data governance issues in blockchains in terms of privacy and quality assurance.","['Blockchain', 'Distributed databases', 'Smart contracts', 'Computer architecture', 'Software systems', 'Unified modeling language']","['Analytics', 'blockchain', 'databases', 'data governance', 'data handling', 'distributed data management', 'distributed databases', 'software architecture', 'transaction databases']"
"The Tactile Internet presently constitutes a vision of an Internet over which, in addition to current communications modalities, a sense of touch can be transported. In that case, people would no longer need to be physically near the systems they operate, but could control them remotely. The main problem that needs to be solved to realize the Tactile Internet is summarized by the “1 ms challenge.”If the response time of a system is below 1 ms, the end-user will not be able to tell the difference between controlling a system locally or from another location. This paper offers a summary of the requirements for haptic communications, followed by an overview of challenges in realizing the Tactile Internet. In addition, possible solutions to these challenges are proposed and discussed. For example, the development of the fifth generation mobile communication networks will provide a good foundation upon which a Tactile Internet could be built. This paper also describes the design of a modular testbed needed for testing of a wide variety of haptic system applications.","['Haptic interfaces', 'Internet', 'Delays', '5G mobile communication', 'Security', 'Reliability']","['Tactile Internet', 'haptic communications', '5G communications']"
"With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.","['Cloud computing', 'Big data', 'Open source code', 'Service robots', 'Internet of things', 'Multi-robot systems', 'Energy efficiency', 'Real-time systems']","['cloud computing', 'big data', 'open source', 'cloud robotics', 'internet of things']"
"In information-centric networking, accurately predicting content popularity can improve the performance of caching. Therefore, based on software defined network (SDN), this paper proposes Deep-Learning-based Content Popularity Prediction (DLCPP) to achieve the popularity prediction. DLCPP adopts the switch's computing resources and links in the SDN to build a distributed and reconfigurable deep learning network. For DLCPP, we initially determine the metrics that can reflect changes in content popularity. Second, each network node collects the spatial-temporal joint distribution data of these metrics. Then, the data are used as input to stacked auto-encoders (SAE) in DLCPP to extract the spatiotemporal features of popularity. Finally, we transform the popularity prediction into a multi-classification problem through discretizing the content popularity into multiple classifications. The Softmax classifier is used to achieve the content popularity prediction. Some challenges for DLCPP are also addressed, such as determining the structure of SAE, realizing the neuron function on an SDN switch, and deploying DLCPP on an OpenFlow-based SDN. At the same time, we propose a lightweight caching scheme that integrates cache placement and cache replacement-caching based on popularity prediction and cache capacity (CPC). Abundant experiments demonstrate good performance of DLCPP, and it achieves close to 2.1%~15% and 5.2%~40% accuracy improvements over neural networks and auto regressive, respectively. Benefitting from DLCPP's better prediction accuracy, CPC can yield a steady improvement of caching performance over other dominant cache management frameworks.","['Machine learning', 'Correlation', 'Switches', 'Feature extraction', 'Predictive models', 'Artificial neural networks', 'Data mining']","['Information-centric networking', 'SDN', 'deep learning', 'content popularity prediction', 'caching scheme']"
"Device-to-device (D2D) communications as an underlay to cellular networks can not only increase the system capacity and energy efficiency but also enable national security and public safety services. A key requirement for these services is to provide alternative access to cellular networks when they are partially or fully damaged due to a natural disaster event. In this paper, we employ energy harvesting (EH) at the relay with simultaneous wireless information and power transfer to prolong the lifetime of energy constrained network. In particular, we consider a user equipment relay that harvests energy from radio frequency signal via base station and use harvested energy for D2D communications. We integrate clustering technique with D2D communications into cellular networks such that communication services can be maintained when the cellular infrastructure becomes partially dysfunctional. Simulation results show that our proposed EH-based D2D clustering model performs efficiently in terms of coverage, energy efficiency, and cluster formation to extend the communication area. Moreover, a novel concept of power transfer in D2D clustering with user equipment relay and cluster head is proposed to provide a new framework to handle critical and emergency situations. The proposed approach is shown to provide significant energy saving for both mobile users and clustering heads to survive in emergency and disaster situations.","['Device-to-device communication', 'Relays', 'Computer architecture', 'Safety', 'Energy harvesting', 'Cellular networks', 'Microprocessors']","['D2D', 'SWIPT', 'UERCH', 'energy harvesting', 'clustering']"
"Human emotions recognition (HERO) is considered as one of the important techniques for realizing the intelligent Internet of Things. The demand for a robust and precise facial expression recognition algorithm is urgent for the HERO. In this paper, we propose a deep recognition algorithm based on the ensemble deep learning model. The proposed algorithm consists of three sub-networks with different depths. Each sub-network is comprised of convolutional neutral networks and trained independently. The sub-network with more convolutional layers recognizes emotions by extracting local details such as the features of eyes and mouth, while the sub-network with less convolutional layers focuses on the macrostructure of the input image. The three sub-networks are assembled together to constitute the whole model. The experiment is based on the Kaggle facial expression recognition challenge database (FER2013), the Japanese female facial expression database, and the AffectNet database. The experimental results show that the proposed algorithm achieves a test accuracy of 71.91%, 96.44%, and 62.11% better than other competitors, and increases the test accuracy by approximately 2-3% than unique sub-networks.","['Feature extraction', 'Face recognition', 'Deep learning', 'Classification algorithms', 'Training', 'Training data', 'Emotion recognition']","['Facial expression recognition', 'ensemble learning', 'deep learning', 'convolution neutral networks']"
"The importance of image security in the field of medical imaging is challenging. Several research works have been conducted to secure medical healthcare images. Encryption, not risking loss of data, is the right solution for image confidentiality. Due to data size limitations, redundancy, and capacity, traditional encryption techniques cannot be applied directly to e-health data, especially when patient data are transferred over the open channels. Therefore, patients may lose the privacy of data contents since images are different from the text because of their two particular factors of loss of data and confidentiality. Researchers have identified such security threats and have proposed several image encryption techniques to mitigate the security problem. However, the study has found that the existing proposed techniques still face application-specific several security problems. Therefore, this paper presents an efficient, lightweight encryption algorithm to develop a secure image encryption technique for the healthcare industry. The proposed lightweight encryption technique employs two permutation techniques to secure medical images. The proposed technique is analyzed, evaluated, and then compared to conventionally encrypted ones in security and execution time. Numerous test images have been used to determine the performance of the proposed algorithm. Several experiments show that the proposed algorithm for image cryptosystems provides better efficiency than conventional techniques.","['Security', 'Encryption', 'Medical services', 'Privacy', 'Protocols', 'Organizations', 'Authentication']","['Internet of Medical Things', 'medical image encryption', 'lightweight encryption']"
"Grey Wolf Optimizer (GWO) simulates the grey wolves’ nature in leadership and hunting manners. GWO showed a good performance in the literature as a meta-heuristic algorithm for feature selection problems, however, it shows low precision and slow convergence. This paper proposes a Modified Binary GWO (MbGWO) based on Stochastic Fractal Search (SFS) to identify the main features by achieving the exploration and exploitation balance. First, the modified GWO is developed by applying an exponential form for the number of iterations of the original GWO to increase the search space accordingly exploitation and the crossover/mutation operations to increase the diversity of the population to enhance exploitation capability. Then, the diffusion procedure of SFS is applied for the best solution of the modified GWO by using the Gaussian distribution method for random walk in a growth process. The continuous values of the proposed algorithm are then converted into binary values so that it can be used for the problem of feature selection. To ensure the stability and robustness of the proposed MbGWO-SFS algorithm, nineteen datasets from the UCI machine learning repository are tested. The K-Nearest Neighbor (KNN) is used for classification tasks to measure the quality of the selected subset of features. The results, compared to binary versions of the-state-of-the-art optimization techniques such as the original GWO, SFS, Particle Swarm Optimization (PSO), hybrid of PSO and GWO, Satin Bowerbird Optimizer (SBO), Whale Optimization Algorithm (WOA), Multiverse Optimization (MVO), Firefly Algorithm (FA), and Genetic Algorithm (GA), show the superiority of the proposed algorithm. The statistical analysis by Wilcoxon’s rank-sum test is done at the 0.05 significance level to verify that the proposed algorithm can work significantly better than its competitors in a statistical way.","['Feature extraction', 'Optimization', 'Machine learning algorithms', 'Fractals', 'Benchmark testing', 'Search problems', 'Machine learning']","['Feature selection', 'meta-heuristics', 'stochastic fractal search', 'binary optimizer', 'K-Nearest Neighbor', 'Wilcoxon’s rank-sum test']"
"Optimization algorithms are one of the effective stochastic methods in solving optimization problems. In this paper, a new swarm-based algorithm called Northern Goshawk Optimization (NGO) algorithm is presented that simulates the behavior of northern goshawk during prey hunting. This hunting strategy includes two phases of prey identification and the tail and chase process. The various steps of the proposed NGO algorithm are described and then its mathematical modeling is presented for use in solving optimization problems. The ability of NGO to solve optimization problems is evaluated on sixty-eight different objective functions. To analyze the quality of the results, the proposed NGO algorithm is compared with eight well-known algorithms, particle swarm optimization, genetic algorithm, teaching-learning based optimization, gravitational search algorithm, grey wolf optimizer, whale optimization algorithm, tunicate swarm algorithm, and marine predators algorithm. In addition, for further analysis, the proposed algorithm is also employed to solve four engineering design problems. The results of simulations and experiments show that the proposed NGO algorithm, by creating a proper balance between exploration and exploitation, has an effective performance in solving optimization problems and is much more competitive than similar algorithms.","['Optimization', 'Statistics', 'Sociology', 'Mathematical models', 'Linear programming', 'Search problems', 'Games']","['Exploitation', 'exploration', 'northern goshawk', 'optimization', 'optimization problem']"
"Metaverse (MS) is a digital universe accessible through a virtual environment. It is established through the merging of virtually improved physical and digital reality. Metaverse (MS) offers enhanced immersive experiences and a more interactive learning experience for students in learning and educational settings. It is an expanded and synchronous communication setting that allows different users to share their experiences. The present study aims to evaluate students’ perception of the application of MS in the United Arab Emirates (UAE) for medical-educational purposes. In this study, 1858 university students were surveyed to examine this model. The study’s conceptual framework consisted of adoption constructs including Technology Acceptance Model (TAM), Personal innovativeness (PI), Perceived Compatibility (PCO), User Satisfaction (US), Perceived Triability (PTR), and Perceived Observability (POB). The study was unique because the model correlated technology-based features and individual-based features. The study also used hybrid analyses such as Machine Learning (ML) algorithms and Structural Equation Modelling (SEM). The present study also employs the Importance Performance Map Analysis (IPMA) to assess the importance and performance factors. The study finds US as an essential determinant of users’ intention to use the metaverse (UMS). The present study’s finding is useful for stakeholders in the educational sector in understanding the importance of each factor and in making plans based on the order of significance of each factor. The study also methodologically contributes to Information Systems (IS) literature because it is one of the few studies that have used a complementary multi-analytical approach such as ML algorithms to investigate the UMS metaverse systems.","['Education', 'Virtual environments', 'Three-dimensional displays', 'Real-time systems', 'Mathematical models', 'Avatars', 'Task analysis']","['Personal innovativeness', 'satisfaction', 'triability', 'compatibility', 'users’ satisfaction Metaverse', 'observability']"
"In this paper, real measurements were conducted to investigate the impact of rain on the propagation of millimeter waves at 26 GHz. The measurements were accomplished using a microwave fifth generation radio link system with 1.3 km path length implemented at Universiti Teknologi Malaysia Johor Bahru, Malaysia. The implemented system consisted of Ericsson CN500 mini E-link, radio unit, rain gauge, and data logger. The measurements were attained and logged daily for a continuous year, with 1-min time intervals. Next, the MATLAB software was used to process and analyze the annual rain rate and rain attenuation, including for the worst month. From the analyzed results, it was found that at 0.01% percentage of time, the rain rate was 120 mm/hr; while the specific rain attenuation was 26.2 dB/km and the total rain attenuation over 1.3 km was 34 dB. In addition, the statistics acquired from the measurements for the worst month were lower than what was predicted by the international telecommunication union (ITU) model; around 51% and 34% for the rain rate and rain attenuation, respectively. The average percentage of error calculated between the measurements and predicted results for the rain rate and rain attenuation were 143% and 159%, respectively. Thus, it can be concluded that the statistics for the worst month in Malaysia is lower than what was predicted by the ITU model.","['Rain', 'Attenuation', '5G mobile communication', 'Microwave measurement', 'Mathematical model', 'Attenuation measurement', 'Wireless communication']","['Millimeter wave', 'rain attenuation', 'propagation', 'microwave 5G link', 'access 5G link', 'tropical regions', 'fifth generation systems']"
"This paper presents a feasibility and sensitivity analysis of renewable energy-based off-grid and grid-connected microgrids by investigating the potentials of wind and solar energy at different areas, namely, Kuakata, Sitakunda, Magnama, Dinajpur and Rangpur in Bangladesh - a country that experiences a tropical climate. A specialized neural network algorithm has been employed to track the wind speed and solar irradiance all year round in two salient regions and the promising results have been analyzed for making the decision whether the data are reliable for forecasting or not. Four different types of models including PV-Grid, Wind-Grid, Wind-PV-Grid, and off-grid hybrid renewables are designed using the Hybrid Optimization of Multiple Energy Resources (HOMER Pro) software. By considering the key factors: net present cost, cost of energy, renewable fraction, local load demand, availability of renewable energy resources, system economics and greenhouse gas emissions, the optimal hybrid renewable energy system (HRES) configurations (Wind/PV/Grid/Battery) for the mentioned regions are determined. Various sensitivity and optimization variables, such as RE resources, local load demand, grid energy price, nominal discount rate, the life-time of wind turbine, the capacity of wind turbine, PV arrays, converter, and battery are used to make the decision. Detailed sensitivity analyses are performed to investigate how the optimal system configurations change with a tiny variation in input variables and results show output results are more sensitive on the variations in long-term average wind speed and solar irradiance, nominal discount rate, and the lifetime of wind turbines than the other inputs which is definitely a vital finding of this investigation. Finally, considering several decision making factors, a detailed feasibility chart is presented for two distinct nominal discount rates, i.e., 9% and 10%, which depicts the economically viable renewable energy based plant size in the mentioned regions. Although the crux of this paper is based on providing low-cost electricity to people living in rural areas of Bangladesh, our propositions carry with them certain concomitant benefits, not least of which are environmental and social benefits.","['Renewable energy sources', 'Biological system modeling', 'Wind speed', 'Economics', 'Batteries', 'Optimization', 'Wind energy']","['Cost of energy', 'net present cost', 'greenhouse gas', 'hybrid power system', 'plant size', 'wind', 'solar', 'renewable energy sources']"
"The recent trends to design more efficient and versatile maritime (both marine and offshore) vessels have attracted significant attention toward high penetration of power electronics systems in electric ship systems, which trigged a variety of power system architectures in civilian and naval ships. The availability of advanced power electronics converters further supported to improve maneuverability, efficiency, and compactness at reduced greenhouse gas emission in marine vessels. The fast-growing penetration of these power electronics converters adds a number of advantages to the ship power system. However, risk factors associated with the quality and reliability of the whole system should be considered. Power quality issues in marine networks have been reported from recent field accidents, therefore, the marine regulatory bodies need to revise and/or develop new power quality standards to ensure the reliability and scrutinize the safety of the whole ship system and crews. This paper presents 1) a classification of marine vessels and their power system architectures; 2) power electronics converters topologies and their non-linear characteristics; 3) control and protection architecture; 4) energy efficiency indicators; 5) a comprehensive case study to elaborate power quality in the marine system, and; 6) extensive discussion about power quality standards and highlights the urgency to update existing power quality standards.","['Marine vehicles', 'Propulsion', 'Power quality', 'Power electronics', 'Generators', 'Fuels']","['Marine and ship networks', 'power system architectures', 'micro grids', 'distribution networks', 'power quality', 'energy efficiency', 'regulations', 'standardization', 'grid robustness']"
"Employment of ground-based positioning systems has been consistently growing over the past decades due to the growing number of applications that require location information where the conventional satellite-based systems have limitations. Such systems have been successfully adopted in the context of wireless emergency services, tactical military operations, and various other applications offering location-based services. In current and previous generation of cellular systems, i.e., 3G, 4G, and LTE, the base stations, which have known locations, have been assumed to be stationary and fixed. However, with the possibility of having mobile relays in 5G networks, there is a demand for novel algorithms that address the challenges that did not exist in the previous generations of localization systems. This paper includes a review of various fundamental techniques, current trends, and state-of-the-art systems and algorithms employed in wireless position estimation using moving receivers. Subsequently, performance criteria comparisons are given for the aforementioned techniques and systems. Moreover, a discussion addressing potential research directions when dealing with moving receivers, e.g., receiver's movement pattern for efficient and accurate localization, non-line-of-sight problem, sensor fusion, and cooperative localization, is briefly given.","['Wireless communication', 'Receivers', 'Global Positioning System', 'Wireless sensor networks', 'Radio frequency', 'Kalman filters', 'Geolocation']","['AOA', 'Gaussian mixture', 'geolocation', 'FDOA', 'Kalman filter', 'particle filter', 'TDOA', 'TOA']"
"Mobile devices, such as smartphones, can offload applications and data to the cloud via access points or base stations to reduce energy consumption and improve user experience. However, mobile offloading is vulnerable to smart attackers that use smart and programmable radio devices, such as universal software radio peripherals, to perform multiple types of attacks, such as spoofing and jamming, based on the radio environment and offloading transmissions. In this paper, a mobile offloading game is investigated that consists of three players: a mobile device that chooses its offloading rate, a smart attacker that determines its attack mode, and a security agent that decides whether or not to initiate full protection for the serving access point during the offloading. Nash and Stackelberg equilibria of the offloading game are derived and their existence conditions are discussed. A Q-learning-based mobile offloading strategy is proposed for mobile devices that are unaware of system parameters, such as the channel conditions, in dynamic radio environments. Simulation results show that the proposed offloading strategy can improve the utility of the mobile device and reduce the attack rate of smart attackers.","['Mobile communication', 'Game theory', 'Computer hacking', 'Computer security', 'Computer crime', 'Cloud computing', 'Smart phones', 'Energy consumption', 'Software radio', 'Base stations']","['Mobile offloading', 'spoofing', 'jamming', 'game theory', 'smart attacks', 'Q-learning']"
"In this paper, a new Multi-Objective Arithmetic Optimization Algorithm (MOAOA) is proposed for solving Real-World constrained Multi-objective Optimization Problems (RWMOPs). Such problems can be found in different fields, including mechanical engineering, chemical engineering, process and synthesis, and power electronics systems. MOAOA is inspired by the distribution behavior of the main arithmetic operators in mathematics. The proposed multi-objective version is formulated and developed from the recently introduced single-objective Arithmetic Optimization Algorithm (AOA) through an elitist non-dominance sorting and crowding distance-based mechanism. For the performance evaluation of MOAOA, a set of 35 constrained RWMOPs and five ZDT unconstrained problems are considered. For the fitness and efficiency evaluation of the proposed MOAOA, the results obtained from the MOAOA are compared with four other state-of-the-art multi-objective algorithms. In addition, five performance indicators, such as Hyper-Volume (HV), Spread (SD), Inverted Generational Distance (IGD), Runtime (RT), and Generational Distance (GD), are calculated for the rigorous evaluation of the performance and feasibility study of the MOAOA. The findings demonstrate the superiority of the MOAOA over other algorithms with high accuracy and coverage across all objectives. This paper also considers the Wilcoxon signed-rank test (WSRT) for the statistical investigation of the experimental study. The coverage, diversity, computational cost, and convergence behavior achieved by MOAOA show its high efficiency in solving ZDT and RWMOPs problems.","['Optimization', 'Pareto optimization', 'Task analysis', 'Sorting', 'Genetic algorithms', 'Convergence']","['Arithmetic optimization algorithm (AOA)', 'CEC-2021 real-world problems', 'constrained optimization', 'multi-objective arithmetic optimization algorithm (MOAOA)']"
"The next generation (NG) optical technologies will unveil certain unique features, namely ultra-high data rate, broadband multiple services, scalable bandwidth, and flexible communications for manifold end-users. Among the optical technologies, free space optical (FSO) technology is a key element to achieve free space data transmission according to the requirements of the future technologies, which is due to its cost effective, easy deployment, high bandwidth enabler, and high secured. In this article, we give the overview of the recent progress on FSO technology and the factors that will lead the technology towards ubiquitous application. As part of the review, we provided fundamental concepts across all types of FSO system, including system architecture comprising of single beam and multiple beams. The review is further expanded into the investigation of rain and haze effects toward FSO signal propagation. The final objective that we cover is the scalability of an FSO network via the implementations of hybrid multi-beam FSO system with wavelength division multiplexing (WDM) technology.","['Laser beams', 'Optical transmitters', 'Optical receivers', 'Optical filters', 'Optical scattering', 'Vertical cavity surface emitting lasers', 'Fresnel reflection']","['FSO', 'rain attenuation', 'haze attenuation', 'DWDM multiplexing', 'scalability']"
"To solve the low attack path quantification degree and complex path finding in the industrial Internet of Things, a vulnerability assessment method based on attack graph and maximum flow is proposed. The method takes into account the factors influencing the attack behavior and relationship between network nodes. The attack risk is calculated by common vulnerability scoring system, which increases the attack path quantification degree. The maximum loss flow describes the attack path, evaluates the network vulnerability by maximum loss flow and loss saturation and represents the vulnerability relevance. Avoiding the repeat calculation and obtaining the potential key vulnerability path fast, the augmented road algorithm is used to find optimal attack path within global path. The result shows that the method is feasible and can evaluate the vulnerability and risk path objectively.","['Security', 'Internet of Things', 'Probability', 'Analytical models', 'Correlation', 'Communication networks', 'Maintenance engineering']","['Vulnerability assessment', 'attack graph', 'maximum flow', 'industrial Internet of Things']"
"The liver is a common site for the development of primary (i.e., originating from the liver, e.g., hepatocellular carcinoma) or secondary (i.e., spread to the liver, e.g., colorectal cancer) tumor. Due to its complex background, heterogeneous, and diffusive shape, automatic segmentation of tumor remains a challenging task. So far, only the interactive method has been adopted to obtain the acceptable segmentation results of a liver tumor. In this paper, we design an Attention Hybrid Connection Network architecture which combines soft and hard attention mechanism and long and short skip connections. We also propose a cascade network based on the liver localization network, liver segmentation network, and tumor segmentation network to cope with this challenge. Simultaneously, the joint dice loss function is proposed to train the liver localization network to obtain the accurate 3D liver bounding box, and the focal binary cross entropy is used as a loss function to fine-tune the tumor segmentation network for detecting more potentially malignant tumor and reduce false positives. Our framework is trained using the 110 cases in the LiTS dataset and extensively evaluated by the 20 cases in the 3DIRCADb dataset and the 117 cases in the Clinical dataset, which indicates that the proposed method can achieve faster network convergence and accurate semantic segmentation and further demonstrate that the proposed method has a good clinical value.","['Tumors', 'Liver', 'Image segmentation', 'Three-dimensional displays', 'Task analysis', 'Biomedical imaging', 'Computed tomography']","['Liver tumor segmentation', 'deep convolutional neural network', 'feature fusion', 'attention mechanism']"
"How to manage the uncertainty of the basic probability assignment accurately and efficiently is of significance and also an open issue. Plenty of functions have been established to cover the issue, especially Deng entropy recently. Deng entropy can deal with the more complex situation of the focal elements (propositions). However, Deng entropy has some limitations when the propositions are of the intersection. In this paper, a modified function is proposed by considering the scale of the frame of discernment and the influence of the intersection between statements on uncertainty. The proposed belief entropy provides a promising way to measure the uncertain information. Some numerical examples and an application in pattern recognition are used to show the efficiency and accuracy of the proposed belief entropy.","['Entropy', 'Uncertainty', 'Measurement uncertainty', 'Weight measurement', 'Pattern recognition', 'Decision making', 'Reliability']","['Entropy', 'Deng entropy', 'Shannnon entropy', 'Dempster-Shafer evidence theory', 'pattern recognition']"
"Personnel selection is a critical obstacle that influences the success of the enterprise. The complexity of personnel selection is to determine efficiently the proper applicantion to fulfill enterprise requirements. The decision makers do their best to match enterprise requirements with the most suitable applicant. Unfortunately, the numerous criterions, alternatives, and goals make the process of choosing among several applicants is very complex and confusing to decision making. The environment of decision making is a multi-criteria decision making surrounded by inconsistency and uncertainty. This paper contributes to support personnel selection process by integrating neutrosophic analytical hierarchy process (AHP) with the technique for order preference by similarity to an ideal solution (TOPSIS) to illustrate an ideal solution amongst different alternatives. A case study on smart village Cairo Egypt is developed based on decision maker's judgments recommendations. The proposed study applies neutrosophic AHP and TOPSIS to enhance the traditional methods of personnel selection to achieve the ideal solutions. By reaching the ideal solutions, the smart village will enhance the resource management for attaining the goals to be a successful enterprise. The proposed method demonstrates a great impact on the personnel selection process rather than the traditional decision-making methods.","['Personnel', 'Uncertainty', 'Analytic hierarchy process', 'Organizations', 'Complexity theory']","['Personnel selection', 'multi-criteria decision making (MCDM)', 'neutrosophic sets', 'analytic hierarchy process (AHP)', 'topsis']"
"Correct identifying analog circuit incipient faults is useful to the circuit's health monitoring, and yet it is very hard. In this paper, an analog circuit incipient fault diagnosis method using deep belief network (DBN) based features extraction is presented. In the diagnosis scheme, time responses of analog circuits are measured, and then features are extracted by using the DBN method. Meanwhile, the learning rates of DBN are produced by using quantum-behaved particle swarm optimization (QPSO) algorithm, which is beneficial to optimizing the structure parameters of DBN. Afterward, a support vector machine (SVM) based incipient fault diagnosis model is constructed on basis of the extracted features to classify incipient faulty components, where the regularization parameter and width factor of SVM are yielded by using the QPSO algorithm. Sallen-Key bandpass filter and four-op-amp biquad high pass filter incipient fault diagnosis simulations are conducted to demonstrate the proposed diagnosis method, and comparisons verify that the proposed diagnosis method can produce higher diagnosis accuracy than other typical analog circuit fault diagnosis methods.","['Feature extraction', 'Fault diagnosis', 'Analog circuits', 'Circuit faults', 'Support vector machines', 'Data mining', 'Electrical engineering']","['Analog circuits', 'incipient fault diagnosis', 'DBN', 'SVM', 'QPSO']"
"Anomaly detection has attracted considerable attention from the research community in the past few years due to the advancement of sensor monitoring technologies, low-cost solutions, and high impact in diverse application domains. Sensors generate a huge amount of data while monitoring the physical spaces and objects. These huge collected data streams can be analyzed to identify unhealthy behaviors. It may reduce functional risks, avoid unseen problems, and prevent downtime of the systems. Many research methodologies have been designed and developed to determine such anomalous behaviors in security and risk analysis domains. In this paper, we present the results of a systematic literature review about anomaly detection techniques except for these dominant research areas. We focus on the studies published from 2000 to 2018 in the application areas of intelligent inhabitant environments, transportation systems, health care systems, smart objects, and industrial systems. We have identified a number of research gaps related to the data collection, the analysis of imbalanced large datasets, limitations of statistical methods to process the huge sensory data, and few research articles in abnormal behavior prediction in real scenarios. Based on our analysis, researchers and practitioners can acquaint themselves with the existing approaches, use them to solve real problems, and/or further contribute to developing novel techniques for anomaly detection, prediction, and analysis.","['Anomaly detection', 'Bibliographies', 'Systematics', 'Temperature sensors', 'Databases', 'Monitoring', 'Security']","['Statistical learning', 'machine learning', 'intelligent environments', 'smart objects', 'intelligent transportation systems', 'industrial systems']"
"Increasingly, blockchain technology is attracting significant attentions in various agricultural applications. These applications could satisfy the diverse needs in the ecosystem of agricultural products, e.g., increasing transparency of food safety and IoT based food quality control, provenance traceability, improvement of contract exchanges, and transactions efficiency. As multiple untrusted parties, including small-scale farmers, food processors, logistic companies, distributors and retailers, are involved into the complex farm-to-fork pipeline, it becomes vital to achieve optimal trade-off between efficiency and integrity of the agricultural management systems as required in contexts. In this paper, we provide a survey to study both techniques and applications of blockchain technology used in the agricultural sector. First, the technical elements, including data structure, cryptographic methods, and consensus mechanisms are explained in detail. Secondly, the existing agricultural blockchain applications are categorized and reviewed to demonstrate the use of the blockchain techniques. In addition, the popular platforms and smart contract are provided to show how practitioners use them to develop these agricultural applications. Thirdly, we identify the key challenges in many prospective agricultural systems, and discuss the efforts and potential solutions to tackle these problems. Further, we conduct an improved food supply chain in the post COVID-19 pandemic economy as an illustration to demonstrate an effective use of blockchain technology.","['Cryptography', 'Data integrity', 'Supply chains', 'Memory', 'Ecosystems', 'Agriculture']","['Blockchain technology', 'agricultural applications', 'food supply chains management', 'data integrity', 'traceability']"
"The diagnosis of breast cancer histology images with hematoxylin and eosin stained is non-trivial, labor-intensive and often leads to a disagreement between pathologists. Computer-assisted diagnosis systems contribute to help pathologists improve diagnostic consistency and efficiency. With the recent advances in deep learning, convolutional neural networks (CNNs) have been successfully used for histology images analysis. The classification of breast cancer histology images into normal, benign, and malignant sub-classes is related to cells' density, variability, and organization along with overall tissue structure and morphology. Based on this, we extract both smaller and larger size patches from histology images, including cell-level and tissue-level features, respectively. However, there are some sampled cell-level patches that do not contain enough information that matches the image tag. Therefore, we propose a patches' screening method based on the clustering algorithm and CNN to select more discriminative patches. The approach proposed in this paper is applied to the 4-class classification of breast cancer histology images and achieves 95% accuracy on the initial test set and 88.89% accuracy on the overall test set. The results are competitive compared to the results of other state-of-the-art methods.","['Feature extraction', 'Breast cancer', 'Data mining', 'Image resolution', 'Deep learning']","['Breast cancer histology images', 'multi-size patches', 'discriminating patches', 'CNN', 'image classification']"
"Via processing the computation intensive applications (apps) at the network edge, mobile edge computing (MEC) becomes a promising technology to enhance the ability of the user equipments (UEs). Most existing works usually focus on whether to offload or where to offload the apps under the premise that sufficient resources are owned by the network edge. However, the demand heterogeneity of UEs and the limitation of resources are usually failed to be considered. Since the limited resources may constrain the number of accessed UEs, how the MEC service providers (SPs) choose the UEs to serve while ensuring UEs' Quality of Service (QoS) is a key issue. Under this context, in this paper, we study the matching problem between the MEC SPs and the UEs in a multi-MEC and multi-UE scenario. Within this scenario, MEC SPs are equipped with limited wireless and computational resources. Auction theory is utilized to model the matching relationship between MEC SPs and UEs as the commodity trading. With this trading, UEs can obtain MEC service from SPs, when they successfully purchase the combinational resources (including computational and wireless resources) from SPs. To complete the auction process, a multi-round-sealed sequential combinatorial auction mechanism is proposed. The properties of the auction are proved and various simulation results are done to show that the proposed approach has better system performance compared with the existing algorithms.","['Wireless communication', 'Cost accounting', 'Computational modeling', 'Cloud computing', 'Delays', 'Resource management', 'Mobile communication']","['Mobile edge computing', 'computation offloading', 'MEC SP and UE matching', 'combinational auction', 'demand heterogeneity']"
"Rotating machinery is of vital importance in the field of engineering, including aviation and navigation. Its failure will lead to severe loss to personnel safety and the stability of the equipment system. It is a long way to investigate the relevant fault diagnosis method, especially the intelligent fault diagnosis method on the basis of deep learning. In consideration of the limitations of traditional fault diagnosis approaches based on shallow layer network structure, the methods based on deep neural network (DNN) are worthy of thorough exploration. As a common DNN with special structure, deep convolutional neural network is of great concern in intelligent fault diagnosis due to its advantages in processing nonlinear problems. This review will play an emphasis on convolutional neural network (CNN). The basic structure and principle are introduced. The applications of CNN-based fault diagnosis method in rotating machinery are summarized and analyzed. Furthermore, the diagnosis performance and potential mechanism from different CNN methods are discussed. In the end, this review is highlighted on the challenges and the potential key points in research on novel intelligent fault diagnosis strategies. The corresponding analysis and discussion will provide some references and lay the foundation for the investigation in related fields.","['Fault diagnosis', 'Machinery', 'Feature extraction', 'Support vector machines', 'Convolution', 'Transforms', 'Convolutional neural networks']","['Deep learning', 'convolutional neural network', 'intelligent fault diagnosis', 'rotating machinery']"
"Recently, building an accurate mathematical model with the help of the experimentally measured data of solar cells and Photovoltaic (PV) modules, as a tool for simulation and performance evaluation of the PV systems, has attracted the attention of many researchers. In this work, Coyote Optimization Algorithm (COA) has been applied for extracting the unknown parameters involved in various models for the solar cell and PV modules, namely single diode model, double diode model, and three diode model. The choice of COA algorithm for such an application is made because of its good tracking characteristics and the balance creation between the exploration and exploitation phases. Additionally, it has only two control parameters and such a feature makes it very simple in application. The Root Mean Square Error (RMSE) value between the data based on the optimized parameters for each model and those based on the measured data of the solar cell and PV modules is adopted as the objective function. Parameters' estimation for various types of PV modules (mono-crystalline, thin-film, and multi-crystalline) under different operating scenarios such as a change in intensity of solar radiation and cell temperature is studied. Furthermore, a comprehensive statistical study has been performed to validate the accurateness and stability of the applied COA as a competitor to other optimization algorithms in the optimal design of PV module parameters. Simulation results, as well as the statistical measurement, validate the superiority and the reliability of the COA algorithm not only for parameter extraction of different PV modules but also under different operating scenarios. With the COA, precise PV models have been established with acceptable RMSE of 7.7547×10 -4 , 7.64801×10 -4 , and 7.59756×10 -4 for SDM, DDM, and TDM respectively considering R.T.C. France solar cell.","['Mathematical model', 'Integrated circuit modeling', 'Optimization', 'Photovoltaic cells', 'Analytical models', 'Parameter estimation', 'Estimation']","['Solar cells', 'PV modules', 'parameter extraction', 'optimization', 'coyote optimization algorithm', 'single diode model', 'double diode model', 'three diode model']"
"This article addresses the problem of detecting misleading information related to COVID-19. We propose a misleading-information detection model that relies on the World Health Organization, UNICEF, and the United Nations as sources of information, as well as epidemiological material collected from a range of fact-checking websites. Obtaining data from reliable sources should assure their validity. We use this collected ground-truth data to build a detection system that uses machine learning to identify misleading information. Ten machine learning algorithms, with seven feature extraction techniques, are used to construct a voting ensemble machine learning classifier. We perform 5-fold cross-validation to check the validity of the collected data and report the evaluation of twelve performance metrics. The evaluation results indicate the quality and validity of the collected ground-truth data and their effectiveness in constructing models to detect misleading information.","['Feature extraction', 'Social network services', 'Reliability', 'Machine learning algorithms', 'Diseases', 'Machine learning', 'Data models']","['Coronavirus', 'COVID-19', 'fake news detection', 'infodemic', 'misleading information', 'pandemic', 'SARS-CoV-2', 'social media', 'social networks', 'text classification', 'text mining', 'web mining', 'WHO']"
"Fog computing is an emerging technology to address computing and networking bottlenecks in large scale deployment of IoT applications. It is a promising complementary computing paradigm to cloud computing where computational, networking, storage and acceleration elements are deployed at the edge and network layers in a multi-tier, distributed and possibly cooperative manner. These elements may be virtualized computing functions placed at edge devices or network elements on demand, realizing the “computing everywhere” concept. To put the current research in perspective, this paper provides an inclusive taxonomy for architectural, algorithmic and technologic aspects of fog computing. The computing paradigms and their architectural distinctions, including cloud, edge, mobile edge and fog computing are subsequently reviewed. Practical deployment of fog computing includes a number of different aspects such as system design, application design, software implementation, security, computing resource management and networking. A comprehensive survey of all these aspects from the architectural point of view is covered. Current reference architectures and major application-specific architectures describing their salient features and distinctions in the context of fog computing are explored. Base architectures for application, software, security, computing resource management and networking are presented and are evaluated using a proposed maturity model.","['Edge computing', 'Cloud computing', 'Computer architecture', 'Resource management', 'Security', 'Taxonomy', 'Software']","['Cloud Computing', 'edge computing', 'fog computing', 'Internet of Things (IoT)', 'advanced internet architecture']"
"An automatic modulation classification has a very broad application in wireless communications. Recently, deep learning has been used to solve this problem and achieved superior performance. In most cases, the input size is fixed in convolutional neural network (CNN)-based modulation classification. However, the duration of the actual radio signal burst is variable. When the signal length is greater than the CNN input length, how to make full use of the complete signal burst to improve the classification accuracy is a problem needs to be considered. In this paper, three fusion methods are proposed to solve this problem, such as voting-based fusion, confidence-based fusion, and feature-based fusion. The simulation experiments are done to analyze the performance of these methods. The results show that the three fusion methods perform better than the non-fusion method. The performance of the two fusion methods based on confidence and feature is very close, which is better than that of the voting-based fusion.","['Modulation', 'Convolution', 'Wireless communication', 'Deep learning', 'Training', 'Convolutional neural networks']","['Modulation classification', 'deep learning', 'fusion', 'convolutional neural network', 'residual network', 'wireless communications', 'cognitive radio']"
"There is a series of image degradation in the image acquired in haze and other weather. The single image dehazing is a challenging and ill-posed problem. Using deep neural network methods, it solves the drawbacks of manually designing haze-related features. This paper proposes a dehazing algorithm using residual-based deep CNN. The network model is divided into two phases: in the first stage, a haze image is input, and the transmission map is estimated by network; in the second stage, the ratio of foggy image and transmission map is used as input, and the residual network is used to remove haze. It avoids the estimation of atmospheric light and improves the efficiency of dehazing. To train the proposed network, we use the NYU2 depth dataset as the training set. In the full-reference metric peak signal to noise ratio, structural similarity, and feature similarity and no-reference metric Spatial-Spectral Entropy-based Quality, Blind/Referenceless Image Spatial Quality Evaluator, and Natural Image Quality Evaluator aspect, the experimental results confirm the efficiency and robustness of the proposed method.","['Atmospheric modeling', 'Scattering', 'Image restoration', 'Training', 'Convolutional neural networks']","['Image dehazing', 'residual network', 'deep learning', 'convolutional neural network']"
"As we all know that the technology is projected to be next to humans very soon because of its holistic growth. Now-a-days, we see a lot of applications that are making our lives comfortable such as smart cars, smart homes, smart traffic management, smart offices, smart medical consultation, smart cities, etc. All such facilities are in the reach of a common man because of the advancement in Information and Communications Technology (ICT). Because of this advancement, new computing and communication environment such as Internet of Things (IoT) came into picture. Lot of research work is in progress in IoT domain which helps for the overall development of the society and makes the lives easy and comfortable. But in the resource constrained environment of Wireless Sensor Network (WSN) and IoT, it is almost inconceivable to establish a fully secure system. As we are moving forward very fast, technology is becoming more and more vulnerable to the security threats. In future, the number of Internet connected people will be less than the smart objects so we need to prepare a robust system for keeping the above mentioned environments safe and standardized it for the smooth conduction of communication among IoT objects. In this survey paper, we provide the details of threat model applicable for the security of WSN and IoT based communications. We also discuss the security requirements and various attacks possible in WSN and IoT based communication environments. The emerging projects of WSNs integrated to IoT are also briefed. We then provide the details of different architectures of WSN and IoT based communication environments. Next, we discuss the current issues and challenges related to WSN and IoT. We also provide a critical literature survey of recent intrusion detection protocols for IoT and WSN environments along with their comparative analysis. A taxonomy of security and privacy-preservation protocols in WSN and IoT is also highlighted. Finally, we discuss some research challenges which need to be addressed in the coming future.","['Wireless sensor networks', 'Monitoring', 'Temperature sensors', 'Security', 'Temperature measurement', 'Intelligent sensors']","['Wireless sensor network (WSN)', 'Internet of Things (IoT)', 'intrusion detection', 'cloud computing', 'fog computing', 'edge computing', 'security']"
"Non-orthogonal multiple access (NOMA) is one promising technology, which provides high system capacity, low latency, and massive connectivity, to address several challenges in the fifth-generation wireless systems. In this paper, we first reveal that the NOMA techniques have evolved from single-carrier NOMA (SC-NOMA) into multi-carrier NOMA (MC-NOMA). Then, we comprehensively investigated on the basic principles, enabling schemes and evaluations of the two most promising MC-NOMA techniques, namely sparse code multiple access (SCMA) and pattern division multiple access (PDMA). Meanwhile, we consider that the research challenges of SCMA and PDMA might be addressed with the stimulation of the advanced and matured progress in SC-NOMA. Finally, yet importantly, we investigate the emerging applications, and point out the future research trends of the MC-NOMA techniques, which could be straightforwardly inspired by the various deployments of SC-NOMA.","['NOMA', '5G mobile communication', 'Wireless communication', '3GPP', 'Market research', 'Multiaccess communication', 'Radio access networks']","['Non-orthogonal multiple access (NOMA)', 'multi-carrier NOMA (MC-NOMA)', 'power domain NOMA (PD-NOMA)', 'sparse code multiple access (SCMA)', 'pattern division multiple access (PDMA)']"
"Mobile cyber-physical systems (CPS) that take the advantages and extend the application domains of CPS have become increasingly popular in recent years. For example, mobile CPS could be a kind of foundational techniques to support the development of vehicular networking systems, thereby improving security and privacy of users in the dynamic environments of vehicular networks. In this paper, we first distinguish mobile CPS from traditional CPS. Then, we introduce their three emerging application areas, i.e., vehicular networking systems, healthcare systems, and mobile education. After that, we discuss four main research challenges of mobile CPS regarding security, energy consumption, mobile dynamic environment, and system stability. Also, we consider the corresponding techniques, which may address these challenges, and analyze the inter-relations among them. Finally, we outline the possible research directions and applications of mobile CPS in the future.","['Mobile communication', 'Mobile computing', 'Medical services', 'Education', 'Sensors', 'Security', 'Vehicle dynamics']","['Mobile cyber-physical systems', 'vehicular networks', 'security', 'privacy', 'dynamic']"
"Accompanied by the rapid development of mobile video service requirements, the dramatic increase in video streaming traffic causes a heavy burden for mobile networks. Mobile edge computing (MEC) has become a promising paradigm to enhance the mobile networks by providing cloudcomputing capabilities within the radio access network (RAN). With the ability of content caching and context awareness, MEC could provide low-latency and adaptive-bitrate video streaming to improve service providing ability of the RAN. In this paper, we propose an MEC enhanced adaptive bitrate (ABR) video delivery scheme, which combines content caching and ABR streaming technology together. The MEC server acts as a controlling component to implement the video caching strategy and adjust the transmitted bitrate version of videos flexibly. A Stackelberg game is formulated to deal with the storage resources occupied by each base station. The joint cache and radio resource allocation (JCRA) is tackled into a matching problem. We propose the JCRA algorithm to solve the matching problem in order to make the cooperation between cache and radio resources. Simulation results reveal that the proposed scheme could improve both the cache hit ratio and the system throughput over other schemes.","['Streaming media', 'Mobile communication', 'Servers', 'Bit rate', 'Wireless communication', 'Mobile computing', 'Resource management']","['MEC', 'content caching', 'adaptive bitrate streaming', 'Stackelberg game', 'matching theory']"
"In recent years, the environmental problems in China have become more and more serious, for example, resource depletion, environmental pollution, ecological imbalance, and so on. At the same time, the laws and regulations about the environmental protection in the world are constantly introduced, the academic research about the environmental issues is also increasing, more and more consumers show concern for the green products, and the restrictions of the “green trade barrier”in the international to the export products in China enterprises must pay attention to the influence of their behavior on the environment in pursuit of economic efficiency. In this context, the green supply chain management (GSCM) emerges. GSCM theory first appeared in some foreign countries, and started later in China. Compared with some developed countries, the GSCM theory in China is still not mature. From the source speaking, there is lack of a complete GSCM system. In this paper, we combine the generalized weighted Bonferroni mean (GWBM) operator, generalized weighted geometric Bonferroni mean (GWGBM) operator, dual GWBM operator, and dual GWGBM operator with Pythagorean 2-tuple linguistic numbers to propose the generalized Pythagorean 2-tuple linguistic WBM (GP2TLWBM) operator, generalized Pythagorean 2-tuple linguistic WGBM (GP2TLWGBM) operator, dual GP2TLWBM (DGP2TLWBM) operator, and dual GP2TLWGBM (DGP2TLWGBM) operator, and then, the multiple attribute decision-making (MADM) methods are developed based on DGP2TLWBM and DGP2TLWGBM operators. Finally, we use an example for green supplier selection to prove the MADM process of the proposed algorithms.","['Pragmatics', 'Green products', 'Supply chain management', 'Fuzzy sets', 'Fuses', 'Decision making', 'Tools']","['Multiple attribute decision making (MADM)', 'Pythagorean 2-tuple linguistic numbers (P2TLNs)', 'weighted Bonferroni mean (WBM) operator', 'weighted geometric Bonferroni mean (WGBM) operator', 'green supplier selection', 'green supply chain management (GSCM)']"
"The Internet of Things (IoT) connects billions of devices to afford inventive opportunities between things and people. The rapid development of products related to the IoT is a new challenge to keep security issues, lack of confidence, and understanding of the IoT. Analytical hierarchy process (AHP) is a classic multi-criteria decision making (MCDM) method used to analyze and scale complex problems and to obtain weights for the selected criteria. The vague and inconsistent information in real situations can lead to the decision maker's confusion. The decision makers cannot determine accurate judgments for all situations due to the conditions of uncertainty factors in real life; in addition to the limited knowledge and experience of decision makers. In this research, we present a neutrosophic AHP of the IoT in enterprises to help decision makers to estimate the influential factors. The estimation of influential factors can affect the success of the IoT-related enterprise. This study combines AHP methods with neutrosophic techniques to effectively present the criteria related to influential factors. The recommended alternatives are presented based on neutrosophic techniques satisfying the estimated influential factors for a successful enterprise. A case study is applied in Smart Village, Cairo, Egypt, to show the applicability of the proposed model. The smart village' consistency rate is measured after applying neutrosophic methodologies to reach to nearest optimum results. Additional case studies on the smart city in the U.K. and China have been presented to justify that our proposal can be used and replicated in different environments.","['Internet of Things', 'Analytic hierarchy process', 'Estimation', 'Uncertainty', 'Security', 'Smart cities']","['Multi-criteria decision making (MCDM)', 'analytical hierarchal Process (AHP)', 'neutrosophic sets', 'Internet of Things (IoT)']"
"Chronic Kidney Disease is one of the most critical illness nowadays and proper diagnosis is required as soon as possible. Machine learning technique has become reliable for medical treatment. With the help of a machine learning classifier algorithms, the doctor can detect the disease on time. For this perspective, Chronic Kidney Disease prediction has been discussed in this article. Chronic Kidney Disease dataset has been taken from the UCI repository. Seven classifier algorithms have been applied in this research such as artificial neural network, C5.0, Chi-square Automatic interaction detector, logistic regression, linear support vector machine with penalty L1 & with penalty L2 and random tree. The important feature selection technique was also applied to the dataset. For each classifier, the results have been computed based on (i) full features, (ii) correlation-based feature selection, (iii) Wrapper method feature selection, (iv) Least absolute shrinkage and selection operator regression, (v) synthetic minority over-sampling technique with least absolute shrinkage and selection operator regression selected features, (vi) synthetic minority over-sampling technique with full features. From the results, it is marked that LSVM with penalty L2 is giving the highest accuracy of 98.86% in synthetic minority over-sampling technique with full features. Along with accuracy, precision, recall, F-measure, area under the curve and GINI coefficient have been computed and compared results of various algorithms have been shown in the graph. Least absolute shrinkage and selection operator regression selected features with synthetic minority over-sampling technique gave the best after synthetic minority over-sampling technique with full features. In the synthetic minority over-sampling technique with least absolute shrinkage and selection operator selected features, again linear support vector machine gave the highest accuracy of 98.46%. Along with machine learning models one deep neural network has been applied on the same dataset and it has been noted that deep neural network achieved the highest accuracy of 99.6%.","['Kidney', 'Diseases', 'Classification algorithms', 'Machine learning algorithms', 'Support vector machines', 'Prediction algorithms', 'Machine learning']","['Chronic kidney disease', 'machine learning', 'prediction']"
"In recent years, electronic word of mouth (e-WOM) has been widely used by consumers on different online platforms. The numerous studies have emphasized the growing importance of e-WOM for the consumer decision-making process, particularly in the tourist sector. There are various factors that will influence the adoption of e-WOM by the users but among all these factors, credibility is of paramount importance. Changes in the platform, new consumer trends, and possible fake information require a continuous update and analysis of the factors that can influence the e-WOM perceived credibility and e-WOM adoption on TripAdvisor and other social tourism platforms. In the present study, we analyzed the following five factors that can impact e-WOM perceived credibility and e-WOM adoption: 1) volume of e-WOM; 2) source credibility; 3) rate extremism; 4) consumer involvement, and; 5) perceived e-WOM credibility. For the analysis, the Elaboration Likelihood Model (ELM) and PLS-SEM were used. The sample consisted of a total of 221 participants who responded to the questionnaire. The results revealed that, with the exception rate extremism, the four remaining factors have a significant impact on e-WOM perceived credibility and adoption. Therefore, these factors are important drivers of the e-WOM perceived credibility resulting in the e-WOM adoption. The results of the present study provide meaningful practical implications for hotel or social tourism platforms managers in terms of possible strategies to improve their online reputation.","['Companies', 'Industries', 'Internet', 'Information processing', 'Consumer electronics', 'Decision making', 'Analytical models']","['e-WOM', 'ELM', 'reviews', 'reputation management', 'tourism', 'marketing', 'credibility']"
"Deep learning techniques have gained significant importance among artificial intelligence techniques for any computing applications. Among them, deep convolutional neural networks (DCNNs) is one of the widely used deep learning networks for any practical applications. The accuracy is generally high and the manual feature extraction process is not necessary in these networks. However, the high accuracy is achieved at the cost of huge computational complexity. The complexity in DCNN is mainly due to: 1) increased number of layers between input and output layers and 2) two set of parameters (one set of filter coefficients and another set of weights) in the fully connected network need to be adjusted. In this paper, the second aspect is targeted to reduce the computational complexity of conventional DCNN. Suitable modifications are performed in the training algorithm to reduce the number of parameter adjustments. The weight adjustment process in the fully connected layer is completely eliminated in the proposed modified approach. Instead, a simple assignment process is used to find the weights of this fully connected layer. Thus, the computational complexity is significantly reduced in the proposed approach. The application of modified DCNN is explored in the context of magnetic resonance brain tumor image classification. Abnormal brain tumor images from four different classes are used in this paper. The experimental results show promising results for the proposed approach.","['Image classification', 'Convolutional neural networks', 'Biomedical imaging', 'Tumors', 'Convolution', 'Brain']","['Deep learning', 'convolutional neural network', 'brain images', 'image classification']"
"In this article, a novel method based on interval type-3 fuzzy logic systems (IT3-FLSs) and an online learning approach is designed for power control and battery charge planing for photovoltaic (PV)/battery hybrid systems. Unlike the other methods, the dynamics of battery, PV and boost converters are considered to be fully unknown. Also, the effects of variation of temperature, radiation, and output load are taken into account. The robustness and the asymptotic stability of the proposed method is analyzed by the Lyapunov/LaSalle's invariant set theorems, and the tuning rules are extracted for IT3-FLS. Also, the upper bound of approximation error (AE) is approximated, and then a new compensator is designed to deal with the effects of dynamic AEs. The superiority of the proposed method is examined in several conditions and is compared with some other well-known methods. It is shown that the schemed method results in high performance under difficult conditions such as variation of temperature and radiation and abruptly changing in the output load.","['Batteries', 'Fuzzy logic', 'Solar energy', 'Control systems', 'Voltage control', 'Uncertainty', 'Thermal stability']","['Fuzzy systems', 'learning algorithms', 'power management', 'type-3 fuzzy systems', 'adaptive control', 'machine learning', 'artificial intelligence']"
"Clustering sensor nodes is an effective method in designing routing algorithms for Wireless Sensor Networks (WSNs), which improves network lifetime and energy efficiency. In clustered WSNs, cluster heads are the key nodes, they need to perform more tasks, so they consume more energy. Therefore, it is an important problem to select the optimal cluster heads. In this paper, we propose a clustering algorithm that selects cluster heads using an improved artificial bee colony (ABC) algorithm. Based on the standard ABC algorithm, an efficient improved ABC algorithm is proposed, and then the network cluster head energy, cluster head density, cluster head location and other similar factors are introduced into the improved ABC algorithm theory to solve the clustering problem in WSNs. In the network initialization period, all nodes have the same energy level, the improved ABC algorithm is used to optimize fuzzy C-means clustering to find the optimal clustering method. We also propose an energy-efficient routing algorithm based on an improved ant colony optimization for routing between the cluster heads and the base station. In order to improve energy efficiency and further improve network throughput, in the stable transmission phase, we introduce a polling control mechanism based on busy/idle nodes into intra-cluster communication. The performance of the proposed protocol is evaluated in several different scenarios. The simulation results show that the proposed protocol has a better performance compared to a number of recent similar protocols.","['Base stations', 'Clustering algorithms', 'Wireless sensor networks', 'Energy consumption', 'Routing', 'Routing protocols']","['WSN', 'clustering', 'energy efficiency', 'network lifetime', 'high throughput', 'polling', 'routing algorithm', 'artificial bee colony']"
"As one of the key functions in lithium-ion battery management system, the state-of-health (SOH) estimation is of great significance to ensure the safe and reliable operation and reduce the maintenance cost of the battery energy storage system. Unscented particle filter (UPF) algorithm is becoming a promising method for battery state estimation since it combines the latest measurement information to give the proposal distribution which is closer to the true posterior distribution. At the same time, UPF algorithm is able to represent the uncertainty involved in the estimation results, which makes great significance for battery SOH estimation. On the other hand, it is difficult to measure the battery actual capacity in practice despite the capacity is a direct indicator of battery SOH. In this paper, an on-line health indicator (HI) is extracted from the measurable parameters while battery is working. The mapping model between the extracted HI and battery SOH is established and applied as the observation in the state-space model. An on-line estimator based on UPF algorithm is developed for battery SOH assessment. The maximum estimation error based on battery cycling test data is less than 5%. This indicates that the proposed method has a good adaptability for lithium-ion battery degradation with non-linear and non-Gaussian characteristics. Additionally, the experiments on different types of lithium-ion battery show the good robustness and applicability of this approach.","['Estimation', 'Lithium-ion batteries', 'Battery charge measurement', 'Degradation', 'Time measurement', 'Standards']","['Lithium-ion battery', 'on-line SOH estimation', 'health indicator', 'unscented particle filter']"
"Citation recommendation is an interesting and significant research area as it solves the information overload in academia by automatically suggesting relevant references for a research paper. Recently, with the rapid proliferation of information technology, research papers are rapidly published in various conferences and journals. This makes citation recommendation a highly important and challenging discipline. In this paper, we propose a novel citation recommendation method that uses only easily obtained citation relations as source data. The rationale underlying this method is that, if two citing papers are significantly co-occurring with the same citing paper(s), they should be similar to some extent. Based on the above rationale, an association mining technique is employed to obtain the paper representation of each citing paper from the citation context. Then, these paper representations are pairwise compared to compute similarities between the citing papers for collaborative filtering. We evaluate our proposed method through two relevant real-world data sets. Our experimental results demonstrate that the proposed method significantly outperforms the baseline method in terms of precision, recall, and F1, as well as mean average precision and mean reciprocal rank, which are metrics related to the rank information in the recommendation list.","['Collaboration', 'Filtering', 'Citation recommendation', 'Context modeling', 'Text mining']","['Citation Recommendation', 'Collaborative Filtering', 'Citation Context', 'Citation Relation Matrix', 'Association Mining']"
"This paper presents a dual autoencoder network model based on the retinex theory to perform the low-light enhancement and noise reduction by combining the stacked and convolutional autoencoders. The proposed method first estimates the spatially smooth illumination component which is brighter than an input low-light image using a stacked autoencoder with a small number of hidden units. Next, we use a convolutional autoencoder which deals with 2-D image information to reduce the amplified noise in the brightness enhancement process. We analyzed and compared roles of the stacked and convolutional autoencoders with the constraint terms of the variational retinex model. In the experiments, we demonstrate the performance of the proposed algorithm by comparing with the state-of-the-art existing low-light and contrast enhancement methods.","['Lighting', 'Image enhancement', 'Brightness', 'Image reconstruction', 'Noise reduction', 'Convolution', 'Image edge detection']","['Autoencoder', 'image processing', 'image enhancement', 'neural networks', 'variational retinex model', 'unsupervised learning']"
"Wireless sensor networks (WSNs) are a prominent fundamental technology of the Internet of Things (IoTs). Rather than device-to-device communications, group communications in the form of broadcasting and multicasting incur efficient message deliveries among resource-constrained sensor nodes in the IoT-enabled WSNs. Secure and efficient key management is in many cases used to protect the authenticity, integrity, and confidentiality of multicast messages. This paper develops two group key establishment protocols for secure multicast communications among the resource-constrained devices in IoT. Major deployment conditions and requirements of each protocol are described in terms of the specific IoT application scenarios. Furthermore, the applicability of the two protocols is analyzed and justified by a comprehensive analysis of the performance, scalability, and security of the protocols proposed.","['Protocols', 'Wireless sensor networks', 'Multicast communication', 'Digital signatures', 'Public key', 'Scalability']","['Internet of Things', 'Wireless Sensor Networks', 'multicast', 'security', 'group key establishment']"
"Electroencephalography (EEG) is immediate and sensitive to cortical impairment resulting from ischemic stroke and is considered as the potential predictive tool of stroke onset, and post-stroke clinical management. Brainwave monitoring outside the heavily equipped clinical environment demands a low-cost, portable, and wearable EEG system. This study aims to assess the feasibility of using an ambulatory EEG system to classify the stroke patient group with neurological changes due to ischemic stroke and the control healthy adult group. HealthSOS, a real-time health monitoring system for stroke prognostics, is proposed here, which consists of an eye-mask embedded portable EEG device, data analytics, and medical ontology based health advisor service. This system was investigated with 37 stroke patients (mean age 71.6 years, 61% male) admitted in the emergency unit of a hospital and 36 healthy elderly volunteers (mean age 76 years, 28% male). EEG was recorded in resting-state using the portable device with frontal cortical electrodes (Fp1, Fp2) embedded in an eye-mask within 120 h after the onset of symptoms of ischemic stroke (confirmed clinically). The EEG data acquisition of the left and right brain hemispheres was done for at least 15 minutes in the awake resting state while subjects laid down on the bed. The statistical result shows that the revised brain symmetry index (rsBSI), the delta-alpha ratio, and the delta-theta ratio of the stroke group differ significantly from those of the healthy control group. In the machine learning analysis, the support vector machine (SVM) model shows the highest accuracy (Overall accuracy: 92%) and the highest Gini coefficient (95%) in classification performance. This study will be useful for early stroke prognostics and the management of post-stroke treatment.","['Electroencephalography', 'Feature extraction', 'Monitoring', 'Stroke (medical condition)', 'Electrodes', 'Biomedical monitoring', 'Sleep']","['Sensor systems and applications', 'brain–computer interfaces', 'neuroscience', 'biomedical monitoring']"
"In many microarray studies, classifiers have been constructed based on gene signatures to predict clinical outcomes for various cancer sufferers. However, signatures originating from different studies often suffer from poor robustness when used in the classification of data sets independent from which they were generated from. In this paper, we present an unsupervised feature learning framework by integrating a principal component analysis algorithm and autoencoder neural network to identify different characteristics from gene expression profiles. As the foundation for the obtained features, an ensemble classifier based on the AdaBoost algorithm (PCA-AE-Ada) was constructed to predict clinical outcomes in breast cancer. During the experiments, we established an additional classifier with the same classifier learning strategy (PCA-Ada) in order to perform as a baseline to the proposed method, where the only difference is the training inputs. The area under the receiver operating characteristic curve index, Matthews correlation coefficient index, accuracy, and other evaluation parameters of the proposed method were tested on several independent breast cancer data sets and compared with representative gene signature-based algorithms including the baseline method. Experimental results demonstrate that the proposed method using deep learning techniques performs better than others.","['Feature extraction', 'Principal component analysis', 'Machine learning', 'Gene expression', 'Neural networks', 'Breast cancer']","['Cancer prognosis', 'ensemble classifier', 'principal component analysis', 'deep learning']"
"Fog Computing has emerged as an extension to cloud computing by providing an efficient infrastructure to support IoT. Fog computing acting as a mediator provides local processing of the end-users' requests and reduced delays in communication between the end-users and the cloud via fog devices. Therefore, the authenticity of incoming network traffic on the fog devices is of immense importance. These devices are vulnerable to malicious attacks. All kinds of information, especially financial and health information travel through these devices. Attackers target these devices by sending malicious data packets. It is imperative to detect these intrusions to provide secure and reliable service to the user. So, an effective Intrusion Detection System (IDS) is essential for the secure functioning of fog without compromising efficiency. In this paper, we propose a method (Auto-IF) for intrusion detection based on deep learning approach using Autoencoder (AE) and Isolation Forest (IF) for the fog environment. This approach targets only binary classification of the incoming packets as fog devices are more concerned about differentiating attack from normal packets in real-time. We validate the proposed method on the benchmark NSL-KDD dataset. Our technique of intrusion detection achieves a high accuracy rate of 95.4% as compared to many other state-of-art intrusion detection methods.","['Intrusion detection', 'Machine learning', 'Cloud computing', 'Edge computing', 'Forestry', 'Support vector machines']","['Autoencoder', 'fog computing', 'intrusion detection', 'isolation forest']"
"The advancement in Information and Communications Technology (ICT) has changed the entire paradigm of computing. Because of such advancement, we have new types of computing and communication environments, for example, Internet of Things (IoT) that is a collection of smart IoT devices. The Internet of Medical Things (IoMT) is a specific type of IoT communication environment which deals with communication through the smart healthcare (medical) devices. Though IoT communication environment facilitates and supports our day-to-day activities, but at the same time it has also certain drawbacks as it suffers from several security and privacy issues, such as replay, man-in-the-middle, impersonation, privileged-insider, remote hijacking, password guessing and denial of service (DoS) attacks, and malware attacks. Among these attacks, the attacks which are performed through the malware botnet (i.e., Mirai) are the malignant attacks. The existence of malware botnets leads to attacks on confidentiality, integrity, authenticity and availability of the data and other resources of the system. In presence of such attacks, the sensitive data of IoT communication may be disclosed, altered or even may not be available to the authorized users. Therefore, it becomes essential to protect the IoT/IoMT environment from malware attacks. In this review paper, we first perform the study of various types of malware attacks, and their symptoms. We also discuss some architectures of IoT environment along with their applications. Next, a taxonomy of security protocols in IoT environment is provided. Moreover, we conduct a comparative study on various existing schemes for malware detection and prevention in IoT environment. Finally, some future research challenges and directions of malware detection in IoT/IoMT environment are highlighted.","['Malware', 'Computer architecture', 'Security', 'Internet of Things', 'Servers', 'Medical services', 'Smart homes']","['Internet of Things (IoT)', 'Internet of Medical Things (IoMT)', 'security', 'IoT malware', 'malware detection']"
"The precise electrical modeling of photovoltaic (PV) module is crucial due to the large-scale permeation of PV power plants into electric power networks. Therefore, a triple-diode photovoltaic (TDPV) model is presented to address all PV losses. However, the TDPV is mathematically modelled by a nonlinear I-V behavior, including nine-parameters that cannot be directly determined from the PVs datasheet due to the lack data offered by the PV manufacturers. This article presents a new application of the marine predators algorithm (MPA) to properly extract the electrical parameters of the TDPV model of a PV panel. The validity of the MPA-based TDPV model is widely appraised by the numerical analyses, which are carried out under various temperatures and solar irradiations. The optimal nine-parameters achieved using the MPA are compared with that realized by different optimization approaches-based PV model. For a realistic study, the numerical results and the measured data are compared for the marketable Kyocera KC200GT and Solarex MSX-60 PV panels. The efficacy of the MPA-based TDPV model is properly executed by checking its current error with that obtained from various models. With the MPA technology, a highly accurate model of any marketable PV module can be attained, which represents a new contribution to the sector of PV power systems.","['Mathematical model', 'Biological system modeling', 'Numerical models', 'Analytical models', 'Optimization', 'Photovoltaic systems', 'Power systems']","['Marine predators algorithm', 'photovoltaic modeling', 'photovoltaic power systems', 'solar energy', 'triple-diode model']"
"In 2016, dolphin swarm algorithm (DSA) that has received sustained research interest due to its simplicity and effectiveness was proposed. However, when solving high-dimensional function optimization problems, DSA is prone to fall into local optimization problems, which leads to low optimization accuracy or even failure. In this paper, to solve this problem, chaotic mapping is introduced into DSA, and chaotic dolphin swarm algorithm (CDSA) is successfully proposed. Based on high-dimensional Rastrigin function, the optimal chaotic map is determined among eight chaotic maps (e.g., Logistic). Then, in view of high-dimensional Levy function, Rotated Hyper-Ellipsoid function and Sum Squares function respectively, the performance of CDSA and that of the state-of-the-art algorithms (e.g. (whale optimization algorithm) WOA) are compared. The results show that the performance of CDSA based on Kent map is best and the performance of CDSA outperform that of the state-of-the-art algorithms considered to be compared. Finally, it is concluded that such a new meta-heuristic algorithm could help to improve the shortcomings of DSA and increase the applied range of DSA.","['Optimization', 'Dolphins', 'Particle swarm optimization', 'Heuristic algorithms', 'Fitting', 'Chaos', 'Logistics']","['Chaotic maps', 'dolphin swarm algorithm', 'high-dimensional function', 'optimization']"
"Vehicular ad-hoc NETworks (VANETs) have received considerable attention in recent years, due to its unique characteristics, which are different from mobile ad-hoc NETworks, such as rapid topology change, frequent link failure, and high vehicle mobility. The main drawback of VANETs network is the network instability, which yields to reduce the network efficiency. In this paper, we propose three algorithms: cluster-based life-time routing (CBLTR) protocol, Intersection dynamic VANET routing (IDVR) protocol, and control overhead reduction algorithm (CORA). The CBLTR protocol aims to increase the route stability and average throughput in a bidirectional segment scenario. The cluster heads (CHs) are selected based on maximum lifetime among all vehicles that are located within each cluster. The IDVR protocol aims to increase the route stability and average throughput, and to reduce end-to-end delay in a grid topology. The elected intersection CH receives a set of candidate shortest routes (SCSR) closed to the desired destination from the software defined network. The IDVR protocol selects the optimal route based on its current location, destination location, and the maximum of the minimum average throughput of SCSR. Finally, the CORA algorithm aims to reduce the control overhead messages in the clusters by developing a new mechanism to calculate the optimal numbers of the control overhead messages between the cluster members and the CH. We used SUMO traffic generator simulators and MATLAB to evaluate the performance of our proposed protocols. These protocols significantly outperform many protocols mentioned in the literature, in terms of many parameters.","['Routing protocols', 'Vehicular ad hoc networks', 'Routing', 'Clustering algorithms', 'Topology']","['VANET', 'MANET', 'ICH', 'IDVR', 'grid topology', 'AODV', 'life-time', 'CBLTR', 'CBR', 'SCSR', 'CORA', 'CMHELLO message', 'CHADS message', 'control overhead', 'CH', 'CM']"
"Passenger flow prediction is important for the operation of urban rail transit. The prediction of abnormal passenger flow is difficult due to rare similar history data. A model based on the fusion of support vector regression (SVR) and long short-term memory (LSTM) neural network is proposed. The inputs of the model are the abnormal features, which consist of the recent real volume series and the predicted volume series based on the periodic features. A two-stage training method is designed to train the LSTM model, which can reflect the large fluctuations of abnormal flow more timely and approximately. A combination method based on the real-time prediction errors is proposed, on which the outputs of SVR and LSTM are combined into the final outputs of the prediction model. The results of the experiments show that the SVR-LSTM model more accurately reflects the abnormal fluctuations of passenger flow, which performs well and yields greater forecast accuracy than the individual models.","['Predictive models', 'Public transportation', 'Rails', 'Neural networks', 'Support vector machines', 'Fluctuations', 'Real-time systems']","['Short-term passenger flow prediction', 'urban rail transit', 'support vector regression (SVR)', 'long short-term memory (LSTM)']"
"Excessive Power Consumption (PC) and demand for power is increasing on a daily basis, due to advancements in technology, the rise in electricity-dependent machinery, and the growth of the human population. It has become necessary to predict PC in order to improve power management and co-operation between the energy used in a building and the power grid. State-of-the-art Energy Consumption Prediction (ECP) methods are limited in terms of predicting the energy effectively, due to various challenges such as weather conditions and the dynamic behaviour of occupants. Thus, to overcome the drawbacks of these methods, we present an intelligent hybrid technique that combines a Convolutional Neural Network (CNN) with a Multi-layer Bi-directional Long-short Term Memory (M-BDLSTM) method using three steps. When applied to short-term power ECP, this approach helps to provide efficient power management i.e. it can assist the supplier to produce the optimum amount of power. The first step in our proposed method integrates the pre-processing and data organisation mechanisms to refine the data and remove abnormalities. The second step employs a deep learning network, where the sequence of refined data is fed into the CNN via the M-BDLSTM network to learn the sequence pattern effectively. The third step generates the ECP/PC by comparing actual and predicted data series and evaluates the prediction using error metrics. The proposed method achieves better prediction results than existing techniques, thus demonstrating its effectiveness. Furthermore, it achieved the smallest value of the Mean Square Error (MSE) and Root Mean Square Error (RMSE) for individual household dataset using 10-fold Cross Validation (CV) and a hold-out (CV) method.","['Energy consumption', 'Buildings', 'Power demand', 'Deep learning', 'Support vector machines', 'Power system management']","['Artificial intelligence', 'deep learning', 'power consumption', 'CNN', 'bi-directional LSTM', 'short-term energy consumption']"
"With the improvement of living standard, people begin to pay more attention to food safety and product quality. Therefore, for consumers, it is necessary to establish a reliable system that can trace the source of products. However, most existing traceability systems tend to lack transparency, data is primarily stored within the enterprise, and the cost of tampering with data is very low. Besides, the supply chain nodes are easy to evade responsibility when product safety or quality issues arise under the traditional centralized management model, and it is difficult to trace the root of issues. The development of blockchain technology provides us with new ideas for realizing the traceability of products in supply chain scenarios. Due to its characteristics of decentralization, transparency, and immutability, blockchain can be effectively used to alleviate the above problems. In this paper, we propose a product traceability system based on blockchain technology, in which all product transferring histories are perpetually recorded in a distributed ledger by using smart contracts and a chain is formed that can trace back to the source of the products. In particular, we design an event response mechanism to verify the identities of both parties of the transaction, so that the validity of the transaction can be guaranteed. And all events are permanently stored in the form of logs as a basis for handling disputes and tracking responsible entities. Furthermore, a system prototype is constructed based on the testing framework of Truffle. The contract code is deployed on a test network TestRpc that runs in local memory, and a decentralized web page interface is implemented based on the prototype. Finally, the system security analysis and experimental results show that our solution is feasible.","['Blockchain', 'Supply chains', 'Smart contracts', 'Safety', 'Prototypes', 'Industries', 'Internet of Things']","['Blockchain', 'smart contract', 'supply chain', 'traceability', 'accountability']"
"Finding an optimal node deployment strategy in wireless sensor networks (WSNs) that would reduce cost, be robust to node failures, reduce computation, and communication overhead, and guarantee a high level of coverage along with network connectivity is a difficult problem. In fact, sensing coverage and network connectivity are two of the most fundamental problems in WSNs as they can directly impact the network lifetime and operation. In this paper, we consider deriving optimal conditions for connectivity with coverage in WSNs. Most versions of this problem are (NP-complete), while approximation algorithms cannot be developed for some versions of polynomial time, unless P = NP. Hence, we also develop a heuristic for some versions of the problem and the efficacy of the heuristic will be evaluated through extensive simulations. We are also interested in determining the probability of finding a path between a given pair of nodes over a given topology of WSNs. This will serve as a measure of connectivity with coverage of the network. Hence, we derive necessary and sufficient conditions for connectivity with coverage over a clustered structure in WSNs. Then, employing queuing networks modeling techniques, we present a dynamic programming study of the connectivity with coverage of clustered structure and its effect on routing in generalized WSNs. The performance evaluation of the proposed schemes shows that availability of nodes, sensor node coverage, and the connectivity were sufficiently enhanced to maximize network lifetime.","['Wireless sensor networks', 'Monitoring', 'Protocols', 'Temperature measurement', 'Temperature sensors', 'Approximation algorithms']","['Deployment', 'coverage', 'connectivity', 'wireless sensor networks', 'WSN']"
"This paper proposes a new interleaved non-isolated high step-up dc-dc converter for interfacing renewable energy applications. The proposed converter achieves a very high step-up voltage gain by using two coupled inductors and a voltage multiplier cell. This topology utilizes the interleaved boost converter in the input side, and the input current is shared with low ripple. Moreover, a voltage multiplier cell with the secondary windings of the coupled inductors is employed in the output side to achieve the interleaved energy storage. The voltage stress on the semiconductor switches and the passive components is significantly reduced and lower than the output voltage. The aforementioned converter can be operated without an extreme duty cycle or a high turns ratio. The reverse recovery problem of the diodes is mitigated, and the leakage energy is recycled. Furthermore, by implementing low-voltage-rated MOSFETs with a small ON-resistance, the conduction losses can be reduced, and the efficiency can be improved. The topology is fed by a single input voltage, and the mathematical expression is methodically explored. The operation principle of the proposed converter and the comparison between the proposed converter with other topologies are discussed. The design, parameters selection, and experimental results are thoroughly introduced. A 32 to 800 V-dc is verified and simulated by using PLECS. Consequently, a 400 W hardware prototype is verified to validate the theory and the design.","['Inductors', 'DC-DC power converters', 'Capacitors', 'Stress', 'Semiconductor diodes', 'Inductance']","['Coupled inductors', 'high voltage gain', 'high step-up dc-dc converter', 'high efficiency', 'interleaved boost converter', 'PV', 'renewable energy systems', 'voltage multiplier']"
"Controlling active/reactive power in distribution systems has a great impact on its performance. The placement of distributed generators (DGs) and shunt capacitors (SCs) are the most popular mechanisms to improve the distribution system performance. In this line, this paper proposes an enhanced genetic algorithm (EGA) that combines the merits of genetic algorithm and local search to find the optimal placement and capacity of the simultaneous allocation of DGs/SCs in the radial systems. Incorporating local search scheme enhances the search space capability and increases the exploration rate for finding the global solution. The proposed procedure aims at minimizing both total real power losses and the total voltage deviation in order to enhance the distribution system performance. To prove the proposed algorithm ability and scalability, three standard test systems, IEEE 33 bus, 69 bus, and 119-bus test distribution networks, are considered. The simulation results show that the proposed EGA can efficiently search for the optimal solutions of the problem and outperforms the other existing algorithms in the literature. Moreover, an economic based cost analysis is provided for light, shoulder and heavy loading levels. It was proven, the proposed EGA leads to significant improvements in the technical and economic points of view.","['Genetic algorithms', 'Capacitors', 'Reactive power', 'Indexes', 'Optimization', 'Stability criteria']","['Distributed generators (DGs)', 'shunt capacitors (SCs)', 'distribution system performance', 'enhanced genetic algorithm (EGA)']"
"Mobile users are increasing exponentially to adopt ubiquitous services offered by various sectors. This has attracted attention for a secure communication framework to access e-health data on mobile devices. The wearable sensor device is attached to the patient's body which monitors the blood pressure, body temperature, serum cholesterol, glucose level, etc. In the proposed secure framework, first, the task starts with the patient authentication, after that the sensors device linked to the patient is activated and the sensor values of the patient are transmitted to the cloud server. The patient's biometrics information has been added as a parameter in addition to the user name and password. The authentication scheme is coined with the SHA-512 algorithm that ensures integrity. To securely send the sensor information, the method follows two kinds of encryption: Substitution-Ceaser cipher and improved Elliptical Curve Cryptography (IECC). Whereas in improved ECC, an additional key (secret key) is generated to enhance the system's security. In this way, the intricacy of the two phases is augmented. The computational cost of the scheme in the proposed framework is 4H + Ec + Dc which is less than the existing schemes. The average correlation coefficient value is about 0.045 which is close to zero shows the strength of the algorithm. The obtained encryption and decryption time are 1.032 μs and 1.004μs respectively. The overall performance is analyzed by comparing the proposed improved ECC with existing Rivest-Shamir-Adleman (RSA)and ECC algorithms.","['Cloud computing', 'Authentication', 'Medical services', 'Encryption', 'Elliptic curve cryptography', 'Servers']","['Internet of Things', 'wearable sensors', 'cloud wireless sensors', 'encryption', 'ECC', 'RSA']"
"The remarkable success of machine learning (ML) in a variety of research domains has inspired academic and industrial communities to explore its potential to address hardware Trojan (HT) attacks. While numerous works have been published over the past decade, few survey papers, to the best of our knowledge, have systematically reviewed the achievements and analyzed the remaining challenges in this area. To fill this gap, this article surveys ML-based approaches against HT attacks available in the literature. In particular, we first provide a classification of all possible HT attacks and then review recent developments from four perspectives, i.e., HT detection, design-for-security (DFS), bus security, and secure architecture. Based on the review, we further discuss the lessons learned in and challenges arising from previous studies. Despite current work focusing more on chip-layer HT problems, it is notable that novel HT threats are constantly emerging and have evolved beyond chips and to the component, device, and even behavior layers, therein compromising the security and trustworthiness of the overall hardware ecosystem. Therefore, we divide the HT threats into four layers and propose a hardware Trojan defense (HTD) reference model from the perspective of the overall hardware ecosystem, therein categorizing the security threats and requirements in each layer to provide a guideline for future research in this direction.","['Trojan horses', 'IP networks', 'Hardware', 'Security', 'Taxonomy', 'System-on-chip']","['Machine learning', 'hardware Trojan detection', 'design-for-security', 'bus security', 'secure architecture']"
"Touch plays a prominent role in communicating emotions and intensifying interpersonal communication. Affective haptics is an emerging field, which focuses on the analysis, design, and evaluation of systems that can capture, process, or display emotions through the sense of touch. The objective of this paper is to present an overview of the recent achievements in affective haptics and to discuss how the sense of touch can elicit or influence human emotions. We first introduce a definition to the term affective haptics and describe its multidisciplinary nature-as a field that integrates ideas from affective computing, haptic technology, and user experience. Second, we provide a thorough discussion about the effectiveness of using the haptic channel to communicate affective information through direct and mediated means. Third, we present a variety of applications in the area ranging from interhuman social interaction systems to human robot interaction applications. Finally, we discuss some of the key findings discerned from the various surveyed papers, and present some of the challenges and trends in this field. We extract the following conclusions pertaining to affective haptics: 1) haptic stimulation can be successfully used to achieve a higher level of emotional immersion during media consumption or emotional telepresence; 2) existing research has demonstrated that haptics is effective in communicating valence and arousal, and the emotions of happiness, sadness, anger and fear, and less focus have been given to the communication of disgust and surprise; 3) the haptic-based affect detection remains an understudied topic, whereas the haptic-based affect display is a well-established subject; and 4) the interpretation of the haptic stimulation by human beings is highly contextual.","['Affective computing', 'Haptic interfaces', 'Psychology', 'Human computer interaction', 'Emotion recognition', 'Force feedback', 'Tactile sensors']","['Affective computing', 'Haptic interfaces', 'Human computer interaction', 'social computing', 'tactile sensors']"
"Face spoofing detection is commonly formulated as a two-class recognition problem where relevant features of both positive (real access) and negative samples (spoofing attempts) are utilized to train the system. However, the diversity of spoofing attacks, any new means of spoofing attackers, may invent (previously unseen by the system) the problem of imaging sensor interoperability, and other environmental factors in addition to the small sample size make the problem quite challenging. Considering these observations, in this paper, a number of propositions in the evaluation scenario, problem formulation, and solving are presented. First of all, a new evaluation protocol to study the effect of occurrence of unseen attack types, where the train and test data are produced by different means, is proposed. The new evaluation protocol better reflects the realistic conditions in spoofing attempts where an attacker may come up with new means for spoofing. Inter-database and intra-database experiments are incorporated into the evaluation scheme to account for the sensor interoperability problem. Second, a new and more realistic formulation of the spoofing detection problem based on the anomaly detection concept is proposed where the training data come from the positive class only. The test data, of course, may come from the positive or negative class. Such a one-class formulation circumvents the need for the availability of negative training samples, which, in an in deal case, should be the representative of all possible spoofing types. Finally, a thorough evaluation and comparison of 20 different one-class and two-class systems on the video sequences of three widely employed databases is performed to investigate the merits of the one-class anomaly detection approaches compared with the common two-class formulations. It is demonstrated that the anomaly-based formulation is not inferior as compared with the conventional two-class approach.","['Face', 'Training', 'Protocols', 'Databases', 'Imaging', 'Training data', 'Biometrics (access control)']","['Face spoofing detection', 'anomaly detection', 'one-class classification', 'inter-type face spoofing detection']"
"Blockchain is a new distributed and decentralized technology, and gradually attracts worldwide attention, but it is vulnerable to quantum attacks that would solve elliptic curve digital logarithm problem, which is mainly used for transaction authentication in blockchain. The key needed for authentication comes from the wallet. To ensure that the size of the wallet is fixed and easy to manage, deterministic wallets are required to be used. But if existing anti-quantum signature schemes, such as lattice-based signature are used directly in blockchain to solve the problem, it would have made the wallet bloat. In this paper, we present a novel anti-quantum transaction authentication scheme in the blockchain. In order to construct lightweight nondeterministic wallets, the key point is that public and private keys are generated from a set of master public and private key(Seed Key). We leverage on Bonsai Trees technology and propose a new authentication method which can extend a lattice space to multiple lattice spaces accompanied by the corresponding key. Every signature of a transaction uses a lattice space so as to ensure the randomness and the security of the master private key. And we give the complete security proof and analysis. This paper provides the theoretical support for the application of blockchain in the post quantum age.","['Lattices', 'Authentication', 'Bitcoin', 'Public key', 'Receivers']","['Lattice', 'blockchain', 'transaction authentication', 'signature']"
"The Internet of Things (IoT) aims at connecting things to the Internet in a peer-to-peer paradigm for data collecting and data sharing in our daily life. A blockchain is an immutable append-only ledger maintained by a peer-to-peer network, where the whole network needs to reach a consensus on the transactional data stored on the ledger. With the decentralization nature, the design of IoT and blockchain aligns with each other well. Blockchain has been integrated with the IoT to solve the existing IoT problems. Our research focuses on analyzing the solutions proposed in academia and the methodologies used to integrate blockchain with the IoT. Through conducting a systematic literature review (SLR) on peer-reviewed, published articles on blockchain-based solutions for IoT, we gather the knowledge on current technical approaches implemented to integrate blockchain into the IoT. Majority of the research in this space is either at a conceptual level or at a very early stage. However, we only found 35 published papers with the real implementation of blockchain in the IoT platforms. We elicit the challenges of the IoT that were being addressed, and the detailed design of the blockchain-based solutions from two perspectives, namely data management and thing management. The evaluation methods and metrics used by those works are also being recorded and analyzed. In addition to the analysis of the literature, we provide our insights on improving the existing solutions and research methodology based on our expertise and experience on the blockchain.","['Blockchain', 'Internet of Things', 'Security', 'Peer-to-peer computing', 'Data collection', 'Databases', 'Smart contracts']","['Internet of Things', 'blockchain', 'data privacy', 'identity management systems']"
"This paper presents a compact, low-cost unmanned aerial system for antenna measurement. The proposed system overcomes existing limitations in terms of unmanned aerial vehicle positioning and data geo-referring accuracy using a real-time kinematic positioning system to achieve centimeter-level accuracy. Amplitude-only measurements acquired using a low-cost power sensor are processed by means of the phaseless sources reconstruction method. This is an iterative phase retrieval technique that allows recovering an equivalent currents distribution, which characterizes the antenna under test (AUT). From these equivalent currents, near-field to far-field transformation is applied to calculate the AUT radiation pattern. This contribution also analyzes probe antenna characterization and the impact of positioning and geo-referring accuracy on the radiation pattern. Two application examples of antenna measurement at Sand C-bands using the implemented system are presented.","['Antenna measurements', 'Unmanned aerial vehicles', 'Antenna radiation patterns', 'Current measurement', 'Phase measurement', 'Power measurement']","['Unmanned aerial vehicles (UAVs)', 'antenna measurement', 'antenna diagnostics', 'real time kinematic (RTK)', 'phaseless measurements', 'near-field to far-field transformation (NF-FF)', 'sources reconstruction method (SRM)']"
"A sentiment analysis has received a lot of attention from researchers working in the fields of natural language processing and text mining. However, there is a lack of annotated data sets that can be used to train a model for all domains, which is hampering the accuracy of sentiment analysis. Many research studies have attempted to tackle this issue and to improve cross-domain sentiment classification. In this paper, we present the results of a comprehensive systematic literature review of the methods and techniques employed in a cross-domain sentiment analysis. We focus on studies published during the period of 2010-2016. From our analysis of those works, it is clear that there is no perfect solution. Hence, one of the aims of this review is to create a resource in the form of an overview of the techniques, methods, and approaches that have been used to attempt to solve the problem of cross-domain sentiment analysis in order to assist researchers in developing new and more accurate techniques in the future.","['Sentiment analysis', 'Systematics', 'Bibliographies', 'Libraries', 'Data mining', 'Terminology']","['Cross-domain sentiment analysis', 'domain adaptation for sentiment analysis', 'multi-domain sentiment analysis', 'sentiment analysis', 'systematic literature review', 'transfer learning']"
"In this paper, a new image segmentation method is proposed by combining the FCM clustering algorithm with a rough set theory. First, the attribute value table is constructed based on the segmentation results of FCM under different clustering numbers, and the image is divided into several small regions based on the indistinguishable relationship of attributes. Then, the weight values of each attribute are obtained by value reduction and used as the basis to calculate the difference between regions and then the similarity evaluation of each region is realized through the equivalence relationship defined by the difference degree. Finally, the final equivalence relation defined by similarity is used to merge regions and complete image segmentation. This method is validated in the segmentation of artificially generated images, brain CT images, and MRI images. The experimental results show that compared with the FCM method, the proposed method can reduce the error rate and achieve better segmentation results for the fuzzy boundary region. And, the experimental results also prove that the algorithm has strong anti-noise ability.","['Image segmentation', 'Clustering algorithms', 'Rough sets', 'Brain', 'Classification algorithms', 'Kernel', 'Clustering methods']","['Brain image segmentation', 'FCM clustering', 'rough set', 'system']"
"Salp swarm algorithm (SSA) is a newly developed meta-heuristic algorithm, which is mainly developed based on the swarming behavior of salps sailing and foraging in the ocean. An improved salp swarm-based optimizer is proposed in this paper to overcome the potential shortcomings of original SSA, including being easily trapped in local or deceptive optima and its slow convergence rates in dealing with some high-dimensional and multimodal landscapes. The designed variant is called CMSSA that combines two strategies simultaneously. First, a chaotic exploitative mechanism with “shrinking” mode is introduced into the basic SSA to improve the exploitative tendencies of the algorithm. Then, a combined mutation scheme is adapted to make full use of the strong intensification capabilities of Gaussian mutation and the strong exploratory leanings of Cauchy mutation. In addition, the embedded strategies can achieve a more stable equilibrium between the core searching patterns of the SSA, which are diversification and intensification. We thoroughly studied the optimization advantages of the improved CMSSA using several representative benchmark cases, including unimodal, multimodal, and fixed-dimension multimodal functions, and three well-regarded engineering cases. The obtained experimental results, statistical tests, and comparative simulations indicate that the exploratory and exploitative proclivities of the SSA and its convergence patterns are vividly improved. The results indicate that the proposed CMSSA is a promising algorithm and shows superior efficacy compared with other algorithms.","['Optimization', 'Convergence', 'Benchmark testing', 'Sociology', 'Statistics', 'Linear programming', 'Particle swarm optimization']","['Salp swarm algorithm', 'optimization', 'chaos-induced exploitation', 'Gaussian mutation', 'Cauchy mutation', 'engineering design']"
This paper presents a deep learning-based pansharpening method for fusion of panchromatic and multispectral images in remote sensing applications. This method can be categorized as a component substitution method in which a convolutional autoencoder network is trained to generate original panchromatic images from their spatially degraded versions. Low resolution multispectral images are then fed into the trained convolutional autoencoder network to generate estimated high resolution multispectral images. The fusion is achieved by injecting the detail map of each spectral band into the corresponding estimated high resolution multispectral bands. Full reference and no-reference metrics are computed for the images of three satellite datasets. These measures are compared with the existing fusion methods whose codes are publicly available. The results obtained indicate the effectiveness of the developed deep learning-based method for multispectral image fusion.,"['Convolution', 'Spatial resolution', 'Computer architecture', 'Image reconstruction', 'Convolutional codes', 'Image fusion']","['Multispectral image fusion by convolutional autoencoder', 'fusion of panchromatic and multispectral images in remote sensing', 'convolutional autoencoder-based pansharpening']"
"Metaheuristics are computational procedures that intelligently lead the search process through the efficient exploration of the search space associated with an optimization problem. With the progressive outburst of problems with large data sets in various fields, there is an ongoing quest for enhancing existing metaheuristic algorithms as well as developing new ones with greater accuracy and efficiency. In general, a powerful and efficient metaheuristic algorithm is based on a rich inspiration source, implemented effectively through a precise mathematical model. Aiming to develop a highly efficient, nature-inspired optimization algorithm, here we propose a novel metaheuristic called Crystal Structure Algorithm (CryStAl). This method is chiefly inspired by the principles underlying the formation of crystal structures from the addition of the basis to the lattice points, which is a natural phenomenon that can be seen in the symmetric arrangement of constituents (i.e. atoms, molecules, or ions) in crystalline minerals such as quartz. A total number of 239 mathematical functions which are categorized into four different groups are utilized to evaluate the overall performance of the proposed method. To validate the results of this novel algorithm, 12 different classical and modern metaheuristic algorithms are selected from the literature. The minimum, mean, and standard deviation values alongside the number of function evaluations for CryStAl and the other metaheuristics for a specific tolerance are calculated and presented accordingly. The obtained results, further supported by a complete statistical analysis, demonstrated that the proposed algorithm is capable of providing very competitive results, outperforming the other metaheuristics in most cases.","['Crystals', 'Optimization', 'Lattices', 'Classification algorithms', 'Mathematical model', 'Shape', 'Standards']","['Crystal Structure Algorithm (CryStAl)', 'lattice', 'function', 'metaheuristic', 'optimization', 'statistical analysis']"
"The Internet of Things (IoT) will shortly be undergoing a major transformation from a sensor-driven paradigm to one that is heavily complemented by actuators, drones, and robots. The real-time situational awareness of such active systems requires sensed data to be transmitted in the uplink to edge-cloud, processed, and control instructions transmitted in the downlink. Since many of these applications will be mission critical, the most suitable connectivity family will be cellular due to the availability of licensed spectrum able to protect the offered communications service. However, while much focus in the past was on the uplink of machine-type communications, little attention has been paid to the end-to-end reliability, latency, and energy consumption comprising both up and downlinks. To address this gap, in this paper, we focus on the definition, design, and analysis of machine-type multicast service (MtMS). We discuss the different procedures that need to be redesigned for MtMS and we derive the most appropriate design drivers by analyzing different performance indicators, such as scalability, reliability, latency, and energy consumption. We also discuss the open issues to be considered in future research aimed at enhancing the capabilities of MtMS to support a wide variety of 5G IoT use cases.","['Internet of things', 'Long Term Evolution', 'Multi-cast communication', 'Robot sensing systems', 'Uplink', 'Downlink', 'Energy consumption', 'Actuators', 'Robots', 'Drones', 'Machine-to-machine communication']","['IoT', '5G', 'MTC', 'E2E', 'multicast', 'MtMS', 'LTE-M']"
"Electric load forecasting (ELF) is vitally beneficial for electrical power planning and economical running in smart grid. However, the medium-term load forecasting has been rarely studied. In addition, existing ELF models mainly consider the impact of limited external factors, which are usually difficult to forecast accurately. In this paper, the characteristics of the electric loads are analyzed and used as a guideline for the design of the proposed methods. To fully exploit the quasi-periodicity with different time ranges, i.e., year, quarter, month, and week, two deep learning methods, time-dependency convolutional neural network (TD-CNN), and cycle-based long short-term memory (C-LSTM) network are proposed to improve the forecasting performance of short-term load forecasting and MTLF with a little payload of computational complexity. Both of them only utilize the historical electric load and can mine the underlying load patterns by extracting the long-term global integrated features and short-term local similar features. By representing the loads as pixels and rearranging them into a 2-D photograph, TD-CNN transforms the temporal correlation of load series into the spatial correlation and keeps the long-term memory. Specifically, the convolutional kernel with special size targeted to load data is designed to extract the local pattern with similar characteristic, while the pooling layer is removed in order to keep the finer features. Moreover, in order to extract the temporal correlation between the long-term sequences with lower complexity, the proposed C-LSTM method generates a new short series from the original long load series without information loss. The LSTM is then applied to model the dynamical relationship of the load series with shorter time steps. The experimental results show that the proposed methods outperform the existing method with greatly reduced computation complexity, whose training time is about two-to-five times shorter than the existing method.","['Load modeling', 'Ground penetrating radar', 'Geophysical measurement techniques', 'Load forecasting', 'Predictive models', 'Correlation', 'Feature extraction']","['MTLF', 'long-term historical load data', 'spatial correlation', 'CNN', 'LSTM']"
"Colorectal cancer is the second most frequently diagnosed cancer in women and the third most frequently diagnosed cancer in men. At least 80%-95% of the colorectal cancers are evolved from intestinal polyps. Although colonoscopy is regarded as the most effective method for screening and diagnosis, the success of the procedure is highly dependent on the level of hand-eye coordination and the operator skills. Thus, we are primarily motivated by the need for obtaining an early and accurate diagnosis of polyps in the colonoscopy images. In this paper, we employed the powerful object detection neural network “Mask R-CNN” to identify and segment polyps in the colonoscopy images. Also, we proposed an ensemble method to combine the two Mask R-CNN models with different backbone structures (ResNet50 and ResNet101) to enhance the performance. Mask R-CNNs in our model were first trained on COCO dataset, and then finely tuned using intestinal polyp dataset since a large number of annotated colonoscopy images are not easily accessible. In order to evaluate our proposed model, we used three open intestinal polyp datasets, CVC-ClinicDB, ETIS-Larib, and CVC-ColonDB. Our results show that our transfer learning-based ensemble model significantly outperforms state-of-the-art methods.","['Image segmentation', 'Feature extraction', 'Cancer', 'Colonoscopy', 'Task analysis', 'Biomedical imaging', 'Deep learning']","['Polyp segmentation', 'transfer learning', 'medical image analysis', 'deep learning', 'machine learning', 'artificial intelligence']"
"Over the past several decades, the development of technologies and the production of autonomous vehicles have enhanced the need for intelligent intersection management systems. Subsequently, growing interest in studying the traffic management of autonomous vehicles at intersections has been evident, which indicates a critical need to conduct a systematic literature review on this topic. This paper offers a systematic review of the proposed methodologies for intelligent intersection management systems and presents the remaining research gaps and possible future research approaches. We consider both pure autonomous vehicle traffic and mixed traffic at four-way signalized and unsignalized intersection(s). We searched for articles published from 2008 to 2019, and identified 105 primary studies. We applied the thematic analysis method to analyze the extracted data, which led to the identification of four main classes of methodologies, namely rule-based, optimization, hybrid, and machine learning methods. We also compared how well the methods satisfy their goals, namely efficiency, safety, ecology, and passenger comfort. This analysis allowed us to determine the primary challenges of the presented methodologies and propose new approaches in this area.","['Autonomous vehicles', 'Accidents', 'Delays', 'Roads', 'Systematics', 'Safety']","['Autonomous vehicle', 'intelligent intersection management system', 'mixed traffic', 'vehicle-to-infrastructure (V2I) communication', 'vehicle-to-vehicle (V2V) communication']"
"Industrial Internet of Things (IIoT) is producing massive data which are valuable for knowing running status of the underlying equipment. However, these data involve various operation events that span some time, which raise questions on how to model long memory of states, and how to predict the running status based on historical data accurately. This paper aims to develop a method of: (1) analyzing equipment working condition based on the sensed data; (2) building a prediction model for working status forecasting and designing a deep neural network model to predict equipment running data; and (3) improving the prediction accuracy by systematic feature engineering and optimal hyperparameter searching. We evaluate our method with real-world monitoring data collected from 33 sensors of a main pump in a power station for three months. The model achieves less root mean square error than that of autoregressive integrated moving average model. Our method is applicable to general IIoT equipment for analyzing time series data and forecasting operation status.","['Time series analysis', 'Sensors', 'Predictive models', 'Data models', 'Monitoring', 'Internet of Things', 'Power generation']","['Time series prediction', 'LSTM model', 'power equipment', 'industry Internet of Things']"
"Physiological signs can be remotely observed from the physiological and physical effects caused by a cardiorespiratory activity. A wide range of research on remote cardiorespiratory monitoring systems has been done using different methods, including methods based on Doppler effect, thermal imaging, and video camera imaging. The aim of this paper was to review and compare the newest and most promising of such remote measuring methods, introducing their merits and limitations under different circumstances. In addition, this paper summarizes the performance of these methods in a table regarding the noise artifacts, subject movement, the number of regions of interest, generalization to multiple subjects, detection range (distance), biological effects, and cost. This is a thorough general overview of the remote measurement of cardiorespiratory methods.","['Blood', 'Respiratory system', 'Heart', 'Physiology', 'Carotid arteries', 'Doppler radar', 'Biomedical monitoring']","['Cardiorespiratory signal', 'remote measurement methods', 'Doppler effect', 'thermal imaging', 'camera imaging', 'imaging photoplethysmography']"
"The ever-increasing demand for unlicensed spectrum has prompted regulators in the US and Europe to consider opening up the 6 GHz bands for unlicensed access. These bands will open up 1.2 GHz of additional spectrum for unlicensed radio access technologies (RATs), such as Wi-Fi and 5G New Radio Unlicensed (NR-U), in the US and if permitted, 500 MHz of additional spectrum in Europe. The abundance of spectrum in these bands creates new opportunities for the design of mechanisms and features that can support the emerging bandwidth-intensive and latency-sensitive applications. However, coexistence of unlicensed devices both with the bands’ incumbent users and across different unlicensed RATs present significant challenges. In this paper, we provide a comprehensive survey of the existing literature on various issues surrounding the operations of unlicensed RATs in the 6 GHz bands. In particular, we discuss how key features in next-generation Wi-Fi are being designed to leverage these additional unlicensed bands. We also shed light on the foreseeable challenges that designers of unlicensed RATs might face in the near future. Our survey encompasses key research papers, contributions submitted to standardization bodies and regulatory agencies, and documents presented at various other venues. Finally, we highlight a few key research problems that are likely to arise due to unlicensed operations in the 6 GHz bands. Tackling these research challenges effectively will be critical in ensuring that the new unlicensed bands are efficiently utilized while guaranteeing the interference-free operation of the bands’ incumbent users.","['Wireless fidelity', '5G mobile communication', 'Radio access technologies', 'Europe', 'IEEE 802.11ax Standard', 'FCC', 'Next generation networking']","['6 GHz unlicensed spectrum', 'IEEE 802.11ax', 'IEEE 802.11be', '5G NR-U']"
"As an aggregator involved in various renewable energy sources, energy storage systems, and loads, a virtual power plant (VPP) plays a key role as a prosumer. A VPP may enable itself to supply energy and ancillary services to the utility grid. This paper proposes a novel scheme for optimizing the operation and bidding strategy of VPPs. By scheduling the energy storage systems, demand response, and renewable energy sources, VPPs can join bidding markets to achieve maximum benefits. The potential uncertainties caused by renewable energy sources and the demand response are considered in a robust optimization model. Moreover, the robust VPP optimization accounts for its influence on markets to ensure optimal energy and reserve capacity bidding transactions in the day-ahead market and deals balancing in the real-time market. To demonstrate the performance of the proposed scheme, markets comprising various participants and managed by the system operator are implemented using mathematical models. The proposed method is evaluated using an illustrative system and the practical Taiwan power (Taipower) system with diverse uncertainty levels. The numerical results demonstrate the promising performance and the efficiency of the proposed method. The results also verify the effectiveness of the proposed method VPP with various combinations of renewable energy sources, energy storage systems, and loads.","['Power generation', 'Load modeling', 'Energy storage', 'Uncertainty', 'Mathematical model', 'Elasticity', 'Load management']","['Virtual power plant', 'demand response model', 'ancillary service', 'energy storage system', 'electricity markets', 'renewable energy source', 'robust optimization', 'game theory', 'mixed integer programming']"
"This paper presents a Hybrid Shunt Active Power Filter (HSAPF) optimized by hybrid Particle Swarm Optimization-Grey Wolf Optimization (PSO-GWO) and Fractional Order Proportional-Integral-Derivative Controller (FOPIDC) for reactive power and harmonic compensation under balance and unbalance loading conditions. Here, the parameters of FOPID controller are tuned by PSO-GWO technique to mitigate the harmonics. Comparing Passive with Active Filters, the former is tested to be bulky and design is complex and the later is not cost effective for high rating. Hence, a hybrid structure of shunt active and passive filter is designed using MATLAB/Simulink and in real time experimental set up. The compensation process for shunt active filter is different from predictable methods such as (p-q) or (i d -i q ) theory, in which only the source current is to be sensed. The performance of the proposed controller is tested under different operating conditions such as steady and transient states and indices like Total Harmonic Distortion (THD), Input Power Factor (IPF), Real Power (P) and Reactive Power (Q) are estimated and compared with that of other controllers. The parameters of FOPIDC and Conventional PID Controller (CPIDC) are optimized by the techniques such as PSO, GWO and hybrid PSO-GWO. The comparative simulation/experiment results reflect the better performance of PSO-GWO optimized FOPIDC based HSAPF with respect to PSO/GWO optimized FOPIDC/CPIDC based HSAPF under different operating conditions.","['Power harmonic filters', 'Active filters', 'Harmonic analysis', 'Passive filters', 'Optimization', 'Reactive power']","['Fractional order proportional-integral-derivative controller (FOPIDC)', 'harmonic compensation', 'hybrid shunt active power filter (HSAPF)', 'particle swarm optimization-grey wolf optimization (PSO-GWO)', 'power quality']"
"Nonsmall cell lung cancer is a prevalent disease. It is diagnosed and treated with the help of computed tomography (CT) scans. In this paper, we apply radiomics to select 3-D features from CT images of the lung toward providing prognostic information. Focusing on cases of the adenocarcinoma nonsmall cell lung cancer tumor subtype from a larger data set, we show that classifiers can be built to predict survival time. This is the first known result to make such predictions from CT scans of lung cancer. We compare classifiers and feature selection approaches. The best accuracy when predicting survival was 77.5% using a decision tree in a leave-one-out cross validation and was obtained after selecting five features per fold from 219.","['Cancer', 'Cells (biology)', 'Lung cancer', 'Computed tomography', 'Biomedical image processing', 'Three-dimensional displays', 'Tumors', 'Diseases', 'Support vector machines']","['Computed tomography', 'CT 3D texture features', 'support vector machine']"
"This paper proposes a new computational model to predict the earth pressure balance (EPB) shield performance during tunnelling. The proposed model integrates an improved particle swarm optimization (PSO) with adaptive neurofuzzy inference system (ANFIS) based on the fuzzy C-mean (FCM) clustering method. In particular, the proposed model uses shield operational parameters as inputs and computes the advance rate as the output. Prior to modeling, critical operational parameters are identified through principle component analysis (PCA). The hybrid model is applied to the prediction of the shield performance in the tunnel section of Guangzhou Metro Line 9 in China. The prediction results indicate that the improved PSO-ANFIS model shows high accuracy in predicting the EPB shield performance in terms of the multiobjective fitness function [i.e. root mean square error (RMSE) = 0.07, coefficient of determination (R 2 ) = 0.88, variance account (VA) = 0.84 for testing datasets, respectively]. The good agreement between the actual measurements and predicted values demonstrates that the proposed model is promising for predicting the EPB shield tunnel performance with good accuracy.","['Tunneling', 'Predictive models', 'Adaptation models', 'Fuzzy logic', 'Computational modeling', 'Optimization']","['Earth pressure balance shield', 'principle component analysis', 'improved PSO-ANFIS', 'fuzzy C-mean', 'advance rate']"
"Traditional steganography methods often hide secret data by establishing a mapping relationship between secret data and a cover image or directly in a noisy area, but has a low embedding capacity. Based on the thought of deep learning, in this paper, we propose a new image steganography scheme based on a U-Net structure. First, in the form of paired training, the trained deep neural network includes a hiding network and an extraction network; then, the sender uses the hiding network to embed the secret image into another full-size image without any modification and sends it to the receiver. Finally, the receiver uses the extraction network to reconstruct the secret image and original cover image correctly. The experimental results show that the proposed scheme compresses and distributes the information of the embedded secret image into all available bits in the cover image, which not only solves the obvious visual cues problem, but also increases the embedding capacity.","['Neural networks', 'Decoding', 'Gallium nitride', 'Feature extraction', 'Receivers', 'Image coding', 'Transforms']","['Information security', 'reversible image steganography', 'deep learning', 'U-Net structure']"
"Internet of things (IoT) is considered as a collection of heterogeneous devices, such as sensors, Radio-frequency identification (RFID) and actuators, which form a huge network, enabling non-internet components in the network to produce a better world of services, like smart home, smart city, smart transportation, and smart industries. On the other hand, security and privacy are the most important aspects of the IoT network, which includes authentication, authorization, data protection, network security, and access control. Additionally, traditional network security cannot be directly used in IoT networks due to its limitations on computational capabilities and storage capacities. Furthermore, authentication is the mainstay of the IoT network, as all components undergo an authentication process before establishing communication. Therefore, securing authentication is essential. In this paper, we have focused on IoT security particularly on their authentication mechanisms. Consequently, we highlighted enormous attacks and technical methods on the IoT authentication mechanism. Additionally, we discussed existing security verification techniques and evaluation schemes of IoT authentication. Furthermore, analysis against current existing protocols have been discussed in all parts and provided some recommendation. Finally, the aim of our study is to help the future researcher by providing security issues, open challenges and future scopes in IoT authentication.","['Authentication', 'Internet of Things', 'Protocols', 'Sensor phenomena and characterization', 'Logic gates']","['Authentication', 'authentication protocols', 'Internet of Things', 'network attacks', 'security', 'wireless sensor network']"
"Sarcasm is often used to express a negative opinion using positive or intensified positive words in social media. This intentional ambiguity makes sarcasm detection, an important task of sentiment analysis. Sarcasm detection is considered a binary classification problem wherein both feature-rich traditional models and deep learning models have been successfully built to predict sarcastic comments. In previous research works, models have been built using lexical, semantic and pragmatic features. We extract the most significant features and build a feature-rich SVM that outperforms these models. In this paper, we introduce a multi-head attention-based bidirectional long-short memory (MHA-BiLSTM) network to detect sarcastic comments in a given corpus. The experiment results reveal that a multi-head attention mechanism enhances the performance of BiLSTM, and it performs better than feature-rich SVM models.","['Feature extraction', 'Task analysis', 'Neural networks', 'Deep learning', 'Support vector machines', 'Logic gates', 'Computer architecture']","['Sarcasm detection', 'deep learning', 'self-attention', 'machine learning', 'social data']"
"The deployment of cryptocurrencies in e-commerce has reached a significant number of transactions and continuous increases in monetary circulation; nevertheless, they face two impediments: a lack of awareness of the technological utility, and a lack of trust among consumers. E-commerce carried out through social networks expands its application to a new paradigm called social commerce. Social commerce uses the content generated within social networks to attract new consumers and influence their behavior. The objective of this paper is to analyze the role played by social media in increasing trust and intention to use cryptocurrencies in making electronic payments. It develops a model that combines constructs from social support theory, social commerce, and the technology acceptance model. This model is evaluated using the partial least square analysis. The obtained results show that social commerce increases the trust and intention to use cryptocurrencies. However, mutual support among participants does not generate sufficient trust to adequately promote the perceived usefulness of cryptocurrencies. This research provides a practical tool for analyzing how collaborative relationships that emerge in social media can influence or enhance the adoption of a new technology in terms of perceived trust and usefulness. Furthermore, it provides a significant contribution to consumer behavior research by applying the social support theory to the adoption of new information technologies. These theoretical and practical contributions are detailed in the final section of the paper.","['Bitcoin', 'Social network services', 'Analytical models', 'Online banking']","['Cryptocurrencies', 'trust', 'social commerce', 'social support', 'technology acceptance model']"
"A number of modern metaheuristic optimization techniques are being exploited to work out a single-objective economic dispatch (ED) problem. The dispatch problems even become more complicated and complex when they consider operational and system constraints, such as network transmission losses, valve-point loading effects originating due to sequential opening of a number of steam admission valves to meet the ever-increasing demand, ramp rate limits, prohibited operating zones, multiple fuel options, spinning reserve, and so on. The heavy constraints make the otherwise convex linear smooth dispatch problem as highly nonconvex nonlinear nonsmooth one. Finding optimal solution for such kind of a constrained nonlinear problem through the deterministic numerical and convex characteristics-based optimization techniques is a difficult task to accomplish. Researchers have frequently employed one of the metaheuristic optimization techniques with powerful computational ability named particle swarm optimization (PSO) to deal with this rather a complicated and toilsome dispatch problem. In Part I of the two-part paper, a comprehensive review or a survey of PSO and its modified versions (involve alterations in the basic structure of PSO) to resolve the constrained ED problem is presented. Part II covers purely the survey of hybrid forms of PSO (hybridization of PSO with other optimization techniques) to tackle the ED problem. The survey is presented in such a way that readers may understand how PSO can be made computationally more efficient.","['Space vector pulse width modulation', 'Electric potential', 'Voltage control', 'Distortion', 'Power harmonic filters', 'Electromagnetic interference', 'Topology']","['ED problem', 'optimization techniques', 'operational and system constraints', 'PSO and its variants and modified versions', 'POZ', 'survey', 'VPL effects']"
"In this paper, an effective approach for mitigating the near-field coupling between four-port circularly polarized (CP) antennas in a 30-GHz multiple-input, multiple-output (MIMO) system is suggested and investigated. This is obtained by incorporating a two-layer transmission-type frequency selective surface (FSS) superstrate based on planar crossed-dipole metal strips. This paper presents a comparison between the mutual coupling when the patches are radiating in free space and in the presence of the FSS layers. The simulated results, when the FSS layers are applied, show an average of 6-12-dB improvement in the isolation between four adjacent CP-MIMO antennas. In addition, an accurate study is carried out on the insignificant reflections produced by the FSS layers to redirect those and also prevent any interference. The proposed 2 x 2 CP-MIMO antenna along with the superstrate is implemented and tested to validate the simulation results. Experimental results of the coupling and reflection coefficients and axial ratio show an acceptable agreement with the corresponding simulated ones.","['Frequency selective surfaces', 'Couplings', 'Mutual coupling', 'MIMO', 'Antenna radiation patterns', 'Dipole antennas', 'Impedance']","['MIMO', 'coupling reduction', 'frequency selective surface (FSS)', 'cross dipole', 'circularly polarized (CP)', 'antenna']"
"Proton exchange membrane fuel cell (PEMFC) can be a significant eco-friendly alternative power source for vehicles. However, under subfreezing conditions, cell degradation and irreversible performance decay can occur because of ice formation and repetitive thaw/freeze cycles. These problems have limited the further commercialization of PEMFC in cold weather countries. Thus, many improvements have been made to repair the freeze protection and rapid cold startup problems in PEMFC vehicles. In this paper, a comprehensive review dedicated to engineers of the recent research progress on the PEMFC cold start problems is presented. Systems and methods for fuel cell shutdown are summarized and classified into two categories: purge solution and material to avoid freezing. Regarding the system and solutions for PEMFC cold startup, different heating solutions are classified into two main groups depending on their heating sources and categorized as internal and external heating methods. This paper concludes with a detailed review of cold startup strategies based on an exhaustive survey of journal papers and patents.","['Fuel cells', 'Heating', 'Protons', 'Degradation', 'Alternative power sources', 'Cold startup systems', 'Vehicles']","['Cold start strategies', 'heating solutions', 'hybrid and electric vehicles', 'PEMFC', 'purge']"
"Microgrid, because of its advantages over conventional utility grids, is a prudent approach to implement renewable resource-based electricity generation. Despite its advantages, microgrid has to operate with a significant proportion of constant power loads that exhibit negative incremental impedance and thus cause serious instability in the system. In this paper, a comprehensive review is presented on accomplished research work on stabilization of dc and ac microgrid. After reviewing these, microgrid system stabilization techniques are classified with required discussions. As found out in this paper, the stabilization techniques can basically be classified as compensation done: 1) at feeder side; 2) by adding intermediate circuitry; and 3) at load side. Finally, after analyzing the merits and drawbacks of each generalized technique, several infographics are presented to highlight the key findings of this paper.","['Microgrids', 'Mathematical model', 'Power system stability', 'Stability analysis', 'Load modeling', 'Rotors', 'Impedance']","['Constant power load', 'feeder side compensation', 'load side compensation', 'negative incremental impedance', 'stabilization of ac microgrid', 'stabilization of dc microgrid']"
"Antennas on-chip are a particular type of radiating elements valued for their small footprint. They are most commonly integrated in circuit boards to electromagnetically interface free space, which is necessary for wireless communications. Antennas on-chip radiate and receive electromagnetic (EM) energy as any conventional antennas, but what distinguishes them is their miniaturized size. This means they can be integrated inside electronic devices. Although on-chip antennas have a limited range, they are suitable for cell phones, tablet computers, headsets, global positioning system (GPS) devices, and WiFi and WLAN routers. Typically, on-chip antennas are handicapped by narrow bandwidth (less than 10%) and low radiation efficiency. This survey provides an overview of recent techniques and technologies investigated in the literature, to implement high performance on-chip antennas for millimeter-waves (mmWave) and terahertz (THz) integrated-circuit (IC) applications. The technologies discussed here include metamaterial (MTM), metasurface (MTS), and substrate integrated waveguides (SIW). The antenna designs described here are implemented on various substrate layers such as Silicon, Graphene, Polyimide, and GaAs to facilitate integration on ICs. Some of the antennas described here employ innovative excitation mechanisms, for example comprising open-circuited microstrip-line that is electromagnetically coupled to radiating elements through narrow dielectric slots. This excitation mechanism is shown to suppress surface wave propagation and reduce substrate loss. Other techniques described like SIW are shown to significantly attenuate surface waves and minimise loss. Radiation elements based on the MTM and MTS inspired technologies are shown to extend the effective aperture of the antenna without compromising the antenna’s form factor. Moreover, the on-chip antennas designed using the above technologies exhibit significantly improved impedance match, bandwidth, gain and radiation efficiency compared to previously used technologies. These features make such antennas a prime candidate for mmWave and THz on-chip integration. This review provides a thorough reference source for specialist antenna designers.","['Antennas', 'System-on-chip', 'Substrates', 'Silicon', 'Microwave antennas', 'Dipole antennas', 'Bandwidth']","['Antenna on-chip (AoC)', 'metamaterial (MTM)', 'metasurface (MTS)', 'substrate integrated waveguide (SIW)', 'millimeter-waves (mmWave) and terahertz (THz) spectrum', 'intgrated RF transciver circuits', 'multilayer structures', 'electromagnetic (EM) coupled feed mechanism']"
"With the development of new technologies in the field of renewable energy and batteries, increasing number of houses have been equipped with renewable energy sources (RES) and energy storage systems (ESS) to reduce home energy cost. These houses usually have home energy management systems (HEMS) to control and schedule every electrical device. Various studies have been conducted on HEMS and optimization algorithms for energy cost and peak-to-average ratio (PAR) reduction. However, none of papers give a sufficient study on the utilization of main grid’s electricity and selling electricity. In this paper, firstly, we propose a new HEMS architecture with RES and ESS where we take utilization of the electricity of the main grid and electricity selling into account. With the proposed HEMS, we build general mathematical formulas for energy cost and PAR during a day. We then optimize these formulas using both the particle swarm optimization (PSO) and the binary particle swarm optimization (BPSO). Results clearly show that, with our HEMS system, RES and ESS can help to drop home energy cost significantly to 19.7%, compared with the results of previous works. By increasing charge/discharge rate of ESS, energy cost can be decreased by 4.3% for 0.6 kW and 8.5% for 0.9 kW. Moreover, by using multi-objective optimization, our system can achieve better PAR with an acceptable energy cost.","['Optimization', 'Renewable energy sources', 'Meteorology', 'Energy storage', 'Convergence', 'Peak to average power ratio']","['Home energy management systems', 'electricity selling', 'renewable energy sources', 'energy storage systems', 'day-ahead price', 'meta-heuristic algorithms']"
"This paper introduces a hybrid maximum power point tracking (MPPT) technique for photovoltaic (PV) arrays working under partial shading conditions. This new algorithm can combine a traditional MPPT algorithm, such as perturb and observe, or incremental conductance, with the artificial neural network (ANN) technique. The proposed hybrid MPPT algorithm is based on the ANN and used to predict the global MPP region by estimating its voltage boundaries. Consequently, the conventional MPPT algorithm searches for the MPP in the predicted region. The proposed technique is modeled and simulated using MATLAB/Simulink. The results show the effectiveness of the proposed hybrid MPPT technique to track the global MPP accurately with a rapid response comparing to the ANN; this increases the output power level of the PV array under various shading patterns.","['Maximum power point trackers', 'Photovoltaic systems', 'Mathematical model', 'Artificial neural networks', 'Hybrid power systems']","['MPPT', 'neural network', 'partial shading conditions', 'perturb & observe', 'PV']"
"A chaotic oscillator utilizing a flux-controlled memristor to produce a signal that grows in amplitude and frequency over time is introduced in this paper. It was found that the initial condition can be used to change the starting oscillation as well as the amplitude and frequency. From this, a new regime of homogenous multistability was found, where various attractors with different initial conditions are of the same type but have different amplitudes and frequencies.","['Oscillators', 'Memristors', 'Chaotic communication', 'Time-frequency analysis', 'Frequency control', 'Frequency modulation', 'Trajectory']","['Homogenous multistability', 'increasing amplitude and frequency', 'memristive chaotic oscillator']"
"Ransomware is a type of advanced malware that has spread rapidly in recent years, causing significant financial losses for a wide range of victims, including organizations, healthcare facilities, and individuals. Modern host-based detection methods require the host to be infected first in order to identify anomalies and detect the malware. By the time of infection, it can be too late as some of the system’s assets would have been already exfiltrated or encrypted by the malware. Conversely, the network-based methods can be effective in detecting ransomware attacks, as most ransomware families try to connect to command and control servers before their harmful payloads are executed. Therefore, a careful analysis of ransomware network traffic can be one of the key means for early detection. This paper demonstrates a comprehensive behavioral analysis of crypto ransomware network activities, taking Locky, one of the most serious families, as a case study. A dedicated testbed was built, and a set of valuable and informative network features were extracted and classified into multiple types. A network-based intrusion detection system was implemented, employing two independent classifiers working in parallel on different levels: packet and flow levels. The experimental evaluation of the proposed detection system demonstrates that it offers high detection accuracy, low false positive rate, valid extracted features, and is highly effective in tracking ransomware network activities.","['Ransomware', 'Feature extraction', 'Servers', 'Protocols', 'Encryption']","['Domain Generation Algorithm (DGA)', 'dynamic malware analysis', 'Locky', 'machine learning', 'malware analysis', 'ransomware']"
"Renewable energy sources (RESs) are growing rapidly and highly penetrated in microgrids (MGs). As a result of the replacement of the synchronous generators with a large amount of RESs, the overall system inertia might be dramatically reduced which negatively affected the MG dynamics and performance in face of uncertainties, leading to weakening of the MG stability, which considers being a serious challenge in such grids. Therefore, in order to cope with this challenge and benefit from a maximum capacity of the RESs, robust control strategy must be applied. Hence, in this paper, a new application of robust virtual inertia control-based coefficient diagram method (CDM) controller is proposed in an islanded MG considering high-level RESs penetration for enhancement the system's validity and robustness in face of disturbances and parametric uncertainties. The proposed controller's proficiency has been checked and compared with H-infinite controller using MATLAB/Simulink which approved that the CDM controller achieved superior dynamic responses in terms of accurate reference frequency tracking and disturbance reduction over H-infinite in all test scenarios. Thus, the proposed controller alleviates the difficulties of H-infinite controller such as the experience and necessary abilities to design the form of the weighting functions for the system. Consequently, the frequency stability is improved and approved that the proposed CDM-based virtual inertia controller can significantly support a low-inertia islanded microgrid against RESs and load fluctuations.","['Frequency control', 'Power system stability', 'Stability analysis', 'Microgrids', 'Power system dynamics', 'Power generation', 'Synchronous generators']","['Virtual inertia control', 'renewable energy sources', 'coefficient diagram method (CDM)', 'frequency control']"
"Welding quality directly affects the welding structure's service performance and life. Hence, the effective monitoring welding defects is essential to ensure the quality of the weld structure. Owing to the non-uniformity of the shape, position and size of welding defects, it is a complicated task to analyze and evaluate the acquired welding defects images manually. Fortunately, deep learning has been successfully applied to image analysis and target recognition. However, the use of deep learning to identify welding defects is time-consuming and less accurate due to the lack of adequate training data samples, which easily cause redundancy into the classifier. In this situation, we proposed a new transfer learning model based on MobileNet as a welding defect feature extractor. By using the ImageNet dataset (non-welding defect data) to pre-train a MobileNet model, migrate the MobileNet model to the welding defects classification field. This article suggested a new TL-MobileNet structure by adding a new Full Connection layer (FC-128) and a Softmax classifier into a traditional model called MobileNet. The entire training process of TL-MobileNet model has been successfully optimized by the DropBlock technology and Global average pooling (GAP) method. They can effectively accelerate the convergence rate and improve the classification network generalization. By testing the proposed TL-MobileNet on the welding defects dataset, it turned out our model prediction accuracy has arrived at 97.69%. The experimental results show that in several aspects, TL-MobileNet have better performance than other transfer learning models and traditional neural network methods.","['Welding', 'Feature extraction', 'X-ray imaging', 'Image recognition', 'Data models', 'Training', 'Testing']","['Welding defects classification', 'feature extraction', 'deep learning', 'DropBlock', 'transfer learning', 'MobileNet']"
"Industry 4.0 represents the fourth phase of industry and manufacturing revolution, unique in that it provides Internet-connected smart systems, including automated factories, organizations, development on demand, and `just-in-time' development. Industry 4.0 includes the integration of cyber-physical systems (CPSs), Internet of Things (IoT), cloud and fog computing paradigms for developing smart systems, smart homes, and smart cities. Given Industry 4.0 is comprised sensor fields, actuators, fog and cloud processing paradigms, and network systems, designing a secure architecture faces two major challenges: handling heterogeneous sources at scale and maintaining security over a large, disparate, data-driven system that interacts with the physical environment. This paper addresses these challenges by proposing a new threat intelligence scheme that models the dynamic interactions of industry 4.0 components including physical and network systems. The scheme consists of two components: a smart management module and a threat intelligence module. The smart data management module handles heterogeneous data sources, one of the foundational requirements for interacting with an Industry 4.0 system. This includes data to and from sensors, actuators, in addition to other forms of network traffic. The proposed threat intelligence technique is designed based on beta mixture-hidden Markov models (MHMMs) for discovering anomalous activities against both physical and network systems. The scheme is evaluated on two well-known datasets: the CPS dataset of sensors and actuators and the UNSW-NB15 dataset of network traffic. The results reveal that the proposed technique outperforms five peer mechanisms, suggesting its effectiveness as a viable deployment methodology in real-Industry 4.0 systems.","['Industries', 'Manufacturing', 'Internet of Things', 'Cloud computing', 'Actuators', 'Security', 'Cyber-physical systems']","['Industry 4.0', 'threat intelligence', 'cyber-attacks', 'cyber-physical systems (CPS)', 'Internet of Things (IoT)', 'cloud', 'fog', 'beta mixture-hidden Markov models (MHMM)']"
"Capacitive proximity sensors (CPSs) are ubiquitous because of their simple design, low cost and low consumption. Capacitive displacement sensing, as one of the three sensing modalities, works for long distance and can be unitized to measure more physical quantities compared with capacitive volume and deformation sensing. In this paper, we firstly introduce the concept of capacitive displacement sensing. After that, we present applications of capacitive displacement sensing under three broad categories: distance measurements, indirect measurements, and the applications applied in smart environments. Finally, we discuss the challenges and possible solutions for CPSs development. We show that both the detection range and accuracy of CPS can be improved by multi-sensor fusion, and the application scenarios can be extensive through machine/deep learning approaches. We aim to provide a comprehensive, and state-of-the-art review of the capacitive displacement sensing, and inspire more researchers and developers to find wide application perspectives.","['Electrodes', 'Displacement measurement', 'Capacitive sensors', 'Strain', 'Dielectric measurement', 'Dielectric constant']","['Capacitive proximity sensor (CPS)', 'capacitive displacement sensing', 'distance measurement', 'indirect measurement', 'smart environment']"
"This paper presents a wearable inertial measurement system and its associated spatiotemporal gait analysis algorithm to obtain quantitative measurements and explore clinical indicators from the spatiotemporal gait patterns for patients with stroke or Parkinson's disease. The wearable system is composed of a microcontroller, a triaxial accelerometer, a triaxial gyroscope, and an RF wireless transmission module. The spatiotemporal gait analysis algorithm, consisting of procedures of inertial signal acquisition, signal preprocessing, gait phase detection, and ankle range of motion estimation, has been developed for extracting gait features from accelerations and angular velocities. In order to estimate accurate ankle range of motion, we have integrated accelerations and angular velocities into a complementary filter for reducing the accumulation of integration error of inertial signals. All 24 participants mounted the system on their foot to walk along a straight line of 10 m at normal speed and their walking recordings were collected to validate the effectiveness of the proposed system and algorithm. Experimental results show that the proposed inertial measurement system with the designed spatiotemporal gait analysis algorithm is a promising tool for automatically analyzing spatiotemporal gait information, serving as clinical indicators for monitoring therapeutic efficacy for diagnosis of stroke or Parkinson's disease.","['Legged locomotion', 'Accelerometers', 'Spatiotemporal phenomena', 'Gyroscopes', 'Biomedical monitoring', 'Wearable computing', 'Diseases']","['Inertial sensing', 'gait analysis', 'complementary filter', 'sensor fusion', 'stroke', 'Parkinson’s disease']"
"Internet of Things (IoT) technologies have been broadly applied in smart grid for monitoring physical or environmental conditions. Especially, state estimation is an important IoT-based application in smart grid, which is used in system monitoring to get the best estimate of the power grid state through an analysis of the meter measurements and power system topologies. However, false data injection attack (FDIA) is a severe threat to state estimation, which is known for the difficulty of detection. In this paper, we propose an efficient detection scheme against FDIA. First, two parameters that reflect the physical property of smart grid are investigated. One parameter is the control signal from the controller to the static Var compensator (CSSVC). A large CSSVC indicates there exists the intense voltage fluctuation. The other parameter is the quantitative node voltage stability index (NVSI). A larger NVSI indicates a higher vulnerability level. Second, according to the values of the CSSVC and NVSI, an optimized clustering algorithm is proposed to distribute the potential vulnerable nodes into several classes. Finally, based on these classes, a detection method is proposed for the real-time detection of the FDIA. The simulation results show that the proposed scheme can detect the FDIA effectively.","['Smart grids', 'Power system stability', 'State estimation', 'Voltage measurement', 'Stability criteria', 'Monitoring']","['Smart grid', 'state estimation', 'false data injection attack', 'control signal', 'node voltage stability index']"
"Wireless sensor networks (WSNs) have been proliferating due to their wide applications in both military and commercial use. However, one critical challenge to WSNs implementation is source location privacy. In this paper, we propose a novel tree-based diversionary routing scheme for preserving source location privacy using hide and seek strategy to create diversionary or decoy routes along the path to the sink from the real source, where the end of each diversionary route is a decoy (fake source node), which periodically emits fake events. Meanwhile, the proposed scheme is able to maximize the network lifetime of WSNs. The main idea is that the lifetime of WSNs depends on the nodes with high energy consumption or hotspot, and then the proposed scheme minimizes energy consumption in hotspot and creates redundancy diversionary routes in nonhotspot regions with abundant energy. Hence, it achieves not only privacy preservation, but also network lifetime maximization. Furthermore, we systematically analyze the energy consumption in WSNs, and provide guidance on the number of diversionary routes, which can be created in different regions away from the sink. In addition, we identify a novel attack against phantom routing, which is widely used for source location privacy preservation, namely, direction-oriented attack. We also perform a comprehensive analysis on how the direction-oriented attack can be defeated by the proposed scheme. Theoretical and experimental results show that our scheme is very effective to improve the privacy protection while maximizing the network lifetime.","['Wireless sensor networks', 'Privacy', 'Position measurement', 'Energy consumption', 'Routing protocols', 'Source location']","['wireless sensor networks', 'source location privacy', 'network lifetime']"
"Intrusion detection has been an important countermeasure to secure computing infrastructures from malicious attacks. To improve detection performance and reduce bias towards frequent attacks, this paper proposes a two-step hybrid method based on binary classification and k-NN technique. Step 1 employs several binary classifiers and one aggregation module to effectively detect the exact classes of network connections. After step 1, the connections whose classes are uncertain are sent to step 2 to further determine their classes by the k-NN algorithm. Step 2 is based on the outcomes of step 1 and yields a beneficial supplement to step 1. By combining the two steps, the proposed method achieves reliable results on the NSL-KDD data set. The effectiveness of the proposed method is evaluated in comparison with five supervised learning techniques. Experimental results demonstrate that the proposed method outperforms baselines with respect to various evaluation criteria. In particular, for U2R and R2L attacks, the F1-scores of the proposed method are much higher than those of baselines. Furthermore, comparisons with some recent hybrid approaches are also listed. The results illustrate that the proposed method is competitive.","['Intrusion detection', 'Support vector machines', 'Feature extraction', 'Training', 'Principal component analysis', 'Genetic algorithms']","['Intrusion detection', 'hybrid method', 'binary classification', 'C4.5', 'k-nearest neighbors']"
"Based on the boost full bridge isolated converter (BFBIC) topology and considering the sudden changes in the external environment, a global maximum power point tracking (GMPPT) control strategy based on an improved gray wolf optimizer (IGWO) algorithm is proposed in this paper. In the strategy, a nonlinear tangent trigonometric function as a convergence factor is integrated into the gray wolf optimizer (GWO) algorithm. In addition, the active-clamp circuit and phase-shift are used to implement the soft switch technology for BFBIC converter in photovoltage (PV) system. Finally, the maximum power point tracking (MPPT) performance on PV system with the proposed IGWO algorithm under static and dynamic partial shading conditions (PSCs) was investigated and compared with other common perturb and observe(P&O), particle swarm optimization (PSO), artificial bee colony (ABC), adapt inertia weight salp swarm algorithm (WSSA), salp swarm algorithm with grey wolf optimizer (SSA-GWO), SSA with PSO (SSA-PSO), enhanced GWO (EGWO) MPPT algorithms. The effectiveness and stability of the proposed control strategy are validated, especially tracking speed under PSCs. Simulation results show that the BFBIC topology with the proposed IGWO algorithm outperforms other algorithms on most cases, especially only takes the tracking time of 0.24s and reaches the efficiency of 98.54% under the most severe PSCs.","['Maximum power point trackers', 'Heuristic algorithms', 'Topology', 'Inductors', 'Clamps', 'Switches', 'Circuit stability']","['Boost full bridge isolated converter (BFBIC)', 'improved grey wolf optimizer (IGWO)', 'global maximum power point tracking (GMPPT)', 'partial shading conditions (PSCs)']"
"Images taken under water usually suffer from the problems of quality degradation, such as low contrast, blurring details, color deviations, non-uniform illumination, etc. As an important problem in image processing and computer vision, the restoration and enhancement of underwater image are necessary for numerous practical applications. Over the last few decades, underwater image restoration and enhancement have been attracting an increasing amount of research effort. However, a comprehensive and in-depth survey of related achievements and improvements is still missing, especially the survey of underwater image dataset which is a key issue in underwater image processing and intelligent application. In this exposition, we first summarize more than 120 studies about the latest progress in underwater image restoration and enhancement, including the techniques, datasets, available codes, and evaluation metrics. We analyze the contributions and limitations of existing methods to facilitate the comprehensive understanding of underwater image restoration and enhancement. Furthermore, we provide detailed objective evaluations and analysis of the representative methods on five types of underwater scenarios, which verifies the applicability of these methods in different underwater conditions. Finally, we discuss the potential challenges and open issues of underwater image restoration and enhancement and suggest possible research directions in the future.","['Image restoration', 'Atmospheric modeling', 'Degradation', 'Optical imaging', 'Optical scattering', 'Image quality']","['Underwater image quality degradation', 'underwater image database', 'underwater image enhancement and restoration', 'underwater image quality evaluation']"
"Electric Vehicles’ Controller Area Network (CAN) bus serves as a legacy protocol for in-vehicle network communication. Simplicity, robustness, and suitability for real-time systems are the salient features of CAN bus. Unfortunately, the CAN bus protocol is vulnerable to various cyberattacks due to the lack of a message authentication mechanism in the protocol itself, paving the way for attackers to penetrate the network. This paper proposes a new effective anomaly detection model based on a modified one-class support vector machine in the CAN traffic. The proposed model makes use of an improved algorithm, known as the modified bat algorithm, to find the most accurate structure in the offline training. To evaluate the effectiveness of the proposed method, CAN traffic is logged from an unmodified licensed electric vehicle in normal operation to generate a dataset for each message ID and a corresponding occurrence frequency without any attacks. In addition, to measure the performance and superiority of the proposed method compared to the other two famous CAN bus anomaly detection algorithms such as Isolation Forest and classical one-class support vector machine, we provided Receiver Operating Characteristic (ROC) for each method to quantify the correctly classified windows in the test sets containing attacks. Experimental results indicate that the proposed method achieved the highest rate of True Positive Rate (TPR) and lowest False Positive Rate (FPR) for anomaly detection compared to the other two algorithms. Moreover, in order to show that the proposed method can be applied to other datasets, we used two recent popular public datasets in the scope of CAN bus traffic anomaly detection. Benchmarking with more CAN bus traffic datasets proves the independency of the proposed method from the meaning of each message ID and data field that make the model adaptable with different CAN datasets.","['Protocols', 'Anomaly detection', 'Clocks', 'Electric vehicles', 'Message authentication', 'Intrusion detection', 'Cyberattack']","['Electric vehicles', 'controller area network (CAN Bus)', 'anomaly detection', 'one-class support vector machine', 'optimization algorithm']"
"Internet of Things (IoT) is making strong advances in healthcare with the promise of transformation in technological, social and economic prospects, paving the way for a healthy future. Medical devices equipped with wireless communication enable remote monitoring features and are increasingly becoming connected to each other and to the Internet. Such smart and connected medical devices referred to as the Internet of Medical Things have enabled continuous real-time patient monitoring, increase in diagnostic accuracy, and effective treatment. In spite of their numerous benefits, these devices open up newer attack surfaces thereby introducing multitude of security and privacy concerns. Attacks on Internet connected medical devices can potentially cause significant physical harm and life-threatening damage to the patients. In this research, we design and develop a novel mobile agent based intrusion detection system to secure the network of connected medical devices. In particular, the proposed system is hierarchical, autonomous, and employs machine learning and regression algorithms to detect network level intrusions as well as anomalies in sensor data. We simulate a hospital network topology and perform detailed experiments for various subsets of Internet of Medical things including wireless body area networks and other connected medical devices. Our simulation results demonstrate that we are able to achieve high detection accuracy with minimal resource overhead.","['Wireless communication', 'Medical diagnostic imaging', 'Body area networks', 'Mobile agents', 'Intrusion detection', 'Communication system security']","['Wireless body area networks (WBAN)', 'Internet of Medical Things', 'intrusion detection', 'mobile agents', 'machine learning', 'healthcare security']"
"In this paper, a novel image watermarking method is proposed which is based on discrete wave transformation (DWT), Hessenberg decomposition (HD), and singular value decomposition (SVD). First, in the embedding process, the host image is decomposed into a number of sub-bands through multi-level DWT, and the resulting coefficients of which are then used as the input for HD. The watermark is operated on the SVD at the same time. The watermark is finally embedded into the host image by the scaling factor. Fruit fly optimization algorithm, one of the natural-inspired optimization algorithms is devoted to find the scaling factor through the proposed objective evaluation function. The proposed method is compared to other research works under various spoof attacks, such as the filter, noise, JPEG compression, JPEG2000 compression, and sharpening attacks. The experimental results show that the proposed image watermarking method has a good trade-off between robustness and invisibility even for the watermarks with multiple sizes.","['Watermarking', 'Discrete wavelet transforms', 'Robustness', 'Matrix decomposition', 'Optimization', 'Symmetric matrices', 'Transform coding']","['Image watermarking', 'discrete wave transformation', 'singular value decomposition', 'Hessenberg decomposition', 'fruit fly optimization algorithm']"
"In view of the influence of information's “incompleteness” and “asymmetry” to supply chain operation efficiency, we make big production enterprise as the object and apply blockchain to its supply chain endogenous risk management, to research the specific operation mechanism and application value. In the operation process of big production enterprise supply chain, because of the information's asymmetry, the fraud problem will produce among the business subjects; blockchain is a decentralized distributed accounting and data storage technology, and with blockchain technology, we can resolve the business subjects' fraud problem and can provide more accurate decision information basis for each business section, and realize group decision. This paper has described the system structure and intelligent contract operation mechanism under consensus authentication of blockchain applying in big production enterprise supply chain and analyzed by the case. In view of the limitation of classical blockchain technology applying in big production enterprise supply chain, we constructed the corresponding blockchain data storage mechanism and data access mechanism. Analyzed the economic value of this paper researching from the aspects of response speed, supply accuracy, cooperation integrity, business interaction economic cost, supply quality, and supply price. This paper research will provide ideas and model structure for developing supply chain area's blockchain system and will promote the application research development of blockchain in specific area.","['Supply chains', 'Blockchain', 'Risk management', 'Authentication', 'Contracts']","['Blockchain', 'big production enterprise', 'supply chain', 'endogenous risk management']"
"The concept of Bitcoin was first introduced by an unknown individual (or a group of people) named Satoshi Nakamoto before it was released as open-source software in 2009. Bitcoin is a peer-to-peer cryptocurrency and a decentralized worldwide payment system for digital currency where transactions take place among users without any intermediary. Bitcoin transactions are performed and verified by network nodes and then registered in a public ledger called blockchain, which is maintained by network entities running Bitcoin software. To date, this cryptocurrency is worth close to U.S. $150 billion and widely traded across the world. However, as Bitcoin's popularity grows, many security concerns are coming to the forefront. Overall, Bitcoin security inevitably depends upon the distributed protocols-based stimulant-compatible proof-of-work that is being run by network entities called miners, who are anticipated to primarily maintain the blockchain (ledger). As a result, many researchers are exploring new threats to the entire system, introducing new countermeasures, and therefore anticipating new security trends. In this survey paper, we conduct an intensive study that explores key security concerns. We first start by presenting a global overview of the Bitcoin protocol as well as its major components. Next, we detail the existing threats and weaknesses of the Bitcoin system and its main technologies including the blockchain protocol. Last, we discuss current existing security studies and solutions and summarize open research challenges and trends for future research in Bitcoin security.","['Bitcoin', 'Peer-to-peer computing', 'Machine learning']","['Bitcoin', 'blockchain', 'security', 'machine learning (ML)', 'anomaly detection']"
"In response to the new challenges in the design and operation of communication networks, and taking inspiration from how living beings deal with complexity and scalability, in this paper we introduce an innovative system concept called COgnition-BAsed NETworkS (COBANETS). The proposed approach develops around the systematic application of advanced machine learning techniques and, in particular, unsupervised deep learning and probabilistic generative models for system-wide learning, modeling, optimization, and data representation. Moreover, in COBANETS, we propose to combine this learning architecture with the emerging network virtualization paradigms, which make it possible to actuate automatic optimization and reconfiguration strategies at the system level, thus fully unleashing the potential of the learning approach. Compared with the past and current research efforts in this area, the technical approach outlined in this paper is deeply interdisciplinary and more comprehensive, calling for the synergic combination of expertise of computer scientists, communications and networking engineers, and cognitive scientists, with the ultimate aim of breaking new ground through a profound rethinking of how the modern understanding of cognition can be used in the management and optimization of telecommunication networks.","['Communication networks', 'Cognitive networks', 'Hierarchical networks', 'Optimization', 'Deep learning']","['Cognitive networks', 'deep learning', 'hierarchical generative models', 'optimization']"
"Despite the public enthusiasm for gamification training for employees, gamification is not yet been fully incorporated for instructor training in universities. Previous studies have examine factors that improves employee participation, motivation and engagement that leads to the employee intentions to use gamification for training. Therefore, in this study, task technology fit (TTF), social motivations (SM) and knowledge gain from using gamifiction were investigated. The TAM is enhanced with other factors; such as the task technology fit (TTF) and social motivation. The TTF is used to examine gamification utility, while social motivation is used to examine social influence (SI) and social recognition (SR). Data were collected in two phases, in the first phase 375 data were used for the TAM, secondly, 31 data were used for the pre and posttest. A structural equation model were presented to test the TAM while the t-test were used to study the knowledge gain from using the gamification system. However, the foundation for understanding instructors' behavior in this study's context are: (1) perceived usefulness and attitudes are crucial to the continuance intentions to use gamified Moodle for training; (2) perceived usefulness mediates the relationships among social recognition, TTF, perceived ease of use, and social influence on continuance intentions; (3) when predicting continuance intentions, TTF, social recognition, social influence, and perceived ease of use are vital; (4) TTF positively affects perceived ease of use; and, unexpectedly, (5) the TTF and social influence have no significant effects on perceived usefulness. Detailed results and educational implications are discussed.","['Training', 'Task analysis', 'Games', 'Technology acceptance model', 'Emotion recognition', 'Bibliographies']","['Gamification', 'gamified Moodle training platform', 'gamification in higher institution', 'technology acceptance model', 'motivation', 'task technology fit', 'social motivation']"
"Recently, for satisfying users’ various mobile Internet service requests for data exchange anytime and anywhere even in their moving vehicles, the generated mobile data traffic has been rapidly increasing and has become a serious burden on current cellular networks. To partially address such a serve challenge, vehicular ad hoc networks (VANETs) have emerged as an effective approach for enhancing vehicular services and applications by equipping vehicles with wireless and processing capabilities. In this paper, we survey the recent advances in the data offloading techniques through VANETs. Particularly, based on the communication patterns among vehicles and infrastructures, we classify these techniques into three categories, i.e., data offloading through vehicle-to-vehicle communications, vehicle-to-infrastructure communications, and vehicle-to-everything communications. Besides, we present a detailed taxonomy of the related techniques by discussing the pros and cons for various offloading techniques for different problems in VANETs. Finally, some opening research issues and challenges are outlined to provide guidelines for future research work.","['Vehicular ad hoc networks', 'Cellular networks', 'Data communication', 'Internet']","['Vehicle ad hoc network', 'data offloading', 'communication patterns', 'vehicle-to-vehicle', 'vehicle-to-infrastructure', 'vehicle-to-everything']"
"In this paper, we proposed a decentralized cooperative lane-changing decision-making framework for connected autonomous vehicles, which is composed of three modules, i.e., state prediction, candidate decision generation, and coordination. In other words, each connected autonomous vehicle makes cooperative lane-changing decision independently. In the state prediction module, we employed existing cooperative car-following models to predict the vehicles’ future state. In the candidate decision generation module, we proposed incentive based model to generate a candidate decision. In the candidate decision coordination module, we proposed an algorithm to avoid candidate lane-changing decision that may lead to a vehicle collision or traffic deterioration to be final decision. Moreover, the effects of decentralized cooperative lane-changing decision-making framework on traffic stability, efficiency, homogeneity, and safety are investigated in a numerical simulation experiment. Some stability, efficiency, homogeneity, and safety indicators are evaluated and show the high potential of our proposed framework in traffic dynamics.","['Decision making', 'Acceleration', 'Technological innovation', 'Autonomous vehicles', 'Collaboration', 'Traffic control']","['Connected autonomous vehicles', 'decentralized cooperative lane-changing decision-making framework', 'state prediction module', 'candidate decision generation module', 'candidate decision coordination module']"
"In this paper, a disturbance observer-based fuzzy sliding mode control (DOBFSMC) strategy is proposed for a single-phase PV grid-connected inverter. In the fact that the uncertainties caused by the inverter component parameter variations and the changes of climatic conditions may seriously affect the control performance of the inverter, a disturbance observer is designed to estimate these disturbances in real time and a sliding mode controller designed with the output information of the disturbance observer is employed to control the output voltage of the DC-AC inverter, and a fuzzy system is used to approximate the upper bound of the observation error between the actual disturbance and its observation value in order to improve the performance of the control system. The inverter has strong robustness since the disturbances can be adaptively compensated, and the chattering is greatly reduced since the switching gain can be very small as the upper bound of observation error is estimated by the fuzzy system. Finally, simulation results verify the effectiveness of the proposed method and demonstrate it can work reliably under different conditions.","['Inverters', 'Disturbance observers', 'Uncertainty', 'Switches', 'DC-DC power converters', 'Sliding mode control', 'Voltage control']","['PV grid-connected inverter', 'disturbance observer', 'fuzzy-sliding mode control']"
"In general, the mobile ad hoc networks (MANETs) are built on the basis of the random distribution of the nodes, while the nodes of real networks usually have the characteristics of location preference choice. The evolving network model based on local-area choice is proposed for MANET based on the complex network theory. The proposed model of the topology not only considers the scale-free nature of the network and the actual mobility of MANET but also considers the consumption of the node energy. Random failures often occur in MANET. Most of the existing research focuses on the changes in network topology caused by random node failures. In order to describe the impact of random edge failures on the topology of MANET, we focus on the average shortest path length (ASPL) which is an important feature of the network topology and propose the formula for calculating the ASPL of the MANET after the random edge failure. The experimental simulation analyzes the change of the ASPL of MANET in the random failure scenario (after random edge deletion). By comparing with the actual scene results, the proposed estimation formula which describes this change more accurately is proved. The formula proposed in this paper provides a general framework for studying the shortest path of MANET.","['Mobile ad hoc networks', 'Complex networks', 'Topology', 'Mathematical model', 'Routing', 'Routing protocols']","['ASPL', 'local-area choice', 'random edge failure', 'complex network', 'random failure', 'MANET']"
"Wireless power transfer (WPT) has long been one of the main goals of Nikola Tesla, the forefather of electromagnetic applications. In this paper, we investigate radio-frequency beamforming in the radiative far field for WPT. First, an analytical model of the channel fading is presented, and a blind adaptive beamforming algorithm is adapted to the WPT context. The algorithm is computationally light, because we need not explicitly estimate the channel state information. Then, a testbed with a multiple-antenna software-defined radio configuration on the transmitting side and a programmable energy harvester on the receiving side is developed in order to validate the algorithm in this specific power application. From the results, it can be seen that the implementation of this version of beamforming indeed improves the harvested power. Specifically, at various distances from 50 cm to 1.5 m, the algorithm converges with two, three, and four antennas with an increasing gain as we increase the number of antennas. These encouraging results could have far-reaching consequences in providing wireless power to Internet of Things devices, our target application.","['Array signal processing', 'Radio frequency', 'Wireless power transfer', 'Couplings', 'Transmitting antennas', 'Receivers', 'Magnetic resonance']","['Wireless power transfer', 'radio-frequency energy harvesting', 'software-defined radios', 'experiments', 'beamforming']"
"Fault diagnosis technology is key to the safe and stable operation of wind turbines. An effective fault diagnosis technology for wind turbines can quickly identify fault types to reduce the operation and maintenance costs of wind farms and improve power generation efficiency. Currently, most wind farms obtain operation and maintenance data via supervisory control and data acquisition (SCADA) systems, which contain rich information related to the operation characteristics of wind turbines. However, few SCADA systems provide fault diagnosis functionality. Support vector machines (SVMs) are a popular intelligence method in the fault diagnosis of wind turbines. SVM parameter selection is key for accurate model classification. The sparrow search algorithm (SSA) is a novel and highly efficient optimization method used to optimize the penalty factor and kernel function parameter of SVM in this paper and to construct the SSA-SVM wind turbine fault diagnosis model. Data are acquired from a wind farm SCADA system and form a faulting set after preprocessing and feature selection. Experiments show that the SSA-SVM diagnostic model effectively improves the accuracy of wind turbine fault diagnosis compared with the GS-SVM, GA-SVM and PSO-SVM models and has fast convergence speed and strong optimization ability. Moreover, the SSA-SVM diagnostic model can be used to diagnose faults in practical engineering applications.","['Wind turbines', 'Fault diagnosis', 'Support vector machines', 'SCADA systems', 'Wind farms', 'Kernel', 'Biological system modeling']","['Sparrow search algorithm (SSA)', 'fault diagnosis', 'wind turbines', 'support vector machine (SVM)', 'parameter optimization']"
"In this article, we present a comprehensive study with an experimental analysis of federated deep learning approaches for cyber security in the Internet of Things (IoT) applications. Specifically, we first provide a review of the federated learning-based security and privacy systems for several types of IoT applications, including, Industrial IoT, Edge Computing, Internet of Drones, Internet of Healthcare Things, Internet of Vehicles, etc. Second, the use of federated learning with blockchain and malware/intrusion detection systems for IoT applications is discussed. Then, we review the vulnerabilities in federated learning-based security and privacy systems. Finally, we provide an experimental analysis of federated deep learning with three deep learning approaches, namely, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). For each deep learning model, we study the performance of centralized and federated learning under three new real IoT traffic datasets, namely, the Bot-IoT dataset, the MQTTset dataset, and the TON_IoT dataset. The goal of this article is to provide important information on federated deep learning approaches with emerging technologies for cyber security. In addition, it demonstrates that federated deep learning approaches outperform the classic/centralized versions of machine learning (non-federated learning) in assuring the privacy of IoT device data and provide the higher accuracy in detecting attacks.","['Internet of Things', 'Collaborative work', 'Data models', 'Servers', 'Computer crime', 'Deep learning', 'Training']","['Federated learning', 'intrusion detection', 'deep learning', 'cyber security', 'the IoT', 'blockchain']"
"We study a scenario where multiple drone-mounted base stations cruise freely over a macro hotspot to serve mobile users on the ground. The drone base stations move constantly and update their moving directions following our proposed mobility control algorithm. The constant movement of drones reduces the distance between the base stations and users, which in turn improves the probability of having a line of sight connection. We consider a practical user association scheme for the moving base stations, which enables user equipments to switch their serving base stations based only on the received signal strength. via extensive simulations, we demonstrate that the drone base stations moving according to our proposed algorithms can improve the average packet throughput by 82% and the 5th-percentile packet throughput by 430% compared to a baseline scenario, where drones hover over fixed locations. These improvements can be realized regardless of users' and base stations' density. The constant movement of the drones also helps reduce the total number of drones required to cover the macro hotspot.","['Drones', 'Base stations', 'Satellite broadcasting', 'Throughput', 'Interference', 'Signal to noise ratio', 'Cellular networks']","['Unmanned aerial vehicles', 'Drone base station', 'mobility control', 'game theory', 'network optimization']"
"Critical infrastructures, e.g., electricity generation and dispersal networks, chemical processing plants, and gas distribution, are governed and monitored by supervisory control and data acquisition systems (SCADA). Detecting intrusion is a prevalent area of study for numerous years, and several intrusion detection systems have been suggested in the literature for cyber-physical systems and industrial control system (ICS). In recent years, the viruses seismic net, duqu, and flame against ICS attacks have caused tremendous damage to nuclear facilities and critical infrastructure in some countries. These intensified attacks have sounded the alarm for the security of the ICS in many countries. The challenge in constructing an intrusion detection framework is to deal with unbalanced intrusion datasets, i.e. when one class is signified by a lesser amount of instances (minority class). To this end, we outline an approach to deal with this issue and propose an anomaly detection method for the ICS. Our proposed approach uses a hybrid model that takes advantage of the anticipated and consistent nature of communication patterns that occur among ground devices in ICS setups. First, we applied some preprocessing techniques to standardize and scale the data. Second, the dimensionality reduction algorithms are applied to improve the process of anomaly detection. Third, we employed an edited nearest-neighbor rule algorithm to balance the dataset. Fourth, by using the Bloom filter, a signature database is created by noting the system for a specific period lacking the occurrence of abnormalities. Finally, to detect new attacks, we combined our package contents-level detection with another instance-based learner to make a hybrid method for anomaly detection. The experimental results with a real large-scale dataset generated from a gas pipeline SCADA system show that the proposed approach HML-IDS outperforms the benchmark models with an accuracy rate of 97%.","['Integrated circuits', 'Intrusion detection', 'SCADA systems', 'Anomaly detection', 'Process control', 'Protocols']","['Bloom filters', 'zero-day attacks', 'intrusion detection', 'SCADA', 'industrial control systems']"
"The modern automobile is a complex piece of technology that uses the Controller Area Network (CAN) bus system as a central system for managing the communication between the electronic control units (ECUs). Despite its central importance, the CAN bus system does not support authentication and authorization mechanisms, i.e., CAN messages are broadcast without basic security features. As a result, it is easy for attackers to launch attacks at the CAN bus network system. Attackers can compromise the CAN bus system in several ways including Denial of Service (DoS), Fuzzing and Spoofing attacks. It is imperative to devise methodologies to protect modern cars against the aforementioned attacks. In this paper, we propose a Long Short-Term Memory (LSTM)-based Intrusion Detection System (IDS) to detect and mitigate the CAN bus network attacks. We generate our own dataset by first extracting attack-free data from our experimental car and by injecting attacks into the latter and collecting the dataset. We use the dataset for testing and training our model. With our selected hyper-parameter values, our results demonstrate that our classifier is efficient in detecting the CAN bus network attacks, we achieved an overall detection accuracy of 99.995%. We also compare the proposed LSTM method with the Survival Analysis for automobile IDS dataset which is developed by the Hacking and Countermeasure Research Lab, Korea. Our proposed LSTM model achieves a higher detection rate than the Survival Analysis method.","['Automobiles', 'Fuzzing', 'Protocols', 'Intrusion detection', 'Machine learning', 'Computer crime']","['Modern car security', 'controller area network', 'deep learning', 'LSTM', 'intrusion detection system']"
"Autism Spectrum Disorder (ASD) is a group of neurodevelopmental disabilities that are not curable but may be ameliorated by early interventions. We gathered early-detected ASD datasets relating to toddlers, children, adolescents and adults, and applied several feature transformation methods, including log, Z-score and sine functions to these datasets. Various classification techniques were then implemented with these transformed ASD datasets and assessed for their performance. We found SVM showed the best performance for the toddler dataset, while Adaboost gave the best results for the children dataset, Glmboost for the adolescent and Adaboost for the adult datasets. The feature transformations resulting in the best classifications was sine function for toddler and Z-score for children and adolescent datasets. After these analyses, several feature selection techniques were used with these Z-score-transformed datasets to identify the significant ASD risk factors for the toddler, child, adolescent and adult subjects. The results of these analytical approaches indicate that, when appropriately optimised, machine learning methods can provide good predictions of ASD status. This suggests that it may possible to apply these models for the detection of ASD in its early stages.","['Pediatrics', 'Tools', 'Autism', 'Support vector machines', 'Computer science', 'Australia', 'Feature extraction']","['ASD', 'AQ-10 tools', 'classifier', 'FT', 'FST', 'prediction model']"
"Running very complex applications on mobile devices is still challenging since they are constrained by limited resources, such as memory capacity, network bandwidth, processor speed, and battery power. Mobile Cloud Computing (MCC) is a combination of cloud computing and mobile internet, which could effectively alleviate the resource constraints of mobile devices. How to efficiently offload computation intensive parts of mobile applications from mobile devices to capable cloud servers is one of the keys. In mobile environments, the resource heterogeneity of mobile devices and cloud services, the interruption of heterogeneous wireless networks, the complexity of mobile applications, and the characteristic of transferring a large amount of data, are the major bottlenecks that have prevented this technology from being widely used. This paper takes these constraints into an account at the same time and explores methods of multi-objective decision making for timeand energy-aware task offloading for MCC. It is designed to ensure the right computational tasks are executed in the right way, at the right time and place.","['Cloud computing', 'Mobile communication', 'Mobile handsets', 'Wireless networks', 'Mobile computing', 'Decision making']","['Mobile cloud computing', 'mobile edge computing', 'offloading', 'decision-making', 'energy-efficient']"
"In conventional cognitive radio (CR), the users in secondary network (SN) can only access the idle spectrum when users in primary network (PN) are absent. This novel strategy provides higher spectrum efficiency when detecting the presence of the PN. Hence, spectrum utilization of the traditional scheme can be further improved as exploiting application of non-orthogonal multiple access (NOMA). As combination of CR and NOMA, such CR-NOMA has been proposed to improve spectrum efficiency to adapt to requirements in 5G communications. In this study, the relaying scheme is employed in the SN of the proposed CR-NOMA and the relay is allowed to energy harvesting (EH) from the secondary transmitter to serve signal forwarding to distant secondary users. With this regard, the complex model of EH-assisted CR-NOMA is explored in outage behavior and throughput performance as awareness on imperfect successive interference cancellation (SIC) at the receiver. As most important results, the exact closed-form of the exact outage probability is derived for each NOMA destination by assuming that the channel coefficients among considered links follow Rayleigh distribution. Furthermore, performance gap between two NOMA users can be controlled by various parameters such as transmit power, energy harvesting coefficients and levels of imperfect SIC. Simulation results verify our analytical results.","['NOMA', 'Relays', 'Silicon carbide', 'Power system reliability', 'Probability', 'Fading channels', 'Resource management']","['Energy harvesting', 'imperfect SIC', 'NOMA', 'outage probability', 'underlay cognitive radio']"
"The increase in power outages caused by high-impact low-probability events, such as extreme weather-related climate variation events, is the main reason behind studying power system resilience. However, the concepts of resilience as well as the proactive procedures that can be carried out to address these events are such have not so far been satisfactorily investigated notwithstanding their growing benefits. This paper exhibits a review of the current research on power system resilience; which predominantly focuses on proactive resilience against natural disasters. Firstly, it gives a theoretical framework to acquire insights into power system resilience and its key features. Secondly, it presents frameworks for proactive resilience of power systems with a spotlight on the extreme weather events and their effect. Finally, various strategies for preparing, hardening and enhancing proactive resilience with a focus on microgrids for improving power system resilience are reviewed.","['Resilience', 'Meteorology', 'Power system reliability', 'Absorption', 'Robustness', 'Resistance']","['Power system resilience', 'proactive management', 'natural disasters', 'microgrid', 'extreme weather', 'resilience enhancement']"
"Unmanned aerial vehicles (UAVs) have gained popularity for diverse applications and services in both the military and civilian domains. For cooperation and collaboration among UAVs, they can be wirelessly interconnected in an ad hoc manner, resulting in a UAV network. UAV networks have unique features and characteristics that are different from mobile ad hoc networks and vehicular ad hoc networks. The dynamic behavior of rapid mobility and topology changes in UAV networks makes the design of a routing protocol quite challenging. In this paper, we review the routing protocols for UAV networks, in which the topology-based, position-based, hierarchical, deterministic, stochastic, and social-network-based routing protocols are extensively surveyed. The routing protocols are then compared qualitatively in terms of their major features, characteristics, and performance. Open issues and research challenges are also discussed in the perspective of design and implementation.","['Routing protocols', 'Routing', 'Ad hoc networks', 'Network topology', 'Topology', 'Drones']","['Unmanned aerial vehicle network', 'flying ad hoc network', 'drone ad hoc network', 'routing protocol', 'rapid mobility', 'dynamic topology', 'scalability']"
"With the considerable growth of cybersecurity risks in modern automobiles, cybersecurity issues in the in-vehicle network environment have attracted significant attention from security researchers in recent years. Enhancing the cybersecurity ability of in-vehicle networks while considering the computing resource and cost constraints become an urgent issue. To address this problem, a novel information entropy-based method is proposed in this paper, which uses a fixed number of messages as sliding windows. By improving the sliding window strategy and optimizing the decision conditions, the detection accuracy is increased and the false positive rate is reduced. Experimental results demonstrate that the proposed method can provide real-time response to attacks with a considerably improved detection precision for intrusion detection in the in-vehicle network environment.","['Intrusion detection', 'Information entropy', 'Encryption', 'Automobiles', 'Authentication', 'Protocols']","['Controller area network (CAN)', 'cybersecurity', 'information entropy', 'in-vehicle network', 'intrusion detection system (IDS)']"
"Specific emitter identification (SEI) enables the discrimination of individual radio emitters with the external features carried by the received waveforms. This identification technique has been widely adopted in military and civil applications. However, many previous methods based on hand-crafted features are subject to the present expertise. To remedy these shortcomings, this paper presents a novel SEI algorithm using deep learning architecture. First, we perform Hilbert-Huang transform on the received signal and convert the resulting Hilbert spectrum into a grayscale image. As a signal representation, the Hilbert spectrum image has high information integrity and can provide abundant information about the nonlinear and non-stationary characteristics of signals for identifying emitters. Thereafter, we construct a deep residual network for learning the visual differences reflected in the Hilbert spectrum images. By using the residual architectures, we effectively address the degradation problem, which improves efficiency and generalization. From our analysis, the proposed approach combines high information integrity with low complexity, which outperforms previous studies in the literature. The simulation results validate that the Hilbert spectrum image is a successful signal representation, and also demonstrate that the fingerprints extracted from raw images using deep learning are more effective and robust than the expert ones. Furthermore, our method has the capability of adapting to signals collected under various conditions.","['Feature extraction', 'Radio frequency', 'Relays', 'Deep learning', 'Transforms', 'Fading channels', 'Signal representation']","['Deep residual network', 'Hilbert spectrum grayscale image', 'information integrity', 'Rayleigh fading', 'relay', 'specific emitter identification']"
"T-spherical fuzzy set (T-SPFS) is a generalization of several fuzzy concepts such as fuzzy set (FS), intuitionistic FS, picture FS, Pythagorean FS, and q-rung orthopair FS. T-SPFS is a more powerful mathematical tool to handle uncertain, inconsistent, and vague information than the above-defined sets. In this paper, some limitations in the operational laws for SPF numbers (SPFNs) are discussed and some novel operational laws for SPFNs are proposed. Furthermore, two new aggregation operators for aggregating SPF information are proposed and are applied to multiple-attribute group decision-making (MAGDM). To take the advantages of Muirhead mean (MM) operator and power average operator, the SPF power MM (SPFPMM) operator, weighted SPFPMM operator, SPF power dual MM (SPFPDMM) operator, weighted SPFPDMM operator are introduced and their anticipated properties are discussed. The main advantage of these developed aggregation operators is that they take the relationship among fused data and the interrelationship among aggregated values, thereby getting more information in the process of MAGDM. Moreover, a novel approach to MAGDM based on the developed aggregation operators is established. Finally, a numerical example is given to show the effectiveness of the developed approach and comparison with the existing approaches is also given.","['Fuzzy sets', 'Decision making', 'Pattern recognition', 'Object recognition', 'Finance', 'Economics']","['T-Spherical fuzzy set', 'novel operational laws', 'MAGDM', 'aggregation operator', 'power average operator', 'MM operator', 'power Murihead mean operator']"
"Massive machine-type communication (mMTC) and ultra-reliable and low-latency communication (URLLC) are two key service types in the fifth-generation (5G) communication systems, pursuing scalability and reliability with low-latency, respectively. These two extreme services are envisaged to agglomerate together into critical mMTC shortly with emerging use cases (e.g., wide-area disaster monitoring, wireless factory automation), creating new challenges to designing wireless systems beyond 5G. While conventional network slicing is effective in supporting a simple mixture of mMTC and URLLC, it is difficult to simultaneously guarantee the reliability, latency, and scalability requirements of critical mMTC (e.g., ¡ 4ms latency, 10 6 devices/km 2 for factory automation) with limited radio resources. Furthermore, recently proposed solutions to scalable URLLC (e.g., machine learning aided URLLC for driverless vehicles) are ill-suited to critical mMTC whose machine type users have minimal energy budget and computing capability that should be (tightly) optimized for given tasks. To this end, our paper aims to characterize promising use cases of critical mMTC and search for their possible solutions. To this end, we first review the state-of-the-art (SOTA) technologies for separate mMTC and URLLC services and then identify key challenges from conflicting SOTA requirements, followed by potential approaches to prospective critical mMTC solutions at different layers.","['5G mobile communication', 'Reliability', 'Haptic interfaces', 'Delays', 'Wireless communication', 'Scalability', 'Drones']","['Ultra reliable low latency communication (URLLC)', 'massive machine type communications (mMTC)', 'critical mMTC', '5G', 'beyond 5G']"
"The dynamic uncertain environment and complex tasks determine that the unmanned aerial vehicle (UAV) system is bound to develop towards clustering, autonomy, and intelligence. In this article, we present a comprehensive survey of UAV swarm intelligence from the hierarchical framework perspective. Firstly, we review the basics and advances of UAV swarm intelligent technology. Then we look inside to investigate the research work by classifying UAV swarm intelligence research into five layers, i.e., decision-making layer, path planning layer, control layer, communication layer, and application layer. Furthermore, the relationship between each level is explicitly illustrated, and the research trends of each layer are given. Finally, limitations and possible technology trends of swarm intelligence are also covered to enable further research interests. Through this in-depth literature review, we intend to provide novel insights into the latest technologies in UAV swarm intelligence.","['Task analysis', 'Planning', 'Particle swarm optimization', 'Drones', 'Heuristic algorithms', 'Clustering algorithms']","['UAV', 'swarm intelligence', 'hierarchical control framework', 'trend']"
"Automatic voice pathology detection and classification systems effectively contribute to the assessment of voice disorders, enabling the early detection of voice pathologies and the diagnosis of the type of pathology from which patients suffer. This paper concentrates on developing an accurate and robust feature extraction for detecting and classifying voice pathologies by investigating different frequency bands using autocorrelation and entropy. We extracted maximum peak values and their corresponding lag values from each frame of a voiced signal by using autocorrelation as features to detect and classify pathological samples. We also extracted the entropy for each frame of the voice signal after we normalized its values to be used as the features. These features were investigated in distinct frequency bands to assess the contribution of each band to the detection and classification processes. Various samples of the sustained vowel /a/ for both normal and pathological voices were extracted from three different databases in English, German, and Arabic. A support vector machine was used as a classifier. We also performed u-tests to investigate if there is a significant difference between the means of the normal and pathological samples. The best achieved accuracies in both detection and classification varied depending on the used band, method, and database. The most contributive bands in both detection and classification were between 1000 and 8000 Hz. The highest obtained accuracies in the case of detection were 99.69%, 92.79%, and 99.79% for Massachusetts eye and ear infirmary (MEEI), Saarbrücken voice database (SVD), and Arabic voice pathology database (AVPD), respectively. However, the highest achieved accuracies for classification were 99.54%, 99.53%, and 96.02% for MEEI, SVD, and AVPD, correspondingly, using the combined feature.","['Pathology', 'Feature extraction', 'Databases', 'Correlation', 'Vibrations', 'Speech', 'Acoustics']","['Voice pathology detection and classification', 'frequency investigation', 'Arabic voice pathology database (AVPD)', 'Saarbrücken voice database (SVD)', 'Massachusetts eye and ear infirmary (MEEI)']"
"The 3rd Generation Partnership Project (3GPP) submitted the 5G New Radio (NR) system specifications to International Telecommunication Union (ITU) as a candidate fifth generation (5G) mobile communication system (formally denoted as IMT-2020 systems). As part of the submission, 3GPP provided a self-evaluation for the compliance of 5G NR systems with the ITU defined IMT-2020 performance requirements. This paper considers the defined 5G use case families, Ultra Reliable Low-Latency Communication (URLLC), massive Machine Type Communication (mMTC) and enhanced Mobile Broadband (eMBB), and provides an independent evaluation of the compliance of the 3GPP 5G NR self-evaluation simulations with the IMT-2020 performance requirements for connection density, reliability, and spectral efficiency for future mobile broadband and emerging IoT applications. Independent evaluation indeed shows the compliance of the 3GPP 5G NR system with the ITU IMT-2020 performance requirements for all parameters evaluated by simulations.","['5G mobile communication', '3GPP', 'Ultra reliable low latency communication', 'Spectral efficiency', 'Internet of Things', 'ITU', 'Reliability']","['mMTC', 'eMBB', 'URLLC', 'IoT', '5G', '5G NR', 'LPWA', 'connection density', 'simulation framework', 'spectral efficiency', 'evaluation', '3GPP', 'IMT-2020']"
"Autonomous vehicle path tracking accuracy and vehicle stability can hardly be accomplished by one fixed control frame in various conditions due to the changing vehicle dynamics. This paper presents a model predictive control (MPC) path-tracking controller with switched tracking error, which reduces the lateral tracking deviation and maintains vehicle stability for both normal and high-speed conditions. The design begins by comparing the performance of three MPC controllers with different tracking error. The analyzing results indicate that in the steady-state condition the controller with the velocity heading deviation as the tracking error significantly improves the tracking accuracy. Meanwhile, in the transient condition, by substituting the steady-state sideslip for real-time sideslip to compute the velocity heading deviation, the tracking overshoot can be reduced. To combine the strengths of these two methods, an MPC controller with switched tracking error is designed to improve the performance in both steady-state and transient conditions. The regime condition of a vehicle maneuver and the switching instant are determined by a fuzzy-logic-based condition classifier. Both normal and aggressive driving scenarios with the vehicle lateral and longitudinal acceleration combination of 5 m/s 2 and 8 m/s 2 are designed to test the proposed controller through CarSim-Simulink platform. The simulation results show the improved performance of the MPC controller with switched tracking error both in tracking accuracy and vehicle stability in both scenarios.","['Tires', 'Steady-state', 'Switches', 'Stability analysis', 'Vehicle dynamics', 'Force', 'Tracking']","['Autonomous vehicles', 'path tracking', 'predictive control', 'switched tracking error', 'condition classifier']"
"The paper proposes a new structure of SEPIC with high voltage gain for renewable energy applications. The proposed circuit is designed by amalgamating the conventional SEPIC with a boosting module. Therefore, the converter benefits from various advantages that the SEPIC converter has, such as continuous input current. Also, high voltage gain and input current continuity make the presented converter suitable for renewable energy sources. The modified SEPIC converter (MSC) provides higher voltage gain compared to the conventional SEPIC and recently addressed converters with a single-controlled switch. The analysis of voltage gain in continuous current mode (CCM) and discontinuous current mode (DCM) is analyzed by considering the non-idealities of the semiconductor devices and passive components. The selection of the semiconductor devices depending on the voltage-current rating is presented along with the designing of reactive components. The numerical simulation and experimental work are carried out, and the obtained results prove the feasibility of the MSC concept and the theoretical analysis.","['Inductors', 'Switches', 'Capacitors', 'High-voltage techniques', 'Renewable energy sources', 'DC-DC power converters', 'Resistance']","['DC-DC converter', 'energy conversion', 'high voltage gain', 'SEPIC', 'renewable energy']"
"Unmanned Aerial Vehicles (UAVs) are becoming increasingly popular for applications such as inspections, delivery, agriculture, surveillance, and many more. It is estimated that, by 2040, UAVs/drones will become a mainstream delivery channel to satisfy the growing demand for parcel delivery. Though the UAVs are gaining interest in civil applications, the future of UAV charging is facing a set of vital concerns and open research challenges. Considering the case of parcel delivery, handling countless drones and their charging will become complex and laborious. The need for non-contact based multi-device charging techniques will be crucial in saving time and human resources. To efficiently address this issue, Wireless Power Transmission (WPT) for UAVs is a promising technology for multi-drone charging and autonomous handling of multiple devices. In the literature of the past five years, limited surveys were conducted for wireless UAV charging. Moreover, vital problems such as coil weight constraints, comparison between existing charging techniques, shielding methods and many other key issues are not addressed. This motivates the author in conducting this review for addressing the crucial aspects of wireless UAV charging. Furthermore, this review provides a comprehensive comparative study on wireless charging's technical aspects conducted by prominent research laboratories, universities, and industries. The paper also discusses UAVs' history, UAVs structure, categories of UAVs, mathematical formulation of coil and WPT standards for safer operation.","['Drones', 'Inductive charging', 'Batteries', 'Wireless communication', 'Magnetic resonance', 'Masers', 'IEEE Sections']","['Wireless power transfer', 'drone', 'UAV', 'inductive power transfer', 'capacitive power transfer', 'magnetic resonance charging', 'coil design', 'compensation networks']"
"Despite common arguments about the prevalence of blockchain technology, in terms of security, privacy, and immutability, in reality, several attacks can be launched against them. This paper provides a systematic literature review on long-range attacks for proof of stake protocols. If successful, these attacks may take over the main chain and partially, or even completely, rewrite the history of transactions that are stored in the blockchain. To this end, we describe how proof of stake protocols work, their fundamental properties, their drawbacks, and their attack surface. After presenting long-range attacks, we discuss possible countermeasures and their applicability.","['Blockchain', 'Protocols', 'Peer-to-peer computing', 'Bitcoin', 'History', 'Privacy']",['Blockchain and proof of stake and long-range attacks']
"The use of the digital twin has been quickly adopted in industry in recent years and continues to gain momentum. The recent redefinition of the digital twin from the digital replica of a physical asset to the replica of a living or nonliving entity has increased its potential. The digital twin not only disrupts industrial processes, but also expands the domain of health and well-being towards fostering smart healthcare services in smart cities. In this paper, we propose an ISO/IEEE 11073 standardized digital twin framework architecture for health and well-being. This framework encompasses the process of data collection from personal health devices, the analysis of this data, and conveying the feedback to the user in a loop cycle. The framework proposes a solution to include not only X73 compliant devices, but also noncompliant health devices, by interfacing them with an X73 wrapper module as we explain in this paper. Besides, we propose a configurable X73 mobile application, designed to work with any X73 compliant device. We designed and implemented the proposed framework, and the X73 mobile app, and conducted an experiment as a proof of concept of the digital twin in the domain of health and well-being in smart cities. The experiment shows promising results and the potential of benefiting from the proposed framework, by gaining insights on the health and well-being of individuals, and providing feedback to the individual and caregiver.","['Digital twin', 'ISO Standards', 'IEEE Standards', 'Medical services', 'Biomedical monitoring', 'Smart cities']","['Digital twin', 'health', 'well-being', 'physical activity', 'standards', 'ISO/IEEE 11073', 'X73', 'wearables', 'data collection', 'data analysis', 'artificial intelligence', 'user interaction', 'user feedback']"
"As batteries become more prevalent in grid energy storage applications, the controllers that decide when to charge and discharge become critical to maximizing their utilization. Controller design for these applications is based on models that mathematically represent the physical dynamics and constraints of batteries. Unrepresented dynamics in these models can lead to suboptimal control. Our goal is to examine the state-of-the-art with respect to the models used in optimal control of battery energy storage systems (BESSs). This review helps engineers navigate the range of available design choices and helps researchers by identifying gaps in the state-of-the-art. BESS models can be classified by physical domain: state-of-charge (SoC), temperature, and degradation. SoC models can be further classified by the units they use to define capacity: electrical energy, electrical charge, and chemical concentration. Most energy based SoC models are linear, with variations in ways of representing efficiency and the limits on power. The charge based SoC models include many variations of equivalent circuits for predicting battery string voltage. SoC models based on chemical concentrations use material properties and physical parameters in the cell design to predict battery voltage and charge capacity. Temperature is modeled through a combination of heat generation and heat transfer. Heat is generated through changes in entropy, overpotential losses, and resistive heating. Heat is transferred through conduction, radiation, and convection. Variations in thermal models are based on which generation and transfer mechanisms are represented and the number and physical significance of finite elements in the model. Modeling battery degradation can be done empirically or based on underlying physical mechanisms. Empirical stress factor models isolate the impacts of time, current, SoC, temperature, and depth-of-discharge (DoD) on battery state-of-health (SoH). Through a few simplifying assumptions, these stress factors can be represented using regularization norms. Physical degradation models can further be classified into models of side-reactions and those of material fatigue. This article demonstrates the importance of model selection to optimal control by providing several example controller designs. Simpler models may overestimate or underestimate the capabilities of the battery system. Adding details can improve accuracy at the expense of model complexity, and computation time. Our analysis identifies six gaps: deficiency of real-world data in control literature, lack of understanding in how to balance modeling detail with the number of representative cells, underdeveloped model uncertainty based risk-averse and robust control of BESS, underdevelopment of nonlinear energy based SoC models, lack of hysteresis in voltage models used for control, lack of entropy heating and cooling in thermal modeling, and deficiency of knowledge in what combination of empirical degradation stress factors is most accurate. These gaps are opportunities for future research.","['Batteries', 'Computational modeling', 'Mathematical model', 'Optimal control', 'Degradation', 'Predictive models']","['Batteries', 'modeling', 'distributed energy resources', 'battery energy storage system (BESS)', 'state-of-charge (SoC)', 'state-of-health (SoH)', 'energy storage', 'optimal control']"
"This paper proposes a general characteristic mode-based design procedure of simple three steps for wideband circularly polarized (CP) antenna design. First of all, the characteristic mode analysis is carried out to understand the different modes of a proposed antenna geometry without feeding network. Second, modal currents and their corresponding modal fields (radiation patterns) are studied for choosing modes to shape the required radiation pattern. Finally, a suitable feeding structure is chosen to excite the desired modes at the same time owns a good impedance matching. As an example, a CP patch antenna fed with cross-shaped aperture is proposed and designed following the design procedure. Patch consisting of H-shaped unit cells is used as the radiator. Characteristic mode method is applied to analyze the modes of the proposed antenna and explains the property of wide band circular polarization. It is revealed that higher order modes of the patch can be used to achieve circular polarization over a wideband of frequency. The antenna is fabricated using printed circuit techniques. The return loss and radiation properties are measured and compared with simulation results. With the highly coupled units, a wide impedance bandwidth of 38.8% is obtained. Besides, a wide 3-dB axial ratio bandwidth of 14.3% is achieved.","['Bandwidth', 'Antenna feeds', 'Patch antennas', 'Antenna theory', 'Antenna radiation patterns', 'Substrates']","['Characteristic mode theory', 'circular polarization', 'wide band']"
"In today's world, due to the advancement of technology, predicting the students' performance is among the most beneficial and essential research topics. Data Mining is extremely helpful in the field of education, especially for analyzing students' performance. It is a fact that predicting the students' performance has become a severe challenge because of the imbalanced datasets in this field, and there is not any comparison among different resampling methods. This paper attempts to compare various resampling techniques such as Borderline SMOTE, Random Over Sampler, SMOTE, SMOTE-ENN, SVM-SMOTE, and SMOTE-Tomek to handle the imbalanced data problem while predicting students' performance using two different datasets. Moreover, the difference between multiclass and binary classification, and structures of the features are examined. To be able to check the performance of the resampling methods better in solving the imbalanced problem, this paper uses various machine learning classifiers including Random Forest, K-Nearest-Neighbor, Artificial Neural Network, XG-boost, Support Vector Machine (Radial Basis Function), Decision Tree, Logistic Regression, and Naïve Bayes. Furthermore, the Random hold-out and Shuffle 5-fold cross-validation methods are used as model validation techniques. The achieved results using different evaluation metrics indicate that fewer numbers of classes and nominal features will lead models to better performance. Also, classifiers do not perform well with imbalanced data, so solving this problem is necessary. The performance of classifiers is improved using balanced datasets. Additionally, the results of the Friedman test, which is a statistical significance test, confirm that the SVM-SMOTE is more efficient than the other resampling methods. Moreover, The Random Forest classifier has achieved the best result among all other models while using SVM-SMOTE as a resampling method.","['Data mining', 'Predictive models', 'Machine learning', 'Data models', 'Artificial neural networks', 'Decision trees', 'Logistics']","['Classification', 'data mining', 'educational data mining', 'imbalanced data problem', 'machine learning', 'resampling methods', 'statistical analysis']"
"Cloud computing is becoming an increasingly admired paradigm that delivers high-performance computing resources over the Internet to solve the large-scale scientific problems, but still it has various challenges that need to be addressed to execute scientific workflows. The existing research mainly focused on minimizing finishing time (makespan) or minimization of cost while meeting the quality of service requirements. However, most of them do not consider essential characteristic of cloud and major issues, such as virtual machines (VMs) performance variation and acquisition delay. In this paper, we propose a meta-heuristic cost effective genetic algorithm that minimizes the execution cost of the workflow while meeting the deadline in cloud computing environment. We develop novel schemes for encoding, population initialization, crossover, and mutations operators of genetic algorithm. Our proposal considers all the essential characteristics of the cloud as well as VM performance variation and acquisition delay. Performance evaluation on some well-known scientific workflows, such as Montage, LIGO, CyberShake, and Epigenomics of different size exhibits that our proposed algorithm performs better than the current state-of-the-art algorithms.","['Cloud computing', 'Genetic algorithms', 'Quality of service', 'Virtual machining', 'Algorithm design and analysis', 'Cost benefit analysis', 'High performance computing']","['Cloud computing', 'scientific workflows', 'resource provisioning', 'scheduling', 'quality of service (QoS)']"
"Smart cities take advantage of recent Information and Communication Technology (ICT) developments to provide added value to existing public services and improve quality of life for the citizens. The Internet of Things (IoT) paradigm makes the Internet more pervasive where objects equipped with computing, storage, and sensing capabilities are interconnected with communication technologies. Because of the widespread diffusion of IoT devices, applying the IoT paradigm to smart cities is an excellent solution to build sustainable ICT platforms. Having citizens involved in the process through mobile crowdsensing (MCS) techniques augments capabilities of these ICT platforms without additional costs. For proper operation, MCS systems require the contribution from a large number of participants. Simulations are therefore a candidate tool to assess the performance of MCS systems. In this paper, we illustrate the design of CrowdSenSim, a simulator for mobile crowdsensing. CrowdSenSim is designed specifically for realistic urban environments and smart cities services. We demonstrate the effectiveness of CrowdSenSim for the most popular MCS sensing paradigms (participatory and opportunistic), and we present its applicability using a smart public street lighting scenario.","['Sensors', 'Smart cities', 'Tools', 'Layout', 'Sociology', 'Statistics']","['Mobile crowdsensing', 'simulations', 'smart cities']"
"This survey focuses on deep learning-based aspect-level sentiment classification (ASC), which aims to decide the sentiment polarity for an aspect mentioned within the document. Along with the success of applying deep learning in many applications, deep learning-based ASC has attracted a lot of interest from both academia and industry in recent years. However, there still lack a systematic taxonomy of existing approaches and comparison of their performance, which are the gaps that our survey aims to fill. Furthermore, to quantitatively evaluate the performance of various approaches, the standardization of the evaluation methodology and shared datasets is necessary. In this paper, an in-depth overview of the current state-of-the-art deep learning-based methods is given, showing the tremendous progress that has already been made in ASC. In particular, first, a comprehensive review of recent research efforts on deep learning-based ASC is provided. More concretely, we design a taxonomy of deep learning-based ASC and provide a comprehensive summary of the state-of-the-art methods. Then, we collect all benchmark ASC datasets for researchers to study and conduct extensive experiments over five public standard datasets with various commonly used evaluation measures. Finally, we discuss some of the most challenging open problems and point out promising future research directions in this field.","['Deep learning', 'Sentiment analysis', 'Recurrent neural networks', 'Benchmark testing', 'Measurement']","['Aspect based sentiment analysis', 'aspect-level sentiment classification', 'attention', 'convolutional neural network (CNN)', 'deep learning', 'memory network', 'neural networks', 'recurrent neural network (RNN)']"
"Daily peak load forecasting is an essential tool for decision making in power system operation and planning. However, the daily peak load is a nonlinear, nonstationary, and volatile time series, which makes it difficult to be forecasted accurately. This paper, for the first time, proposes a bespoke gated recurrent neural network combining dynamic time warping (DTW) for accurate daily peak load forecasting. The shape-based DTW distance is used to match the most similar load curve, which can capture trends in load changes. By analyzing the relationship between the load curve and the cycle of human social activities, the some-hot encoding scheme is first applied on the discrete variables to expand the features to further characterize their impact on load curves. Then, a three-layer gated recurrent neural network is developed to forecast daily peak load. The proposed algorithm is implemented on the Theano deep learning platform and tested on the loaded dataset of the European Network on Intelligent Technologies. The simulation results show that the proposed algorithm achieves satisfactory results compared with other algorithms using the same dataset in this paper.","['Load forecasting', 'Time series analysis', 'Recurrent neural networks', 'Heuristic algorithms', 'Forecasting', 'Logic gates']","['Daily peak load forecasting', 'dynamic time warping', 'one-hot encoding', 'gated recurrent unit']"
"With the booming development of Internet-of-Things (IoT) and communication technologies such as 5G, our future world is envisioned as an interconnected entity where billions of devices will provide uninterrupted service to our daily lives and the industry. Meanwhile, these devices will generate massive amounts of valuable data at the network edge, calling for not only instant data processing but also intelligent data analysis in order to fully unleash the potential of the edge big data. Both the traditional cloud computing and on-device computing cannot sufficiently address this problem due to the high latency and the limited computation capacity, respectively. Fortunately, the emerging edge computing sheds a light on the issue by pushing the data processing from the remote network core to the local network edge, remarkably reducing the latency and improving the efficiency. Besides, the recent breakthroughs in deep learning have greatly facilitated the data processing capacity, enabling a thrilling development of novel applications, such as video surveillance and autonomous driving. The convergence of edge computing and deep learning is believed to bring new possibilities to both interdisciplinary researches and industrial applications. In this article, we provide a comprehensive survey of the latest efforts on the deep-learning-enabled edge computing applications and particularly offer insights on how to leverage the deep learning advances to facilitate edge applications from four domains, i.e., smart multimedia, smart transportation, smart city, and smart industry. We also highlight the key research challenges and promising research directions therein. We believe this survey will inspire more researches and contributions in this promising field.","['Edge computing', 'Deep learning', 'Cloud computing', 'Data processing', 'Servers', 'Computational modeling', 'Autonomous vehicles']","['Internet of Things', 'edge computing', 'deep learning', 'intelligent edge applications']"
"Wireless sensor networks (WSN) over the years have become one of the most promising networking solutions with exciting new applications for the near future. Its deployment has been enhanced by its small, inexpensive, and smart sensor nodes, which are easily deployed, depending on its application and coverage area. Common applications include its use for military operations, monitoring environmental conditions (such as volcano detection, agriculture, and management), distributed control systems, healthcare, and the detection of radioactive sources. Notwithstanding its promising attributes, security in WSN is a big challenge and remains an ongoing research trend. Deployed sensor nodes are vulnerable to various security attacks due to its architecture, hostile deployment location, and insecure routing protocol. Furthermore, the sensor nodes in WSNs are characterized by their resource constraints, such as, limited energy, low bandwidth, short communication range, limited processing, and storage capacity, which have made the sensor nodes an easy target. Therefore, in this paper, we present a review of denial of service attacks that affect resource availability in WSN and their countermeasure by presenting a taxonomy. Future research directions and open research issues are also discussed.","['Wireless sensor networks', 'Monitoring', 'Network topology', 'Topology', 'Security', 'Routing protocols', 'Base stations']","['Denial of service (DoS)', 'detection techniques', 'intrusion detection system (IDS)', 'resource availability', 'resource depletion', 'wireless sensor networks (WSNs)']"
"Class imbalance is a serious problem that plagues the semantic segmentation task in urban remote sensing images. Since large object classes dominate the segmentation task, small object classes are usually suppressed, so the solutions based on optimizing the overall accuracy are often unsatisfactory. In the light of the class imbalance of the semantic segmentation in urban remote sensing images, we developed the concept of the Down-sampling Block (DownBlock) for obtaining context information and the Up-sampling Block (UpBlock) for restoring the original resolution. We proposed an end-to-end deep convolutional neural network (DenseU-Net) architecture for pixel-wise urban remote sensing image segmentation. The main idea of the DenseU-Net is to connect convolutional neural network features through cascade operations and use its symmetrical structure to fuse the detail features in shallow layers and the abstract semantic features in deep layers. A focal loss function weighted by the median frequency balancing (MFB_Focal loss ) is proposed; the accuracy of the small object classes and the overall accuracy are improved effectively with our approach. Our experiments were based on the 2016 ISPRS Vaihingen 2D semantic labeling dataset and demonstrated the following outcomes. In the case where boundary pixels were considered (GT), MFB_Focal loss achieved a good overall segmentation performance using the same U-Net model, and the F1-score of the small object class “car” was improved by 9.28% compared with the cross-entropy loss function. Using the same MFB_Focal loss loss function, the overall accuracy of the DenseU-Net was better than that of U-Net, where the F1-score of the “car” class was 6.71% higher. Finally, without any post-processing, the DenseU-Net+MFB_Focal loss achieved the overall accuracy of 85.63%, and the F1-score of the “car” class was 83.23%, which is superior to HSN+OI+WBP both numerically and visually.","['Image segmentation', 'Feature extraction', 'Semantics', 'Remote sensing', 'Task analysis', 'Image resolution', 'Automobiles']","['Class imbalance', 'deep convolutional neural networks', 'median frequency balancing', 'semantic segmentation', 'urban remote sensing images']"
"A load-independent wireless power transfer system with constant current and constant voltage output for electric vehicles charging is designed and optimized in this paper. Wireless charging system based on LCL-S or LCL-LCL compensation topology is systematically analyzed. And dynamic LCL-S/LCL switching topology is designed and simplified to achieve constant current in the transmitting coil and load-independent constant current and constant voltage output, which can be controlled easily. Moreover, the coupling structures composed of different coil shapes and shielding structures are comparatively studied to improve the coupling stability under misalignment. Figure-of-merit and coupling change rate Δk t defined in this paper are the key parameters in the process of coupling structure design and optimization. The combination of rounded rectangular spiral coil and splicing magnet core units is optimized as the coupling structure of the wireless charging system. Finally, the resonant wireless charging system prototype is being built and tested. The experimental results show that the load-independent and other characteristics of the implemented system are well correlated with the theoretical analysis and design.","['Inductive charging', 'Topology', 'Couplings', 'Transmitters', 'Receivers', 'Magnetic resonance', 'Switches']","['Load-independent', 'wireless charging system', 'compensation topology', 'coupling structure']"
"A low profile omnidirectional patch antenna with filtering response is investigated in this paper. The triangular patch antenna is axially fed by a probe at its center, exciting both its TM 10 and TM 11 modes. Comparing with the traditional circular patch, the triangular patch can not only minimize the patch size but also can generate a radiation null at the upper band edge. A ring slot and a series of shorting vias are introduced into the patch to merge the two modes, enhancing the bandwidth of the passband. The combination of the two elements simultaneously generates a radiation null at the lower band edge. Consequently, a compact filtering patch antenna with quasi-elliptic bandpass response is obtained without involving specific filtering circuits. The prototype with profile of $0.03 λ 0 has a 10-dB impedance bandwidth of 8.9% (4.3-4.7 GHz), an average gain of 6.0 dBi within passband, an out-of-band suppression level of more than 30 dB within lower stopband (0-3.6 GHz), and more than 20 dB within upper stopband (5.1-6.3 GHz).","['Filtering', 'Slot antennas', 'Patch antennas', 'Omnidirectional antennas', 'Antenna measurements', 'Dipole antennas']","['Patch antenna', 'omnidirectional antenna', 'filtering antenna']"
"The electric power supply system is one of the most important research areas within sustainable and energy-efficient aviation for more- and especially all electric aircraft. This paper discusses the history in electrification, current trends with a broad overview of research activities, state of the art of electrification and an initial proposal for a short-range aircraft. It gives an overview of the mission profile, electrical sources, approaches for the electrical distribution system and the required electrical loads. Current research aspects and questions are discussed, including voltage levels, semiconductor technology, topologies and reliability. Because of the importance for safety possible circuit breakers for the proposed concept are also presented and compared, leading to a initial proposal. Additionally, a very broad review of literature and a state of the art discussion of the wiring harness is given, showing that this topic comes with a high number of aspects and requirements. Finally, the conclusion sums up the most important results and gives an outlook on important future research topics.","['Aircraft', 'Aerospace electronics', 'Circuit breakers', 'High-voltage techniques', 'Power electronics', 'Europe', 'Power systems']","['Aviation', 'aerospace electronics', 'MEA', 'AEA', 'electric power supply systems', 'dc-dc power converters', 'power semiconductor devices', 'wide bandgap semiconductors', 'high voltage direct current (HVDC)', 'circuit breaker', 'hybrid circuit breaker']"
"The rapid growth of the Internet of Things (IoT) has accelerated strong interests in the development of low-power wireless sensors. Today, wireless sensors are integrated within IoT systems to gather information in a reliable and practical manner to monitor processes and control activities in areas such as transportation, energy, civil infrastructure, smart buildings, environment monitoring, healthcare, defense, manufacturing, and production. The long-term and self-sustainable operation of these IoT devices must be considered early on when they are designed and implemented. Traditionally, wireless sensors have often been powered by batteries, which, despite allowing low overall system costs, can negatively impact the lifespan and the performance of the entire network they are used in. Energy Harvesting (EH) technology is a promising environment-friendly solution that extends the lifetime of these sensors, and, in some cases completely replaces the use of battery power. In addition, energy harvesting offers economic and practical advantages through the optimal use of energy, and the provisioning of lower network maintenance costs. We review recent advances in energy harvesting techniques for IoT. We demonstrate two energy harvesting techniques using case studies. Finally, we discuss some future research challenges that must be addressed to enable the large-scale deployment of energy harvesting solutions for IoT environments.","['Wireless sensor networks', 'Energy harvesting', 'Wireless communication', 'Sensors', 'Batteries', 'Internet of Things', 'Communication system security']","['Energy efficiency', 'energy harvesting', 'Internet of Things', 'IoT device', 'wireless sensor networks']"
"In this paper, we propose particle swarm optimization (PSO)-enhanced ensemble deep neural networks and hybrid clustering models for skin lesion segmentation. A PSO variant is proposed, which embeds diverse search actions including simulated annealing, levy flight, helix behavior, modified PSO, and differential evolution operations with spiral search coefficients. These search actions work in a cascade manner to not only equip each individual with different search operations throughout the search process but also assign distinctive search actions to different particles simultaneously in every single iteration. The proposed PSO variant is used to optimize the learning hyper-parameters of convolutional neural networks (CNNs) and the cluster centroids of classical Fuzzy C-Means clustering respectively to overcome performance barriers. Ensemble deep networks and hybrid clustering models are subsequently constructed based on the optimized CNN and hybrid clustering segmenters for lesion segmentation. We evaluate the proposed ensemble models using three skin lesion databases, i.e., PH2, ISIC 2017, and Dermofit Image Library, and a blood cancer data set, i.e., ALL-IDB2. The empirical results indicate that our models outperform other hybrid ensemble clustering models combined with advanced PSO variants, as well as state-of-the-art deep networks in the literature for diverse challenging image segmentation tasks.","['Image segmentation', 'Lesions', 'Skin', 'Biological system modeling', 'Computational modeling', 'Brain modeling', 'Particle swarm optimization']","['Convolutional neural network', 'ensemble model', 'Fuzzy C-Means clustering', 'image segmentation', 'particle swarm optimization']"
"Ostrowski inequality provides the estimation of a function to its integral mean. It is useful in error estimations of quadrature rules in numerical analysis. The objective of this paper is to define a more general form of Riemann-Liouville k-fractional integrals with respect to an increasing function, which are used to obtain fractional integral inequalities of Ostrowski type. A simple and straightforward approach is followed to establish these inequalities. The applications of established results are also briefly discussed and succeeded to get bounds of some fractional Hadamard inequalities.",[],[]
"A modern vehicle is a complex system of sensors, electronic control units, and actuators connected through different types of intra-vehicle networks to control and monitor the state of the vehicle. In addition, modern vehicles are becoming increasingly connected to the outside world through V2X technologies. However, these provide new attack surfaces that increase the cybersecurity risk to modern vehicles. To this end, there are two distinct and key challenges that need to be addressed to ensure safety and consumer trust. While modern vehicles must be equipped with the best countermeasures against cybersecurity threats, a reliable mechanism shall be also in place to detect the potential intrusions of the system while in operation, which is termed as intrusion detection. This paper provides a structured and comprehensive review of the state of the art of the intra-vehicle intrusion detection systems (IDSs) for passenger vehicles. We first provide an overview of intra-vehicle networks before reviewing contemporary research in intra-vehicle IDSs. The approach employed is to categorize the reviewed works based on their detection technique and to examine the used feature and feature selection methods, evaluation dataset, attack type, performance metrics, and benchmark models. This paper also presents outstanding research challenges and gaps in intra-vehicle IDS research.","['Intrusion detection', 'Sensors', 'Feature extraction', 'Safety', 'Measurement', 'Benchmark testing']","['CAN bus', 'intra-vehicle network', 'intrusion detection', 'intrusion detection systems (IDSs)']"
"Wireless communication is essential for search and rescue operations in the aftermath of natural disasters. In post-disaster scenarios, unmanned aerial vehicles (UAVs) can be used to capture image and video data from the disaster area and transfer the data to a ground station, owing to their rapid mobility. However, packet forwarding is a challenge because of unstable links and intermittent connectivity in highly dynamic UAV networks. In this paper, we propose a location-aided delay tolerant routing (LADTR) protocol for UAV networks for use in post-disaster operations, which exploits location-aided forwarding combined with a store-carry-forward (SCF) technique. Ferrying UAVs are introduced to enable an efficient SCF, and this is the first attempt at introducing and using ferrying UAVs for routing in UAV networks, to the best of our knowledge. Ferrying UAVs improve the availability of connection paths between searching UAVs and the ground station, thus reducing end-to-end delays and increasing the packet delivery ratio. Future UAV locations are estimated based on the location and speed of UAVs equipped with a global positioning system. The forwarding UAV node predicts the position of the destination UAV node and then decides where to forward. The proposed LADTR ensures that the contact rate between UAV nodes remains high, which enables a high packet delivery ratio, and ensures single-copy data forwarding to avoid replication of each message. Our performance study shows that the proposed LADTR outperforms the four typical routing protocols reported in the literature in terms of packet delivery ratio, average delay, and routing overhead.","['Routing', 'Routing protocols', 'Unmanned aerial vehicles', 'Delays', 'Global Positioning System', 'Unicast']","['Unmanned aerial vehicle network', 'routing protocol', 'store-carry-forward', 'delay tolerant networking', 'data ferry', 'location awareness']"
"Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.","['Machine learning', 'Security', 'Data models', 'Machine learning algorithms', 'Training', 'Training data', 'Prediction algorithms']","['Artificial intelligence security', 'poisoning attacks', 'backdoor attacks', 'adversarial examples', 'privacy-preserving machine learning']"
"Recently, mobility has gathered tremendous interest as the users’ desire for consecutive connections and better quality of service has increased. An accurate prediction of user mobility in mobile networks provides efficient resource and handover management, which can avoid unacceptable degradation of the perceived quality. Therefore, mobility prediction in wireless networks is of great importance and many works have been dedicated to this issue. In this paper, the necessity of mobility prediction, together with its intrinsic characteristics in terms of movement predictability, prediction outputs, and performance metrics is discussed. Moreover, the learning perspective of solutions to mobility prediction has been studied. Specifically, an overview of the state-of-the-art approaches is provided, including Markov chain, hidden Markov model, artificial neural network, Bayesian network, and data mining based on different kinds of knowledge. At last, this paper also explores the open research challenges due to the advent of the fifth-generation mobile system and puts forward some potential trends in the near future.","['Handover', 'Quality of service', 'History', 'Hidden Markov models', 'Prediction algorithms', 'Measurement']","['Mobility prediction', 'quality of service (QoS)', 'resource reservation', 'handover management', 'the fifth-generation mobile system (5G)']"
"Due to the advantages of superior harmonics attenuation ability and reduced size, the LCL filter has been widely adopted to interface between the inverter and the grid for improving the quality of injected grid currents. However, the high-order characteristics and various constraints of the LCL filter complicate the filter design. Moreover, the stability of the internal current control loop of the individual inverter is susceptible to the inherent LCL -filter resonance peak. Meanwhile, the overall system stability would be aggravated by the external interactions between the inverter and the weak grid as well as among the paralleled inverters. Both the LCL -filter resonance peak and two types of interaction would cause severely distorted grid currents. Motivated by the existing problems, a comprehensive review on the modeling and stability analysis of the LCL -type grid-connected inverters is conducted in this paper. Concretely, the generalized parameter constraints of the LCL filter are outlined to facilitate the passive components selection, and the magnetic integration techniques of filter inductors are also introduced to reduce the weight and size of filter for increasing the power density of the system. Then, the various damping methods for enhancing the individual internal stability and the relevant application issues are also discussed. Furthermore, the impedance-based method for evaluating the system-level interactive stability is subsequently reviewed, with the emphasis on different modeling methods of inverter output impedance and online impedance measurement techniques. Finally, the future research trends on the modeling and stability analysis of LCL -type grid-connected inverters are also presented.","['Inverters', 'Power system stability', 'Impedance', 'Harmonic analysis', 'Stability criteria', 'Inductors']","['LCL-filter', 'grid-connected inverters', 'parameters design', 'magnetic integration', 'damping methods', 'delay', 'stability', 'impedance-based stability analysis', 'impedance modeling', 'impedance measurement']"
"The increase of network size and sensory data leads to many serious problems to the wireless sensor networks due to the limited energy. Data prediction method is helpful to reduce network traffic and increase the network lifetime accordingly, especially by exploring data correlation among the sensory data. Data prediction can also be used to recover abnormal/lost data in case these sensor nodes fail to work. The current prediction methods in wireless sensor networks do not make full usage of the spatial-temporal correlation between wireless sensor nodes, and thus leads to higher prediction error relatively. This paper proposes a novel model for multi-step sensory data prediction in wireless sensor network. Firstly, we introduce the artificial neural networks based on 1-D CNN (One-Dimensional Convolutional Neural Network) and Bi-LSTM (Bidirectional Long and Short-Term Memory) to get the abstract features of different attributes via the pre-processed sensory data. Then, these abstract features are used to obtain one-step prediction. Finally, the multi-step prediction is introduced by using historical data and the prediction results of the previous step iteratively. Experiment results show that after selecting suitable node combinations in which the spatial-temporal correlation is highlighted, the proposed multi-step predictive model can predict multi-step (short and medium term) sensory data, and its performance is better compared with other related methods.","['Wireless sensor networks', 'Predictive models', 'Correlation', 'Feature extraction', 'Data mining', 'Temperature sensors', 'Energy consumption']","['Neural networks', 'predictive models', 'wireless sensor networks']"
"Along with the development of Information Technology, Online Social Networks (OSN) are constantly developing and have become popular media in the world. Besides communication enhancement benefits, OSN have such limitations on rapid spread of false information as rumors, fake news, and contradictory news. False information spread is collectively referred to as misinformation which has significant on social communities. The more sources and topics of misinformation are, the greater the number of users are affected. Therefore, it is necessary to prevent the spread of misinformation with multiple topics within a given period of time. In this paper, we propose a Multiple Topics Linear Threshold model for misinformation diffusion, and define a misinformation blocking problem based on this model that takes account of multiple topics and budget constraint. The problem is to find a set of nodes that minimizes the impact of misinformation at an allowed cost when blocking them from the network. We prove that the problem is NP-hard and the time complexity of the objective function calculation is \#P -hard. We also prove that the objective function is monotone and submodular. We propose an approximation algorithm with approximation ratio (1-1/\sqrt {e}) based on these attributes. For large networks, we propose an extended algorithm by using a tree data structure for quickly updating and calculating the objective function. Experiments conducted on real-world datasets show efficiency and effectiveness of our proposed algorithms in comparison with other state-of-the-art algorithms.","['Integrated circuit modeling', 'Approximation algorithms', 'Linear programming', 'Social network services', 'Information technology', 'Optimization']","['Information diffusion', 'misinformation blocking', 'optimization', 'social networks']"
"To detect multiple sclerosis (MS) diseases early, we proposed a novel method on the hardware of magnetic resonance imaging, and on the software of three successful methods: biorthogonal wavelet transform, kernel principal component analysis, and logistic regression. The materials were 676 MR slices containing plaques from 38 MS patients, and 880 MR slices from 34 healthy controls. The statistical analysis showed our method achieved a sensitivity of 97.12±.14%, a specificity of 98.25±0.16%, and an accuracy of 97.76±0.10%. Our method is superior to five state-of-the-art approaches in MS detection.","['Multiple sclerosis', 'Medical diagnosis', 'Wavelet analysis', 'Wavelet transforms', 'Principal component analysis', 'Logical regression', 'Biorthogonal wavelet transform']","['Biorthogonal wavelet transform', 'kernel principal component analysis', 'logistic regression', 'multiple sclerosis', 'computer vision', 'machine learning']"
"The solar PV based power generation systems are growing faster due to the depletion of fossil fuels and environmental concerns. Combining PV panels and energy buffers such as battery through multi-port converter is one of the viable solutions to deal with the intermittency of PV power. The goal of this paper is to design and analyze the proposed triple port DC-DC buck-boost converter for high step-up/step-down applications. It has two unidirectional ports (port-1 and port-3) and one bi-directional port (port-2) for harnessing photovoltaic energy and charging the battery. At port-1, the combined structure of buck and buck-boost converter is used with a particular arrangement of switches and inductors. The step-up/step-down voltage conversion ratio is higher than the conventional buck-boost converter, and the polarity of the output voltage is maintained positive. The battery is added at the bi-directional port, for the storage of energy through the bi-directional boost converter. The switches operate synchronously for most of the modes making the control strategy simple. The characteristics and modes of operation along with a switching strategy, are elaborated. Experimental results are presented which validate the agreement with the developed theoretical expectation.","['Batteries', 'Inductors', 'Capacitors', 'Bidirectional control', 'Voltage control', 'DC-DC power converters', 'Switches']","['Buck-Boost converter', 'DC-DC', 'non-isolated', 'bi-directional', 'triple port', 'photovoltaic']"
"The wide implementation of electronic health record (EHR) systems facilitates the collection of large-scale health data from real clinical settings. Despite the significant increase in adoption of EHR systems, these data remain largely unexplored, but present a rich data source for knowledge discovery from patient health histories in tasks, such as understanding disease correlations and predicting health outcomes. However, the heterogeneity, sparsity, noise, and bias in these data present many complex challenges. This complexity makes it difficult to translate potentially relevant information into machine learning algorithms. In this paper, we propose a computational framework, Patient2Vec, to learn an interpretable deep representation of longitudinal EHR data, which is personalized for each patient. To evaluate this approach, we apply it to the prediction of future hospitalizations using real EHR data and compare its predictive performance with baseline methods. Patient2Vec produces a vector space with meaningful structure, and it achieves an area under curve around 0.799, outperforming baseline methods. In the end, the learned feature importance can be visualized and interpreted at both the individual and population levels to bring clinical insights.","['Logic gates', 'Medical services', 'Task analysis', 'Recurrent neural networks', 'Electronic medical records', 'Machine learning', 'Natural language processing']","['Attention mechanism', 'gated recurrent unit', 'hospitalization', 'longitudinal electronic health record', 'personalization', 'representation learning']"
"The advancement and popularity of smartphones have made it an essential and all-purpose device. But lack of advancement in battery technology has held back its optimum potential. Therefore, considering its scarcity, optimal use and efficient management of energy are crucial in a smartphone. For that, a fair understanding of a smartphone’s energy consumption factors is necessary for both users and device manufacturers, along with other stakeholders in the smartphone ecosystem. It is important to assess how much of the device’s energy is consumed by which components and under what circumstances. This paper provides a generalized, but detailed analysis of the power consumption causes (internal and external) of a smartphone and also offers suggestive measures to minimize the consumption for each factor. The main contribution of this paper is four comprehensive literature reviews on: 1) smartphone’s power consumption assessment and estimation (including power consumption analysis and modelling); 2) power consumption management for smartphones (including energy-saving methods and techniques); 3) state-of-the-art of the research and commercial developments of smartphone batteries (including alternative power sources); and 4) mitigating the hazardous issues of smartphones’ batteries (with a details explanation of the issues). The research works are further subcategorized based on different research and solution approaches. A good number of recent empirical research works are considered for this comprehensive review, and each of them is succinctly analysed and discussed.","['Batteries', 'Power demand', 'Estimation', 'Power measurement', 'Mobile handsets', 'Hardware', 'Energy consumption']","['Battery availability prediction', 'battery capacity', 'battery charging', 'energy profiling', 'energy-saving techniques', 'hazards', 'issues', 'Lithium-ion batteries', 'power consumption estimation', 'power consumption modelling', 'power management']"
"One of the essential tasks for the planning and development of talents training programs in different colleges of universities is to find how we can reasonably guide students to pursue a master's degree concerning their comprehensive situations. The purpose of this study is to develop a modified fuzzy k-Nearest Neighbor (FKNN) framework to predict the college students' intentions for master programs in advance, that is, students choose to attend the postgraduate exam or find a job after graduation. The proposed integrated framework combines the random forest (RF), FKNN, and a new chaos-enhanced sine cosine-inspired algorithm (CESCA). In this model, RF is employed to evaluate the importance of features in the dataset, while the FKNN is utilized to establish the relationship framework between the features and the college students' decisions to earn a master's degree or not. The proposed CESCA is utilized to tune the key parameters of the FKNN automatically. All eight variants of SCA have been rigorously compared based on 13 benchmark problems to validate the effectiveness of the proposed CESCA. Then, the CESCA-based FKNN (CESCA-FKNN) has been further compared against the other three classical classifiers in terms of four common performance metrics. The experimental results indicate that the proposed CESCA-FKNN can obtain the best classification accuracy. The results indicate that the established adaptive FKNN framework can be served as a powerful tool for college students' intention before pursuing a master's degree.","['Predictive models', 'Benchmark testing', 'Employment', 'Radio frequency', 'Classification algorithms', 'Education', 'Data models']","['Fuzzy k-nearest neighbor method', 'sine cosine algorithm', 'chaos theory', 'students’ intentions for master programs', 'feature selection']"
"e-Healthcare promises to be the next big wave in healthcare. It offers all the advantages and benefits imaginable by both the patient and the user. However, current e-Healthcare systems are not yet fully developed and mature, and thus lack the degree of confidentiality, integrity, privacy, and user trust necessary to be widely implemented. Two primary aspects of any operational healthcare enterprise are the quality of healthcare services and patient trust over the healthcare enterprise. Trust is intertwined with issues like confidentiality, integrity, accountability, authenticity, identity, and data management, to name a few. Privacy remains one of the biggest obstacles to ensuring the success of e-Healthcare solutions in winning patient trust as it indirectly covers most security concerns. Addressing privacy concerns requires addressing security issues like access control, authentication, non-repudiation, and accountability, without which end-to-end privacy cannot be ensured. Achieving privacy from the point of data collection in wireless sensor networks, to incorporating the Internet of Things, to communication links, and to data storage and access, is a huge undertaking and requires extensive work. Privacy requirements are further compounded by the fact that the data handled in an enterprise are of an extremely personal and private nature, and its mismanagement, either intentionally or unintentionally, could seriously hurt both the patient and future prospects of an e-Healthcare enterprise. Research carried out in order to address privacy concerns is not homogenous in nature. It focuses on the failure of certain parts of the e-Healthcare enterprise to fully address all aspects of privacy. In the middle of this ongoing research and implementation, a gradual shift has occurred, moving e-Healthcare enterprise controls away from an organizational level toward the level of patients. This is intended to give patients more control and authority over decision making regarding their protected health information/electronic health record. A lot of works and efforts are necessary in order to better assess the feasibility of this major shift in e-Healthcare enterprises. Existing research can be naturally divided on the basis of techniques used. These include data anonymization/pseudonymization and access control mechanisms primarily for stored data privacy. This, however, results in giving a back seat to certain privacy requirements (accountability, integrity, non-repudiation, and identity management). This paper reviews research carried out in this regard and explores whether this research offers any possible solutions to either patient privacy requirements for e-Healthcare or possibilities for addressing the (technical as well as psychological) privacy concerns of the users.","['Privacy', 'Medical services', 'Electronic mail', 'Wireless sensor networks', 'Access control', 'Data privacy']","['e-Healthcare', 'privacy', 'anonymity', 'access control']"
"Based on the mutual coupling effect among the compressor, the air cooler and pipes in the system of natural gas pipeline, innovatively with the goal of minimum energy consumption, this paper established a combined operation optimization model of the air cooler and compressor through the optimization of the switching scheme of compressors and air coolers, which can greatly reduce the production energy consumption of the pipeline system. Moreover, when the air temperature is taken as an optimization variable, the most proper temperature to start the air cooler of each compressor station can be worked out to guide the optimized operation of the pipeline, which is of high value for promotion and application. The case analysis of west-east natural gas pipeline II showed that among genetic algorithm (GA), particle swarm optimization (PSO), and simulated annealing (SA) algorithm that are used to solve the optimization model, the genetic algorithm is the fastest, and the simulated annealing algorithm the slowest, but the optimization results of the simulated annealing algorithm is the best, in which the reduced production energy consumption accounted for 33.77%, testifying the practicability and creativity of the optimization model.","['Compressors', 'Pipelines', 'Optimization', 'Natural gas', 'Energy consumption', 'Atmospheric modeling', 'Mathematical model']","['Natural gas pipeline', 'air cooler', 'compressor', 'operation optimization', 'algorithm']"
"Internet of medical things (IoMT) is getting researchers' attention due to its wide applicability in healthcare. Smart healthcare sensors and IoT enabled medical devices exchange data and collaborate with other smart devices without human interaction to securely transmit collected sensitive healthcare data towards the server nodes. Alongside data communications, security and privacy is also quite challenging to securely aggregate and transmit healthcare data towards Fog and cloud servers. We explored the existing surveys to identify a gap in literature that a survey of fog-assisted secure healthcare data collection schemes is yet contributed in literature. This paper presents a survey of different data collection and secure transmission schemes where Fog computing based architectures are considered. A taxonomy is presented to categorize the schemes. Fog assisted smart city, smart vehicle and smart grids are also considered that achieve secure, efficient and reliable data collection with low computational cost and compression ratio. We present a summary of these scheme along with analytical discussion. Finally, a number of open research challenges are identified. Moreover, the schemes are explored to identify the challenges that are addressed in each scheme.","['Medical services', 'Data aggregation', 'Servers', 'Cloud computing', 'Edge computing', 'Computer architecture', 'Data privacy']","['IoT', 'healthcare', 'smart medical devices', 'fog computing', 'data aggregation', 'security', 'compression']"
"Distributed denial of service (DDoS) attack is an attempt to make an online service unavailable by overwhelming it with traffic from multiple sources. Therefore, it is necessary to propose an effective method to detect DDoS attack from massive data traffics. However, the existing schemes have some limitations, including that supervised learning methods, need large numbers of labeled data and unsupervised learning algorithms have relatively low detection rate and high false positive rate. In order to tackle these issues, this paper presents a semi-supervised weighted k-means detection method. Specifically, we firstly present a Hadoop-based hybrid feature selection algorithm to find the most effective feature sets and propose an improved density-based initial cluster centers selection algorithm to solve the problem of outliers and local optimal. Then, we provide the Semi-supervised K-means algorithm using hybrid feature selection (SKM-HFS) to detect attacks. Finally, we exploit DARPA DDoS dataset, CAIDA “DDoS attack 2007” dataset, CICIDS “DDoS attack 2017” dataset and real-world dataset to carry out the verification experiment. The experiment results have demonstrated that the proposed method outperforms the benchmark in the respect of detection performance and technique for order preference by similarity to an ideal solution (TOPSIS) evaluation factor.","['Feature extraction', 'Computer crime', 'Entropy', 'Clustering algorithms', 'Unsupervised learning', 'Supervised learning', 'Machine learning']","['DDoS attack', 'semi-supervised k-means', 'Hadoop-based hybrid feature selection', 'ratio of average sum of squared errors (SSE) to cluster distance (RSD)', 'TOPSIS']"
"In traffic accident, an accurate and timely severity prediction method is necessary for the successful deployment of an intelligent transportation system to provide corresponding levels of medical aid and transportation in a timely manner. The existing traffic accident’s severity prediction methods mainly use shallow severity prediction models and statistical models. To promote the prediction accuracy, a novel traffic accident’s severity prediction-convolutional neural network (TASP-CNN) model for traffic accident’s severity prediction is proposed that considers combination relationships among traffic accident’s features. Based on the weights of traffic accident’s features, the feature matrix to gray image (FM2GI) algorithm is proposed to convert a single feature relationship of traffic accident’s data into gray images containing combination relationships in parallel as the input variables for the model. Moreover, experiments demonstrated that the proposed model for traffic accident’s severity prediction has a better performance.","['Accidents', 'Predictive models', 'Data models', 'Injuries', 'Analytical models', 'Artificial neural networks', 'Prediction algorithms']","['Traffic accident', 'severity prediction', 'convolutional neural network', 'gray image']"
"An ultra wide band (UWB)-based time-delay indoor human localization scheme is proposed to provide indoor human localization with time-delay measurements. The human position is localized using the UWB-based distance data and the extended finite impulse response (EFIR) estimator employing the timedelay localization model. Only one-step delayed measurements are considered in this paper. We employ the state augmentation method to combine the delayed and not delayed states. To improve the localization robustness for the time-delay localization model, we employ the EFIR filter, which does not require the noise statistics. The experimental results have shown that the EFIR estimator is more robust than the extended Kalman filter-based one for the delayed data.","['Delays', 'Robustness', 'Mathematical model', 'Data models', 'Algorithm design and analysis', 'Indoor environments', 'Kalman filters']","['Indoor localization', 'ultra wide band', 'extended FIR filter', 'extended Kalman filter', 'time-delay model']"
"With the development of the artificial intelligence (AI), the AI applications have influenced and changed people's daily life greatly. Here, a wearable affective robot that integrates the affective robot, social robot, brain wearable, and Wearable 2.0 is proposed for the first time. The proposed wearable affective robot is intended for a wide population, and we believe that it can improve the human health on the spirit level, meeting the fashion requirements at the same time. In this paper, the architecture and design of an innovative wearable affective robot, which is dubbed as Fitbot, are introduced in terms of hardware and algorithm's perspectives. In addition, the important functional component of the robot-brain wearable device is introduced from the aspect of the hardware design, EEG data acquisition and analysis, user behavior perception, and algorithm deployment. Then, the EEG-based cognition of user's behavior is realized. Through the continuous acquisition of the in-depth, in-breadth data, the Fitbot we present can gradually enrich user's life modeling and enable the wearable robot to recognize user's intention and further understand the behavioral motivation behind the user's emotion. The learning algorithm for the life modeling embedded in Fitbot can achieve better user's experience of affective social interaction. Finally, the application service scenarios and some challenging issues of a wearable affective robot are discussed.","['Artificial intelligence', 'Service robots', 'Cognition', 'Personal digital assistants', 'Hardware']","['Emotion cognition', 'social robot', 'RNN', 'EEG', 'Wearable 20']"
"With the widespread use of deep learning system in many applications, the adversary has strong incentive to explore vulnerabilities of deep neural networks and manipulate them. Backdoor attacks against deep neural networks have been reported to be a new type of threat. In this attack, the adversary will inject backdoors into the model and then cause the misbehavior of the model through inputs including backdoor triggers. Existed research mainly focuses on backdoor attacks in image classification based on CNN, little attention has been paid to the backdoor attacks in RNN. In this paper, we implement a backdoor attack against LSTM-based text classification by data poisoning. After the backdoor is injected, the model will misclassify any text samples that contains a specific trigger sentence into the target category determined by the adversary. The backdoor attack is stealthy and the backdoor injected in the model has little impact on the performance of the model. We consider the backdoor attack in black-box setting, where the adversary has no knowledge of model structures or training algorithms except for a small amount of training data. We verify the attack through sentiment analysis experiment on the dataset of IMDB movie reviews. The experimental results indicate that our attack can achieve around 96% success rate with 1% poisoning rate.","['Training', 'Text categorization', 'Neural networks', 'Logic gates', 'Data models', 'Deep learning', 'Sentiment analysis']","['Backdoor attacks', 'LSTM', 'poisoning data', 'text classification']"
"The identification of grape leaf diseases based on deep learning is critical to controlling the spread of diseases and ensuring the healthy development of the grape industry. Focusing on the lack of training images of grape leaf diseases, this paper proposes a novel model named Leaf GAN, which is based on generative adversarial networks (GANs), to generate images of four different grape leaf diseases for training identification models. A generator model with degressive channels is first designed to generate grape leaf disease images; then, the dense connectivity strategy and instance normalization are fused into an efficient discriminator to identify real and fake disease images by utilizing their excellent feature extraction capability on grape leaf lesions. Finally, the deep regret gradient penalty method is applied to stabilize the training process of the model. Using a total of 4,062 grape leaf disease images, the Leaf GAN model ultimately generates 8,124 grape leaf disease images. The generated grape leaf disease images based on Leaf GAN model can obtain better performance than DCGAN and WGAN in terms of the Fréchet inception distance. The experimental results show that the proposed Leaf GAN model generates sufficient grape leaf disease images with prominent lesions, providing a feasible solution for the data augmentation of grape leaf disease images. For the eight prevailing classification models with the expanded dataset, the identification performance based on CNNs indicated higher accuracies, whereby all the accuracies were better than those of the initial dataset with other data augmentation methods. Among them, Xception achieves a recognition accuracy of 98.70% on the testing set. The results demonstrate that the proposed data augmentation method represents a new approach to overcoming the overfitting problem in disease identification and can effectively improve the identification accuracy.","['Diseases', 'Pipelines', 'Generators', 'Gallium nitride', 'Training', 'Feature extraction', 'Generative adversarial networks']","['Generative adversarial networks', 'convolutional neural networks', 'data augmentation', 'grape leaf disease identification']"
"Feature selection is an important research area for big data analysis. In recent years, various feature selection approaches have been developed, which can be divided into four categories: filter, wrapper, embedded, and combined methods. In the combined category, many hybrid genetic approaches from evolutionary computations combine filter and wrapper measures of feature evaluation to implement a population-based global optimization with efficient local search. However, there are limitations to existing combined methods, such as the two-stage and inconsistent feature evaluation measures, difficulties in analyzing data with high feature interaction, and challenges in handling large-scale features and instances. Focusing on these three limitations, we proposed a hybrid genetic algorithm with wrapper-embedded feature approach for selection approach (HGAWE), which combines genetic algorithm (global search) with embedded regularization approaches (local search) together. We also proposed a novel chromosome representation (intron+exon) for global and local optimization procedures in HGAWE. Based on this “intron+exon” encoding, the regularization method can select the relevant features and construct the learning model simultaneously, and genetic operations aim to globally optimize the control parameters in the above non-convex regularization. We mention that any efficient regularization approach can serve as the embedded method in HGAWE, and a hybrid L 1/2 + L 2 regularization approach is investigated as an example in this paper. Empirical study of the HGAWE approach on some simulation data and five gene microarray data sets indicates that it outperforms the existing combined methods in terms of feature selection and classification accuracy.","['Feature extraction', 'Genetic algorithms', 'Optimization', 'Genetics', 'Focusing', 'Data models', 'Correlation']","['Feature selection', 'wrapper−embedded method', 'memetic framework', 'genetic algorithm', 'L½ + L₂ regularization']"
"Recently, diagnosing diseases using medical images became crucial. As these images are transmitted through the network, they need a high level of protection. If the data in these images are liable for unauthorized usage, this may lead to severe problems. There are different methods for securing images. One of the most efficient techniques for securing medical images is encryption. Confusion and diffusion are the two main steps used in encryption algorithms. This paper presents a new encryption algorithm for encrypting both grey and color medical images. A new image splitting technique based on image blocks introduced. Then, the image blocks scrambled using a zigzag pattern, rotation, and random permutation. Then, a chaotic logistic map generates a key to diffuse the scrambled image. The efficiency of our proposed method in encrypting medical images is evaluated using security analysis and time complexity. The security is tested in entropy, histogram differential attacks, correlation coefficient, PSNR, keyspace, and sensitivity. The achieved results show a high-performance security level reached by successful encryption of both grey and color medical images. A comparison with various encryption methods is performed. The proposed encryption algorithm outperformed the recent existing encryption methods in encrypting medical images.","['Biomedical imaging', 'Encryption', 'Medical diagnostic imaging', 'Logistics', 'Entropy', 'Security', 'Correlation']","['Image encryption', 'chaotic logistic map', 'color medical images', 'image blocks scrambling']"
"With the wide applications of wireless sensor networks (WSNs) in various fields, such as environment monitoring, battlefield surveillance, healthcare, and intrusion detection, trust establishment among sensor nodes becomes a vital requirement to improve security, reliability, and successful cooperation. The existing trust management approaches for large-scale WSN are failed due to their low dependability (i.e., cooperation), higher communication, and memory overheads (i.e., resource inefficient). In this paper, we propose a novel and comprehensive trust estimation approach (LTS) for large-scale WSN that employs clustering to improve cooperation, trustworthiness, and security by detecting malicious (faulty or selfish) sensor nodes with reduced resource (memory and power) consumption. The proposed scheme (LTS) operates on two levels, namely, intra-cluster and inter-cluster along with distributed approach and centralized approach, respectively, to make accurate trust decision of sensor nodes with minimum overheads. LTS consists of unique features, such as robust trust estimation function, attack resistant, and efficient trust aggregation at the cluster, head to obtain the global feedback trust value. Data trust along with communication trust plays a significant role to cope with malicious nodes. In LTS, punishment and trust severity can be tuned according to the application requirement, which makes it an innovative LTS. Moreover, dishonest recommendations (outliers) are eliminated before aggregation at the base station by observing the statistical dispersion. The theoretical and mathematical validations along with simulation results exhibit the great performance of our proposed approach in terms of trust evaluation cost, prevention, and detection of malicious nodes as well as communication overhead.","['Wireless sensor networks', 'Security', 'Reliability', 'Estimation', 'Computational modeling', 'Peer-to-peer computing', 'Base stations']","['Trust management', 'data trust', 'communication trust', 'attack mitigation']"
"This paper presents a reliable digital watermarking technique that provides high imperceptibility and robustness for copyright protection using an optimal discrete cosine transform (DCT) psychovisual threshold. An embedding process in this watermarking technique utilizes certain frequency regions of DCT, such that insertion of watermark bits causes the least image distortion. Thus, the optimal psychovisual threshold is determined to embed the watermark in the host image for the best image quality. During the insertion of watermark bits into the certain frequencies of the image, watermark bits are not directly inserted into the frequency coefficient; rather, the certain coefficients are modified based on some rules to construct the watermarked image. The embedding frequencies are determined by using modified entropy finding large redundant areas. Furthermore, the watermark is scrambled before embedding to provide an additional security. In order to verify the proposed technique, our technique is tested under several signal processing and geometric attacks. The experimental results show that our technique achieves higher invisibility and robustness than the existing schemes. The watermark extraction produces high image quality after different types of attacks.","['Watermarking', 'Robustness', 'Entropy', 'Discrete cosine transforms', 'Distortion', 'Transform coding', 'Image coding']","['Image watermarking', 'modified entropy', 'embedding scheme', 'extraction scheme', 'psychovisual threshold']"
"As the sensor layer of Internet of Things (IOT), enormous amount of sensor nodes are densely deployed in a hostile environment to monitor and sense the changes in the physical space. Since sensor nodes are driven with limited power batteries, it is very difficult and expensive for wireless sensor networks (WSNs) to extend network lifetime. In order to achieve reliable data transmission in WSNs, energy efficient routing protocol is a crucial issue in extending the network lifetime of a network. However, traditional routing protocols usually propagate throughout the whole network to discover a reliable route or employ some cluster heads to undertake data transmission for other nodes, which both require large amount energy consumption. In this paper, to maximize the network lifetime of the WSN, we propose a novel energy efficient region source routing protocol (referred to ER-SR). In ER-SR, a distributed energy region algorithm is proposed to select the nodes with high residual energy in the network as source routing node dynamically. Then, the source routing nodes calculate the optimal source routing path for each common node, which enables partial nodes to participate in the routing process and balances the energy consumption of sensor nodes. Furthermore, to minimize the energy consumption of data transmission, we propose an effective distance-based ant colony optimization algorithm to search the global optimal transmission path for each node. Simulation results demonstrate that ER-SR exhibits higher energy efficiency, and has moderate performance improvements on network lifetime, packet delivery ratio, and delivery delay, compared with other routing protocols in WSNs.","['Routing protocols', 'Wireless sensor networks', 'Routing', 'Energy consumption', 'Data communication', 'Delays']","['Wireless sensor network', 'source routing', 'ER-SR', 'energy efficient', 'network lifetime']"
"Deep Learning (DL) is vulnerable to out-of-distribution and adversarial examples resulting in incorrect outputs. To make DL more robust, several posthoc (or runtime) anomaly detection techniques to detect (and discard) these anomalous samples have been proposed in the recent past. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection for DL based applications. We provide a taxonomy for existing techniques based on their underlying assumptions and adopted approaches. We discuss various techniques in each of the categories and provide the relative strengths and weaknesses of the approaches. Our goal in this survey is to provide an easier yet better understanding of the techniques belonging to different categories in which research has been done on this topic. Finally, we highlight the unsolved research challenges while applying anomaly detection techniques in DL systems and present some high-impact future research directions.","['Anomaly detection', 'Machine learning', 'Training data', 'Data models', 'Training', 'Neural networks']","['Anomaly detection', 'out-of-distribution', 'adversarial examples', 'deep learning', 'neural network']"
"Feature selection has gained much consideration from scholars working in the domain of machine learning and data mining in recent years. Feature selection is a popular problem in Machine learning with the goal of finding optimal features with increase accuracy. As a result, several studies have been conducted on multi-objective feature selection through numerous multi-objective techniques and algorithms. The objective of this paper is to present a systematic literature review of the challenges and issues of the multi-objective feature selection problem and critically analyses the proposed techniques used to tackle this problem. The conducted review covered all related studies published since 2012 up to 2019. The outcomes of the reviewed of these studies clearly showed that no perfect solution to the multi-objective feature selection problem yet. The authors believed that the conducted review would serve as the main source of the techniques and methods used to resolve the problem of multi-objective feature selection. Furthermore, current challenges and issues are deliberated to find promising research domains for further study.","['Feature extraction', 'Systematics', 'Optimization', 'Bibliographies', 'Machine learning', 'Data models', 'Databases']","['Feature selection', 'multi-objective optimization', 'classification', 'systematic literature review', 'optimization', 'benchmark', 'heuristic']"
"The world is facing problems, such as uneven distribution of medical resources, the growing chronic diseases, and the increasing medical expenses. Blending the latest information technology into the healthcare system will greatly mitigate the problems. This paper presents the big health application system based on the health Internet of Things and big data. The system architecture, key technologies, and typical applications of big health system are introduced in detail.","['Medical services', 'Internet of things', 'Big data', 'Wearable computing', 'Cloud computing', 'Diseases', 'System architecture', 'Computer applications']","['Big health', 'wearable computing', 'cloud computing', 'Internet of Things', 'big data']"
"An automated warehouse system contains a number of materials, workstations, and multiple Automated Guided Vehicles (AGVs). The automated warehouse is server-controlled. This paper proposes a collision-free routing method for AGVs based on collision classification. This method can deal with collisions arising in the automated warehouse. It first divides the warehouse environment into five areas, and then performs route planning. In this paper, the environment map for AGVs is described by using the grid method. The initial route of each task is predetermined by improved Dijkstra’s algorithm. The server detects the potential collisions by comparing each workstation’s ID and corresponding time window in every route. This paper presents four collision classifications and three solutions. Based upon the analyses and experiments, we select the corresponding solution for each type of collision. Presented case studies demonstrate the efficiency of the proposed collision-free route planning approach.","['Planning', 'Workstations', 'Task analysis', 'Routing', 'Aerospace electronics', 'Servers', 'Space charge']","['Multiple AGVs', 'route planning', 'time window', 'the status of AGV', 'collision classification']"
"Gallium Nitride High Electron Mobility Transistors (GaN HEMTs) enable higher efficiency, higher power density, and smaller passive components resulting in lighter, smaller and more efficient electrical systems as opposed to conventional Silicon (Si) based devices. This paper investigates the detailed benefits of using GaN devices in transportation electrification applications. The material properties of GaN including the applications of GaN HEMTs at different switch ratings are presented. The challenges currently facing the transportation industry are introduced and possible solutions are presented. A detailed review of the use of GaN in the Electric Vehicle (EV) powertrain is discussed. The implementation of GaN devices in aircraft, ships, rail vehicles and heavy-duty vehicles is briefly covered. Future trends of GaN devices in terms of cost, voltage level, gate driver design, thermal management and packaging are investigated.","['Gallium nitride', 'Silicon', 'HEMTs', 'MODFETs', 'Switches', 'Silicon carbide', 'MOSFET']","['Electric vehicle', 'gallium nitride', 'high electron mobility transistor', 'hybrid electric vehicle', 'wide bandgap devices']"
"This paper presents a comprehensive review of the principle and application of deep learning in retinal image analysis. Many eye diseases often lead to blindness in the absence of proper clinical diagnosis and medical treatment. For example, diabetic retinopathy (DR) is one such disease in which the retinal blood vessels of human eyes are damaged. The ophthalmologists diagnose DR based on their professional knowledge, that is labor intensive. With the advances in image processing and artificial intelligence, computer vision-based techniques have been applied rapidly and widely in the field of medical images analysis and are becoming a better way to advance ophthalmology in practice. Such approaches utilize accurate visual analysis to identify the abnormality of blood vessels with improved performance over manual procedures. More recently, machine learning, in particular, deep learning, has been successfully implemented in this area. In this paper, we focus on recent advances in deep learning methods for retinal image analysis. We review the related publications since 1982, which include more than 80 papers for retinal vessels detections in the research scope spanning from segmentation to classification. Although deep learning has been successfully implemented in other areas, we found only 17 papers so far focus on retinal blood vessel segmentation. This paper characterizes each deep learning based segmentation method as described in the literature. Analyzing along with the limitations and advantages of each method. In the end, we offer some recommendations for future improvement for retinal image analysis.","['Deep learning', 'Retina', 'Biomedical imaging', 'Image analysis', 'Biological neural networks', 'Image segmentation', 'Blood vessels']","['Retinal colour fundus images', 'convolutional neural networks', 'retinal vessels segmentation']"
"Dynamic channel allocation (DCA) is the key technology to efficiently utilize the spectrum resources and decrease the co-channel interference for multibeam satellite systems. Most works allocate the channel on the basis of the beam traffic load or the user terminal distribution of the current moment. These greedy-like algorithms neglect the intrinsic temporal correlation among the sequential channel allocation decisions, resulting in the spectrum resources underutilization. To solve this problem, a novel deep reinforcement learning (DRL)-based DCA (DRL-DCA) algorithm is proposed. Specifically, the DCA optimization problem, which aims at minimizing the service blocking probability, is formulated in the multibeam satellite systems. Due to the temporal correlation property, the DCA optimization problem is modeled as the Markov decision process (MDP) which is the dominant analytical approach in DRL. In modeled MDP, the system state is reformulated into an image-like fashion, and then, convolutional neural network is used to extract useful features. Simulation results show that the DRL-DCA algorithm can decrease the blocking probability and improve the carried traffic and spectrum efficiency compared with other channel allocation algorithms.","['Satellites', 'Optimization', 'Channel allocation', 'Heuristic algorithms', 'Dynamic scheduling', 'Feature extraction', 'Interference']","['Dynamic channel allocation (DCA)', 'multibeam satellite systems', 'Markov decision process (MDP)', 'deep reinforcement learning (DRL)', 'blocking probability']"
"With the proliferation of technology, the field of e-learning has garnered significant attention in recent times. This is because it has allowed users from around the world to learn and access new information. This has added to the growing amount of collected data that is already being generated through different devices and sensors employed around the world. This has led to the need to analyze collected data and extract useful information from it. Machine learning (ML) and data analytics (DA) are proposed techniques that can help extract information and find valuable patterns within the collected data. In this paper, the field of e-learning is investigated in terms of definitions and characteristics. Moreover, the various challenges facing the different participants within this process are discussed. In addition, some of the works proposed in the literature to tackle these challenges are presented. Then, a brief survey about some of the most popular ML and DA techniques is given. Finally, some of the research opportunities available that employ such techniques are proposed to give insights into the areas that merit further exploration and investigation.","['Electronic learning', 'Machine learning', 'Data analysis', 'Computers', 'Computer aided instruction', 'Internet']","['E-learning', 'machine learning', 'data analytics']"
"With the booming development of medical informatization and the ubiquitous connections in the fifth generation mobile communication technology (5G) era, the heterogeneity and explosive growth of medical data have brought huge challenges to data access, security and privacy, as well as information processing in Internet of Medical Things (IoMT). This article provides a comprehensive review of how to realize the timely processing and analysis of medical big data and the sinking of high-quality medical resources under the constraints of the existing medical environment and medical-related equipment. We mainly focus on the advantages brought by the cloud computing, edge computing and artificial intelligence technologies to the IoMT. We also explore how to rationalize the use of medical resources and the security and privacy of medical data, so that high-quality medical services can be provided to patients. Finally, we discuss the current challenges and possible future research directions in the edge-cloud computing and artificial intelligence related IoMT.","['Cloud computing', 'Computer architecture', 'Medical diagnostic imaging', 'Edge computing', 'Medical services', 'Radiofrequency identification']","['Internet of medical things (IoMT)', 'deep learning', 'edge of computing', 'computation offloading']"
"Sensor nodes spend the most of their limited energy on communicating with environmental information gathered in receivers. Hence, it is important to determine the optimal monitoring sensor nodes and information flow paths to the destination and sink in order to survive the sensor networks. Additionally, the heavy traffic load for transferring packets in nodes closer to the sink increases energy consumption and reduces battery life. It is desirable to reduce the energy between nodes and sink. The main goal is to extend the network lifetime through extending the lifetime of operating sensors as well transferring gathered data from super node to the sink. In this paper, Bat Algorithm (BA) is used to select the optimum monitoring sensor node and resulted path to reduce energy consumption. Simulation results and comparison with other algorithms show the superiority of the proposed algorithm. The simulation results of the proposed algorithm show that the proposed algorithm has been able to reduce the power consumption of the network and increase the lifetime of the network. Also, the proposed algorithm is able to outperform the comparable algorithms on average by 27%.","['Energy consumption', 'Wireless sensor networks', 'Monitoring', 'Power demand', 'Batteries', 'Simulation']","['Wireless sensor networks', 'energy', 'lifetime', 'Bat algorithm']"
"Energy efficiency is one of the main challenges in developing Wireless Sensor Networks (WSNs). Since communication has the largest share in energy consumption, efficient routing is an effective solution to this problem. Hierarchical clustering algorithms are a common approach to routing. This technique splits nodes into groups in order to avoid long-range communication which is delegated to the cluster head (CH). In this paper, we present a new clustering algorithm that selects CHs using the grey wolf optimizer (GWO). GWO is a recent swarm intelligence algorithm based on the behavior of grey wolves that shows impressive characteristics and competitive results. To select CHs, the solutions are rated based on the predicted energy consumption and current residual energy of each node. In order to improve energy efficiency, the proposed protocol uses the same clustering in multiple consecutive rounds. This allows the protocol to save the energy that would be required to reform the clustering. We also present a new dual-hop routing algorithm for CHs that are far from the base station and prove that the presented method ensures minimum and most balanced energy consumption while remaining nodes use single-hop communication. The performance of the protocol is evaluated in several different scenarios and it is shown that the proposed protocol improves network lifetime in comparison to a number of recent similar protocols.","['Protocols', 'Clustering algorithms', 'Energy consumption', 'Wireless sensor networks', 'Routing', 'Relays', 'Energy efficiency']","['Clustering', 'grey wolf optimizer', 'routing', 'WSN']"
"The explosive growth of mobile date traffic and ubiquitous mobile services cause an high energy consumption in mobile devices with limited energy supplies, which has become a bottleneck for deploying device-to-device (D2D) communication. Simultaneous wireless information and power transfer (SWIPT), which enables mobile devices to harvest energy from the radio frequency signals, has emerged as a promising solution to improve the energy efficiency (EE) performance. In this paper, we address joint power control and spectrum resource allocation problem in SWIPT-based energy-harvesting D2D underlay networks. First, we formulate joint optimization problem as a 2-D matching between D2D pairs and cellular user equipments (CUEs), and propose a preference establishment algorithm based on Dinkelbach method and Lagrange dual decomposition. Second, we propose an energy-efficient stable matching algorithm by exploring the Gale-Shapley algorithm, which is able to maximize the EE performance of D2D pairs and the amount of energy harvested by CUEs simultaneously. Third, we provide in-depth theoretical analysis of the proposed matching algorithm in terms of stability, optimality, and complexity. Simulation results demonstrate that the proposed algorithm can bring significant EE performance gains compared with some heuristic algorithms.","['Device-to-device communication', 'Resource management', 'Power control', 'Algorithm design and analysis', 'Mobile communication', 'Mobile handsets', 'Performance evaluation']","['Device-to-device communication', 'energy harvesting', 'SWIPT', 'resource allocation', 'matching theory']"
"Due to the advantages of high energy density, no memory effect, and long cycle life, Li-ion batteries are being widely studied and proverbially used as power sources for electric vehicles. The performance of Li-ion battery systems is largely dependent on the thermal conditions and the temperature gradient uniformity inside. In order to tackle with the inconsistency problems of temperature distribution among battery cells in a battery pack, a thermal model for a cylindrical battery based on the finite-element method was developed. Physical structure and electrochemical reactions were both considered, and the initial conditions, boundary conditions, and thermal characteristic parameters of the battery components were determined through theoretical calculation and experiments. The discharge thermal characteristics were further investigated. In addition, the experiments were conducted to verify the accuracy of the presented model. Comparing the theoretical analysis with experimental results, it shows that the relative errors between the simulation and the tests are small at varied ambient temperatures and discharge rates. Therefore, the model can be efficiently applied to predicting the thermal behaviors of Li-ion batteries in practical applications.","['Heating systems', 'Heat transfer', 'Mathematical model', 'Finite element analysis', 'Computational modeling']","['Li-ion battery', 'finite element method', 'thermal model', 'temperature distribution']"
"An automatic retinal vessel segmentation method is proposed for quick and accurate segmentation of eye vessels. Such a method would play a vital role in analyzing many eye diseases. A retinal fundus image contains varying low contrasts, which undermine the performance of the segmentation process. Independent component analysis (ICA) is largely used for noise removal and consists of two architectures, designated as ICA1 and ICA2. We have validated both ICA architectures on retinal color fundus images and selected the one that provides improved contrast values. For retinal fundus, ICA2 architecture performed better than ICA1 by virtue of being more effective in compensating the low contrast values. Experiments conducted here validated the improvements over previously reported state-of-the-art methods. The impact of proposed segmentation model was assessed on publicly available databases like DRIVE and STARE. In case of the DRIVE database, the sensitivity increased 3% by (from 72% to 75%) while maintaining a segmentation accuracy of around 96%.","['Retina', 'Image segmentation', 'Biomedical imaging', 'Blood vessels', 'Image color analysis', 'Diseases', 'Independent component analysis']","['Retinal', 'segmentation', 'morphological filtering', 'ICA vessel enhancement']"
"Objective of multiple object tracking (MOT) is to assign a unique track identity for all the objects of interest in a video, across the whole sequence. Tracking-by-detection is the most common approach used in addressing MOT problem. In this work, we propose a method to address MOT by defining a dissimilarity measure based on object motion, appearance, structure, and size. We calculate the appearance and structure-based dissimilarity measure by matching histograms following a grid architecture. Motion and size for each track are predicted using the information from track's history. These dissimilarity values are then used in the Hungarian algorithm, in the data association step for track identity assignment. In addition, we introduce a method to address any false detection in stable tracks. The proposed method runs in real time following an online approach. We evaluate our method in both MOT17 benchmark data-set for pedestrian tracking and KITTI benchmark data-set for vehicle tracking using the same system parameters to verify the robustness of the proposed method. The method can achieve state-of-the-art results in both benchmarks.","['Histograms', 'Real-time systems', 'Object tracking', 'Target tracking', 'Detectors', 'Benchmark testing']","['Multiple object tracking', 'grid-based histograms', 'tracking by detection', 'online tracking', 'multiple car tracking', 'multiple human tracking']"
"Large-scale wireless sensor network (LSWSN) is composed of a huge number of sensor nodes that are distributed in some region of interest (ROI), to sense and measure the environmental conditions like pressure, temperature, pollution levels, humidity, wind, and so on. The objective is to collect data for real-time monitoring so that appropriate actions can be taken promptly. One of the sensor nodes used in an LSWSN is called the sink node, which is responsible for processing and analyzing the collected information. It works as a station between the network sensor nodes and the administrator. Also, it is responsible for controlling the whole network. Determining the sink node location in an LSWSN is a challenging task, as it is crucial to the network lifetime, for keeping the network activity to the most possible extent. In this paper, the Harris' hawks optimization (HHO) algorithm is employed to solve this problem and subsequently the Prim's shortest path algorithm is used to reconstruct the network by making minimum transmission paths from the sink node to the rest of the sensor nodes. The performance of HHO is compared with other well-known algorithms such as particle swarm optimization (PSO), flower pollination algorithm (FPA), grey wolf optimizer (GWO), sine cosine algorithm (SCA), multi-verse optimizer (MVO), and whale optimization algorithm (WOA). The simulation results of different network sizes, with single and multiple sink nodes, show the superiority of the employed approach in terms of energy consumption and localization error, and ultimately prolonging the lifetime of the network in an efficacious way.","['Wireless sensor networks', 'Network topology', 'Topology', 'Optimization', 'Energy consumption', 'Heuristic algorithms', 'Computers']","['Large-scale wireless sensor network', 'Harris’ hawks optimization', 'topology control', 'sink node placement']"
"Cell planning (CP) is the most important phase in the life cycle of a cellular system as it determines the operational expenditure, capital expenditure, as well as the long-term performance of the system. Therefore, it is not surprising that CP problems have been studied extensively for the past three decades for all four generations of cellular systems. However, the fact that small cells, a major component of future networks, are anticipated to be deployed in an impromptu fashion makes CP for future networks vis-a-vis 5G a conundrum. Furthermore, in emerging cellular systems that incorporate a variety of different cell sizes and types, heterogeneous networks (HetNets), energy efficiency, self-organizing network features, control and data plane split architectures (CDSA), massive multiple input multiple out (MIMO), coordinated multipoint (CoMP), cloud radio access network, and millimetre-wave-based cells plus the need to support Internet of Things (IoT) and device-to-device (D2D) communication require a major paradigm shift in the way cellular networks have been planned in the past. The objective of this paper is to characterize this paradigm shift by concisely reviewing past developments, analyzing the state-of-the-art challenges, and identifying future trends, challenges, and opportunities in CP in the wake of 5G. More specifically, in this paper, we investigate the problem of planning future cellular networks in detail. To this end, we first provide a brief tutorial on the CP process to identify the peculiarities that make CP one of the most challenging problems in wireless communications. This tutorial is followed by a concise recap of past research in CP. We then review key findings from recent studies that have attempted to address the aforementioned challenges in planning emerging networks. Finally, we discuss the range of technical factors that need to be taken into account while planning future networks and the promising research directions that necessitates the paradigm shift to do so.","['Planning', '5G mobile communication', 'Optimization', 'Cellular networks', 'Object recognition', 'Tutorials', 'Wireless communication']","['HetNets planning', 'energy efficient planning', '5G network planning']"
"A microgrid (MG) is a small-scale power system with a cluster of loads and distributed generators operating together through energy management software and devices that act as a single controllable entity with respect to the grid. MG has become a key research element in smart grid and distribution power systems. MG mainly contains different renewable energy sources (RESs) that use various technological advancements, such as power electronics-based technologies. However, it has an unstable output, thereby causing different types of power quality (PQ) events. As a result, standards and mitigation methods have been developed in recent years. To mitigate PQ issues due to MG integration, various methods and standards have been proposed over the last years. Although these individual methods are well documented, a comparative overview had not been introduced so far. Thus, this study aims to fill the gap by reviewing and comparing the prior-art PQ issues, solutions, and standards in MGs. We compare the main issues related to voltage sag, voltage swell, voltage and current harmonics, system unbalances, and fluctuations to ensure high-quality MG output power. The new technologies associated with MGs generate harmonics emission in the range of 2-150 kHz, thereby causing a new phenomenon, namely, supraharmonics (SH) emission, which is not sufficiently covered in the literature. Therefore, the characteristics, causes, consequences, and measurements of SH are highlighted and analyzed. The mitigation strategies, control, and devices of PQ issues are also discussed. Moreover, a comparison is conducted between the most popular devices used to mitigate the PQ issues in MG in terms of cost, rating, and different aspects of performance. This review study can strengthen the efforts toward the mitigation and standards development of PQ issues in MG applications, especially SH. Finally, some recommendations and suggestions to improve PQ of MG, including SH, are highlighted.","['Standards', 'Power quality', 'Microgrids', 'Power system stability', 'Harmonic analysis', 'Voltage control', 'Power system harmonics']","['Microgrid', 'power quality', 'PQ disturbance', 'renewable energy sources', 'MG configuration', 'distributed generation', 'smart grid', 'supraharmonics']"
"The automation of robotic processes has been experiencing an increasing trend of interest in recent times. However, most of literature describes only theoretical foundations on RPA or industrial results after implementing RPA in specific scenarios, especially in finance and outsourcing. This paper presents a systematic mapping study with the aim of analyzing the current state-of-the-art of RPA and identifying existing gaps in both, scientific and industrial literature. Firstly, this study presents an in-depth analysis of the 54 primary studies which formally describe the current state of the art of RPA. These primary studies were selected as a result of the conducting phase of the systematic review. Secondly, considering the RPA study performed by Forrester, this paper reviews 14 of the main commercial tools of RPA, based on a classification framework defined by 48 functionalities and evaluating the coverage of each of them. The result of the study concludes that there are certain phases of the RPA lifecycle that are already solved in the market. However, the Analysis phase is not covered in most tools. The lack of automation in such a phase is mainly reflected by the absence of technological solutions to look for the best candidate processes of an organization to be automated. Finally, some future directions and challenges are presented.","['Robots', 'Software', 'Automation', 'Companies', 'Systematics']","['Robotic process automation', 'RPA', 'systematic mapping study']"
"In the context of fifth-generation mobile networks, the concept of “Slice as a Service”promotes mobile network operators to flexibly share infrastructures with mobile service providers and stakeholders. However, it also challenges with an emerging demand for efficient online algorithms to optimize the request-and-decision-based inter-slice resource management strategy. Based on genetic algorithms, this paper presents a novel online optimizer that efficiently approaches toward the ideal slicing strategy with maximized long-term network utility. The proposed method encodes slicing strategies into binary sequences to cope with the request-and-decision mechanism. It requires no a priori knowledge about the traffic/utility models and therefore supports heterogeneous slices while providing solid effectiveness, good robustness against non-stationary service scenarios, and high scalability.","['Resource management', 'Optimization', '5G mobile communication', 'Quality of service', 'Network slicing', 'Genetics']","['5G mobile communication', 'business model', 'communication system operations and management', 'genetic algorithms', 'network slicing', 'optimal scheduling', 'optimization', 'resource management']"
"As a very attractive computing paradigm, cloud computing makes it possible for resource-constrained users to enjoy cost-effective and flexible resources of diversity. Considering the untrustworthiness of cloud servers and the data privacy of users, it is necessary to encrypt the data before outsourcing it to the cloud. However, the form of encrypted storage also poses a series of problems, such as: How can users search over the outsourced data? How to realize user-side verifiability of search results to resist malicious cloud servers? How to enable server-side verifiability of outsourced data to check malicious data owners? How to achieve payment fairness between the user and the cloud without introducing any third party? Towards addressing these challenging issues, in this paper, we introduce TKSE, a trustworthy keyword search scheme over encrypted data without any third party, trusted or not. In TKSE, the encrypted data index based on digital signature allows a user to search over the outsourced encrypted data and check whether the search result returned by the cloud fulfills the pre-specified search requirements. In particular, for the first time, TKSE realizes server-side verifiability which protects honest cloud servers from being framed by malicious data owners in the data storage phase. Furthermore, blockchain technologies and hash functions are used to enable payment fairness of search fees without introducing any third party even if the user or the cloud is malicious. Our security analysis and performance evaluation indicate that TKSE is secure and efficient and it is suitable for cloud computing.","['Cloud computing', 'Servers', 'Keyword search', 'Encryption', 'Indexes']","['Blockchain', 'cloud computing', 'fair payment', 'searchable encryption', 'verifiability']"
"Blockchain as emerging technology is revolutionizing several industries, and its abundant privileges have opened up a bunch of research directions in various industries; thereby, it has acquired many interests from the research community. The rapid evolution of blockchain research papers in recent years has resulted in a need to conduct research studies that investigate a detailed analysis of the current body of knowledge in this field. To address this need, a few review papers have been published to report the latest accomplishments and challenges of blockchain technology from different perspectives. Nonetheless, there has not been any bibliometric analysis of the state of the art in blockchain where Web of Science (WoS) has been taken into consideration as a literature database. Hence, a thorough analysis of the current body of knowledge in blockchain research through a bibliometric study would be needed. In this paper, we performed a bibliometric analysis of all Blockchain’s conference papers, articles, and review papers that have been indexed byWoS from 2013 to 2018. We have analyzed those collected papers against five research questions. The results revealed some valuable insights, including yearly publications and citations trends, hottest research areas, top-ten influential papers, favorite publication venues, and most supportive funding bodies. The findings of this paper offer several implications that can be used as a guideline by both fresh and experienced researchers to establish a baseline before initiating a blockchain research project in the future.","['Blockchain', 'Bibliometrics', 'Market research', 'Bitcoin', 'Industries', 'Databases']","['Blockchain', 'bibliometric study', 'Web of Science']"
"The coronavirus outbreak has brought unprecedented measures, which forced the authorities to make decisions related to the instauration of lockdowns in the areas most hit by the pandemic. Social media has been an important support for people while passing through this difficult period. On November 9, 2020, when the first vaccine with more than 90% effective rate has been announced, the social media has reacted and people worldwide have started to express their feelings related to the vaccination, which was no longer a hypothesis but closer, each day, to become a reality. The present paper aims to analyze the dynamics of the opinions regarding COVID-19 vaccination by considering the one-month period following the first vaccine announcement, until the first vaccination took place in UK, in which the civil society has manifested a higher interest regarding the vaccination process. Classical machine learning and deep learning algorithms have been compared to select the best performing classifier. 2 349 659 tweets have been collected, analyzed, and put in connection with the events reported by the media. Based on the analysis, it can be observed that most of the tweets have a neutral stance, while the number of in favor tweets overpasses the number of against tweets. As for the news, it has been observed that the occurrence of tweets follows the trend of the events. Even more, the proposed approach can be used for a longer monitoring campaign that can help the governments to create appropriate means of communication and to evaluate them in order to provide clear and adequate information to the general public, which could increase the public trust in a vaccination campaign.","['COVID-19', 'Social networking (online)', 'Vaccines', 'Machine learning algorithms', 'Support vector machines', 'Sentiment analysis', 'Classification algorithms']","['Opinion mining', 'social media', 'COVID-19', 'SARS-CoV-2', 'stance classification', 'vaccine']"
"The next-generation cellular network is to provide a large variety of services for different kinds of terminals, from traditional voice and data services over mobile phones to small packet transmission over massive machine-type terminals. Although orthogonal-subcarrier-based waveforms are widely used nowadays in many practical systems, they can hardly meet the requirements in the coming 5G networks. Therefore, more flexible waveforms have been proposed to address the unprecedented challenges. In this paper, we will provide comprehensive analysis and comparison for typical waveforms. To offer an insightful analysis, we will not only introduce the basic principles of the waveforms, but also reveal the underlying characteristics. Moreover, a comprehensive comparison in terms of different performance metrics will also be presented in thispaper, which provides an overall understanding of the new waveforms.","['OFDM', '5G mobile communication', 'Receivers', 'Bandwidth', 'Demodulation', 'Interference']","['5G', 'waveform', 'analysis', 'comparison']"
"The current cellular technology and vehicular networks cannot satisfy the mighty strides of vehicular network demands. Resource management has become a complex and challenging objective to gain expected outcomes in a vehicular environment. The 5G cellular network promises to provide ultra-high-speed, reduced delay, and reliable communications. The development of new technologies such as the network function virtualization (NFV) and software defined networking (SDN) are critical enabling technologies leveraging 5G. The SDN-based 5G network can provide an excellent platform for autonomous vehicles because SDN offers open programmability and flexibility for new services incorporation. This separation of control and data planes enables centralized and efficient management of resources in a very optimized and secure manner by having a global overview of the whole network. The SDN also provides flexibility in communication administration and resource management, which are of critical importance when considering the ad-hoc nature of vehicular network infrastructures, in terms of safety, privacy, and security, in vehicular network environments. In addition, it promises the overall improved performance. In this paper, we propose a flow-based policy framework on the basis of two tiers virtualization for vehicular networks using SDNs. The vehicle to vehicle (V2V) communication is quite possible with wireless virtualization where different radio resources are allocated to V2V communications based on the flow classification, i.e., safety-related flow or non-safety flows, and the controller is responsible for managing the overall vehicular environment and V2X communications. The motivation behind this study is to implement a machine learning-enabled architecture to cater the sophisticated demands of modern vehicular Internet infrastructures. The inclination towards robust communications in 5G-enabled networks has made it somewhat tricky to manage network slicing efficiently. This paper also presents a proof of concept for leveraging machine learning-enabled resource classification and management through experimental evaluation of special-purpose testbed established in custom mininet setup. Furthermore, the results have been evaluated using Long Short-Term Memory (LSTM), Convolutional Neural Network (CNN), and Deep Neural Network (DNN). While concluding the paper, it is shown that the LSTM has outperformed the rest of classification techniques with promising results.","['Resource management', '5G mobile communication', 'Computer architecture', 'Wireless communication', 'Machine learning', 'Ad hoc networks', 'Communication system security']","['Future internet architectures', 'machine learning', 'network reliability', 'privacy', 'resource management', 'security', 'software defined networks', 'vehicular networks']"
"Covert channels represent unforeseen communication methods that exploit authorized overt communication as the carrier medium for covert messages. Covert channels can be a secure and effective means of transmitting confidential information hidden in overt traffic. For covert timing channel, the covert message is usually modulated into inter-packet delays (IPDs) of legitimate traffic, which is not suitable for voice over LTE (VoLTE) since the IPDs of VoLTE traffic are fixed to lose the possibility of being modulated. For this reason, we propose a covert channel via adjusting silence periods, which modulates covert message by the postponing or extending silence periods in VoLTE traffic. To keep the robustness, we employ the Gray code to encode the covert message to reduce the impact of packet loss. Moreover, the proposed covert channel enables the tradeoff between the robustness and voice quality which is an important performance indicator for VoLTE. The experiment results show that the proposed covert channel is undetectable by statistical tests and outperforms the other covert channels based on IPDs in terms of robustness.","['Robustness', 'Timing', 'Long Term Evolution', 'Buildings', 'Mobile computing', '5G mobile communication']","['Covert channel', 'VoLTE', 'voice activity detection', 'silence period']"
"In this paper, an antenna interference cancellation chip (AICC) with a high-pass response is proposed to mitigate the mutual coupling of two antennas resonating in contiguous frequency bands. Using the most up-to-date low temperature co-fired ceramic (LTCC) technology, the chip only occupies a compact volume of 1.6 × 0.8 × 0.6 mm 3 . Two external tuning capacitors and two shunt inductors together with the LTCC AICC device which are in shunt with two coupled antennas, are able to improve the antenna isolation near band-edge by more than 15 dB without sacrificing antenna performance in its useful resonating bands. The high-pass property of the AICC device prevents the decoupling design near 2.4GHz affecting the successful operation of GPS at 1.575 GHz. The superiority of the proposed method is verified with active measurement of a Mi-Fi (mobile Wi-Fi) device in Wi-Fi hotspot mode using the AICC device. The proposed AICC device and corresponding decoupling method with the device can find plenty of applications in long-term-evolution and future 5G wireless platforms.","['Antenna measurements', 'Wireless fidelity', 'Admittance', 'Antenna accessories', 'Antenna feeds', 'Resonant frequency']","['Antenna array mutual coupling', 'decoupling network', 'interference suppression', 'in-device coexistence (IDC)', 'high-pass filter']"
"Many deep learning (DL) models have shown exceptional promise in radar-based human activity recognition (HAR) area. For radar-based HAR, the raw data is generally converted into a 2-D spectrogram by using short-time Fourier transform (STFT). All the existing DL methods treat the spectrogram as an optical image, and thus the corresponding architectures such as 2-D convolutional neural networks (2D-CNNs) are adopted in those methods. These 2-D methods that ignore temporal characteristics ordinarily lead to a complex network with a huge amount of parameters but limited recognition accuracy. In this paper, for the first time, the radar spectrogram is treated as a time sequence with multiple channels. Hence, we propose a DL model composed of 1-D convolutional neural networks (1D-CNNs) and long short-term memory (LSTM). The experiments results show that the proposed model can extract spatio-temporal characteristics of the radar data and thus achieves the best recognition accuracy and relatively low complexity compared to the existing 2D-CNN methods.",[],[]
"In recent years, the unmanned aerial vehicles (UAVs) have exhibited significant market potential to greatly reduce the cost and time in the field of logistics. The use of UAVs to provide commercial courier has become an emerging industry, remarkably shifting the energy use of the freight sector. However, due to limited battery capacities, the flight duration of civilian rotorcraft UAVs is still short, hindering them from performing remote jobs. In this case, people customarily utilize ground vehicles to carry and assist UAVs in various applications, including cargo delivery. Most previous studies on vehicle-drone cooperative parcel delivery considered only one UAV, thereby suffering from low efficiency when serving a large number of customers. In this paper, we propose a novel hybrid genetic algorithm, which supports the cooperation of a ground vehicle and multiple UAVs for efficient parcel delivery. Our routing and scheduling algorithm allows multiple UAVs carried by the vehicle to simultaneously deliver multiple parcels to customers residing in different locations. The proposed algorithm consists of a pipeline of several modules: population management, heuristic population initialization, and population education. The performance evaluation results show that the proposed algorithm has significant efficiency over existing algorithms.","['Routing', 'Genetic algorithms', 'Education', 'Land vehicles', 'Sociology', 'Statistics', 'Drones']","['Unmanned aerial vehicle', 'cargo delivery', 'routing', 'scheduling']"
"A planar, low-profile, dual-band and dual-polarized antenna on a semi-flex substrate is proposed in this paper. The antenna is fabricated on Rogers substrate with a thickness of 3.04 mm and sized at 70.4 \times 76.14 \times 3.11 mm 3 ( 0.37\lambda _{0} \times 0.40\lambda _{0}\times 0.016 \lambda _{0} ) only. The circular polarization property is enabled in the global navigation satellite system (GNSS) L1/E1 (lower) band by introducing a complementary split ring resonator on the antenna patch. Meanwhile, the antenna operates in the second (upper) 2.45 GHz WLAN band is enabled by etching a U-shaped slot on its ground plane. This simultaneous, dual-band and dual-polarized operation enables the proposed antenna to be applied in the indoor/outdoor wearable application. To isolate the antenna against the influence of the human body, a multiband artificial magnetic conductor (AMC) plane is added on the reverse side of the dual-band radiator. Comparison of the antenna without AMC in free space and when evaluated on the chest of a human body backed by AMC showed improved gain; from 3–5.1 dBi in the lower band, and from 1.53–5.03 dBi in the upper band. Besides that, the front-to-back ratio of the AMC backed monopole antenna also improved from 11–21.88 dB and from 2.5–24.5 dB in the GNSS and WLAN bands, respectively. Next, the specific absorption rate (SAR) of the monopole antenna with and without the AMC plane is assessed. Evaluation results indicate that the maximum SAR value decreased by up to 89.45% in comparison with the antenna without AMC in the lower band. This indicates the effectiveness of the AMC array in increasing gain and FBR, besides reducing EM absorption in the human body.","['Substrates', 'Dual band', 'Biomedical monitoring', 'Antenna feeds', 'Global navigation satellite system']","['Wearable antennas', 'dual-band antennas', 'dual-polarized antennas', 'circularly polarized antennas', 'artificial magnetic conductor (AMC) plane']"
"Based on the concept of switched-capacitor based multilevel inverter topology, a new structure for a boost multilevel inverter topology has been recommended in this paper. The proposed topology uses 11 unidirectional switches with a single switched capacitor unit to synthesize nine-level output voltage waveform. Apart from the twice voltage gain, self-voltage balancing of capacitor voltage without any auxiliary method along with reduced voltage stress has been the main advantages of this topology. The merits of proposed topology have been analyzed through various comparison parameters including component counts, voltage stresses, cost and efficiency with a maximum value of 98.3%, together with the integration of switched capacitors into the topology following recent development. Phase disposition pulse width modulation (PD-PWM) technique and nearest level control PWM (NLC-PWM) have been used for the control of switches. Different simulation and hardware results with different operating conditions are included in the paper to demonstrate the performance of the proposed topology.","['Topology', 'Switches', 'Capacitors', 'Inverters', 'Stress', 'Pulse width modulation', 'Logic gates']","['Multilevel inverter', 'boost inverter topology', 'switched-capacitor', 'single dc source', 'reduce switch count', 'PWM']"
"The Internet of Things (IoT) consists of resource-constrained smart devices capable to sense and process data. It connects a huge number of smart sensing devices, i.e., things, and heterogeneous networks. The IoT is incorporated into different applications, such as smart health, smart home, smart grid, etc. The concept of smart healthcare has emerged in different countries, where pilot projects of healthcare facilities are analyzed. In IoT-enabled healthcare systems, the security of IoT devices and associated data is very important, whereas Edge computing is a promising architecture that solves their computational and processing problems. Edge computing is economical and has the potential to provide low latency data services by improving the communication and computation speed of IoT devices in a healthcare system. In Edge-based IoT-enabled healthcare systems, load balancing, network optimization, and efficient resource utilization are accurately performed using artificial intelligence (AI), i.e., intelligent software-defined network (SDN) controller. SDN-based Edge computing is helpful in the efficient utilization of limited resources of IoT devices. However, these low powered devices and associated data (private sensitive data of patients) are prone to various security threats. Therefore, in this paper, we design a secure framework for SDN-based Edge computing in IoT-enabled healthcare system. In the proposed framework, the IoT devices are authenticated by the Edge servers using a lightweight authentication scheme. After authentication, these devices collect data from the patients and send them to the Edge servers for storage, processing, and analyses. The Edge servers are connected with an SDN controller, which performs load balancing, network optimization, and efficient resource utilization in the healthcare system. The proposed framework is evaluated using computer-based simulations. The results demonstrate that the proposed framework provides better solutions for IoT-enabled healthcare systems.","['Edge computing', 'Medical services', 'Servers', 'Artificial intelligence', 'Internet of Things', 'Authentication']","['Healthcare systems', 'security', 'software-defined network', 'edge computing', 'Internet of Things']"
"The chest X-ray is considered a significant clinical utility for basic examination and diagnosis. The human lung area can be affected by various infections, such as bacteria and viruses, leading to pneumonia. Efficient and reliable classification method facilities the diagnosis of such infections. Deep transfer learning has been introduced for pneumonia detection from chest X-rays in different models. However, there is still a need for further improvements in the feature extraction and advanced classification stages. This paper proposes a classification method with two stages to classify different cases from the chest X-ray images based on a proposed Advanced Squirrel Search Optimization Algorithm (ASSOA). The first stage is the feature learning and extraction processes based on a Convolutional Neural Network (CNN) model named ResNet-50 with image augmentation and dropout processes. The ASSOA algorithm is then applied to the extracted features for the feature selection process. Finally, the Multi-layer Perceptron (MLP) Neural Network’s connection weights are optimized by the proposed ASSOA algorithm (using the selected features) to classify input cases. A Kaggle chest X-ray images (Pneumonia) dataset consists of 5,863 X-rays is employed in the experiments. The proposed ASSOA algorithm is compared with the basic Squirrel Search (SS) optimization algorithm, Grey Wolf Optimizer (GWO), and Genetic Algorithm (GA) for feature selection to validate its efficiency. The proposed (ASSOA + MLP) is also compared with other classifiers, based on (SS + MLP), (GWO + MLP), and (GA + MLP), in performance metrics. The proposed (ASSOA + MLP) algorithm achieved a classification mean accuracy of (99.26%). The ASSOA + MLP algorithm also achieved a classification mean accuracy of (99.7%) for a chest X-ray COVID-19 dataset tested from GitHub. The results and statistical tests demonstrate the high effectiveness of the proposed method in determining the infected cases.","['X-ray imaging', 'Feature extraction', 'Diseases', 'Optimization', 'Lung', 'COVID-19', 'Classification algorithms']","['Chest X-ray', 'transfer learning', 'convolutional neural network', 'squirrel search optimization', 'multilayer perceptron', 'optimization algorithm']"
"Ester-based dielectric fluids have gained widespread popularity for applications in high voltage apparatus. Synthetic and natural esters have been subjected to research for decades vis-à-vis mineral insulating oils around the world. Although many researchers favor the application of ester fluids, utilities are still uncertain and application of these alternatives remains a challenge. The intent of this survey is to present recent research progress and highlight the state of the art of key aspects that should be emphasized in future research. The contemporary research scenarios pertaining to the performance of ester fluids versus mineral oils, miscibility, and retrofilling of insulating fluids are discussed. In addition, pre-breakdown phenomena, usage of esters in on-load tap changers, environmental and fire resistance properties, and use of esters in cold climates are also discussed. Importantly, challenges and future aspects that should be investigated to improve the existing knowledge of ester dielectric fluids for applications in transformer technology are highlighted.","['Power transformer insulation', 'Oil insulation', 'Minerals', 'Vegetable oils', 'Dielectrics']","['Transformer', 'dielectric fluids', 'insulating materials', 'ester fluids']"
"ResNet can achieve deeper network and higher performance, but there is no good explanation for how identity shortcut connections solve the gradient fading problems. Moreover, it is not reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified ResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. Second, according to the back propagation of the simplified ResNet, we indirectly explain how the identity shortcut connections solve the problems of gradient fading in convolutional neural networks. Third, we propose an improved ResNet via adjustable shortcut connections, and design a convex k strategy for the improved ResNet according to the different region parameters changing rules. Experimental results on the CIFAR-10 data set show that the test accuracy of the improved ResNet is 78.63%, which is 2.85% higher than that of ResNet. On the CIFAR-100 data set, the test accuracy of the improved ResNet is 42.53%, which is 3.66% higher than that of ResNet. More importantly, the improved ResNet does not increase the amount of computation compared with the classical ResNet.","['Fading channels', 'Training', 'Convolutional neural networks', 'Feature extraction', 'Visualization', 'Computer vision', 'Task analysis']","['Deep convolutional neural networks', 'gradient fading', 'ResNet', 'adjustable shortcut connections', 'convex k strategy']"
"In the context of industry 4.0, the main way to realize the intelligent manufacturing is to build a smart factory integrated with the advanced technologies, such as the Internet of Things (IoT), cloud computing, and artificial intelligence (AI). With the aim to emphasize the role and potential of cloud computing and AI in improving the smart factories' performances, such as system flexibility, efficiency, and intelligence, we comprehensively summarize and explain the AI application in a cloud-assisted smart factory (CaSF). In this paper, a vertically-integrated four-tier CaSF architecture is presented. Also, the key AI technologies involved in the CaSF are classified and described according to the logical relationships in the architecture hierarchy. Finally, the main issues and technical challenges of AI technologies in the CaSF systems are introduced, and some possible solutions are also given. The application of the AI in smart factories has accelerated the implementation of the industry 4.0 to the certain extent.","['Artificial intelligence', 'Smart manufacturing', 'Cloud computing', 'Computer architecture', 'Production', 'Robots']","['Artificial intelligence', 'cloud computing', 'Industry 4.0', 'smart factory']"
"Recently, to address the astonishing capacity requirement of 5G, researchers are investigating the possibility of combining different technologies with ultra-dense networks (UDNs). However, the ultra-dense deployment of small cells in the coverage area of conventional macrocells known as UDNs introduces new technical challenges such as severe interference, unfairness in radio resource sharing, unnecessary handover, a significant increase in energy consumption, and degraded quality-of-service (QoS). To overcome these challenges and achieve the performance requirements in 5G, there is a need to combine UDNs with other 5G enabling technologies and then, design intelligent management techniques for better performance of the overall networks. Hence, in this paper, we present a comprehensive survey on different generations of wireless networks, 5G new radio (NR) standards, 5G enabling technologies and the importance of combining UDNs with other 5G technologies. Also, we present an extensive overview of the recent advances and research challenges in intelligent management techniques and backhaul solutions in the last five years for the combination of UDNs and other enabling technologies that offers the visions of 5G. We summarise the mathematical tools widely exploited in solving these problems and the performance metrics used to evaluate the intelligent management algorithms. Moreover, we classify various intelligent management algorithms according to the adopted enabling technologies, benefits, challenges addressed, mathematical tools and performance metrics used. Finally, we summarise the open research challenges, provide design guidelines and potential research directions for the development of intelligent management techniques and backhaul solutions for the combination of UDNs and other 5G technologies.","['5G mobile communication', 'Macrocell networks', 'Interference', 'Quality of service', 'Wireless networks', 'Resource management', 'Energy consumption']","['Macrocells', 'small cells', 'ultra-dense networks', 'QoS']"
"Progress in Microgrid (MG) research has evolved the MG concept from classical, purely MG power networks to more advanced power and communications networks. The communications infrastructure helps control and manage the unreliable power outputs that most standard power generation elements of the MG (e.g., wind turbines and photo-voltaic panels) deliver. Although communication technologies do offer certain advantages for sensing and control, they generate other complications due to packet loss and packet latency, among other transmission impairments. In this work, we discuss the impact of communications on MG performance, establishing the requirements of data exchanges and system response in the three levels of a hierarchical control approach: primary, secondary, and tertiary. With a focus on the secondary level - responsible for ensuring the restoration of electrical parameters - we identify standards, networking protocols, and communication technologies relevant for the interoperability of MGs and clusters of MGs, including both modes of operation: isolated and grid-connected. We review theoretical approaches and practical implementations that consider the effects of the communications network on the general performance of the MG. Moreover, we undertake an experimental analysis of the influence of wired and wireless communication networks on MG performance, revealing the importance of designing future smart control solutions more robust to communication degradation, especially if wireless technologies are integrated to provide scalable deployments. Aspects such as resilience, security, and interoperability are also shown to require continuing efforts in research and practical applications.","['Frequency control', 'Voltage control', 'Communication networks', 'Smart grids', 'Microgrids', 'Wireless communication', 'Power system stability']","['Communication network', 'latency', 'MG secondary control', 'microgrid', 'smart grid']"
"Rapid industrialization and its automation on the globe demands increased generation of electrical energy with more reliability and quality. Renewable energy (RE) sources are considered as a green form of energy and extensively used as an alternative source of energy for conventional energy sources to meet the increased demand for electrical power. However, these sources, when integrated to the utility grid, pose challenges in maintaining the power quality (PQ) and stability of the power system network. This is due to the unpredictable and variable nature of generation by these sources. The distributed flexible AC transmission system (DFACTS) devices such as distributed static compensator (DSTATCOM) and dynamic voltage restorer (DVR) play an active role in mitigating PQ issues associated with RE penetration. The performance of DFACTS devices is mostly dependent on the type of control algorithms employed for switching of these devices. This paper presents a comprehensive review of various conventional and adaptive algorithms used to control DFACTS devices for improvement of power quality in utility grids with RE penetration. This review intends to provide a summary of the design, experimental hardware, performance and feasibility aspects of these algorithms reported in the literature. More than 170 research publications are critically reviewed, classified, and listed for quick reference for the advantage of engineers and academician working in this area.","['Power quality', 'Voltage control', 'Heuristic algorithms', 'Signal processing algorithms', 'Performance evaluation', 'Harmonic analysis', 'Renewable energy sources']","['Adaptive control algorithm', 'conventional control algorithm', 'DFACTS device', 'modern utility grid', 'power quality', 'renewable energy source']"
"Alzheimer’s Disease (AD) is the most common cause of dementia globally. It steadily worsens from mild to severe, impairing one’s ability to complete any work without assistance. It begins to outstrip due to the population ages and diagnosis timeline. For classifying cases, existing approaches incorporate medical history, neuropsychological testing, and Magnetic Resonance Imaging (MRI), but efficient procedures remain inconsistent due to lack of sensitivity and precision. The Convolutional Neural Network (CNN) is utilized to create a framework that can be used to detect specific Alzheimer’s disease characteristics from MRI images. By considering four stages of dementia and conducting a particular diagnosis, the proposed model generates high-resolution disease probability maps from the local brain structure to a multilayer perceptron and provides accurate, intuitive visualizations of individual Alzheimer’s disease risk. To avoid the problem of class imbalance, the samples should be evenly distributed among the classes. The obtained MRI image dataset from Kaggle has a major class imbalance problem. A DEMentia NETwork (DEMNET) is proposed to detect the dementia stages from MRI. The DEMNET achieves an accuracy of 95.23%, Area Under Curve (AUC) of 97% and Cohen’s Kappa value of 0.93 from the Kaggle dataset, which is superior to existing methods. We also used the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset to predict AD classes in order to assess the efficacy of the proposed model.","['Magnetic resonance imaging', 'Feature extraction', ""Alzheimer's disease"", 'Brain modeling', 'Deep learning', 'Neuroimaging', 'Computational modeling']","['Deep learning', 'Alzheimer’s Disease', 'MRI image', 'convolutional neural network', 'Cohen’s kappa']"
"As energy demand continues to increase, demand response (DR) programs in the electricity distribution grid are gaining momentum and their adoption is set to grow gradually over the years ahead. Demand response schemes seek to incentivise consumers to use green energy and reduce their electricity usage during peak periods which helps support grid balancing of supply-demand and generate revenue by selling surplus of energy back to the grid. This paper proposes an effective energy management system for residential demand response using Reinforcement Learning (RL) and Fuzzy Reasoning (FR). RL is considered as a model-free control strategy which learns from the interaction with its environment by performing actions and evaluating the results. The proposed algorithm considers human preference by directly integrating user feedback into its control logic using fuzzy reasoning as reward functions. Q-learning, a RL strategy based on a reward mechanism, is used to make optimal decisions to schedule the operation of smart home appliances by shifting controllable appliances from peak periods, when electricity prices are high, to off-peak hours, when electricity prices are lower without affecting the customer's preferences. The proposed approach works with a single agent to control 14 household appliances and uses a reduced number of state-action pairs and fuzzy logic for rewards functions to evaluate an action taken for a certain state. The simulation results show that the proposed appliances scheduling approach can smooth the power consumption profile and minimise the electricity cost while considering user's preferences, user's feedbacks on each action taken and his/her preference settings. A user-interface is developed in MATLAB/Simulink for the Home Energy Management System (HEMS) to demonstrate the proposed DR scheme. The simulation tool includes features such as smart appliances, electricity pricing signals, smart meters, solar photovoltaic generation, battery energy storage, electric vehicle and grid supply.","['Home appliances', 'Load management', 'Power demand', 'Pricing', 'Reinforcement learning', 'Smart meters']","['Demand response', 'home energy management system', 'smart home', 'smart appliances', 'reinforcement learning', 'Q-learning', 'fuzzy reasoning']"
"Litchi clusters in fruit groves are randomly scattered and occur irregularly, so it is difficult to detect and locate the fruit-bearing branches of multiple litchi clusters at one time. This is a highly challenging task related to continuous operation in the natural environment for visual-based harvesting robots to carry out. In this study, a reliable algorithm based on RGB-depth (RGB-D) cameras in the fields was developed to accurately and automatically detect and locate the fruit-bearing branches of multiple litchi clusters simultaneously in large environments. A semantics segmentation method, Deeplabv3, was employed to segment the RGB images into three categories: background, fruit and twig. A pre-processing step is proposed to align the segmented RGB images and remove the twigs that did not bear fruits. Subsequently, the twig binary map image was processed via skeleton extraction and pruning operations, which left behind only the main branches of twigs. A method for non-parametric density-based spatial clustering of application with noise was used to cluster the pixels in the three-dimensional space of the skeleton map of the branches; thus, the fruit-bearing branches belonging to the same litchi clusters were determined. Finally, a three-dimensional straight line was fitted to each cluster via principal component analysis, and the linear information corresponded to the location of the fruit-bearing branches. In the experiments, 452 pairs of RGB-D images under different illumination were collected to test the proposed algorithm. The results show that the detection accuracy of a litchi fruit-bearing branch is 83.33%, positioning accuracy is 17.29°±24.57°, and execution time for the determination of a single litchi fruit-bearing branch is 0.464s. Field experiments show that this method can effectively guide the robot to complete continuous picking tasks.","['Robots', 'Cameras', 'Image segmentation', 'Lighting', 'Image color analysis', 'Task analysis', 'Clustering algorithms']","['Continuous picking', 'location detection of fruit-bearing branches', 'harvesting robots', 'RGB-D image']"
"Internet of Things (IoT) technology provides the basic infrastructure for a hyper connected society where all things are connected and exchange information through the Internet. IoT technology is fused with 5G and artificial intelligence (AI) technologies for use various fields such as the smart city and smart factory. As the demand for IoT technology increases, security threats against IoT infrastructure, applications, and devices have also increased. A variety of studies have been conducted on the detection of IoT malware to avoid the threats posed by malicious code. While existing models may accurately detect malicious IoT code identified through static analysis, detecting the new and variant IoT malware quickly being generated may become challenging. This paper proposes a dynamic analysis for IoT malware detection (DAIMD) to reduce damage to IoT devices by detecting both well-known IoT malware and new and variant IoT malware evolved intelligently. The DAIMD scheme learns IoT malware using the convolution neural network (CNN) model and analyzes IoT malware dynamically in nested cloud environment. DAIMD performs dynamic analysis on IoT malware in a nested cloud environment to extract behaviors related to memory, network, virtual file system, process, and system call. By converting the extracted and analyzed behavior data into images, the behavior images of IoT malware are classified and trained in the Convolution Neural Network (CNN). DAIMD can minimize the infection damage of IoT devices from malware by visualizing and learning the vast amount of behavior data generated through dynamic analysis.","['Malware', 'Feature extraction', 'Data visualization', 'Cloud computing', 'Static analysis', 'Convolution', 'Neural networks']","['Cloud-based malware detection', 'convolution neural network', 'dynamic analysis', 'IoT malware', 'malware detection']"
"The continuous growth of mobile devices in recent years has created a variety of opportunities for people to utilize the crowdsourcing technique to execute various intelligent computing and processing tasks, e.g., electricity load forecasting. However, there are few research in the field of real-time and accurate forecasting of electricity load in a dynamic environment, and this leads to an unsatisfactory result when applying the forecasting method to the real environment. In view of this challenge, in this paper, we propose a dynamic mobile crowdsourcing selection method for electricity load forecasting considering the dynamic arrivals of both crowdsourcing tasks and candidate workers to help the crowdsourcing platform find the ideal workers for the crowdsourcing tasks. Concretely, in our method, a system model is firstly established to quantify the ability of candidate workers in executing the crowdsourcing task when both workers and tasks arrive at or leave the platform dynamically; afterwards, a dynamic worker selection method is proposed based on the ability threshold of workers and the task priority. Finally, through a set of simulated experiments, we validate the feasibility of our proposal in terms of effectiveness and efficiency when making accurate electricity load forecasting through mobile crowdsourcing technique.","['Task analysis', 'Crowdsourcing', 'Load modeling', 'Load forecasting', 'Predictive models', 'Mobile handsets', 'Companies']","['Mobile crowdsourcing', 'electricity load forecasting', 'dynamic selection', 'threshold', 'priority']"
"Home energy management systems (HEMSs) help manage electricity demand to optimize energy consumption and distributed renewable energy generation without compromising consumers' comfort. HEMSs operate according to multiple criteria, including energy cost, weather conditions, load profiles, and consumer comfort. They play an increasingly ubiquitous role in energy efficiency through the reduction of electricity consumption within residential and commercial smart grids. This paper presents a comprehensive review of the HEMS literature with reference to main concepts, configurations, and enabling technologies. In doing so, it also provides a summary of HEMS computing trends and popular communication technologies for demand response applications. The ensuing survey offers the reader with an overall overview of current and future trends in HEMS solutions and technologies.","['Smart grids', 'Smart homes', 'Renewable energy sources', 'Load management', 'Energy storage', 'Wireless communication']","['Home energy management system', 'demand response', 'smart technologies', 'integrated wireless technology', 'intelligent scheduling controller']"
"Hybrid precoding is widely studied in millimetre-wave (mmWave) massive MIMO systems due to low cost as well as low power consumption. In general, there are two kinds of hybrid precoding structures: one is fully connected structure (FCS), where each radio frequency (RF) chain is connected to all antennas, and the other is partially connected structure (PCS), where each RF chain is connected to a sub-array. In this paper, we investigate the optimal hybrid precoder design problem for mmWave massive MIMO systems based on PCS, since this kind of structure is more practical for antenna deployment. We first focus on the optimization of analog precoder (AP) and propose two AP design schemes for high signal-to-noise ratio (SNR) condition and low SNR condition, respectively. For each of the schemes, the original optimization problem is reformulated to single-stream optimal transmitter beamforming problem with per-antenna power constraint, which has an optimal solution. Then, the optimal digital precoder is obtained by water-filling algorithm after AP is determined. Moreover, upper bounds of the achievable data rate for the proposed schemes with closed-form expression are derived.","['Radio frequency', 'MIMO', 'Antenna arrays', 'Precoding', 'Optimization', 'Signal to noise ratio']","['Massive MIMO', 'mmWave', 'hybrid precoder', 'partially connected structure']"
"This paper encourages the cooperation of different Internet of Things technologies in industrial environments for avoiding social disruption in novel Industry 4.0 paradigms. For this, green I3A smart factory (GreenISF) scenario is presented, where the deployment of a collaborative mesh network based on Bluetooth low energy (BLE) and long range wide-area network (LoRaWAN) technologies promotes human–machine collaboration towards socially sustainable factories. In order to encourage human-centric architectures in such environments, our smart wristband prototype OperaBLE is introduced in this paper as key enabler for human-in-the-loop systems. Thus, the network deployed in GreenISF is composed of body area networks which monitor labor activity and reinforce security at work by embedding sensors in regulatory industrial clothes. These networks cooperate with our BLE mesh infrastructure aimed to fulfill the major challenges Industry 4.0: zero fails, total coverage, and sustainability. Furthermore, a context information network based on LoRaWAN complements our mesh network to provide the system with valuable environmental data and prevent operators from harmful workplaces. The system is connected to a fog server responsible for preprocessing raw data that will be stored in a global cloud server. The experiments carried out highlight the contribution of OperaBLE towards safer working conditions and a sustainable digitalization of Industry 4.0.","['Industries', 'Mesh networks', 'Green products', 'Standards', 'Sensors', 'Production facilities', 'Monitoring']","['Industry 4.0', 'IoT', 'BLE mesh', 'LoRaWAN', 'body area network', 'OperaBLE']"
"Recently, emotion recognition using low-cost wearable sensors based on electroencephalogram and blood volume pulse has received much attention. Long short-term memory (LSTM) networks, a special type of recurrent neural networks, have been applied successfully to emotion classification. However, the performance of these sequence classifiers depends heavily on their hyperparameter values, and it is important to adopt an efficient method to ensure the optimal values. To address this problem, we propose a new framework to automatically optimize LSTM hyperparameters using differential evolution (DE). This is the first systematic study of hyperparameter optimization in the context of emotion classification. In this paper, we evaluate and compare the proposed framework with other state-of-the-art hyperparameter optimization methods (particle swarm optimization, simulated annealing, random search, and tree of Parzen estimators) using a new dataset collected from wearable sensors. Experimental results demonstrate that optimizing LSTM hyperparameters significantly improve the recognition rate of four-quadrant dimensional emotions with a 14% increase in accuracy. The best model based on the optimized LSTM classifier using the DE algorithm achieved 77.68% accuracy. The results also showed that evolutionary computation algorithms, particularly DE, are competitive for ensuring optimized LSTM hyperparameter values. Although DE algorithm is computationally expensive, it is less complex and offers higher diversity in finding optimal solutions.","['Emotion recognition', 'Optimization', 'Electroencephalography', 'Brain modeling', 'Classification algorithms', 'Sensors', 'Physiology']","['Differential evolution', 'emotion recognition', 'hyperparameter optimization', 'long short term memory', 'wearable physiological sensors']"
"Anomaly-based intrusion detection systems (IDSs) have been deployed to monitor network activity and to protect systems and the Internet of Things (IoT) devices from attacks (or intrusions). The problem with these systems is that they generate a huge amount of inappropriate false alarms whenever abnormal activities are detected and they are not too flexible for a complex environment. The high-level rate of the generated false alarms reduces the performance of IDS against cyber-attacks and makes the tasks of the security analyst particularly difficult and the management of intrusion detection process computationally expensive. We study here one of the challenging aspects of computer and network security and we propose to build a detection model for both known and unknown intrusions (or anomaly detection) via a novel nonparametric Bayesian model. The design of our framework can be extended easily to be adequate for IoT technology and notably for intelligent smart city web-based applications. In our method, we learn the patterns of the activities (both normal and anomalous) through a Bayesian-based MCMC inference for infinite bounded generalized Gaussian mixture models. Contrary to classic clustering methods, our approach does not need to specify the number of clusters, takes into consideration the uncertainty via the introduction of prior knowledge for the parameters of the model, and permits to solve problems related to over- and under-fitting. In order to get better clustering performance, feature weights, model’s parameters, and the number of clusters are estimated simultaneously and automatically. The developed approach was evaluated using popular data sets. The obtained results demonstrate the efficiency of our approach in detecting various attacks.","['Intrusion detection', 'Smart cities', 'Bayes methods', 'Feature extraction', 'Computers', 'Internet of Things']","['Intrusion detection systems (IDS)', 'anomaly intrusion detection', 'infinite mixture models', 'bounded generalized Gaussian models', 'Bayesian inference', 'Markov chain Monte Carlo (MCMC)']"
"Network intrusion detection system (NIDS) is a commonly used tool to detect attacks and protect networks, while one of its general limitations is the false positive issue. On the basis of our comparative experiments and analysis for the characteristics of the particle swarm optimization (PSO) and Xgboost, this paper proposes the PSO-Xgboost model given its overall higher classification accuracy than other alternative models such like Xgboost, Random Forest, Bagging and Adaboost. Firstly, a classification model based on Xgboost is constructed, and then PSO is used to adaptively search for the optimal structure of Xgboost. The benchmark NSL-KDD dataset is used to evaluate the proposed model. Our experimental results demonstrate that PSO-Xgboost model outperforms other comparative models in precision, recall, macro-average (macro) and mean average precision (mAP), especially when identifying minority groups of attacks like U2R and R2L. This work also provides experimental arguments for the application of swarm intelligence in NIDS.","['Adaptation models', 'Network intrusion detection', 'Particle swarm optimization', 'Machine learning algorithms', 'Machine learning', 'Support vector machines', 'Optimization']","['Intrusion detection', 'PSO-Xgboost', 'ensemble learning', 'particle swarm optimization']"
"Internet of Things (IoT) brings the third development wave of the global information industry, which makes users, network, and perception devices cooperate more closely. However, if IoT has security problems, it may cause a variety of damage and even threaten human lives and properties. To improve the abilities of monitoring, providing emergency response, and predicting the development trend of IoT security, a new paradigm called network security situation awareness (NSSA) is proposed. However, it is limited by its ability to mine and evaluate security situation elements from multi-source heterogeneous network security information. To solve this problem, this paper proposes an IoT network security situation awareness model using a situation reasoning method based on semantic ontology and user-defined rules. Ontology technology can provide a unified and formalized description to solve the problem of semantic heterogeneity in the IoT security domain. In this paper, four key sub-domains are proposed to reflect an IoT security situation: context, attack, vulnerability, and network flow. Furthermore, user-defined rules can compensate for the limited description ability of ontology, and hence can enhance the reasoning ability of our proposed ontology model. The examples in real IoT scenarios show that the ability of the network security situation awareness that adopts our situation reasoning method is more comprehensive and more powerful reasoning abilities than the traditional NSSA methods.","['Security', 'Ontologies', 'Communication networks', 'Cognition', 'Real-time systems', 'Semantics', 'Computer science']","['Network security', 'sematic ontology', 'situation awareness', 'situation reasoning', 'reasoning rules']"
"Battery energy storage systems (BESS), demand response (DR) and the dynamic thermal rating (DTR) system have increasingly played important roles in power grids worldwide. In addition to storing energy, BESS can supply peak demands, thereby reducing the frequency of load interruptions and deferring new asset investments. However, study on the precise BESS sizing (i.e. energy and power ratings) to supply peak demands to improve the security of supply of transmission networks is still lacking. The combined efficacy of BESS, DR and DTR have also never been studied, because their simultaneous deployment has never been considered. The first contribution of this paper is proposing a probabilistic evaluation method to evaluate various combinations of BESS power ratings and energy capacities and determines their impacts on the reliability of transmission networks, in which peak demands are supported by charges stored in BESSs to address the security of supply problem. The second contribution extends the proposed method to examine the effects of deploying BESS alongside DR and DTR. Our results show that the security of power supply improves along with BESS sizing by as much as 37.2%, and that its reliability becomes more significant as its capability grows, with bigger BESS having more detrimental effects towards EENS as it becomes unavailable than smaller BESS does. DTR and DR reduce the requirements of BESS sizing without adversely affecting network reliability.","['Security', 'Reliability', 'Power system reliability', 'Energy storage', 'Generators', 'Load modeling', 'Power system dynamics']","['Battery storage', 'reliability', 'dynamic line thermal rating', 'demand response', 'power system']"
"Traditional transmission line ratings are limited by a set of fixed conservative weather assumptions that are also known as static thermal rating (STR). Owing to STR, new line corridors are continuously required to address increasing electricity demands while minimizing the curtailment of renewable energy sources (RES). However, the expansion of an electricity network is expansive, long, and limited due to the scarcity in land and space. To overcome this issue, researchers have proposed a dynamic thermal rating (DTR) system that can increase the capacity of existing transmission lines. Research has shown that actual line ratings are higher than STR most of the time. The potential of using the DTR system to increase the reliability of power systems is therefore significant. Almost every country has begun the process of increasing the integration of RES, and consequently, the DTR system has become increasingly important. Exploring and reviewing critical studies on the DTR system are thus beneficial for researchers who are interested in the developments of DTR technology. This review paper begins by comparing the two main DTR system standards. Then, monitoring technologies of the DTR system are reviewed. Notable research on the reliability impacts of the DTR system on electrical networks are surveyed. Interactions with wind power and other smart grid technologies are also examined, and the concept of power system reliability is briefly discussed.","['Conductors', 'Cooling', 'Temperature sensors', 'IEEE Standards', 'Solar heating', 'Power system reliability']","['Dynamic thermal rating systems', 'standards', 'power system', 'reliability', 'wind power', 'weather']"
"A rise in the population has immensely increased the pressure on the agriculture sector. With the advent of technology, this decade is witnessing a shift from conventional approaches to the most advanced ones. The Internet of Things (IoT) has transformed both the quality and quantity of the agriculture sector. Hybridization of species along with the real-time monitoring of the farms paved a way for resource optimization. Scientists, research institutions, academicians, and most nations across the globe are moving towards the practice and execution of collaborative projects to explore the horizon of this field for serving mankind. The tech industry is racing to provide more optimal solutions. Inclusion of IoT, along with cloud computing, big data analytics, and wireless sensor networks can provide sufficient scope to predict, process, and analyze the situations and improve the activities in the real-time scenario. The concept of heterogeneity and interoperability of the devices by providing flexible, scalable, and durable methods, models are also opening new domains in this field. Therefore, this paper contributes towards the recent IoT technologies in the agriculture sector, along with the development of hardware and software systems. The public and private sector projects and startup's started all over the globe to provide smart and sustainable solutions in precision agriculture are also discussed. The current scenario, applications, research potential, limitations, and future aspects are briefly discussed. Based on the concepts of IoT a precision farming framework is also proposed in this article.","['Agriculture', 'Internet of Things', 'Sociology', 'Statistics', 'Wireless sensor networks', 'Monitoring', 'Diseases']","['Artificial intelligence', 'cloud computing', 'Internet of Things', 'precision agriculture', 'wireless sensor networks']"
"A team of robots are deployed to accomplish a task while maintaining a viable ad-hoc network capable of supporting data transmissions necessary for task fulfillment. Solving this problem necessitates: 1) estimation of the wireless propagation environment to identify viable point-to-point communication links; 2) determination of end-to-end routes to support data traffic; and 3) motion control algorithms to navigate through spatial configurations that guarantee required minimum levels of service. Therefore, we present methods for: 1) estimation of point-to-point channels using pathloss and spatial Gaussian process models; 2) data routing so as to determine suitable end-to-end communication routes given estimates of point-to-point channel rates; and 3) motion planning to determine robot trajectories restricted to configurations that ensure survival of the communication network. Because of the inherent uncertainty of wireless channels, the model of links and routes is stochastic. The criteria for route selection is to maximize the probability of network survival-defined as the ability to support target communication rates-given achievable rates on local point-to-point links. Maximum survival probability routes for present and future positions are input into a mobility control module that determines robot trajectories restricted to configurations that ensure the probability of network survival stays above a minimum reliability level. Local trajectory planning is proposed for simple environments and global planning is proposed for complex surroundings. The three proposed components are integrated and tested in experiments run in two different environments. Experimental results show successful navigation with continuous end-to-end connectivity.","['Routing', 'Wireless communication', 'Trajectory', 'Robot kinematics', 'Planning', 'Shadow mapping']","['Routing protocols', 'path planning', 'wireless networks', 'autonomous agents']"
"Detection and classification of any anomaly at its commencement are very crucial for optimal management of assets in power system grids. This paper presents a novel hybrid approach that combines S-transform (ST) and feedforward neural network (FFNN) for the detection and classification of distribution grid faults. In this proposed strategy, the measured three-phase current signals are processed through ST with a view to extracting useful statistical features. The extracted features are then fetched to FFNN in order to detect and classify different types of faults. The proposed approach is implemented in two different test distribution grids modeled and simulated in real-time digital simulator and MATLAB/SIMULINK. The obtained results justify the efficacy of the presented technique for both noise-free and noisy data. In addition, the developed technique is independent of fault resistance, inception angle, distance, and prefault loading condition. Besides, the comparative results confirm the superiority and competitiveness of the developed technique over the available techniques reported in the literature.","['Feature extraction', 'Noise measurement', 'Loading', 'Transforms', 'Time-frequency analysis', 'Electrical resistance measurement', 'Feedforward neural networks']","['Additive white Gaussian noise', 'distribution grid', 'fault detection', 'fault classification', 'feature extraction', 'feedforward neural network', 'S-transform']"
"Internet of Things (IoT) devices are operating in various domains like healthcare environment, smart cities, smart homes, transportation, and smart grid system. These devices transmit a bulk of data through various sensors, actuators, transceivers, or other wearable devices. Data in the IoT environment is susceptible to many threats, attacks, and risks. Therefore, a robust security mechanism is indispensable to cope with attacks, vulnerabilities, security, and privacy challenges related to IoT. In this research, a systematic literature review has been conducted to analyze the security of IoT devices and to provide the countermeasures in response to security problems and challenges by using mobile computing. A comprehensive and in-depth security analysis of IoT devices has been made in light of mobile computing, which is a novel approach. Mobile computing's technological infrastructures such as smartphones, services, policies, strategies, and applications are employed to tackle and mitigate these potential security threats. In this paper, the security challenges and problems of IoT devices are identified by a systematic literature review. Then, mobile computing has been used to address these challenges by providing potential security measures and solutions. Hardware and software-based solutions furnished by mobile computing towards the IoT security challenges have been elaborated. To the best of our knowledge, this is the first attempt to analyze the security issues and challenges of IoT in light of mobile computing and it will open a gateway towards future research.","['Security', 'Mobile computing', 'Systematics', 'Bibliographies', 'Internet of Things', 'Privacy', 'Smart phones']","['Internet of Things devices', 'security', 'mobile computing', 'mobile applications', 'smartphone']"
"Over the past few years, with the advent of blockchain technology, there has been a massive increase in the usage of Cryptocurrencies. However, Cryptocurrencies are not seen as an investment opportunity due to the market's erratic behavior and high price volatility. Most of the solutions reported in the literature for price forecasting of Cryptocurrencies may not be applicable for real-time price prediction due to their deterministic nature. Motivated by the aforementioned issues, we propose a stochastic neural network model for Cryptocurrency price prediction. The proposed approach is based on the random walk theory, which is widely used in financial markets for modeling stock prices. The proposed model induces layer-wise randomness into the observed feature activations of neural networks to simulate market volatility. Moreover, a technique to learn the pattern of the reaction of the market is also included in the prediction model. We trained the Multi-Layer Perceptron (MLP) and Long Short-Term Memory (LSTM) models for Bitcoin, Ethereum, and Litecoin. The results show that the proposed model is superior in comparison to the deterministic models.","['Neural networks', 'Predictive models', 'Market research', 'Bitcoin', 'Stochastic processes']","['Cryptocurrency', 'multilayer perceptron', 'long short-term memory', 'random walk', 'stochasticity']"
"Blockchain is a revolutionary technology that enables users to communicate in a trust-less manner. It revolutionizes the modes of business between organizations without the need for a trusted third party. It is a distributed ledger technology based on a decentralized peer-to-peer (P2P) network. It enables users to store data globally on thousands of computers in an immutable format and empowers users to deploy small pieces of programs known as smart contracts. The blockchain-based smart contract enables auto enforcement of the agreed terms between two untrusted parties. There are several security vulnerabilities in Ethereum blockchain-based smart contracts, due to which sometimes it does not behave as intended. Because a smart contract can hold millions of dollars as cryptocurrency, so these security vulnerabilities can lead to disastrous losses. In this paper, a systematic review of the security vulnerabilities in the Ethereum blockchain is presented. The main objective is to discuss Ethereum smart contract security vulnerabilities, detection tools, real life attacks and preventive mechanisms. Comparisons are drawn among the Ethereum smart contract analysis tools by considering various features. From the extensive depth review, various issues associated with the Ethereum blockchain-based smart contract are highlighted. Finally, various future directions are also discussed in the field of the Ethereum blockchain-based smart contract that can help the researchers to set the directions for future research in this domain.","['Smart contracts', 'Blockchains', 'Security', 'Codes', 'Libraries', 'Systematics', 'Programming']","['Blockchain', 'smart contract', 'decentralized', 'ethereum', 'vulnerabilities', 'security analysis tool']"
"Controlling or accessing remotely has become a prevalent form of operating numerous types of platforms and infrastructure. An exploding number of vehicles such as drones or cars, in particular, are being controlled wirelessly or connected through networks. This has brought unanimous concern that today's networked vehicle systems are vulnerable to attacks and the results could be fatal. Unfortunately, in contrast to active investigation on the security of the vehicles themselves, sensors, or communication channels, existing approaches for these real-time, safety-critical systems do not take controllers into enough consideration. In order to protect the controller that performs the arithmetic operations using sensor measurements and generates command signals, we adopt homomorphic cryptography for the controller. It removes risks associated with the management of the secret key inside the controller, by eliminating the need to encrypt and decrypt the data for the mathematical operation within the controller. Specifically, we propose an efficient linearly homomorphic authenticated encryption (LinHAE) scheme for the ground control center of a multi-rotor drone, in a manner that enables real-time operation for safe autonomous flight. To facilitate the linear scheme, we design the ground controller targeted to allow state update using additions and multiplications by a system-specific constant. The proposed LinHAE guarantees the security against eavesdropping and forgery attacks, unlike homomorphic encryption alone that does not provide means to check whether the received signal at the drone side is authentic or compromised. We introduce a LinHAE with security and computational tractability, and describe how it can fit into the standard architecture for drone systems and how the specific controller is implemented. Building on these ingredients, we report the first successful operation of a multi-rotor flying robot that autonomously flies under the ground controller with real-time homomorphic authenticated encryption.","['Drones', 'Encryption', 'Sensors', 'Real-time systems', 'Control systems']","['Cryptography', 'encryption', 'cyber-physical systems', 'control design', 'unmanned aerial vehicles']"
"Digital respiratory sounds provide valuable information for telemedicine and smart diagnosis in an non-invasive way of pathological detection. As the typical continuous abnormal respiratory sound, wheeze is clinically correlated with asthma or chronic obstructive lung diseases. Meanwhile, the discontinuous adventitious crackle is clinically correlated with pneumonia, bronchitis, and so on. The detection and classification of both attract many studies for decades. However, due to the contained artifacts and constrained feature extraction methods, the reliability and accuracy of the classification of wheeze, crackle, and normal sounds need significant improvement. In this paper, we propose a novel method for the identification of wheeze, crackle, and normal sounds using the optimized S-transform (OST) and deep residual networks (ResNets). First, the raw respiratory sound is processed by the proposed OST. Then, the spectrogram of OST is rescaled for the Resnet. After the feature learning and classification are fulfilled by the ResNet, the classes of respiratory sounds are recognized. Because the proposed OST highlights the features of wheeze, crackle, and respiratory sounds, and the deep residual learning generates discriminative features for better recognition, this proposed method provides reliable access for respiratory disease-related telemedicine and E-health diagnosis. The experimental results show that the proposed OST and ResNet is excellent for the multi-classification of respiratory sounds with the accuracy, sensitivity, and specificity up to 98.79%, 96.27% and 100%, respectively. The comparison results of the triple-classification of respiratory sounds indicate that the proposed method outperforms the deep-learning-based ensembling convolutional neural network (CNN) by 3.23% and the empirical mode decomposition-based artificial neural network (ANN) by 4.63%, respectively.","['Feature extraction', 'Spectrogram', 'Time-frequency analysis', 'Diseases', 'Transforms', 'Training', 'Lung']","['Deep residual networks (ResNet)', 'optimized S-transform (OST)', 'respiratory sounds classification', 'crackle and wheeze detection']"
"Biometric systems are used for the verification and identification of individuals using their physiological or behavioral features. These features can be categorized into unimodal and multimodal systems, in which the former have several deficiencies that reduce the accuracy of the system, such as noisy data, inter-class similarity, intra-class variation, spoofing, and non-universality. However, multimodal biometric sensing and processing systems, which make use of the detection and processing of two or more behavioral or physiological traits, have proved to improve the success rate of identification and verification significantly. This paper provides a detailed survey of the various unimodal and multimodal biometric sensing types providing their strengths and weaknesses. It discusses the stages involved in the biometric system recognition process and further discusses multimodal systems in terms of their architecture, mode of operation, and algorithms used to develop the systems. It also touches on levels and methods of fusion involved in biometric systems and gives researchers in this area a better understanding of multimodal biometric sensing and processing systems and research trends in this area. It furthermore gives room for research on how to find solutions to issues on various unimodal biometric systems.","['Biometrics (access control)', 'Identification', 'Formal verification', 'Noise measurement', 'Physiology', 'Market research', 'Behavioral science', 'Sensors', 'Performance evaluation']","['Biometrics', 'identification', 'verification', 'multimodal', 'unimodal', 'sensing', 'non-universality']"
"Crowding within emergency departments (EDs) can have significant negative consequences for patients. EDs therefore need to explore the use of innovative methods to improve patient flow and prevent overcrowding. One potential method is the use of data mining using machine learning techniques to predict ED admissions. This paper uses routinely collected administrative data (120 600 records) from two major acute hospitals in Northern Ireland to compare contrasting machine learning algorithms in predicting the risk of admission from the ED. We use three algorithms to build the predictive models: 1) logistic regression; 2) decision trees; and 3) gradient boosted machines (GBM). The GBM performed better (accuracy = 80.31%, AUC-ROC = 0.859) than the decision tree (accuracy = 80.06%, AUC-ROC = 0.824) and the logistic regression model (accuracy = 79.94%, AUC-ROC = 0.849). Drawing on logistic regression, we identify several factors related to hospital admissions, including hospital site, age, arrival mode, triage category, care group, previous admission in the past month, and previous admission in the past year. This paper highlights the potential utility of three common machine learning algorithms in predicting patient admissions. Practical implementation of the models developed in this paper in decision support tools would provide a snapshot of predicted admissions from the ED at a given time, allowing for advance resource planning and the avoidance bottlenecks in patient flow, as well as comparison of predicted and actual admission rates. When interpretability is a key consideration, EDs should consider adopting logistic regression models, although GBM’s will be useful where accuracy is paramount.",[],[]
"In this work, we perform a comprehensive empirical study of smart contracts deployed on the ethereum blockchain. The objective of the analysis is to provide empirical results on smart contracts features, smart contract transactions within the blockchain, the role of the development community, and the source code characteristics. We collected a set of more than 10000 smart contracts source codes and a dataset of meta-data regarding their interaction with the blockchain from etherscan.io. We examined the collected data computing different statistics on naming policies, smart contract ether balance, number of smart contract transactions, functions, and other quantities characterizing the use and purpose of smart contracts. We found that the number of transactions and the balances follow power-law distributions and the software code metrics display, on average, values lower than corresponding metrics in standard software but have high variances. Focusing the attention on the 20 smart contracts with the topmost number of transactions, we found that most of them represent financial smart contracts and some of them have peculiar software development stories behind them. The results show that blockchain software is rapidly changing and evolving and it is no longer devoted only to cryptovalues applications but to general purpose computation.","['Smart contracts', 'Blockchain', 'Software', 'Measurement', 'Computer languages', 'Computer bugs']","['Blockchain', 'code metrics', 'ethereum', 'smart contracts', 'solidity']"
"This paper proposes and designs a best path selection algorithm, which can solve the problem of path planning for intelligent driving vehicles in the case of restricted driving, traffic congestions and accidents. We tried to solve the problem under these emergency situations in path planing process for there's no driver in intelligent driving vehicle. We designed a new method of the best path selection with length priority based on the prior knowledge applied reinforcement learning strategy, and improved the search direction setting of A* shortest path algorithm in the program. This best path planing algorithm can effectively help different types of intelligent driving vehicles to select the best path in the traffic network with limited height, width and weight, accidents and traffic jams. Through simulation experiments and practical test, it is proved that the proposed algorithm has good stability, high efficiency and practicability.","['Path planning', 'Reinforcement learning', 'Accidents', 'Intelligent vehicles', 'Roads', 'Heuristic algorithms', 'Planning']","['Reinforcement learning', 'intelligent driving', 'path planning', 'shortest path algorithm']"
"Currently, Internet of Things (IoT) as an essential infrastructure proposed for industries and different applications has been popularly applied to different domains, such as healthcare and smart farming, for helping people to do something, aiming to improve our living environments. LoRaWAN, as a Long-Range Wide Area Network specification recommended by the LoRa Alliance, is a low power and long distance communication protocol suitable for IoT environments. This protocol adopts a widely used data encryption method, i.e., Advanced Encryption Standard (AES), developed based on powerful algebra operations and multiple encryption cycles to ensure its communication security. LoRaWAN reduces communication power by setting different transmission latencies for different end-devices; however, AES does not take into account its end device's encryption power. In this paper, a high secure but low-power consumption communication scheme for the LoRaWAN, named the Secure Low Power Communication (SeLPC) method, is proposed to further reduce end-devices' data encryption power by reducing encryption cycles of AES. In the SeLPC, encryption key and D-Box update procedure is presented to enhance security level and simplify the AES encryption process so that the power consumption can be further lowered. Comparing with the traditional AES, the analysis results show that the SeLPC can minimize the encryption power up to 26.2%. The SeLPC can also resist three attacks, including known-key, replay, and eavesdropping attacks and is practically helpful for use in LoRaWAN IoT environments.","['Encryption', 'Servers', 'Logic gates', 'Power demand', 'Network servers', 'Internet of Things']","['LoRaWAN', 'low power', 'data encryption', 'AES', 'Internet of Things']"
"Content caching at base stations is a promising solution to address the large demands for mobile data services over cellular networks. Content caching is a challenging problem as it requires predicting the future popularity of the content and the operating characteristics of the cellular networks. In this paper, we focus on constructing an algorithm that improves the users' quality of experience (QoE) and reduces network traffic. The algorithm accounts for users' behavior and properties of the cellular network (e.g. cache size, bandwidth, and load). The constructed content and network aware adaptive caching scheme uses an extreme-learning machine neural network to estimate the popularity of content, and mixed-integer linear programming to compute where to place the content and select the physical cache sizes in the network. The proposed caching scheme simultaneously performs efficient cache deployment and content caching. Additionally, a simultaneous perturbation stochastic approximation method is developed to reduce the number of neurons in the extreme-learning machine method while ensuring a sufficient predictive performance is maintained. Using real-world data from YouTube and a NS-3 simulator, we demonstrate how the caching scheme improves the QoE of users and network performance compared with industry standard caching schemes.","['Cellular networks', 'Adaptive systems', 'Base stations', 'YouTube', 'Delays']","['Content caching', 'cellular network', 'extreme learning machines', 'mixed-integer linear programming', 'popularity prediction', 'feature selection', 'YouTube']"
"The promise of low latency connectivity and efficient bandwidth utilization has driven the recent shift from vehicular cloud computing (VCC) towards vehicular edge computing (VEC). This paper presents an advanced deep learning-based computational offloading algorithm for multilevel vehicular edge-cloud computing networks. To conserve energy and guarantee the efficient utilization of shared resources among multiple vehicles, an integration model of computational offloading, and resource allocation is formulated as a binary optimization problem to minimize the total cost of the entire system in terms of time and energy. However, this problem is considered NP-hard and it is computationally prohibitive to solve this type of problem, particularly for large-scale vehicles, due to the curse-of-dimensionality problem. Therefore, an equivalent reinforcement learning form is generated and we propose a distributed deep learning algorithm to find the near-optimal computational offloading decisions in which a set of deep neural networks are used in parallel. Finally, simulation results show that the proposed algorithm can exhibit fast convergence and significantly reduce the overall consumption of an entire system compared to the benchmark solutions.","['Servers', 'Computational modeling', 'Task analysis', 'Optimization', 'Edge computing', 'Machine learning', 'Resource management']","['Computation offloading', 'vehicular edge-cloud computing', 'autonomous vehicles', '5G', 'resource allocation', 'deep reinforcement learning']"
"In traditional electronic health records (EHRs), medical-related information is generally separately controlled by different hospitals and thus it leads to the inconvenience of information sharing. Cloud-based EHRs solve the problem of information sharing in the traditional EHRs. However, cloud-based EHRs suffer the centralized problem, i.e., cloud service center and key-generation center. This paper works on creating a new EHRs paradigm which can help in dealing with the centralized problem of cloud-based EHRs. Our solution is to make use of the emerging technology of blockchain to EHRs (denoted as blockchain-based EHRs for convenience). First, we formally define the system model of blockchain-based EHRs in the setting of consortium blockchain. In addition, the authentication issue is very important for EHRs. However, existing authentication schemes for blockchain-based EHRs have their own weak points. Therefore, in this paper, we also propose an authentication scheme for blockchain-based EHRs. Our proposal is an identity-based signature scheme with multiple authorities which can resist collusion attack out of N from N-1 authorities. Furthermore, our scheme is provably secure in the random oracle model and has more efficient signing and verification algorithms than existing authentication schemes of blockchain-based EHRs.","['Hospitals', 'Blockchain', 'Authentication', 'Medical diagnostic imaging', 'Servers', 'Insurance']","['Electronic health records', 'blockchain', 'identity-based signatures', 'multiple authorities']"
"Reducing greenhouse gas emissions becomes a top priority in the world with the emergence of global warming and environmental problems. Various renewable energies appear during the last decades. Ocean captures and stores huge amounts of energy, which could satisfy five times of world energy demand. Due to technology limitations and economic considerations, marine current energy appears the most attractive choice compared with the other ocean energy form. Although the existing expertise and technology in offshore wind energy conversion system can be partially transferred to marine current energy conversion system due to the similar structure, there are still many technological challenges to overcome. Meanwhile, the system operates under the water will inevitably have some negative or positive impacts on the surrounding environment. In this paper, it shows the interest and the principle of the marine current energy, and also discusses the advantages and disadvantages. The environmental impacts around the devices, the technological challenges, and the essential support structures are presented as well. The state-of-the-art horizontal axis turbines and their relative technologies and the latest projects are described finally. This review paper gives the useful information about the attraction and challenge of the marine current energy, and the newest development of the technologies and projects.","['Tides', 'Hydraulic turbines', 'Energy conservation', 'Renewable energy sources', 'Offshore installations', 'Wind turbines', 'Power generation', 'Global warming']","['Marine technology', 'oceanic engineering and marine technology', 'turbines', 'reviews', 'marine current energy', 'characteristic', 'technical challenges', 'support structure', 'projects']"
"Cloud is a computing model that provides sharing and supports ubiquitous on-demand access computing, providing new data processing and services for many industries, significantly reducing user computing and storage costs, and improving ease of use. With the development of cloud-scale and intensification, cloud security has become an essential issue in the field of cloud computing. Access control is one of the critical security technologies for protecting sensitive data stored in the cloud by enterprises and individuals. Since the centralized access control mechanism is adopted in the cloud, the sensitive data in the cloud are easy to be tampered with or leaked by hackers or cloud internal managers. To address this issue, we propose a blockchain-based access control framework with privacy protection called AuthPrivacyChain. Firstly, we use the account address of the node in blockchain as the identity, and at the same time, redefine the access control permission of data for the cloud, which is encrypted and stored in blockchain. After that, we design processes of access control, authorization, and authorization revocation in AuthPrivacyChain. Finally, we implement AuthPrivacyChain based on enterprise operation system (EOS), and the results show that AuthPrivacyChain can not only prevent hackers and administrators from illegally accessing resources, but also protect authorized privacy.","['Cloud computing', 'Authorization', 'Privacy', 'Distributed databases']","['Cloud computing', 'cloud security', 'access control', 'blockchain', 'privacy protection']"
"Electrocardiogram (ECG) signals from mobile sensors are expected to increase the availability of authentication in the emerging wearable device industry. However, mobile sensors provide a relatively lower quality signal than the conventional medical devices. This paper proposes a practical authentication procedure for ECG signals that collected via one-chip-solution mobile sensors. We designed a cascading bandpass filter for noise cancellation and suggest eight fiducial features. For classification-based authentication, we use the radial basis function kernel-based support vector machine showing the best performance among nine classifiers through experimental comparisons. In spite of noisy ECG signals in mobile sensors, we achieved 4.61% of the equal error rate (EER) on a single heartbeat, and 1.87% of EER on 15 s testing time on 175 subjects, which is a reasonable result and supports the usability of low-cost ECGs for biometric authentication.","['Biometrics', 'Authentication', 'Biomedical signal processing', 'Electrocardiography', 'Sensors', 'Band-pass filters', 'Noise cancellation', 'Wireless sensor networks']","['Biometric', 'Authentication', 'Electrocardiogram', 'CardioChip', 'BMD101']"
"For most deep learning practitioners, recurrent networks are often used for sequence modeling. However, recent researches indicate that convolutional architectures may be used to optimize recurrent networks on some machine translation tasks. Problems here are which architecture we should use for a new sequence modeling. By integrating and systematically evaluating the general convolution and recurrent architecture used for sequence modeling, a convolution gated recurrent unit (CNN-GRU) network is proposed for the state-of-charge (SOC) estimation of lithium-ion batteries in this paper. Deep-learning models are well suited for SOC estimation because a battery management system is time-varying and non-linear. The CNN-GRU model is trained using data collected from the battery-discharging processes, such as the dynamic stress test and the federal urban driving schedule. The experimental results show that the proposed method can achieve higher estimation accuracy than two commonly used deep learning models (recurrent neural network and gated recurrent unit) and two traditional machine learning approaches (support vector machine and extreme learning machine) for SOC estimation of lithium-ion batteries.","['Logic gates', 'Estimation', 'Convolution', 'State of charge', 'Computer architecture', 'Lithium-ion batteries']","['State-of-charge estimation', 'convolutional gated recurrent unit', 'lithium-ion battery']"
"This paper presents a novel approach for the detection of tables present in documents, leveraging the potential of deep neural networks. Conventional approaches for table detection rely on heuristics that are error prone and specific to a dataset. In contrast, the presented approach harvests the potential of data to recognize tables of arbitrary layout. Most of the prior approaches for table detection are only applicable to PDFs, whereas, the presented approach directly works on images making it generally applicable to any format. The presented approach is based on a novel combination of deformable CNN with faster R-CNN/FPN. Conventional CNN has a fixed receptive field which is problematic for table detection since tables can be present at arbitrary scales along with arbitrary transformations (orientation). Deformable convolution conditions its receptive field on the input itself allowing it to mold its receptive field according to its input. This adaptation of the receptive field enables the network to cater for tables of arbitrary layout. We evaluated the proposed approach on two major publicly available table detection datasets: ICDAR-2013 and ICDAR-2017 POD. The presented approach was able to surpass the state-of-the-art performance on both ICDAR-2013 and ICDAR-2017 POD datasets with a F-measure of 0.994 and 0.968, respectively, indicating its effectiveness and superiority for the task of table detection.","['Feature extraction', 'Convolution', 'Layout', 'Task analysis', 'Hidden Markov models', 'Data mining']","['Deep learning', 'representation learning', 'convolutional neural networks', 'object detection', 'deformable convolution', 'table detection', 'table spotting', 'faster R-CNN', 'FPN']"
"The idea of big data has gained extensive attention from governments and academia all over the world. It is especially relevant for the establishment of a smart city environment combining complex heterogeneous data with data analytics and artificial intelligence (AI) technology. Big data is generated from many facilities and sensor networks in smart cities and often streamed and stored in the cloud storage platform. Ensuring the integrity and subsequent auditability of such big data is essential for the performance of AI-driven data analysis. Recent years has witnessed the emergence of many big data auditing schemes that are often characterized by third party auditors (TPAs). However, the TPA is a centralized entity, which is vulnerable to many security threats from both inside and outside the cloud. To avoid this centralized dependency, we propose a decentralized big data auditing scheme for smart city environments featuring blockchain capabilities supporting improved reliability and stability without the need for a centralized TPA in auditing schemes. To support this, we have designed an optimized blockchain instantiation and conducted a comprehensive comparison between the existing schemes and the proposed scheme through both theoretical analysis and experimental evaluation. The comparison shows that lower communication and computation costs are incurred with our scheme than with existing schemes.","['Big Data', 'Smart cities', 'Cloud computing', 'Reliability', 'Security']","['Big data', 'smart city', 'data auditing', 'blockchain']"
"Although the preclinical detection of Parkinson's disease (PD) has been explored, a practical, inexpensive, and overall screening diagnosis has yet to be made available. However, due to the large variability and complexity in progress of PD and the difficulties in gathering a single time-point measurement of a single sign, the goal of precision treatment and assessment severity would be impossible to achieve. Hence, the repeated monitoring and tracking of individuals during their daily living activities at different times would also be of great importance for treating this chronic disease. We propose a deep multi-layer perceptron (DMLP) classifier for behavior analysis to estimate the progression of PD using smartphones. This paper aims to identify severity in PD patients' actions by analyzing their speech and movement patterns, as measured with a smartphone accelerometer in their pocket at different times of the day. Popular machine learning classification algorithms, such as logistic regression, random forests, k-nearest neighbors, M5P, and DMLP, are applied on one dataset from the University of California Irvine and another dataset collected by the authors to classify each patient as being Parkinson positive or negative. We further measure the success of each method for their ability to correctly classify the patients into one of these categories. Of the experimental models, it is demonstrated that DMLP performs the best in both datasets.","['Smart phones', 'Diseases', 'Legged locomotion', 'Monitoring', 'Biomedical measurement', 'Sensors', 'Accelerometers']","['Parkinson’s disease', 'behavior analysis', 'DMLP', 'classification']"
"Due to the widespread popularity in both academia and industry, vehicular ad hoc networks (VANETs) have been used in a wide range of applications starting from intelligent transportation to e-health and itinerary planning. This paper proposes a new decentralized lightweight authentication and key agreement scheme for VANETs. In the proposed scheme, there are three types of mutual authentications: 1) between vehicles; 2) between vehicles and their respective cluster heads; and 3) between cluster heads and their respective roadside units. Apart from these authentications, the proposed scheme also maintains secret keys between roadside units for their secure communications. The rigorous formal and informal security analysis shows that the proposed scheme is capable to defend various malicious attacks. Moreover, the ns-2 simulation demonstrates the practicability of the proposed scheme in VANET environment.","['Authentication', 'Protocols', 'Vehicular ad hoc networks', 'Electronic mail', 'Roads', 'Computational modeling']","['Vehicular ad hoc networks', 'user authentication', 'key agreement', 'security', 'NS-2 simulation']"
"In this paper, a dual-band and high-efficiency circular polarization (CP) convertor based on anisotropic metamaterial (AMM) was proposed and investigated in microwave region. The proposed AMM based CP convertor is composed of a sub-wavelength metal grating sandwiched with bi-layered disk-split-ring (DSR) structure array, which can convert the normal incident CP wave to its orthogonal one around two adjacent frequency ranges. Based on the intrinsic anisotropic and Fabry-Perot-like cavity-enhanced effect, a high CP conversion efficiency can be achieved by applying the proposed AMM. Numerical simulation results indicate that the cross-polarization transmission coefficients can achieve maximum values of 0.84 at 4.5 GHz, and 0.92 at 7.9 GHz, respectively, which is in well agreement with experiment. In addition, the measured CP conversion efficiency is beyond 99% at resonance frequencies. The mechanism of the CP conversion properties can be explained by the electromagnetic (EM) interference model and the simulated electrical field distribution. Due to its excellent polarization conversion properties, the proposed CP convertor based on AMM structure shows potential application in such as radar, remote sensing, and satellite communication.","['Converters', 'Dual band', 'Gratings', 'Broadband antennas', 'Polarization', 'Interference', 'Broadband communication']","['Anisotropic metamaterial', 'circular polarization conversion', 'Fabry-Perot', 'interference model']"
"Many recent wireless sensor network (WSN) routing protocols are enhancements to address specific issues with the “low-energy adaptive clustering hierarchy” (LEACH) protocol. Since the performance of LEACH deteriorates sharply with increasing network size, the challenge for new WSN protocols is to extend the network lifespan while maintaining high scalability. This paper introduces an energy-efficient clustering and hierarchical routing algorithm named energy-efficient scalable routing algorithm (EESRA). The goal of the proposed algorithm is to extend the network lifespan despite an increase in network size. The algorithm adopts a three-layer hierarchy to minimize the cluster heads' load and randomize the selection of cluster heads. Moreover, EESRA uses multi-hop transmissions for intra-cluster communications to implement a hybrid WSN MAC protocol. This paper compares EESRA against other WSN routing protocols in terms of network performance with respect to changes in the network size. The simulation results show that EESRA outperforms the benchmarked protocols in terms of load balancing and energy efficiency on large-scale WSNs.","['Wireless sensor networks', 'Routing', 'Routing protocols', 'Clustering algorithms', 'Time division multiple access', 'Spread spectrum communication']","['Energy efficiency', 'LEACH', 'load balancing', 'scalability', 'wireless sensor networks']"
"This work presents a systematic design of high performance eight element antenna array for a 5G mobile terminal operating at 2.6/3.5 GHz bands. The proposed eight element slot antenna array based on unit monopole slot antenna embedded in the metal casing or ground resonates at fundamental mode at 2.6 GHz. The antenna array is developed from four antennas (open-end slot antenna) etched near to the corner edges of the printed circuited board with supported pairs of vertically mounted slot antennas in middle section of the long edge ground plane. This combination of the antenna elements provided pattern diversity and enabled the smartphone in the reception of the signal in a different direction. The impedance bandwidth based on -10 dB return loss criteria cover from 2.4 GHz to 3.6 GHz includes the two allocated bands of (2400 MHz to 2600 MHz) and (3400 MHz to 3600 MHz) for 5G cellular communication systems. The vital MIMO performance measures as envelope correlation coefficient or ECC is less than 0.2 for any two antenna array meeting the required standard of less than 0.5 alongside the mean effective gain or MEG ratio of any two antenna meeting the required standard of less than 3 dB for power balance and optimal diversity performance. As modern smartphone demand desires slim handsets, the after mentioned compact multiple antenna structure can be easily implemented for the future smartphones as it utilizes the conductive sheet or chassis and the middle vertically mounted antenna do not use the additional space of the chassis or ground. The customer hand or human hand effect on the multiple antenna array to mimic the use of mobile phone customer is also studied. The maximum MIMO Channel capacity based on measured result is 34.25bps/Hz and is about 3 times of 2 × 2 MIMO operations.","['Slot antennas', 'MIMO communication', 'Antenna arrays', 'Antenna measurements', 'Scattering parameters', '5G mobile communication']","['Channel capacity', 'envelope correlation coefficient', 'mean effective gain', 'mutual coupling', 'slot antennas', 'multiple input multiple output']"
"Face recognition has become a fascinating field for researchers. The motivation behind the enormous interest in the topic is the need to improve the accuracy of many real-time applications. The complexity of the human face and the changes due to different effects make it more challenging to design as well as implement a powerful computational system for human face recognition. In this paper, we presented an enhanced approach to improve human face recognition using a back-propagation neural network (BPNN) and features extraction based on the correlation between the training images. A key contribution of this paper is the generation of a new set called the T-Dataset from the original training data set, which is used to train the BPNN. We generated the T-Dataset using the correlation between the training images without using a common technique of image density. The correlated T-Dataset provides a high distinction layer between the training images, which helps the BPNN to converge faster and achieve better accuracy. Data and features reduction are essential in the face recognition process, and researchers have recently focused on the modern neural network. Therefore, we used a local binary pattern histogram descriptor to prove that there is potential improvement even using traditional methods. We applied five distance measurement algorithms and then combined them to obtain the T-Dataset, which we fed into the BPNN. We achieved higher face recognition accuracy with less computational cost compared with the current approach by using reduced image features. We test the proposed framework on two small data sets, the YALE and AT&T data sets, as the ground truth. We achieved tremendous accuracy. Furthermore, we evaluate our method on one of the state-of-the-art benchmark data sets, Labeled Faces in the Wild (LFW), where we produce a competitive face recognition performance.","['Face recognition', 'Face', 'Feature extraction', 'Histograms', 'Training', 'Artificial neural networks']","['Local binary patterns histogram (LBPH)', 'Haar-cascade detection', 'K-nearest-neighbor', 'back-propagation neural network (BPNN)', 'labeled faces in the wild (LFW)']"
"The use of data-driven ensemble approaches for the prediction of the solar Photovoltaic (PV) power production is promising due to their capability of handling the intermittent nature of the solar energy source. In this work, a comprehensive ensemble approach composed by optimized and diversified Artificial Neural Networks (ANNs) is proposed for improving the 24h-ahead solar PV power production predictions. The ANNs are optimized in terms of number of hidden neurons and diversified in terms of the diverse training datasets used to build the ANNs, by resorting to trial-and-error procedure and BAGGING techniques, respectively. In addition, the Bootstrap technique is embedded to the ensemble for quantifying the sources of uncertainty that affect the ensemble models' predictions in the form of Prediction Intervals (PIs). The effectiveness of the proposed ensemble approach is demonstrated by a real case study regarding a grid-connected solar PV system (231 kWac capacity) installed on the rooftop of the Faculty of Engineering at the Applied Science Private University (ASU), Amman, Jordan. The results show that the proposed approach outperforms three benchmark models, including smart persistence model and single optimized ANN model currently adopted by the PV system's owner for the prediction task, with a performance gain reaches up to 11%, 12%, and 9%, for RMSE, MAE, and WMAE standard performance metrics, respectively. Simultaneously, the proposed approach has shown superior in quantifying the uncertainty affecting the power predictions, by establishing slightly wider PIs that achieve the highest confidence level reaches up to 84% for a predefined confidence level of 80% compared to three other approaches of literature. These enhancements would, indeed, allow balancing power supplies and demands across centralized grid networks through economic dispatch decisions between the energy sources that contribute to the energy mix.","['Production', 'Predictive models', 'Uncertainty', 'Biological system modeling', 'Meteorology', 'Training', 'Artificial neural networks']","['Artificial neural networks', 'ensemble', 'photovoltaic power', 'prediction', 'bootstrap', 'uncertainty quantification']"
"Currently, Machine Learning (ML) is becoming ubiquitous in everyday life. Deep Learning (DL) is already present in many applications ranging from computer vision for medicine to autonomous driving of modern cars as well as other sectors in security, healthcare, and finance. However, to achieve impressive performance, these algorithms employ very deep networks, requiring a significant computational power, both during the training and inference time. A single inference of a DL model may require billions of multiply-and-accumulated operations, making the DL extremely compute- and energy-hungry. In a scenario where several sophisticated algorithms need to be executed with limited energy and low latency, the need for cost-effective hardware platforms capable of implementing energy-efficient DL execution arises. This paper first introduces the key properties of two brain-inspired models like Deep Neural Network (DNN), and Spiking Neural Network (SNN), and then analyzes techniques to produce efficient and high-performance designs. This work summarizes and compares the works for four leading platforms for the execution of algorithms such as CPU, GPU, FPGA and ASIC describing the main solutions of the state-of-the-art, giving much prominence to the last two solutions since they offer greater design flexibility and bear the potential of high energy-efficiency, especially for the inference process. In addition to hardware solutions, this paper discusses some of the important security issues that these DNN and SNN models may have during their execution, and offers a comprehensive section on benchmarking, explaining how to assess the quality of different networks and hardware systems designed for them.","['Hardware', 'Neurons', 'Biological neural networks', 'Computer architecture', 'Computational modeling', 'Field programmable gate arrays', 'Training']","['Machine learning', 'ML', 'artificial intelligence', 'AI', 'deep learning', 'deep neural networks', 'DNNs', 'convolutional neural networks', 'CNNs', 'capsule networks', 'spiking neural networks', 'VLSI', 'computer architecture', 'hardware accelerator', 'adversarial attacks', 'data flow', 'optimization', 'efficiency', 'performance', 'power consumption', 'energy', 'area', 'latency']"
"Real-time locating and tracking Technology plays a significant role in location-based IoT applications. With the extensive installation of WiFi access points, the WiFi based indoor positioning approach has become one of the most widely used location technologies. However, due to the limitations of wireless signals, the classic WiFi-based method has become labor-intensive. Recently, the WiFi-based two-way ranging approach was introduced into the 802.11-REVmc2 protocol, which is built on a new packet type known as fine timing measurement (FTM) frame. In this work, we introduce the round-trip time measurement with clock skew and analyze the distribution of the round trip time (RTT) ranging error. A calibration method is presented to eliminate the RTT range offset at the transmitter end. We also develop an integrated ranging algorithm based on the WiFi round trip time range and received signal strength to enhance the scalability and robustness of the positioning system. The experimental results demonstrate that the proposed fusion method achieves remarkable improvement in scalability and precision in both static and dynamic tests, including outdoor and indoor environments. Compared with the classic fingerprinting approach, the performance of the system is remarkably improved, and achieves an average positioning accuracy of 1.435 m with an update rate of every 0.19 s.","['Distance measurement', 'Fingerprint recognition', 'Wireless fidelity', 'Protocols', 'Indoor environments', 'Clocks']","['Indoor localization', 'smartphone', 'WiFi fine time measurement (FTMs)', 'round trip time (RTT)', 'received signal strength (RSS)', 'Kalman filter']"
"Internet of Drones (IoD) is a decentralized network and management framework that links drones' access to the controlled airspace and provides inter-location navigation services. The interconnection of drones in the IoD network is through the Internet of Things (IoT). Hence the IoD network is vulnerable to all the security and privacy threats that affect IoT networks. It is highly required to safeguard a good atmosphere free from security and privacy threats to get the desired performance from IoD applications. Security and privacy issues have significantly restricted the overall influence of the IoD paradigm. There are existing survey studies that helped lay a vital foundation for understanding the IoD security and privacy issues. However, not all have thoroughly investigated the level of security and privacy threats associated with the various drone categories. Besides, most existing review studies do not examine secured IoD architecture. This paper aims to assess the recent trends in the security and privacy issues that affect the IoD network. We investigate the level of security and privacy threats of the various drone categories. We then highlight the need for secured IoD architecture and propose one. We also give a comprehensive taxonomy of the attacks on the IoD network. Moreover, we review the recent IoD attack mitigating techniques. We also provide the performance evaluation methods and the performance metrics employed by the techniques. Finally, we give research future direction to help researchers identify the latest opportunities in IoD research.","['Drones', 'Security', 'Privacy', 'Taxonomy', 'Internet', 'Cryptography', 'Location awareness']","['Attacks', 'Internet of Drones', 'IoD architecture', 'localization error attacks', 'security and privacy', 'UAS', 'UAV', 'UUV']"
"Vehicular ad hoc networks (VANETs) are a subsystem of the proposed intelligent transportation system (ITS) that enables vehicles to communicate over the wireless communication infrastructure. VANETs are used in multiple applications, such as improving traffic safety and collision prevention. The use of VANETs makes the network vulnerable to various types of attacks, such as denial of service (DoS) and distributed denial of service (DDoS). Many researchers are now interested in adding a high level of security to VANETs. Machine learning (ML) methods were used for constructing a high level of security capabilities based on intrusion detection systems (IDSs). Furthermore, the vast majority of existing research is based on NSL-KDD or KDD-CUP99 datasets. Recent attacks are not present in these datasets. As a result, we employed a realistic dataset called ToN-IoT that derived from a large-scale, heterogeneous IoT network. This work tested various ML methods in both binary and multi-class classification problems. We used the Chi-square (Chi 2 ) technique was used for feature selection and the Synthetic minority oversampling technique (SMOTE) for class balancing. According to the results, the XGBoost method outperformed other ML methods.","['Support vector machines', 'Vehicular ad hoc networks', 'Radio frequency', 'Computer crime', 'Security', 'Industrial Internet of Things', 'Password']","['Intrusion detection system (IDS)', 'Internet of Things (IoT)', 'ToN-IoT dataset', 'machine learning (ML)', 'vehicular ad hoc networks (VANETs)']"
"Ensuring a seamless connection during the mobility of various User Equipments (UEs) will be one of the major challenges facing the practical implementation of the Fifth Generation (5G) networks and beyond. Several key determinants will significantly contribute to numerous mobility challenges. One of the most important determinants is the use of millimeter waves (mm-waves) as it is characterized by high path loss. The inclusion of various types of small coverage Base Stations (BSs), such as Picocell, Femtocell and drone-based BSs is another challenge. Other issues include the use of Dual Connectivity (DC), Carrier Aggregation (CA), the massive growth of mobiles connections, network diversity, the emergence of connected drones (as BS or UE), ultra-dense network, inefficient optimization processes, central optimization operations, partial optimization, complex relation in optimization operations, and the use of inefficient handover decision algorithms. The relationship between these processes and diverse wireless technologies can cause growing concerns in relation to handover associated with mobility. The risk becomes critical with high mobility speed scenarios. Therefore, mobility issues and their determinants must be efficiently addressed. This paper aims to provide an overview of mobility management in 5G networks. The work examines key factors that will significantly contribute to the increase of mobility issues. Furthermore, the innovative, advanced, efficient, and smart handover techniques that have been introduced in 5G networks are discussed. The study also highlights the main challenges facing UEs' mobility as well as future research directions on mobility management in 5G networks and beyond.","['Handover', '5G mobile communication', 'Optimization', 'Protocols', 'Wireless networks']","['Mobility management', 'handover', 'mobility challenges', 'handover problems', 'mobility robustness optimization', 'handover self-optimization', 'load balancing', '5G network', 'future ultra-dense networks']"
"Knowledge graph completion (KGC) is a hot topic in knowledge graph construction and related applications, which aims to complete the structure of knowledge graph by predicting the missing entities or relationships in knowledge graph and mining unknown facts. Starting from the definition and types of KGC, existing technologies for KGC are analyzed in categories. From the evolving point of view, the KGC technologies could be divided into traditional and representation learning based methods. The former mainly includes rule-based reasoning method, probability graph model, such as Markov logic network, and graph computation based method. The latter further includes translation model based, semantic matching model based, representation learning based and other neural network model based methods. In this article, different KGC technologies are introduced, including their advantages, disadvantages and applicable fields. Finally the main challenges and problems faced by the KGC are discussed, as well as the potential research directions.","['Cognition', 'Computational modeling', 'Semantics', 'Task analysis', 'Knowledge representation', 'Natural language processing']","['Knowledge graph', 'knowledge graph completion', 'entity prediction', 'relation prediction', 'deep learning']"
"For this paper, to consider both Bonferroni mean (BM) operator and two-tuple linguistic Pythagorean fuzzy numbers (2TLPFNs), we combine the weighted BM (WBM) operator, the generalized WBM (GWBM) operator, and the dual GWBM operator with 2TLPFNs to propose the two-tuple linguistic Pythagorean WBM (2TLPFWBM) operator, the 2TLPFWGBM operator, the generalized 2TLPFWBM (G2TLPFWBM) operator, the generalized 2TLPFWGBM operator, the dual G2TLPFWBM operator, and the dual G2TLPFWGBM operator. Then, some MADM procedures are developed based on these operators. At last, an applicable example for a safety assessment of construction project is given.","['Linguistics', 'Safety', 'Mathematical model', 'Fuzzy sets', 'Software', 'Business']","['MADM', '2TLPFSs', '2TLPFWBM operator', 'G2TLPFWBM operator', 'DG2TLPFWBM operator', 'safety assessment', 'construction project']"
"Breast cancer is the second most common cause of cancer-related deaths among women. Early detection leads to better prognosis and saves lives. The 5-year survival rate of breast cancer is 99% if it is located only in breast. Conventional computer-aided diagnosis (CADx) systems for breast cancer use the single view information of mammograms to assist the radiologists. More recent work has focused on more than one views. Existing multi-view based CADx systems normally employ only two views namely Cranio-Caudal (CC) and Medio-Lateral-Oblique (MLO). The information fusion of the two views proved the effectiveness of the system for mammogram classification which cannot be achieved by single view information. However, combining the information of four views of mammograms increases the performance of classification. In this study, we propose Multi-View Feature Fusion (MVFF) based CADx system using feature fusion technique of four views for classification of mammogram. The complete CADx tool contains three stages, the first stage have the ability to classify mammogram into abnormal or normal, second stage is about classification of mass or calcification and in the final stage classification of malignant or benign classification is performed. Convolutional Neural Network (CNN) based feature extraction models operate on each view separately. These extracted features were fused into one final layer for ultimate prediction. Our proposed system is trained on four views of mammograms, after data augmentation. We performed our experiments on publicly available datasets such as CBIS-DDSM (Curated Breast Imaging Subset of DDSM) and mini-MIAS database of mammograms. In comparison with literature the MVFF based system is performed better than a single view-based system for mammogram classification. We have achieved area under ROC curve (AUC) of 0.932 for mass and calcification and 0.84 for malignant and benign, which is higher than all single-view based systems. The value of AUC for normal and abnormal classification is 0.93.","['Mammography', 'Breast cancer', 'Deep learning', 'Feature extraction', 'Training']","['Breast cancer', 'classification', 'computer-aided diagnosis', 'deep learning', 'mammogram', 'multi-view', 'feature fusion', 'transfer learning']"
"Recently, directional modulation has become an active research area in wireless communications due to its security. Unlike existing research work, we consider a multi-beam directional modulation (MBDM) scenario with imperfect desired direction knowledge. In such a setting, a robust synthesis scheme is proposed for MBDM in broadcasting systems. In order to implement the secure transmission of a confidential message, the beamforming vector of the confidential message is designed to preserve its power as possible in the desired directions by minimizing its leakage to the eavesdropper directions while the projection matrix of artificial noise (AN) is to minimize the effect on the desired directions and force AN to the eavesdropper directions by maximizing the average receive signal-to-artificial-noise ratio at desired receivers. Simulation results show that compared with conventional methods, the proposed robust scheme achieves much better bit error rate performance along desired directions for a given signal-to-noise ratio (SNR). From the secrecy-rate aspect, the proposed scheme performs better than conventional methods for almost all SNR regions. In particular, in the medium and high SNR regions, the rate improvement of the proposed scheme over conventional methods is significant.","['Noise measurement', 'Bit error rate', 'Signal to noise ratio', 'Modulation', 'Wireless communication', 'Network security', 'Broadcasting', 'Array signal processing', 'Robustness', 'Multi-beam directional modulation']","['Multi-beam', 'directional modulation', 'robust', 'artificial noise', 'projection matrix', 'leakage', 'secrecy rate', 'bit error rate']"
"In this paper, the robustness of model-based state observers including extended Kalman filter (EKF) and unscented Kalman filter (UKF) for state of charge (SOC) estimation of a lithium-ion battery against unknown initial SOC, current noise, and temperature effects is investigated. To more comprehensively evaluate the performance of EKF and UKF, two battery models including the first-order resistor-capacitor equivalent circuit and combined model are considered. A novel method is proposed to identify the parameters of the equivalent circuit model. The performance of SOC estimation is evaluated by employing measurement data from a commercial lithium-ion battery cell. The experiment results show that UKF generally outperforms EKF in terms of estimation accuracy and convergence rate for each battery model. However, the advantages of UKF over EKF with the combined model is not as significant as with the equivalent circuit model. Both EKF and UKF demonstrate strong robustness against current noise. The updates of model parameters corresponding to operational temperatures generally improve the estimation accuracy of EKF and UKF for both models.","['State of charge', 'Integrated circuit modeling', 'Batteries', 'Kalman filters', 'Robustness', 'Observers']","['Extended Kalman filter', 'lithium-ion battery', 'robustness', 'state of charge', 'unscented Kalman filter']"
"In this paper, switched Z-source/quasi-Z-source dc-dc converters (SZSC/SQZSCs) are proposed for the photovoltaic (PV) grid-connected power system, where the high step-up dc-dc converters are required to boost the low voltage to high voltage. The boost factor is increased by adding another one switch and diode to the output terminals of traditional Z-source/quasi-Z-source dc-dc converters. Not only does the output capacitor function as the filter capacitor; it is also connected in series into the inductors' charging loops when both switches are turned on. Compared with existing Z-source based structures, higher boost factor is realized through a small duty cycle (smaller than 0.25). On the one hand, the instability caused by the saturation of the inductors can be avoided. On the other hand, a larger range can be reserved for the modulation index of the backend H-bridge when they are used for the dc-ac conversion. Moreover, much fewer passive components are employed when compared with the recently proposed hybrid 3-Z-network topologies that have the same voltage gain, which can enhance the power density and decrease the cost. The performances of the proposed converters, including their operational principles in continuous and discontinuous current modes, voltage and current parameters of components, and impacts of parasitic parameters, are analyzed. The simulation and experimental results are given to verify the aforementioned characteristics and theoretical analysis.","['Switches', 'Capacitors', 'Inductors', 'DC-DC power converters', 'Topology', 'Inverters', 'Circuit topology']","['PV systems', 'switched Z-source/quasi-Z-source', 'dc-dc converters', 'reduced passive components']"
"Owing to refraction, absorption, and scattering of light by suspended particles in water, raw underwater images have low contrast, blurred details, and color distortion. These characteristics can significantly interfere with visual tasks, such as segmentation and tracking. This paper proposes an underwater image enhancement solution through a deep residual framework. First, the cycle-consistent adversarial networks (CycleGAN) is employed to generate synthetic underwater images as training data for convolution neural network models. Second, the very-deep super-resolution reconstruction model (VDSR) is introduced to underwater resolution applications; with it, the Underwater Resnet model is proposed, which is a residual learning model for underwater image enhancement tasks. Furthermore, the loss function and training mode are improved. A multi-term loss function is formed with mean squared error loss and a proposed edge difference loss. An asynchronous training mode is also proposed to improve the performance of the multi-term loss function. Finally, the impact of batch normalization is discussed. According to the underwater image enhancement experiments and a comparative analysis, the color correction and detail enhancement performance of the proposed methods are superior to that of previous deep learning models and traditional methods.","['Image enhancement', 'Image color analysis', 'Image restoration', 'Scattering', 'Training data', 'Training', 'Task analysis']","['Asynchronous training', 'edge difference loss', 'residual learning', 'underwater image enhancement']"
"An area of intensive research under the umbrella of the Internet of Things (IoT) has resulted in intensive proliferation of globally deployed sensor devices that provide a basis for the development of different use-case applications working with real-time data and demanding a rich user interface. Overcoming the lack of the standard HTML platform, HTML5 specifications WebSocket and Canvas graphics strongly supported the development of rich real-time applications. Such support has been offered by browser plug-ins such as Adobe Flash and Microsoft Silverlight for years. In order to provide a deep insight into IoT Web application performance, we implemented two test applications. In the first application, we measured latencies induced by different communication protocols and message encodings, as well as graphics rendering performance, while comparing the performance of different Web platform implementations. In the second application, we compared Web performance of IoT messaging protocols such as MQTT, AMQP, XMPP, and DDS by measuring the latency of sensor data message delivery and the message throughput rate. Our tests have shown that although Adobe Flash has the best performance at the moment, HTML5 platform is also very capable of running real-time IoT Web applications, whereas Microsoft Silverlight is noticeably behind both platforms. On the other hand, MQTT is the most appropriate messaging protocol for a wide set of IoT Web applications. However, IoT application developers should be aware of certain MQTT message broker implementation shortcomings that could prevent the usage of this protocol.","['Internet of things', 'Real-time systems', 'Graphics', 'User interfaces', 'HTML', 'Sensors', 'Wireless sensor networks', 'Performance evaluation']","['Real-time systems', 'web and internet services', 'performance evaluation', 'sensor systems and applications']"
"Residential demand response is vital for the efficiency of power system. It has attracted much attention from both academic and industry in recent years. Accurate short-term load forecasting is a fundamental task for demand response. While short-term forecasting for aggregated load data has been extensively studied, load forecasting for individual residential users is still challenging due to the dynamic and stochastic characteristic of single users’ electricity consumption behaviors, i.e., the variability of the residential activities. To address this challenge, this paper presents a short-term residential load forecasting framework, which makes use of the spatio-temporal correlation existing in appliances’ load data through deep learning. Multiple time series are conducted in the framework to describe electricity consumption behaviors and their internal spatio-temporal relationship. And a method based on deep neural network and iterative ResBlock is proposed to learn the correlation among different electricity consumption behaviors for short-term load forecasting. Experiments based on real world measurements have been conducted to evaluate the performance of the proposed forecasting approach. The results show that both the appliances’ load data and iterative ResBlocks can help to improve the forecasting performance. Compared with existing methods, measurements on Root Mean Squared Error, Mean Absolute Error and Mean Absolute Percentage Error for the proposed approach are reduced by 3.89%-20.00%, 2.18%-22.58% and 0.69%-32.78%. In addition, further experiments are conducted to evaluate the impact of using appliances’ load data, iterative ResBlocks as well as other factors for the proposed approach.","['Load forecasting', 'Correlation', 'Home appliances', 'Load modeling', 'Forecasting', 'Deep learning', 'Predictive models']","['Smart grid', 'short-term load forecasting', 'deep learning', 'residential load forecasting', 'iterative ResBlocks']"
"Finite control set-model predictive control (FCS-MPC) has been used in power converters due to its advantages, such as fast dynamics, multi-objective control, and easy implement. However, due to variable switching frequency, the harmonics of inverter output current spread in a wide range of frequency. Furthermore, a large amount of computation is required for the implementation of the traditional FCS-MPC method. Here, an improved FCS-MPC algorithm with fast computation and fixed switching frequency is proposed in this paper for two-level three-phase inverters. First, according to the principle of deadbeat control, the inverter voltage vector reference can be constructed. Then, the operation durations and sequences of different voltage vectors are determined according to the location of the inverter voltage vector reference and the cost functions of different voltage vectors. In this algorithm, the operation durations of different voltage vectors are arranged inversely proportional to their cost functions. Compared with the conventional fixed switching frequency FCS-MPC control, the number of sectors involved in the FCS-MPC calculation can be reduced from 6 to 1, which greatly improves the computation efficiency. Moreover, the delay due to digital implementation is effectively compensated in the proposed algorithm. Finally, experimental tests are carried out to verify the advantages of the proposed method in terms of both steady-state and dynamic performance.",[],[]
"This paper presents the automatic load frequency control (ALFC) of two-area multisource hybrid power system (HPS). The interconnected HPS model consists of conventional and renewable energy sources operating in disparate combinations to balance the generation and load demand of the system. In the proffered work, the stability analysis of nonlinear dynamic HPS model was analyzed using the Hankel method of model order reduction. Also, an attempt was made to apply cascade proportional integral - proportional derivative (PI-PD) control for HPS. The gains of the controller were optimized by minimizing the integral absolute error (IAE) of area control error using particle swarm optimization-gravitational search algorithm (PSO-GSA) optimization technique. The performance of cascade control was compared with other classical controllers and the efficiency of this approach was studied for various cases of HPS model. The result shows that the cascade control produced better transient and steady state performances than those of the other classical controllers. The robustness analysis also reveals that the system overshoots/undershoots in frequency response pertaining to random change in wind power generation and load perturbations were significantly reduced by the proposed cascade control. In addition, the sensitivity analysis of the system was performed, with the variation in step load perturbation (SLP) of 1% to 5%, system loading and inertia of the system by ±25% of nominal values to prove the efficiency of the controller. Furthermore, to prove the efficiency of PSO-GSA tuned cascade control, the results were compared with other artificial intelligence (AI) methods presented in the literature. Further, the stability of the system was analyzed in frequency domain for different operating cases.","['Power system stability', 'Stability analysis', 'Optimization', 'Load modeling', 'Analytical models', 'Thermal stability', 'Wind power generation']","['Automatic load frequency control (ALFC)', 'hybrid power system (HPS)', 'cascade control scheme (CCs)', 'proportional integral – proportional derivative (PI-PD) control', 'Hankel method', 'particle swarm optimization – gravitational search algorithm (PSO-GSA)']"
"The Internet of Things (IoT) is a ubiquitous system connecting many different devices - the things - which can be accessed from the distance. The cyber-physical systems (CPSs) monitor and control the things from the distance. As a result, the concepts of dependability and security get deeply intertwined. The increasing level of dynamicity, heterogeneity, and complexity adds to the system's vulnerability, and challenges its ability to react to faults. This paper summarizes the state of the art of existing work on anomaly detection, fault-tolerance, and self-healing, and adds a number of other methods applicable to achieve resilience in an IoT. We particularly focus on non-intrusive methods ensuring data integrity in the network. Furthermore, this paper presents the main challenges in building a resilient IoT for the CPS, which is crucial in the era of smart CPS with enhanced connectivity (an excellent example of such a system is connected autonomous vehicles). It further summarizes our solutions, work-in-progress and future work to this topic to enable “Trustworthy IoT for CPS”. Finally, this framework is illustrated on a selected use case: a smart sensor infrastructure in the transport domain.","['Resilience', 'Security', 'Internet of Things', 'Cyber-physical systems', 'Robustness', 'Safety', 'Monitoring']","['Anomaly detection', 'cyber-physical systems (CPS)', 'Internet of Things (IoT)', 'monitoring', 'resilience', 'long-term dependability and security', 'self-adaptation', 'self-healing']"
"Now more and more data are being outsourced to cloud services. In order to ensure data security and privacy, data are usually stored on the cloud server in the form of ciphertext. When a user requests access to the encrypted data, an access key distributed by a third party is needed. However, if the third party is dishonest, the security of the system will be threatened. Faced with this problem, in this paper, we propose a new secure cloud storage framework with access control by using the Ethereum blockchain technology. Our new scheme is a combination of Ethereum blockchain and ciphertext-policy attribute-based encryption (CP-ABE). The proposed cloud storage framework is decentralized, that is, there is no trusted third party in the system. Our scheme has three main features. First, as the Ethereum blockchain technology is used, the data owner can store ciphertext of data through smart contracts in a blockchain network. Second, the data owner can set valid access periods for data usage so that the ciphertext can only be decrypted during valid access periods. Finally, as the creation and invocation of each smart contract can be stored in the blockchain, thus, the function of the trace is achieved. The analysis of the security and experiment shows that our scheme is feasible.","['Blockchain', 'Access control', 'Cloud computing', 'Encryption', 'Smart contracts', 'Computer science']","['Cloud storage', 'access control', 'Ethereum', 'blockchain', 'smart contract']"
"The rapid adoption of mobile devices has dramatically changed the access to various networking services and led to the explosion of mobile service traffic. Mobile service traffic classification has been a crucial task that attracts strong interest in mobile network management and security as well as machine learning communities for past decades. However, with more and more adoptions of encryption over mobile services, it brings a lot of challenges about mobile traffic classification. Although classical machine learning approaches can solve many issues that port and payload-based methods cannot solve, it still has some limitations, such as time-consuming, costly handcrafted features, and frequent features update. With the excellent ability of automatic feature learning, Deep Learning (DL) undoubtedly becomes a highly desirable approach for mobile services traffic classification, especially encrypted traffic. This survey paper looks at emerging research into the application of DL methods to encrypted traffic classification of mobile services and presents a general framework of DL-based mobile encrypted traffic classification. Moreover, we review most of the recent existing work according to dataset selection, model input design, and model architecture. Furthermore, we propose some noteworthy issues and challenges about DL-based mobile services traffic classification.","['Cryptography', 'Deep learning', 'Feature extraction', 'Hidden Markov models', 'Task analysis']","['Mobile services', 'encrypted traffic classification', 'traffic identification', 'deep Learning', 'CNN']"
"Harris Hawks Optimization (HHO) algorithm is a new metaheuristic algorithm, inspired by the cooperative behavior and chasing style of Harris' Hawks in nature called surprise pounce. HHO demonstrated promising results compared to other optimization methods. However, HHO suffers from local optima and population diversity drawbacks. To overcome these limitations and adapt it to solve feature selection problems, a novel metaheuristic optimizer, namely Chaotic Harris Hawks Optimization (CHHO), is proposed. Two main improvements are suggested to the standard HHO algorithm. The first improvement is to apply the chaotic maps at the initialization phase of HHO to enhance the population diversity in the search space. The second improvement is to use the Simulated Annealing (SA) algorithm to the current best solution to improve HHO exploitation. To validate the performance of the proposed algorithm, CHHO was applied on 14 medical benchmark datasets from the UCI machine learning repository. The proposed CHHO was compared with the original HHO and some famous and recent metaheuristics algorithms, containing Grasshopper Optimization Algorithm (GOA), Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Butterfly Optimization Algorithm (BOA), and Ant Lion Optimizer (ALO). The used evaluation metrics include the number of selected features, classification accuracy, fitness values, Wilcoxon's statistical test (P-value), and convergence curve. Based on the achieved results, CHHO confirms its superiority over the standard HHO algorithm and the other optimization algorithms on the majority of the medical datasets.","['Optimization', 'Classification algorithms', 'Feature extraction', 'Machine learning algorithms', 'Chaos', 'Sociology', 'Statistics']","['Harris Hawks optimization~(HHO) algorithm', 'feature selection', 'wrapper method', 'chaos theory', 'simulated annealing (SA)']"
"The Kingdom of Saudi Arabia is known for its extreme climate where temperatures can exceed 50 °C, especially in summer. Improving agricultural production can only be achieved using innovative environmentally suitable solutions and modern agricultural technologies. Using Internet of Things (IoT) technologies in greenhouse farming allows reduction of the immediate impact of external climatic conditions. In this paper, a highly scalable intelligent system controlling, and monitoring greenhouse temperature using IoT technologies is introduced. The first objective of this system is to monitor the greenhouse environment and control the internal temperature to reduce consumed energy while maintaining good conditions that improve productivity. A Petri Nets (PN) model is used to achieve both monitoring of the greenhouse environment and generating the suitable reference temperature which is sent later to a temperature regulation block. The second objective is to provide an Energy-Efficient (EE) scalable system design that handles massive amounts of IoT big data captured from sensors using a dynamic graph data model to be used for future analysis and prediction of production, crop growth rate, energy consumption and other related issues. The design tries to organize various possible unstructured formats of raw data, collected from different kinds of IoT devices, unified and technology-independent fashion using the benefit of model transformations and model-driven architecture to transform data in structured form.","['Data models', 'Air pollution', 'Green products', 'Internet of Things', 'Temperature sensors', 'Agriculture']","['Intelligent greenhouse agriculture', 'temperature control system', 'the~Internet of Things (IoT)', 'Petri nets (PNs)', 'graph database', 'model transformations', 'model-driven architecture (MDA)']"
"Blockchain technology is becoming increasingly attractive to the next generation, as it is uniquely suited to the information era. Blockchain technology can also be applied to the Internet of Things (IoT). The advancement of IoT technology in various domains has led to substantial progress in distributed systems. Blockchain concept requires a decentralized data management system for storing and sharing the data and transactions in the network. This paper discusses the blockchain concept and relevant factors that provide a detailed analysis of potential security attacks and presents existing solutions that can be deployed as countermeasures to such attacks. This paper also includes blockchain security enhancement solutions by summarizing key points that can be exploited to develop various blockchain systems and security tools that counter security vulnerabilities. Finally, the paper discusses open issues relating to and future research directions of blockchain-IoT systems.","['Blockchain', 'Security', 'Internet of Things', 'Privacy', 'Data privacy', 'Peer-to-peer computing', 'Tools']","['Blockchain', 'Internet of Things', 'threats and attacks', 'security']"
"The COVID-19 pandemic has triggered an urgent call to contribute to the fight against an immense threat to the human population. Computer Vision, as a subfield of artificial intelligence, has enjoyed recent success in solving various complex problems in health care and has the potential to contribute to the fight of controlling COVID-19. In response to this call, computer vision researchers are putting their knowledge base at test to devise effective ways to counter COVID-19 challenge and serve the global community. New contributions are being shared with every passing day. It motivated us to review the recent work, collect information about available research resources, and an indication of future research directions. We want to make it possible for computer vision researchers to find existing and future research directions. This survey article presents a preliminary review of the literature on research community efforts against COVID-19 pandemic.","['Computed tomography', 'Computer vision', 'Diseases', 'Lung', 'Sensitivity', 'X-ray imaging', 'Spirals']","['Artificial intelligence', 'COVID-19', 'computer vision', 'review', 'survey']"
"Loom malfunctions are the main cause of faulty fabric production. A fabric inspection system is a specialized computer vision system used to detect fabric defects for quality assurance. In this paper, a deep-learning algorithm was developed for an on-loom fabric defect inspection system by combining the techniques of image pre-processing, fabric motif determination, candidate defect map generation, and convolutional neural networks (CNNs). A novel pairwise-potential activation layer was introduced to a CNN, leading to high accuracy of defect segmentation on fabrics with intricate features and imbalanced dataset. The average precision and recall of detecting defects in the existing images reached, respectively, over 90% and 80% at the pixel level and the accuracy on counting the number of defects from a publicly available dataset exceeded 98%.","['Fabrics', 'Image segmentation', 'Convolutional neural networks', 'Inspection', 'Correlation', 'Neurons', 'Computer vision']","['Convolutional neural network', 'activation function', 'fabric defects', 'imbalanced dataset']"
"In this paper, we address the problem of confidentiality of keyframes, which are extracted from diagnostic hysteroscopy data using video summarization. We propose an image color coding method aimed at increasing the security of keyframes extracted from diagnostic hysteroscopy videos. In this regard, we use a 2-D logistic map to generate the cryptographic keys sequences, which relies on mixing and cascading the orbits of the chaotic map in order to generate the stream keys for the encryption algorithm. The encrypted images produced by our proposed algorithm exhibit randomness behavior, providing a high-level of security for the keyframes against various attacks. The experimental results and security analysis from different perspectives verify the superior security and high efficiency of our proposed encryption scheme compared to other state-of-the-art image encryption algorithms. Furthermore, the proposed method can be combined with mobile-cloud environments and can be generalized to ensure the security of cloud contents as well as important data during transmission.","['Encryption', 'Cloud computing', 'Data privacy', 'Two dimensional displays', 'Biomedical imaging']","['Image encryption', '2D chaotic map', 'diagnostic hysteroscopy', 'cloud content security']"
"This paper investigates the fault ride through (FRT) capability improvement of a doubly fed induction generator (DFIG)-based wind turbine using a dynamic voltage restorer (DVR). Series compensation of terminal voltage during fault conditions using DVR is carried out by injecting voltage at the point of common coupling to the grid voltage to maintain constant DFIG stator voltage. However, the control of the DVR is crucial in order to improve the FRT capability in the DFIG-based wind turbines. The combined feed-forward and feedback (CFFFB)-based voltage control of the DVR verifies good transient and steady-state responses. The improvement in performance of the DVR using CFFFB control compared with the conventional feed-forward control is observed in terms of voltage sag mitigation capability, active and reactive power support without tripping, dc-link voltage balancing, and fault current control. The advantage of utilizing this combined control is verified through MATLAB/Simulink-based simulation results using a 1.5-MW grid connected DFIG-based wind turbine. The results show good transient and steady-state response and good reactive power support during both balanced and unbalanced fault conditions.","['Voltage control', 'Rotors', 'Wind turbines', 'Stators', 'Power quality', 'Circuit faults', 'Reactive power']","['Doubly-fed induction generator (DFIG)', 'dynamic voltage restorer (DVR)', 'fault ride-through (FRT)', 'low voltage ride through (LVRT)', 'combined feed forward feedback control']"
"In order to enhance the efficiency and safety of production and management of modern agriculture in China, problems, such as the quality and safety of agricultural products and the pollution of the environment from agricultural activities, should be unraveled. Based on the new generation of information technology (IT), an integrated framework system platform incorporating the Internet of Things (IoT), cloud computing, data mining, and other technologies is investigated and a new proposal for its application in the field of modern agriculture is offered. The experimental framework and simulation design suggest that the basic functions of the monitoring system of the IoT for agriculture can be realized. In addition, the innovation derived from integrating different technologies plays an important role in reducing the cost of system development and ensuring its reliability as well as security.","['Cloud computing', 'Internet of Things', 'Logic gates', 'Monitoring', 'Production', 'Agricultural products']","['Management system', 'modern agriculture', 'big data', 'cloud computing', 'Internet of Things (IoT)']"
"Introducing IoT systems to healthcare applications has made it possible to remotely monitor patients' information and provide proper diagnostics whenever needed. However, providing high-security features that guarantee the correctness and confidentiality of patients' data is a significant challenge. Any alteration to the data could affect the patients' treatment, leading to human casualties in emergency conditions. Due to the high dimensionality and prominent dynamicity of the data involved in such systems, machine learning has the promise to provide an effective solution when it comes to intrusion detection. However, most of the available healthcare intrusion detection systems either use network flow metrics or patients' biometric data to build their datasets. This paper aims to show that combining both network and biometric metrics as features performs better than using only one of the two types of features. We have built a real-time Enhanced Healthcare Monitoring System (EHMS) testbed that monitors the patients' biometrics and collects network flow metrics. The monitored data is sent to a remote server for further diagnostic and treatment decisions. Man-in-the-middle cyber-attacks have been used, and a dataset of more than 16 thousand records of normal and attack healthcare data has been created. The system then applies different machine learning methods for training and testing the dataset against these attacks. Results prove that the performance has improved by 7% to 25% in some cases, and this shows the robustness of the proposed system in providing proper intrusion detection.","['Medical services', 'Monitoring', 'Security', 'Sensors', 'Biometrics (access control)', 'Measurement', 'Servers']","['Healthcare monitoring systems', 'IoT', 'machine learning', 'security', 'healthcare dataset']"
"Mobile edge computing (MEC) enhanced satellite based internet of things (SAT-IoT) is an important complement for terrestrial networks based IoT, especially for the remote and depopulated areas. For MEC enhanced SAT-IoT networks with multiple satellites and multiple satellite gateways, the coupled user association, offloading decision, computing and communication resource allocation should be jointly optimized to minimize the latency and energy cost. In this paper, the latency and energy optimization for MEC enhanced SAT-IoT networks are formulated as a dynamic mixed-integer programming problem, which is hard to obtain the optimal solutions. To tackle this problem, we decompose the complex problem into two sub-problems. The first one is computing and communication resource allocation with fixed user association and offloading decision, and the second one is joint user association and offloading with optimal resource allocation. For the sub-problem of resource allocation, the optimal solution is proven to be obtained based on Lagrange multiplier method. And then, the second sub-problem is further formulated as a Markov decision process (MDP), and a joint user association and offloading decision with optimal resource allocation (JUAOD-ORA) is proposed based on deep reinforcement learning (DRL). Simulation results show that the proposed approach can achieve better long-term reward in terms of latency and energy cost.","['Satellites', 'Resource management', 'Internet of Things', 'Logic gates', 'Task analysis', 'Optimization', 'Edge computing']","['Latency and energy optimization', 'MEC', 'SAT-IoT', 'deep reinforcement learning']"
"High-density communications in wireless sensor networks (WSNs) demand for new approaches to meet stringent energy and spectrum requirements. We turn to reinforcement learning, a prominent method in artificial intelligence, to design an energy-preserving MAC protocol, with the aim to extend the network lifetime. Our QL-MAC protocol is derived from Q-learning, which iteratively tweaks the MAC parameters through a trial-and-error process to converge to a low energy state. This has a dual benefit of 1) solving this minimization problem without the need of predetermining the system model and 2) providing a self-adaptive protocol to topological and other external changes. QL-MAC self-adjusts the WSN node duty-cycle, reducing energy consumption without detrimental effects on the other network parameters. This is achieved by adjusting the radio sleeping and active periods based on traffic predictions and transmission state of neighboring nodes. Our findings are corroborated by an extensive set of experiments carried out on off-the-shelf devices, alongside large-scale simulations.","['Wireless sensor networks', 'Reinforcement learning', 'Computational modeling', 'Media Access Protocol', 'Energy consumption', 'Informatics']","['Wireless sensor network', 'artificial intelligence', 'reinforcement learning', 'energy-efficient network', 'medium access control']"
"Due to the space inconsistency between benchmark image and segmentation result in many existing semantic segmentation algorithms for abdominal CT images, an improved model based on the basic framework of DeepLab-v3 is proposed, and Pix2pix network is introduced as the generation adversarial model. Our proposed model realizes the segmentation framework combining deep feature with multi-scale semantic feature. In order to improve the generalization ability and training accuracy of the model, this paper proposes a combination of the traditional multi-classification cross-entropy loss function with the content loss function of generator output and the adversarial loss function of discriminator output. A large number of qualitative and quantitative experimental results show that the performance of our proposed semantic segmentation algorithm is better than the existing algorithms, and can improve the segmentation efficiency while ensuring the space consistency of the semantics segmentation for abdominal CT images.","['Image segmentation', 'Semantics', 'Liver', 'Generators', 'Generative adversarial networks', 'Cancer', 'Convolution']","['Semantic segmentation', 'generation adversarial networks', 'weighted loss function', 'multi-scale features', 'game adversarial', 'atrous space pyramid pooling']"
"Accurate and reliable traffic flow forecasting is of importance for urban planning and mitigation of traffic congestion, and it is also the basis for the deployment of intelligent traffic management systems. However, constructing a reasonable and robust forecasting model is a challenging task due to the uncertainties and nonlinear characteristics of traffic flow. Aiming at the nonlinear relationship affecting traffic flow forecasting effect, a PSO-ELM model based on particle swarm optimization is proposed for short-term traffic flow forecasting, which takes the advantages of particle swarm optimization to search global optimal solution and extreme learning machine to fast deal with the nonlinear relationship. The proposed model improves the accuracy of traffic flow forecasting. The traffic flow data from highways A1, A2, A4, A8 connecting to Amsterdam's ring road are employed for the case study. The RMSEs of PSO-ELM model are respectively 252.61, 173.75, 200.24, 146.05, while the MAPEs of PSO-ELM model are respectively 11.86%, 10.10%, 10.74%, 11.60%. The experimental results show that the performance of the proposal is significantly better than the performance of state-of-the-art models.","['Forecasting', 'Predictive models', 'Particle swarm optimization', 'Training', 'Feedforward neural networks', 'Neurons', 'Computational modeling']","['Short-term traffic flow forecasting', 'extreme learning machine', 'particle swarm optimization', 'time-series model']"
"In the traditional cloud architecture, data needs to be uploaded to the cloud for processing, bringing delays in transmission and response. Edge network emerges as the times require. Data processing on the edge nodes can reduce the delay of data transmission and improve the response speed. In recent years, the need for artificial intelligence of edge network has been proposed. However, the data of a single, individual edge node is limited and does not satisfy the conditions of machine learning. Therefore, performing edge network machine learning under the premise of data confidentiality became a research hotspot. This paper proposes a Privacy-Preserving Asynchronous Federated Learning Mechanism for Edge Network Computing (PAFLM), which can allow multiple edge nodes to achieve more efficient federated learning without sharing their private data. Compared with the traditional distributed learning, the proposed method compresses the communications between nodes and parameter server during the training process without affecting the accuracy. Moreover, it allows the node to join or quit in any process of learning, which can be suitable to the scene with highly mobile edge devices.","['Edge computing', 'Cloud computing', 'Servers', 'Learning systems', 'Training', 'Machine learning', 'Data models']","['Federated learning', 'edge computing', 'privacy preservation', 'asynchronous distributed network', 'gradient compression']"
"Reliable power grids are also vulnerable to extreme events, which are with a low probability but highly risk events, such as a typhoon. Power system, as an important infrastructure, should have the ability to withstand the adverse effect of such extreme events. This paper proposes a quantitative resilience assessment framework for power transmission systems operated under typhoon weather, which considers both the spatial and temporal impacts of typhoon. The proposed framework allows systematic estimation of resilience considering weather intensity, fault location of components, restoration resources, and emergency response plans. The typhoon wind field model for disaster risk assessment is applied to evaluate the intensity and the duration of impacts. The finite element modeling of components is developed to model the outage probability of components. Anew resilience index considering the duration of extreme events (RICD) is proposed, which not only considers the performance of system but also considers characteristics of disruption. The proposed method is demonstrated by four case studies using the modified IEEE 6-bus test system. The numerical results reveal that the proposed method is able to quantify the influence of extreme event on power system resilience, and it shows that RICD is more feasible than two traditional indices in terms of normalization and comparability.","['Resilience', 'Tropical cyclones', 'Wind', 'Data models', 'Power transmission']","['Extreme event', 'power transmission system', 'resilience assessment', 'sequential Monte Carlo simulation', 'typhoon']"
"This paper presents a substrate integrated waveguide Butler matrix with a modified hybrid coupler, operating from 28 to 32 GHz. The modified hybrid coupler is realized by using 90° hybrid coupler followed by a -45° compensating phase shifter. Thus, 45°/135° output phase differences can be obtained using this type of coupler. Compared with the equal-length unequal-width phase shifter, the compensating phase shifter exhibits better phase characteristics, with only 3° phase error over 28-32 GHz. Because the phase of compensating phase shifter is not realized by taking the phase introduced by the crossover as a reference, it gives great flexibility to the design of compensating phase shifter. Adopting the modified hybrid coupler, the designed Butler matrix features the output phases with peak to peak error of 13° and wideband performance from 28 to 32 GHz. The slot array fed by the Butler matrix can radiate four slanted beams with acceptable measured gains, in the range of 9.7~12 dBi for port 1 excitation and 8.4~11.1 dBi for port 2 excitation. The radiated beams can reach a wide azimuthal coverage between ±61°.","['Couplers', 'Butler matrices', 'Phase shifters', 'Ports (Computers)', 'Slot array antennas', 'Substrates', 'Integrated waveguides']","['Modified hybrid coupler', 'Butler matrix', 'compensating phase shifter', 'slot array antenna', 'substrate integrated waveguide (SIW)']"
"This paper is devoted to studying the set stability and stabilization of switched Boolean networks (SBNs) with state-based switching using the semi-tensor product (STP) of matrices. First, the algebraic form of an SBN is obtained by STP. Then, a necessary and sufficient condition for set stability is presented for a given set and state-based switching matrix. In addition, state-based switching matrices are designed such that systems can be stabilized to a given set. The selection strategy for pinning nodes is also given, and pinning controllers are designed such that systems can achieve set stabilization via a state-based switching matrix. Finally, examples are provided to illustrate the effectiveness of the obtained results.","['Switches', 'Mathematics', 'Stability criteria', 'Switching circuits', 'STEM']","['Switched Boolean networks', 'semi-tensor product', 'set stability and stabilization', 'pinning control']"
"Most of the road transportations currently depend on fossil fuels, which results in significant environmental and health issues. This is being addressed with the deployment of electric vehicles (EVs). However, a massive penetration will lead to new technical and economic challenges for power systems. This paper proposes a novel way to account for the effect of this new load and to minimize the negative impacts by providing new tools for the agent responsible of managing the EV charge in some area (EV aggregator). The proposed method allows EV charging at the lowest cost while complying with technical constraints required by distribution system operator and transmission system operator. Moreover, EV users are able to choose among different customer choice products that meet their needs in terms of charging time. A case study in the city of Quito, Ecuador, is analyzed in this paper, where the advantages of the proposed coordinated charging method are quantified. The model presents cost benefits compared to uncoordinated charging while complying with technical constraints. In addition, the savings using the presented model are at least 5% higher than uncoordinated charging and can reach more than 50% at best.","['Electric vehicle charging', 'Batteries', 'Minimization', 'Automobiles', 'Indexes', 'Fossil fuels']","['Electric vehicle', 'smart grid', 'smart charging', 'user preference', 'flexibility']"
"Practical Byzantine fault tolerance (PBFT) is one of the most popular consensus protocols of the blockchain. However, in the PBFT, the enthusiasm of reliable nodes cannot be stimulated effectively, and a large amount of communication resources are used for data consistency. Therefore, a new consensus protocol-credit-delegated Byzantine fault tolerance (CDBFT)-is proposed in this paper. The CDBFT works as the following: 1) a voting rewards and punishments scheme and its corresponding credit evaluation scheme are proposed not only to stimulate enthusiasm of reliable nodes but also to reduce the participation of abnormal nodes in the consensus process, and the virtuous circle of the system can be founded and 2) consistency and checkpoint protocols based on PBFT are proposed to improve the efficiency and flexibility of system. From the simulation results, a conclusion can be drawn, the participation probability of abnormal nodes in the consensus process can be reduced to 5%, and the efficiency and stability of the system are improved greatly in the long-time running.","['Blockchain', 'Protocols', 'Fault tolerance', 'Fault tolerant systems', 'Organizations', 'Consensus algorithm']","['Consortium blockchain', 'consensus mechanism', 'credit', 'PBFT']"
"The key to the explosion of the Internet of Things and the ability to collect, analyze, and provide big data in the cloud is edge computing, which is a new computing paradigm in which data is processed from edges. Edge Computing has been attracting attention as one of the top 10 strategic technology trends in the past two years and has innovative potential. It provides shorter response times, lower bandwidth costs, and more robust data safety and privacy protection than cloud computing. In particular, artificial intelligence technologies are rapidly incorporating edge computing. In this paper, we introduce the concepts, backgrounds, and pros and cons of edge computing, explain how it operates and its structure hierarchically with artificial intelligence concepts, list examples of its applications in various fields, and finally suggest some improvements and discuss the challenges of its application in three representative technological fields. We intend to clarify various analyses and opinions regarding edge computing and artificial intelligence.","['Cloud computing', 'Edge computing', 'Servers', 'Data centers', 'Artificial intelligence', 'Internet of Things', 'Performance evaluation']","['Edge computing', 'cloud computing', 'Internet of Things', 'artificial intelligence', 'engineering']"
"This paper focuses on the problem of vision-based obstacle detection and tracking for unmanned aerial vehicle navigation. A real-time object localization and tracking strategy from monocular image sequences is developed by effectively integrating the object detection and tracking into a dynamic Kalman model. At the detection stage, the object of interest is automatically detected and localized from a saliency map computed via the image background connectivity cue at each frame; at the tracking stage, a Kalman filter is employed to provide a coarse prediction of the object state, which is further refined via a local detector incorporating the saliency map and the temporal information between two consecutive frames. Compared with existing methods, the proposed approach does not require any manual initialization for tracking, runs much faster than the state-of-the-art trackers of its kind, and achieves competitive tracking performance on a large number of image sequences. Extensive experiments demonstrate the effectiveness and superior performance of the proposed approach.","['Object detection', 'Visualization', 'Target tracking', 'Kalman filters', 'Image sequences', 'Real-time systems', 'Unmanned aerial vehicles']","['Salient object detection', 'visual tracking', 'Kalman filter', 'object localization', 'real-time tracking']"
"Distributed safety-critical applications in industrial automation, aerospace, and automotive, require worst-case end-to-end latency analysis for critical communication flows in order to prove their correct behavior in the temporal domain. With the advent of time sensitive networks (TSNs), distributed applications can be built on top of standard Ethernet technologies without sacrificing real-time characteristics. The time-based transmission selection and clock synchronization mechanism defined in the TSN enable the real-time transmission of frames based on a global schedule configured through so-called gate control lists (GCLs). This paper has an enhancement of allowing a mixture of the priority-based scheduling and time-triggered, which expand the solution space for the GCLs. Then, it is necessary to analyze the latency bounds for the critical traffic in the TSN network. In this paper, we start from the assumption that the GCLs, i.e., the communication schedules, and the traffic class (priority) assignment for critical flows are given for each output port and derive, using network calculus, an analysis of the worst-case delays that individual critical flows can experience along the hops from sender to receiver(s). Our method can be employed for the analysis of the TSNs where the GCLs have been created in advance, as well as for driving the GCL synthesis that explores a larger solution space than previous methods, which required a complete isolation of transmission events from different traffic classes. We validate our model and analysis by performing experiments on both synthetic and real-world use-cases, showing the scalability of our implementation as well as the impact of certain GCL properties (gate overlapping and traffic class assignments) on the worst-case latency of critical communication flows.","['Logic gates', 'Delays', 'Schedules', 'Synchronization', 'Calculus', 'Real-time systems', 'Jitter']","['Performance analysis', 'delay', 'TSN', 'deterministic Ethernet', 'network calculus']"
"Recent advances in wireless technologies, micro-electro-mechanical systems, and embedded systems enable the popular usage of the Internet of Things (IoT) and wireless sensor networks (WSNs) in many important applications, such as smart buildings, security, target tracking, industrial automation, and so on. Typically, a WSN consists of a large number of tiny, low-cost sensor nodes that are limited in terms of their capabilities of computation, communication, memory, and power. In WSNs, energy-efficient algorithms are of paramount importance for a long lasting high throughput network. MAC protocol plays a prominent role in extending the life-time of WSNs. MAC protocols provide various schemes on how multiple nodes access a common wireless medium. To achieve a longer lifetime for the nodes and the networks, MAC protocols need to be energy-efficient and reduce the sources of energy wastage. Energy conservation in sensor nodes is generally achieved by duty cycling the radios, and it is the MAC layer protocol that controls when to switch on and off the radio. In this paper, we discuss the essential properties of MAC protocols, the MAC for IoT and the common causes of energy consumptions. Thereafter, we categorize the MAC layer protocols and discuss several protocols under each category in depth, emphasizing their strengths and weaknesses, and giving a detailed comparison of MAC protocols. Finally, we conclude the survey with the insights on future research directions.","['Media Access Protocol', 'Wireless sensor networks', 'Wireless communication', 'Energy efficiency', 'Internet of Things', 'Monitoring']","['MAC protocols', 'wireless sensor networks', 'Internet of Things', 'energy-efficient and energy conservation']"
"The rapid growth of Internet users led to unwanted cyber issues, including cyberbullying, hate speech, and many more. This article deals with the problems of hate speech on Twitter. Hate speech appears to be an inflammatory kind of interaction process that uses misconceptions to express a hate ideology. The hate speech focuses on various protected aspects, including gender, religion, race, and disability. Owing to hate speech, sometimes unwanted crimes are going to happen as someone or a group of people get disheartened. Hence, it is essential to monitor user's posts and filter the hate speech related post before it is spread. However, Twitter receives more than six hundred tweets per second and about 500 million tweets per day. Manually filtering any information from such a huge incoming traffic is almost impossible. Concerning to this aspect, an automated system is developed using the Deep Convolutional Neural Network (DCNN). The proposed DCNN model utilises the tweet text with GloVe embedding vector to capture the tweets' semantics with the help of convolution operation and achieved the precision, recall and F1-score value as 0.97, 0.88, 0.92 respectively for the best case and outperformed the existing models.","['Feature extraction', 'Social networking (online)', 'Blogs', 'Data models', 'Convolutional neural networks', 'Voice activity detection', 'Logistics']","['Convolutional neural network', 'hate speech', 'LSTM', 'Tf-Idf', 'Twitter']"
"A kind of novel method of power allocation with limited cross-tier interference for cognitive radio network (CRN) is proposed in this paper. In this method, an interference-limited power allocation algorithm based on filter bank multi-carrier-offset quadrature amplitude modulation (FBMC-OQAM) is put forward. In order to improve the energy efficiency of the entire network and protect secondary users (SUs) in the network from too much interference, cross-tier interference limit is adopted, at the same time, virtual queue is designed to transform the extra packet delay caused by the contention for the channel of multi-user into the queuing delay. Taking the energy efficiency as the objective function, a nonlinear programming approach with nonlinear constraints is innovatively proposed under the constraints of time delay and transmission power. An iterative algorithm in order to solve the problem is also put forward. In the new algorithm, the fractional objective function is transformed into polynomial form, and the global optimal solution is obtained by iteration after reducing the computational complexity. In addition, a sub-optimal algorithm is proposed to reduce computational complexity. The experimental results show that the optimal algorithm has higher performance while the sub-optimal algorithm has a lower computational complexity. The presented method has very good practical importance for the CRN.","['Resource management', 'Interference', 'Energy efficiency', 'Delays', 'Cognitive radio', 'Throughput', 'OFDM']","['Cognitive radio network (CRN)', 'power allocation', 'FBMC-OQAM', 'Lagrange dual']"
"Due to advancements in the development of wireless medical sensing devices and wireless communication technologies, the wireless body area network (WBAN) has become an eminent part of e-healthcare systems. WBAN uses medical sensors to continuously monitor and collect the physiological parameters of a patient's health and send them to a remote medical server through a portable digital assistance (PDA)/mobile. Due to limitations in communication, such as power, storage, and the computational capabilities of sensors, data aggregation techniques are used to reduce the communication overhead in real-time data transmission in WBAN. However, since the WBAN transmits sensitive health data, data security and data privacy are a major concern. In this paper, we propose a secure privacy-preserving data aggregation (SPPDA) scheme based on bilinear pairing for remote health monitoring systems to improve data aggregation efficiency and data privacy. Our proposed SPPDA scheme utilizes the homomorphic property of the bilinear ElGamal cryptosystem to perform privacy-preserving secure computation and combines it with the aggregate signature scheme, enabling data authenticity/integrity in the WBAN. The proposed SPPDA scheme is proved to be semantically secure under the decisional bilinear Diffie-Hellman assumption. Security analysis demonstrates that our proposed scheme preserves data confidentiality, data authenticity, and data privacy; it also resists passive eavesdropping and replay attacks. A performance evaluation based on simulation results and a comparison of computational cost with related schemes show that data aggregation and batch verification at the PDA significantly reduce communication and transmission overhead and support efficient computation at the remote server.","['Data aggregation', 'Wireless communication', 'Body area networks', 'Data privacy', 'Cryptography', 'Monitoring', 'Sensors']","['Wireless body area network', 'remote health monitoring system', 'secure data aggregation', 'bilinear pairing', 'bilinear ElGamal cryptosystem', 'homomorphic encryption', 'aggregate signature', 'batch verification']"
"Convergence of physical and digital identity and integration of various individual records, such as patient data, into a united repository remains a serious challenge. On one hand, collecting relevant data can help clinicians, specialists and healthcare service providers to facilitate care for patients. On the other hand, Self-Sovereign identity and the right to control personal data comes into question, because patients do not handle their data explicitly. Distributed Ledger Technology (DLT) is a novel method which would allow to securely record time-stamped data and enable patient-driven health and identity records. In this paper, we review the state-of-the-art in Blockchain (BC)-based self-sovereignty and patient data records in healthcare. Our motivation is to investigate the potential of BC technology for use in the patient data and identity management. As a distributed decentralized technology, BC can be very beneficial, giving patients control over their own data and self-sovereign identity. To the extent of our knowledge, there is no literature covering the same concerns. More specifically, the focus is on solutions that aim the realization of holistic BC-based Electronic Health Records (EHR) and Patient Health Records (PHR). EHR and PHR are used to record patient data, such as the doctor's notes upon a visit and radiology images. Hence, they include critical information regarding patient's privacy and identity. Therefore, development of pure decentralized Healthcare Information Systems (HIS) is a great challenge in terms of architectural and technical structure of the systems. Designing robust and reliable EHR and PHR, which represent the foundation of many other healthcare services, relies on carefully finding the balance in a trade-off between many factors, such as level of decentralization, privacy, scalability and data throughput. In this paper, we review the state-of-the-art and provide an analysis on the design trade-offs.","['Medical services', 'Privacy', 'Security', 'Cloud computing', 'Distributed databases', 'Data privacy']","['Blockchain', 'healthcare', 'privacy', 'self-sovereignty']"
"Outlier detection is an extensive research area, which has been intensively studied in several domains such as biological sciences, medical diagnosis, surveillance, and traffic anomaly detection. This paper explores advances in the outlier detection area by finding anomalies in spatio-temporal urban traffic flow. It proposes a new approach by considering the distribution of the flows in a given time interval. The flow distribution probability (FDP) databases are first constructed from the traffic flows by considering both spatial and temporal information. The outlier detection mechanism is then applied to the coming flow distribution probabilities, the inliers are stored to enrich the FDP databases, while the outliers are excluded from the FDP databases. Moreover, a k-nearest neighbor for distance-based outlier detection is investigated and adopted for FDP outlier detection. To validate the proposed framework, real data from Odense traffic flow case are evaluated at ten locations. The results reveal that the proposed framework is able to detect the real distribution of flow outliers. Another experiment has been carried out on Beijing data, the results show that our approach outperforms the baseline algorithms for high-urban traffic flow.","['Anomaly detection', 'Principal component analysis', 'Prediction algorithms', 'Trajectory', 'Urban areas', 'Roads']","['Anomaly detection', 'kNN', 'flow distribution probability']"
"This article claims, an investigation on compact ultrathin triple band polarization independent metamaterial absorber for microwave frequency applications. The proposed absorber unit cell consist of two resonators named as Structure-A and Structure-B. Both the resonators are printed on the upper surface of dual side copper coated FR-4 epoxy glass substrate of thickness 0.8 mm. The proposed absorber structure offers three distinct absorption peaks of 99.67%, 99.48%, and 99.42% with FWHM bandwidth of 170 MHz (4.11-4.28 GHz), 350 MHz (9.17-9.52 GHz), and 480 MHz (11.24-11.72 GHz) at 4.19 GHz, 9.34 GHz, and 11.48 GHz, respectively, under normal incidence. In addition to above, the four fold symmetry of proposed absorber structure make it polarization independent. Proposed absorber structure also offers more than 80% absorptivity at different angle of incidence (up to 60°) under transvers electric and transvers magnetic polarization states. The designed absorber unit cell has compactness of 0.11 λ 0 × 0.11 λ 0 with ultra-thin thickness of 0.0111 λ 0 , where λ 0 is the free space wavelength with respect to the lowest absorption peak of 4.19 GHz. Absorption mechanism of proposed unit cell has been discussed with the help of normalized input impedance, electric field distribution, and surface current density plots. In order to discuss the metamaterial property of proposed absorber unit cell dispersion diagram has been shown.","['Absorption', 'Metamaterials', 'Magnetic materials', 'Electric fields', 'Impedance', 'Copper', 'Surface impedance']","['Metamaterial', 'triple band absorber', 'polarization independent', 'ultra-thin']"
"The rapid development and popularization of the network have brought many problems to network security. Intrusion detection technology is often used as an effective security technology to protect the network. The deep belief network (DBN), as a classic model of deep learning, has good classification performance and is often used in the field of intrusion detection. However, the network structure of DBN is generally set through practical experience. For the optimization problem of the DBN-based intrusion detection classification model (DBN-IDS), this paper proposes a new joint optimization algorithm to optimize the DBN's network structure. First, we design a particle swarm optimization (PSO) based on the adaptive inertia weight and learning factor. Second, we use the fish swarm behavior of cluster, foraging, and other behaviors to optimize the PSO to find the initial optimization solution. Then, based on the initial optimization solution, we use the genetic operators with self-adjusting crossover probability and mutation probability to optimize the PSO to search the global optimization solution. Finally, the global optimization solution constructed by the above-mentioned joint optimization algorithm is used as the network structure of the intrusion detection classification model. The experimental results show that compared with other DBN-IDS optimization algorithms, our algorithm shortens the average detection time by at least 24.69% on the premise of increasing the average training time by 6.9%; compared with the tested classification algorithms, our DBN-IDS improves the average classification accuracy by at least 1.3% and up to 14.80% in the five-category classification, which is proved to be an efficient DBN-IDS optimization method.","['Intrusion detection', 'Optimization methods', 'Particle swarm optimization', 'Biological neural networks', 'Machine learning algorithms']","['Intrusion detection', 'deep belief network', 'particle swarm optimization', 'artificial fish swarm algorithm', 'genetic algorithm']"
"Ultra-reliable low-latency communication (URLLC) has been introduced in 5G new radio for new applications that have strict reliability and latency requirements such as augmented/virtual reality, industrial automation and autonomous vehicles. The first full set of the physical layer design of 5G release, Release 15, was finalized in December 2017. It provided a foundation for URLLC with new features such as flexible sub-carrier spacing, a sub-slot-based transmission scheme, new channel quality indicator, new modulation and coding scheme tables, and configured-grant transmission with automatic repetitions. The second 5G release, Release 16, was finalized in December 2019 and allows achieving improved metrics for latency and reliability to support new use cases of URLLC. A number of new features such as enhanced physical downlink (DL) control channel monitoring capability, new DL control information format, sub-slot physical uplink (UL) control channel transmission, sub-slot-based physical UL shared channel repetition, enhanced mobile broadband and URLLC inter-user-equipment multiplexing with cancellation indication and enhanced power control were standardized. This article provides a detailed overview of the URLLC features from 5G Release 15 to Release 16 by describing how these features allow meeting URLLC target requirements in 5G networks. The ongoing Release 17 targets further enhanced URLLC operation by improving mechanisms such as feedback, intra-user-equipment multiplexing and prioritization of traffic with different priority, support of time synchronization and new quality of service related parameters. In addition, a fundamental feature targeted in URLLC Release 17 is to enable URLLC operation over shared unlicensed spectrum. The potential directions of URLLC research in unlicensed spectrum in Release 17 are presented to serve as a bridge from URLLC in licensed spectrum in Release 16 to URLLC in unlicensed spectrum in Release 17.","['Ultra reliable low latency communication', '5G mobile communication', 'Physical layer', 'Monitoring', '3GPP', 'Long Term Evolution', 'Gaussian processes']","['5G', 'URLLC', 'physical layer design', '3GPP Release 15', '3GPP Release 16', '3GPP Release 17']"
"This work aims to investigate the main determinants that could play an important role in increasing the usage and acceptance of e-learning systems among Saudi students. The study employed the Unified Theory of Acceptance and Use of Technology (e-UTAUT) model and introduced new constructs to study the acceptance of e-learning systems in the Saudi Arabian context. The data were collected using a questionnaire survey from a total of 507 undergraduate and postgraduate students at King Faisal University (KFU). The research model was tested using the structural equation modeling technique (SEM). Based on the results, the factors of course design, course content support, course assessment and instructor characteristics were shown to have a significant effect on the actual use of e-learning systems. However, the influence of social influence on actual use was found to be statistically insignificant. Additionally, the course design, course content support, course assessment and instructor characteristics factors were found to have a positive effect on the performance expectancy of e-learning systems. The research findings serve as an important reference for university managers and researchers on students’ priorities when improving course design, course content and course assessment, thereby increasing the usage and acceptance of e-learning systems among students.","['Electronic learning', 'Learning systems', 'Mathematical model', 'Tools', 'Computer aided instruction']","['E-learning system', 'UTAUT model', 'technology Acceptance', 'SEM', 'Saudi Arabia']"
"The year 2020 has witnessed unprecedented levels of demand for COVID-19 medical equipment and supplies. However, most of today’s systems, methods, and technologies leveraged for handling the forward supply chain of COVID-19 medical equipment and the waste that results from them after usage are inefficient. They fall short in providing traceability, reliability, operational transparency, security, and trust features. Also, they are centralized that can cause a single point of failure problem. In this paper, we propose a decentralized blockchain-based solution to automate forward supply chain processes for the COVID-19 medical equipment and enable information exchange among all the stakeholders involved in their waste management in a manner that is fully secure, transparent, traceable, and trustworthy. We integrate the Ethereum blockchain with decentralized storage of interplanetary file systems (IPFS) to securely fetch, store, and share the data related to the forward supply chain of COVID-19 medical equipment and their waste management. We develop algorithms to define interaction rules regarding COVID-19 waste handling and penalties to be imposed on the stakeholders in case of violations. We present system design along with its full implementation details. We evaluate the performance of the proposed solution using cost analysis to show its affordability. We present the security analysis to verify the reliability of the smart contracts, and discuss our solution from the generalization and applicability point of view. Furthermore, we outline the limitations of our solution in form of open challenges that can act as future research directions. We make our smart contracts code publicly available on GitHub.","['COVID-19', 'Supply chains', 'Biomedical equipment', 'Blockchain', 'Waste management', 'Stakeholders', 'Safety']","['Blockchain', 'Ethereum', 'COVID-19', 'security analysis', 'forward supply chain', 'medical waste management']"
"The explosive growth of various services boosts the innovation and development in terrestrial communication systems for the implementation of the next generation mobile communication networks. However, simply utilizing limited resources in terrestrial communication networks is difficult to support the massive quality of service (QoS) aware requirements and it is hard to guarantee seamless coverage in far remote regions. Leveraging the intrinsic merits of high altitude and the ability of multicasting or broadcasting, satellite communication systems provide an opportunity for novel mobile communication networks with its tight interaction and complementary characteristics to traditional terrestrial networks. It is believed that the convergence of satellite and terrestrial networks can solve the problems existing in current mobile communication systems and make a profound effect on global information dissemination. In this paper, we make a comprehensive survey on the convergence of satellite and terrestrial networks. First, motivations and requirements of satellite-terrestrial network convergence are identified. Then, we summarize related architectures of existing literature, classify the taxonomy of researches on satellite-terrestrial networks, and present the performance evaluation works in different satellite-terrestrial networks. After that, the state-of-the-art of standardization, projects and the key application areas of satellite-terrestrial networks are also reviewed. Finally, we conclude the survey by highlighting the open issues and future directions.","['Satellite broadcasting', 'Convergence', 'Communication networks', 'Satellites', 'Computer architecture', 'Resource management', 'Technological innovation']","['Satellite-terrestrial networks', 'resource allocation', 'mobility management', 'access control', 'security', 'performance evaluation', 'survey']"
"The continued ability to detect malicious network intrusions has become an exercise in scalability, in which data mining techniques are playing an increasingly important role. We survey and categorize the fields of data mining and intrusion detection systems, providing a systematic treatment of methodologies and techniques. We apply a criterion-based approach to select 95 relevant articles from 2007 to 2017. We identified 19 separate data mining techniques used for intrusion detection, and our analysis encompasses rich information for future research based on the strengths and weaknesses of these techniques. Furthermore, we observed a research gap in establishing the effectiveness of classifiers to identify intrusions in modern network traffic when trained with aging data sets. Our review points to the need for more empirical experiments addressing real-time solutions for big data against contemporary attacks.","['Data mining', 'Intrusion detection', 'Systematics', 'Bibliographies', 'Quality assessment', 'Libraries', 'Search problems']","['Intrusion detection system', 'real-time detection', 'data mining', 'network security']"
"Network embedding task aims at learning low-dimension latent representations of vertices while preserving the structure of a network simultaneously. Most existing network embedding methods mainly focus on static networks, which extract and condense the network information without temporal information. However, in the real world, networks keep evolving, where the linkage states between the same vertex pairs at consequential timestamps have very close correlations. In this paper, we propose to study the network embedding problem and focus on modeling the linkage evolution in the dynamic network setting. To address this problem, we propose a deep dynamic network embedding method. More specifically, the method utilizes the historical information obtained from the network snapshots at past timestamps to learn latent representations of the future network. In the proposed embedding method, the objective function is carefully designed to incorporate both the network internal and network dynamic transition structures. Extensive empirical experiments prove the effectiveness of the proposed model on various categories of real-world networks, including a human contact network, a bibliographic network, and e-mail networks. Furthermore, the experimental results also demonstrate the significant advantages of the method compared with both the state-of-the-art embedding techniques and several existing baseline methods.","['Couplings', 'Task analysis', 'Correlation', 'Data models', 'Predictive models', 'Data mining', 'Electronic mail']","['Social network analysis', 'network embedding', 'link prediction', 'deep learning']"
"This paper presents an elegant yet straightforward design procedure for a compact rat-race coupler (RRC) with an extended harmonic suppression. The coupler’s conventionalλ/4 transmission lines (TLs) are replaced by a specialized TL that offers significant size reduction and harmonic elimination capabilities in the proposed approach. The design procedure is verified through the theoretical, circuit, and electromagnetic (EM) analyses, showing excellent agreement among different analyses and the measured results. The circuit and EM results show that the proposed TL replicates the same frequency behaviour of the conventional one at the design frequency of 1.8 GHz while enables harmonic suppression up to the7thharmonic and a size reduction of 74%. According to the measured results, the RRC has a fractional bandwidth of 20%, with input insertion losses of around 0.2 dB and isolation level better than 35 dB. Furthermore, the total footprint of the proposed RRC is only 31.7 mm×15.9mm, corresponding to0.28λ×0.14λ, whereλis the guided wavelength at 1.8 GHz.","['Harmonic analysis', 'Power harmonic filters', 'Couplers', 'Harmonics suppression', 'Impedance', 'Power transmission lines', 'Mathematical model']","['Transmission line', 'rat-race coupler', 'size reduction', 'harmonics suppression']"
"Nowadays research is heading towards the integration of cloud computing and Internet of Things thus creating a Cloud of Things (CoT). This combination generates a new paradigm for pervasive and ubiquitous computing. However, reliable CoT-based services, particularly, highly delay-sensitive services, such as, healthcare, require energy-efficient CoT architectures. Considerable efforts have been proposed to improve the efficiency of CoT architectures. This paper analyses CoT architectures and platforms, as well as the implementation of CoT in the context of smart healthcare. Subsequently, the paper explains some related issues of CoT, including the lack of standardization. Moreover, it focuses on energy efficiency with an in depth analysis of the most relevant proposals available in the literature. An evaluation of all the energy efficiency solutions investigated in this paper shows there is still a need to improve energy efficiency, especially regarding QoS and performance.","['Cloud computing', 'Medical services', 'Energy efficiency', 'Sensors', 'Computer architecture', 'Internet of Things', 'Wireless sensor networks']","['Cloud computing', 'Cloud of Things', 'energy efficiency', 'Internet of Things', 'smart healthcare']"
"Despite the numerous and noticeable inherited gains of Mobile Cloud Computing (MCC) in healthcare, its growth is being hindered by privacy and security challenges. Such issues require the utmost urgent attention to realize its full scale and efficient usage. There is a need to secure Health Information worldwide, regionally, and locally. To fully avail of the health services, it is crucial to put in place the demanded security practices for the prevention of security breaches and vulnerabilities. Hence, this research is deliberated on to provide requirement-oriented health information security using the Modular Encryption Standard (MES) based on the layered modeling of the security measures. The performance analysis shows that the proposed work excels, compared to other commonly used algorithms against the health information security at the MCC environment in terms of better performance and auxiliary qualitative security ensuring measures.","['Security', 'Cloud computing', 'Medical services', 'Monitoring', 'Standards', 'Privacy', 'Encryption']","['MES', 'health information security', 'mobile cloud computing', 'requirement-oriented approach', 'modular protection-based computing']"
"Skin Lesion detection and classification are very critical in diagnosing skin malignancy. Existing Deep learning-based Computer-aided diagnosis (CAD) methods still perform poorly on challenging skin lesions with complex features such as fuzzy boundaries, artifacts presence, low contrast with the background and, limited training datasets. They also rely heavily on a suitable turning of millions of parameters which often leads to over-fitting, poor generalization, and heavy consumption of computing resources. This study proposes a new framework that performs both segmentation and classification of skin lesions for automated detection of skin cancer. The proposed framework consists of two stages: the first stage leverages on an encoder-decoder Fully Convolutional Network (FCN) to learn the complex and inhomogeneous skin lesion features with the encoder stage learning the coarse appearance and the decoder learning the lesion borders details. Our FCN is designed with the sub-networks connected through a series of skip pathways that incorporate long skip and short-cut connections unlike, the only long skip connections commonly used in the traditional FCN, for residual learning strategy and effective training. The network also integrates the Conditional Random Field (CRF) module which employs a linear combination of Gaussian kernels for its pairwise edge potentials for contour refinement and lesion boundaries localization. The second stage proposes a novel FCN-based DenseNet framework that is composed of dense blocks that are merged and connected via the concatenation strategy and transition layer. The system also employs hyper-parameters optimization techniques to reduce network complexity and improve computing efficiency. This approach encourages feature reuse and thus requires a small number of parameters and effective with limited data. The proposed model was evaluated on publicly available HAM10000 dataset of over 10000 images consisting of 7 different categories of diseases with 98% accuracy, 98.5% recall, and 99% of AUC score respectively.","['Lesions', 'Skin', 'Feature extraction', 'Machine learning', 'Skin cancer', 'Training', 'Support vector machines']","['Skin lesion', 'deep leraning', 'CAD', 'classification', 'FCN', 'CRF', 'DenseNet', 'encoder-decoder', 'hyper-parameter', 'skin cancer']"
"The constant miniaturization of hardware and an increase in power efficiency, have made possible the integration of intelligence into ordinary devices. This trend of augmenting so-called non-intelligent everyday devices with computational capabilities has led to the emergence of the Internet of Things (IoT) domain. With a wide variety of applications, such as home automation, smart grids/cities, and critical infrastructure management, the IoT systems make compelling targets for cyber-attacks. In order to effectively compromise these systems, adversaries employ different advanced persistent threat (APT) methods, with one such sophisticated method, being botnets. By employing a plethora of infected machines (bots), attackers manage to compromise the IoT systems and exploit them. Prior to the appearance of the IoT domain, specialized digital forensics mechanisms were developed, in order to investigate Botnet activities in small-scale systems. Since IoT enabled botnets are scalable, technologically diverse and make use of current high-speed networks, developing forensic mechanisms capable of investigating the IoT Botnet activities has become an important challenge in the cyber-security field. Various studies have proposed, deep learning as a viable solution for handling the IoT generated data, as it was designed to handle diverse data in large volumes, requiring near real-time processing. In this study, we provide a review of forensics and deep learning mechanisms employed to investigate botnets and their applicability in the IoT environments. We provide a new definition for the IoT, in addition to a taxonomy of network forensic solutions, that were developed for both conventional, as well as, the IoT settings. Furthermore, we investigate the applicability of deep learning in network forensics, the inherent challenges of applying network forensics techniques to the IoT, and provide future direction for research in this field.","['Botnet', 'Forensics', 'Internet of Things', 'Malware', 'Security', 'Deep learning']","['Internet of Things', 'IoT', 'nework forensics', 'botnets', 'deep learning']"
"Image Steganography is the process of hiding information which can be text, image or video inside a cover image. The secret information is hidden in a way that it not visible to the human eyes. Deep learning technology, which has emerged as a powerful tool in various applications including image steganography, has received increased attention recently. The main goal of this paper is to explore and discuss various deep learning methods available in image steganography field. Deep learning techniques used for image steganography can be broadly divided into three categories - traditional methods, Convolutional Neural Network-based and General Adversarial Network-based methods. Along with the methodology, an elaborate summary on the datasets used, experimental set-ups considered and the evaluation metrics commonly used are described in this paper. A table summarizing all the details are also provided for easy reference. This paper aims to help the fellow researchers by compiling the current trends, challenges and some future direction in this field.","['Deep learning', 'Media', 'Ciphers', 'Tools', 'Market research', 'Image color analysis']","['Image steganography', 'GAN steganography', 'CNN steganography', 'information hiding', 'image data hiding']"
"A 3-D Shenzhen City Web platform based on the Web virtual reality geographical information system is presented. A 3-D global browser is employed to load multiple types of demand data from the city, such as 3-D building model data, residents' information, and real-time and historical traffic data. Using these data, a 3-D analysis and visualization of the city's information are conducted on a platform. The amount of information that can be visualized with this platform is very large, and the GIS-based navigational scheme enables great flexibility to access different available data sources. All the presented functions of the platform are extracted from the customers' practical demand. The system design considers some existing geographic human-computer interaction research results.","['Urban areas', 'Big data', 'Three-dimensional displays', 'Government', 'Data visualization', 'Solid modeling', 'Urban areas', 'China']","['WebVRGIS', 'Smart City', 'Virtual Geographical Environment', 'e-Government', 'HCI']"
"Neighbor discovery was initially conceived as a means to deal with energy issues at deployment, where the main objective was to acquire information about network topology for subsequent communication. Nevertheless, over recent years, it has been facing new challenges due to the introduction of mobility of nodes over static networks mainly caused by the opportunistic presence of nodes in such a scenario. The focus of discovery has, therefore, shifted toward more challenging environments, where connectivity opportunities need to be exploited for achieving communication. In fact, discovery has traditionally been focused on tradeoffs between energy and latency in order to reach an overlapping of communication times between neighboring nodes. With the introduction of opportunistic networking, neighbor discovery has instead aimed toward the more challenging problem of acquiring knowledge about the patterns of encounters between nodes. Many Internet of Things applications (e.g., smart cities) can, in fact, benefit from such discovery, since end-to-end paths may not directly exist between sources and sinks of data, thus requiring the discovery and exploitation of rare and short connectivity opportunities to relay data. While many of the older discovery approaches are still valid, they are not entirely designed to exploit the properties of these new challenging scenarios. A recent direction in research is, therefore, to learn and exploit knowledge about mobility patterns to improve the efficiency in the discovery process. In this paper, a new classification and taxonomy is presented with an emphasis on recent protocols and advances in this area, summarizing issues and ways for potential improvements. As we will show, knowledge integration in the process of neighbor discovery leads to a more efficient scheduling of the resources when contacts are expected, thus allowing for faster discovery, while, at the same time allowing for energy savings when such contacts are not expected.","['Internet of things', 'Knowledge transfer', 'Nearest neighbor searches', 'Search methods', 'Network topology', 'Knowledge engineering', 'Taxonomy']","['Neighbour Discovery', 'Opportunistic Networking', 'Internet of Things', 'Mobility', 'Knowledge']"
"Northern maize leaf blight is one of the major diseases that endanger the health of maize. The complex background of the field and different light intensity make the detection of diseases more difficult. A multi-scale feature fusion instance detection method, based on convolutional neural network, is proposed to detect maize leaf blight. The proposed technique incorporates three major steps of data set preprocessing part, fine-tuning network and detection module. In the first step, the improved retinex is used to process data sets, which successfully solves the problem of poor detection effects caused by high-intensity light. In the second step, the improved RPN is utilized to adjust the anchor box of diseased leaves. The improved RPN network identifies and deletes negative anchors, which reduces the search space of the classifier and provides better initial information for the detection network. In this paper, a transmission module is designed to connect the fine-tuning network with the detection module. On the one hand, the transmission module fuses the features of the low-level and high-level to improve the detection accuracy of small target diseases. On the other hand, the transmission module converts the feature map associated with the fine-tuning network to the detection module, thus realizing the feature sharing between the detection module and the fine-tuning network. In the third step, the detection module takes the optimized anchor as input, focuses on detecting the diseased leaves. By sharing the features of the transmission module, the time-consuming process of using candidate regions layer by layer to detect is eliminated. Therefore, the efficiency of the whole model has reached the efficiency of the one-stage model. In order to further optimize the detection effect of the model, we replace the loss function with generalized intersection over union (GIoU). After 60000 iterations, the highest mean average precision (mAP) reaches 91.83%. The experimental results indicate that the improved model outperforms several existing methods in terms of greater precision and frames per second (FPS).","['Diseases', 'Feature extraction', 'Reflection', 'Low pass filters', 'Machine learning', 'Convolutional neural networks', 'Filtering theory']","['Northern maize leaf blight', 'disease detection', 'transmission module', 'retinex', 'single shot multiBox detector (SSD)']"
"Recently, a significant amount of literature concerning machine learning techniques has focused on automatic recognition of activities performed by people. The main reason for this considerable interest is the increasing availability of devices able to acquire signals which, if properly processed, can provide information about human activities of daily living (ADL). The recognition of human activities is generally performed by machine learning techniques that process signals from wearable sensors and/or cameras appropriately arranged in the environment. Whatever the type of sensor, activities performed by human beings have a strong subjective characteristic that is related to different factors, such as age, gender, weight, height, physical abilities, and lifestyle. Personalization models have been studied to take into account these subjective factors and it has been demonstrated that using these models, the accuracy of machine learning algorithms can be improved. In this work we focus on the recognition of human activities using signals acquired by the accelerometer embedded in a smartphone. The contributions of this research are mainly three. A first contribution is the definition of a clear validation model that takes into account the problem of personalization and which thus makes it possible to objectively evaluate the performances of machine learning algorithms. A second contribution is the evaluation, on three different public datasets, of a personalization model which considers two aspects: the similarity between people related to physical aspects (age, weight, and height) and similarity related to intrinsic characteristics of the signals produced by these people when performing activities. A third and last contribution is the development of a personalization model that considers both the physical and signal similarities. The experiments show that the employment of personalization models improves, on average, the accuracy, thus confirming the soundness of the approach and paving the way for future investigations on this topic.","['Activity recognition', 'Data models', 'Adaptation models', 'Accelerometers', 'Deep learning', 'Solid modeling']","['Personalization', 'human activity recognition', 'ADL', 'similarity', 'machine learning', 'smartphone']"
"With the widespread usage of cloud computing to benefit from its services, cloud service providers have invested in constructing large scale data centers. Consequently, a tremendous increase in energy consumption has arisen in conjunction with its results, including a remarkable rise in costs of operating and cooling servers. Besides, increasing energy consumption has a significant impact on the environment due to emissions of carbon dioxide. Dynamic consolidation of Virtual Machines (VMs) into the minimal number of Physical Machines (PMs) is considered as one of the magic solutions to manage power consumption. The virtual machine placement problem is a critical issue for good VM consolidation. This paper proposes a Power-Aware technique depending on Particle Swarm Optimization (PAPSO) to determine the near-optimal placement for the migrated VMs. A discrete version of Particle Swarm Optimization (PSO) is adopted based on a decimal encoding to map the migrated VMs to the best appropriate PMs. Furthermore, an effective minimization fitness function is employed to reduce power consumption without violating the Service Level Agreement (SLA). Specifically, PAPSO consolidates the migrated VMs into the minimum number of PMs with a major constraint to decrease the number of overloaded hosts as much as possible. Therefore, the number of VM migrations can be reduced drastically by taking into consideration the main sources for VM migrations; overloaded hosts and underloaded ones. PAPSO is implemented in CloudSim and the experimental results on random workloads with different sizes of VMs and PMs show that PAPSO does not violate SLA and outperforms the Power-Aware Best Fit Decreasing algorithm (PABFD). It can reduce about 8.01%, 39.65%, 66.33%, and 11.87% on average in terms of consumed energy, number of VM migrations, number of host shutdowns and the combined metric Energy SLA Violation (ESV), respectively.","['Data centers', 'Particle swarm optimization', 'Servers', 'Cloud computing', 'Energy consumption', 'Power demand', 'Search problems']","['Cloud computing', 'live VM migration', 'dynamic VM consolidation', 'virtual machine placement', 'energy consumption', 'service level agreement', 'particle swarm optimization', 'CloudSim']"
"The deployment of 5G networks will necessarily involve the installation of new base station (BS) equipment to support the requirements of next-generation mobile services. In a scenario where there exist already many sources of electromagnetic fields (EMFs), including overlapping 2G/3G/4G technologies of competing network operators, there is a growing concern that the planning of a 5G network will be severely constrained by the limits on maximum EMF levels established in a wide set of regulations. The goal of this paper is to shed light on EMF-aware 5G network planning and, in particular, on the problem of site selection for 5G BS equipment that abides by downlink EMF limits. To this end, we present the current state of the art in EMF-aware mobile networking and overview the current exposure limits and how the EMF constraints may impact 5G planning. We then substantiate our analysis by reporting on two realistic case studies, which demonstrate the saturation of EMF levels already occurring under current 2G/3G/4G networks, as well as the negative impact of strict regulations on network planning and user quality of service. Finally, we discuss the expected impact of 5G technologies in terms of EMFs and draw the guidelines for an EMF-aware planning of 5G. Our analysis suggests that the EMF-aware 5G planning risks to be a real challenge for network operators, which stimulates further actions at governmental, societal, technological, and research levels.","['5G mobile communication', 'Planning', 'Quality of service', 'Guidelines', 'Cellular networks', 'Pollution measurement', 'Electronic mail']","['5G networks', '5G cellular network planning', 'EMF saturation', 'EMF limits', '5G guidelines', 'EMFs', 'QoS']"
"Reconnaissance mission has a wide application in both civil and military fields, which provides intelligence and basis for the following decision-making to accomplish certain goals. Due to numerous advantages of UAV swarms such as strong flexibility, high efficiency, and low cost, conducting reconnaissance missions by UAV swarms has become a trend of future. However, the path planning problem of UAV swarms is a key challenge in the aspect of model construction, algorithm, selection and high computational complexity, especially when the mission is complicated. In this paper, various distributed particle swarm optimization (DPSO)-based path planning algorithms are proposed for UAV swarms conducting a reconnaissance mission, in which targets are gathered in the form of clusters and different tactic needs are taken into consideration. Three algorithms named the maximum density convergence DPSO algorithm (MDC-DPSO), the fast cross-over DPSO algorithm (FCO-DPSO), and the accurate coverage exploration DPSO algorithm (ACE-DPSO) are proposed correspond to the needs of fast convergence, random cross-over, and accurate search, respectively. Different fitness functions and search strategies are specifically designed considering the mobility and communication constraints of the UAV swarms. Besides, the jump-out mechanism and revisit mechanism are designed to save invalid search efforts and avoid falling into local optimum. The simulation results demonstrate that the proposed algorithms are effective in generating paths for UAV swarms conducting a reconnaissance mission, which can be easily applied to large scale swarms.","['Reconnaissance', 'Path planning', 'Heuristic algorithms', 'Clustering algorithms', 'Particle swarm optimization', 'Convergence', 'Robots']","['Reconnaissance mission', 'path planning', 'distributed particle swarm optimization (DPSO)', 'UAV swarms']"
"Robot navigation in the environment with obstacles is still a challenging problem. In this paper, the navigation problems with wheeled mobile robots (WMRs) are reviewed, the navigation mechanism of WMRs is analyzed in detail, the methods of solving the sub problems such as mapping, localization and path planning which all both related to robot navigation are summarized and the advantages and disadvantages of the existing methods are expounded. Especially in the agricultural field, the precise navigation of robots in the complex agricultural environment is the prerequisite for the completion of various tasks. This paper is aimed at the special complexity of the agricultural environment, prospected the application of the solution to the navigation problem of WMRs in agricultural engineering, put forward the research direction to solve the problems of precise navigation in agricultural environments.","['Navigation', 'Robot sensing systems', 'Path planning', 'Robot kinematics', 'Mobile robots', 'Wheels']","['WMRs', 'navigation', 'mapping', 'localization', 'path planning', 'agriculture']"
"In this paper, a robust model-free nonsingular terminal sliding-mode control (MFNTSMC) algorithm based on the ultra-local model is proposed to reduce the influence of permanent magnet (PM) demagnetization for PM synchronous motors (PMSMs). First, the PMSM mathematical model in normal and demagnetization is described, and the ultra-local model of speed loop and current loop is constructed based on the input and the output of the PMSM vector control system. Then, the MFNTSMC method is proposed and adopted to design the speed controller and d-q-axis current controller, and the sliding-mode observer is designed to estimate the unknown terms of the ultra-local model. Finally, compared with the PI control method and model-free control method, the results of simulations and experimentations show that the MFNTSMC method can improve the dynamic response while maintaining robustness of PMSM driven system, reduce the dependence of the design of controller on the precise PMSM model, and has fault-tolerant control function for PM demagnetization fault.","['Mathematical model', 'Demagnetization', 'Couplings', 'Stators', 'Sliding mode control', 'Rotors', 'Permanent magnet motors']","['Ultra-local model', 'permanent magnet synchronous motor (PMSM)', 'demagnetization', 'model-free nonsingular terminal sliding mode control (MFNTSMC)', 'sliding mode observer (SMO)']"
"The Internet of Things (IoT) paradigm enables computation and communication among tools that everyone uses daily. The vastness and heterogeneity of devices and their composition offer innovative services and scenarios that require a new challenging vision in interoperability, security and data management. Many IoT frameworks and platforms claimed to have solved these issues, aggregating different sources of information, combining their data flows in new innovative services, providing security robustness with respect to vulnerability and respecting the GDPR (General Data Protection Regulation) of the European Commission. Due to the potentially very sensible nature of some of these data, privacy and security aspects have to be taken into account by design and by default. In addition, an end-to-end secure solution has to guarantee a secure environment at the final users for their personal data, in transit and storage, which have to remain under their full control. In this paper, the Snap4City architecture and its security solutions that also respect the GDPR are presented. The Snap4City solution addresses the full stack security, ranging from IoT Devices, IoT Edge on premises, IoT Applications on the cloud and on premises, Data Analytics, and Dashboarding, presenting a number of integrated security solutions that go beyond the state of the art, as shown in the platform comparison. The stress test also included the adoption of penetrations tests verifying the robustness of the solution with respect to a large number of potential vulnerability aspects. The stress security assessments have been performed in a piloting period with more than 1200 registered users, thousands of processes per day, and more than 1.8 million of complex data ingested per day, in large cities such as Antwerp, Helsinki and the entire Tuscany region. Snap4City is a solution produced in response to a research challenge launched by the Select4Cities H2020 research and development project of the European Commission. Select4Cities identified a large number of requirements for modern Smart Cities that support IoT/IoE (Internet of Things/Everything) in the hands of public administrations and Living Labs, and selected a number of solutions. Consequently, at the end of the process after 3 years of work, Snap4City has been identified as the winning solution.","['Internet of Things', 'Security', 'Smart cities', 'Europe', 'Privacy', 'Cloud computing']","['End-2-end', 'GDPR', 'IoT', 'security', 'smart city']"
"Traffic speed prediction, as one of the most important topics in Intelligent Transport Systems (ITS), has been investigated thoroughly in the literature. Nonetheless, traditional methods show their limitation in coping with complexity and high nonlinearity of traffic data as well as learning spatial-temporal dependencies. Particularly, they often neglect the dynamics happening to traffic network. Attention-based models witnessed extensive developments in recent years and have shown its efficacy in a host of fields, which inspires us to leverage graph-attention-based method to handling traffic network speed prediction. In this paper, we propose a novel deep learning framework, Spatial-Temporal Graph Attention Networks (ST-GAT). A graph attention mechanism is adopted to extract the spatial dependencies among road segments. Additionally, we introduce a LSTM network to extract temporal domain features. Compared with previous related research, the proposed approach is able to capture dynamic spatial dependencies of traffic networks. A series of comprehensive case studies on a real-world dataset demonstrate that ST-GAT supersedes existing state-of-the-art results of traffic speed prediction. Furthermore, outstanding robustness against noise and on reduced graphs of the proposed model has been demonstrated through the tests.","['Feature extraction', 'Deep learning', 'Forecasting', 'Predictive models', 'Mathematical model', 'Roads', 'Computational modeling']","['Traffic speed prediction', 'graph attention', 'deep learning', 'intelligent transportation system', 'spatio-temporal domain feature']"
"The development of mobile cloud computing technology has made location-based service (LBS) increasingly more popular. Given the continuous requests to cloud LBS servers, the amounts of location and trajectory information collected by LBS servers are continuously increasing. Privacy awareness for LBS has been extensively studied in recent years. Among the privacy concerns about LBS, trajectory privacy preservation is particularly important. Based on privacy preservation models, previous work have mainly focused on peer-to-peer and centralized architectures. However, the burden on users is heavy in peer-to-peer architectures, because user devices need to communicate with LBS servers directly. In centralized architectures, a trusted third party (TTP) is introduced, and acts as a bridge between users and the LBS server. Anonymity technologies, such as k-anonymity, mix-zone, and dummy technologies, are usually implemented by the TTP to ensure safety. There are certain drawbacks in TTP architectures: Users have no physical control of the TTP. Moreover, the TTP is more attractive to adversaries, because substantially more sensitive information is stored by the TTP. To solve the above-mentioned problems, in this paper, we propose a fog structure to store partial important data with the dummy anonymity technology to ensure physical control, which can be considered as absolutely trust. Compared with cloud computing, fog computing is a promising technique that extends the cloud computing to the edge of a network. Moreover, fog computing provides local computation and storage abilities, wide geo-distribution, and support for mobility. Therefore, mobile users' partial important information can be stored on a fog server to ensure better management. We take the principles of similarity, intersection, practicability, and correlation into consideration and design a dummy rotation algorithm with several properties. The effectiveness of the proposed method is validated through extensive simulations, which show that the proposed method can provide enhanced privacy preservation.","['Servers', 'Trajectory', 'Privacy', 'Computer architecture', 'Mobile communication', 'Edge computing', 'Cloud computing']","['LBS privacy', 'trajectory privacy preservation', 'fog computing', 'rotation']"
"Ultrawideband (UWB) technology can provide short-range, high bandwidth communications at a very low energy consumption level, which is quite attractive for wireless body area networks (WBAN). In such a system, the presence of the human body brings huge challenges for both the design of the wearable antenna and the propagation model. First of all, the coupling between the wearable antenna and the human body should be considered even in the initial steps of the design, in order to be able to deal with both the possibly deteriorating performance of the antenna as a result of the body and the exposure risk for the body. Second, the propagation channel in WBAN is influenced by the continuous movement of the human body, due to the time-varying scattering of the electromagnetic waves. Lots of researchers have been active in this area and some significant progress has been achieved recently. This paper retrospects the latest results in the field of wearable ultrawideband antennas, propagation channels, and their respective application in WBAN systems.","['Ultra wideband antennas', 'Wireless communication', 'Body area networks', 'Topology', 'Biomedical monitoring', 'Substrates']","['Wearable antenna', 'ultrawideband (UWB) antenna', 'wireless body area network (WBAN)', 'propagation properties', 'channel model']"
"Each year, more than 30% of people over 65 years-old suffer some fall. Unfortunately, this can generate physical and psychological damage, especially if they live alone and they are unable to get help. In this field, several studies have been performed aiming to alert potential falls of the older people by using different types of sensors and algorithms. In this paper, we present a novel non-invasive monitoring system for fall detection in older people who live alone. Our proposal is using very-low-resolution thermal sensors for classifying a fall and then alerting to the care staff. Also, we analyze the performance of three recurrent neural networks for fall detections: long short-term memory (LSTM), gated recurrent unit, and Bi-LSTM. As many learning algorithms, we have performed a training phase using different test subjects. After several tests, we can observe that the Bi-LSTM approach overcome the others techniques reaching a 93% of accuracy in fall detection. We believe that the bidirectional way of the Bi-LSTM algorithm gives excellent results because the use of their data is influenced by prior and new information, which compares to LSTM and GRU. Information obtained using this system did not compromise the user's privacy, which constitutes an additional advantage of this alternative.","['Sensor arrays', 'Temperature sensors', 'Infrared sensors', 'Recurrent neural networks', 'Cameras']","['Fall detection', 'older people', 'artificial neural networks']"
"Optical neural network can process information in parallel by using the technology based on free-space and integrated platform. Over the last half century, the development of integrated circuits has been limited by Moore’s law. We know that neural network is based on the digital computer for successive calculation, most of which cannot be made into real-time processing system. Therefore, it is necessary to develop ONN for real-time processing and device miniaturization. In this paper, we review the progress of optical neural networks. Firstly, based on the principle of artificial neural networks, we elaborate the essence of optical matrix multiplier for linear operation. Then we introduce the optical neural network achieved by free-space optical interconnection and waveguide optical interconnection. Finally we talk about the nonlinearity in optical neural networks. With the gradual maturity of nanotechnology and the rapid advancement of silicon photonic integrated circuits, the progress of integrated photonic neural network has been promoted. Therefore, the construction of optical neural network on the future integrated photonic platform has potential application value.","['Optical interconnections', 'Nonlinear optics', 'Optical computing', 'Biological neural networks', 'Biomedical optical imaging', 'Optical imaging', 'Optical fiber networks']","['Optical neural networks', 'optical waveguides', 'free-space optical interconnection', 'optical non-linearities', 'optical elements', 'photonic integrated circuits']"
"Electroencephalography-based sleepiness detection system (ESDS) is a brain-computer interface that evaluates a driver's sleepiness level directly from cerebral activity. The goals of ESDS research are to estimate and produce a timely warning to prevent declines in performance efficiency and to inhibit sleepiness-related accidents. We first, review different types of measures used in sleepiness detection systems (SDSs) and presents their advantages and drawbacks. Second, the review includes several techniques proposed in ESDSs to optimize the number of EEG electrodes, increasing the sleepiness level resolution and incorporation of circadian information. Finally, the review discusses future direction that can be considered in the development of ESDS.","['Sleep', 'Electroencephalography', 'Electrodes', 'Electrostatic discharges', 'Vehicles', 'Fatigue', 'Energy measurement']","['Sleepiness', 'fatigue', 'countermeasure', 'accident prevention', 'alertness monitoring', 'classification', 'electroencephalography', 'multimodal approach', 'brain-computer interface', 'multi-modal approach', 'homeostasis', 'circadian']"
"This paper proposes a combination of phasor particle swarm optimization (PPSO) and a gravitational search algorithm, namely a hybrid PPSOGSA algorithm, for optimal power flow (OPF) in power systems with an integrated wind turbine (WT) and solar photovoltaic (PV) generators. The OPF formulation includes the forecasted active power generation of WT and PV as dependent variables, whereas the voltage magnitude at WT and PV buses is considered as control (decision) variables. Forecasting the output power of WT and PV generators is based on the real-time measurements and the probabilistic models of wind speed and solar irradiance. The proposed OPF approach and the solution method are verified on the IEEE 30-bus test system. The robustness and efficiency of the proposed PPSOGSA algorithm in solving the OPF problem are evaluated by comparing with 20 well-established metaheuristic optimization methods under the same system data, control variables, and constraints. The statistical features of the OPF results are estimated by using the Monte Carlo method.","['Wind speed', 'Generators', 'Linear programming', 'Reactive power', 'Wind power generation']","['Heuristic algorithms', 'load flow', 'optimization', 'wind power generation', 'solar power generation', 'power systems']"
"Works on pico-satellites have gained momentum recently, especially those that consider pico-satellites as part of a much larger constellation or swarm. This feature allows pico-satellites to provide high temporal resolution of observational data and redundancy. In particular, it reduces the need for satellite-to-ground communications and, hence, helps save energy and allows the execution of distributed processing algorithms on the satellites themselves. Consequently, satellite-to-satellite or cross-link communication is critical. To realize these advantages, the cross-link antenna employed on pico-satellites must meet many criteria, namely, small size, lightweight, low-power consumption, high gain, wide bandwidth, circular polarization, and beam steerability. To date, no works have examined the suitability of existing planar antenna designs for the use on pico-satellites. To this end, this paper contributes to the literature by focusing on microstrip patch and slot antennas that have the ability to achieve high gain, beam steering, and wide bandwidth. This paper reviews 66 planar antenna designs, which includes 38-patch and 28-slot antennas. In addition, we provide an extensive qualitative comparison of these antennas in terms of their mass, size, gain, beam steerability, type of polarization, operating frequency band, and return loss. In addition, we have evaluated three antenna designs that best address the pico-satellite challenges on a common platform. We find that the asymmetric E-shaped patch antenna design is the most suitable for the use on 2U CubeSats. This is because of its small size (34 × 13 mm 2 ) and high gain (7.3 dB). In addition, the E-shaped patch antenna yields a wide -10-dB bandwidth of 2300 MHz and a small return loss of -15.2 dB.","['Gain', 'Satellites', 'Microstrip antennas', 'Planar arrays', 'Microstrip', 'Patch antennas']","['circular polarization', 'reconfigurable antennas', 'antenna arrays', 'beam steering', 'CubeSat', 'pico-satellites', 'pico-satellites', 'microstrip patch antennas', 'sequential phase-rotation', 'Photonic Band- Gap (PBG)']"
"Supervisory Control and Data Acquisition (SCADA) systems are used for monitoring industrial devices. However, their security faces the threat of being compromised due to the increasing use of open access networks. The primary objective of this survey paper is to provide a comparative study of the on-going security research in SCADA systems. The paper provides a classification of attacks based on security requirements and network protocol layers. To secure the communication between nodes of SCADA networks, various security standards have been developed by different organizations. We conduct a study of the security standards developed for SCADA networks along with their vulnerabilities. Researchers have proposed various security schemes to overcome the weaknesses of SCADA standards. The paper organizes security schemes based on current standards, detection, and prevention of attacks. It also addresses the future challenges that SCADA networks may face, in particular, from quantum attacks. Furthermore, it outlines directions for further research in the field.","['SCADA systems', 'Quantum computing', 'Standards', 'Computer security', 'Protocols', 'Computer architecture']","['Asymmetric cryptography', 'intrusion detection system', 'key management protocol', 'n-ary tree', 'symmetric cryptography', 'SCADA networks']"
"The emergence of Internet protocol suites and packet-switching technologies tends to the considerations of security, privacy, scalability, and reliability in layered Internet service architectures. The existing service systems allow us to access big data, but few studies focus on the fundamental security and stability in these systems, especially when they involve large-scale networks with overloaded private information. In this paper, we explored the blockchain-based mechanism that aims to improve the critical features of traditional Internet services, including autonomous and decentralized processing, smart contractual enforcement of goals, and traceable trustworthiness in tamper-proof transactions. Furthermore, we provide a comprehensive review to conceptualize the blockchain-based framework to develop the decentralized protocols for the extensive number of Internet services. This comprehensive survey aims to address blockchain integration to secure Internet services and identify the critical requirements of developing a decentralized trustworthy Internet service. Additionally, we present a case study of the blockchain-based Internet of Things (IoT) for neuro-informatics to illustrate the potential applications of blockchain architectures. Finally, we summarize the trends and challenges of blockchain architectures that benefit a multitude of disciplines across all the Internet service fields of interest.","['Web and internet services', 'Blockchain', 'Computer architecture', 'Security', 'Protocols', 'Architecture']","['Internet service architecture', 'blockchain', 'security', 'decentralized network', 'multi-plane']"
"IEEE 802.1 time-sensitive networking (TSN) is a set of amendments to the IEEE 802.1 standard that enable safety-critical and real-time behavior over Ethernet for the industrial automation and automotive domains. Selected TSN mechanisms offer the possibility to emulate the well-known traffic classes found in mixed-criticality distributed systems: Time-triggered (TT) communication with low jitter and bounded endto-end latency, audio-video-bridging (AVB) streams with bounded end-to-end latency, and general besteffort messages, which have no timing guarantees. Critical traffic is guaranteed via the global network schedule which is stored in so-called gate control lists (GCLs) and controls the timely behavior of frames for each queue of an egress port. Although researchers have started to propose approaches for the routing and scheduling (i.e., GCL synthesis) of TT traffic, all previous research has ignored lower priority realtime traffic, such as AVB, resulting in TT configurations that may increase the worst-case delays of AVB traffic, rendering it unschedulable. In this paper, we propose a joint routing and scheduling approach for TT traffic, which takes into account the AVB traffic, such that both TT and the AVB traffic are schedulable. We extensively evaluate our approach on a number of synthetic and realistic test cases.","['Routing', 'Real-time systems', 'Standards', 'Schedules', 'Ethernet', 'Timing', 'Logic gates']","['IEEE 802.1 Time-sensitive networking', 'deterministic ethernet', 'real-time networks', 'routing', 'scheduling', 'meta-heuristic optimization']"
"Software systems are now ubiquitous and are used every day for automation purposes in personal and enterprise applications; they are also essential to many safety-critical and mission-critical systems, e.g., air traffic control systems, autonomous cars, and SCADA systems. With the availability of massive storage capabilities, high speed Internet, and the advent of Internet of Things devices, modern software systems are growing in both size and complexity. Maintaining a high quality of such complex systems while manually keeping the error rate at a minimum is a challenge. Therefore, automated detection of faulty components in a software system is important during software development and also post-delivery. Fault detection models usually needs to be trained on a labeled-balanced dataset with both faulty and nonfaulty samples. Earlier work, e.g. Mohsin et al. (2016), showed that most real fault detection training dataset are imbalanced. Thereby, the trained model gets over-fitted and classifies faulty components as non-faulty components. The consequence of a high false negative rate is cumulative and results in generating more errors when using the model in other software systems -never seen before, which is very expensive. In this paper, we propose a software defect prediction ensemble model which considers the class imbalance problem in real software datasets. We use different oversampling techniques to build an ensemble classifier that can reduce the effect of low minority samples in the defective data. The proposed approach is verified using PROMISE software engineering datasets. The results show that our ensemble oversampling technique can more greatly reduce the false negative rate compared to the standard classification techniques and identify the faulty components more accurately resulting in a less expensive detection system (lowering the rate of non-faulty predictions of faulty modules).","['Fault detection', 'Software systems', 'Training', 'Measurement', 'Prediction algorithms', 'Software algorithms']","['Software quality and fault detection', 'imbalanced metric data', 'ensemble model of detection', 'oversampling', 'highly accurate detection']"
"Medical imaging techniques play a critical role in diagnosing diseases and patient healthcare. They help in treatment, diagnosis, and early detection. Image segmentation is one of the most important steps in processing medical images, and it has been widely used in many applications. Multi-level thresholding (MLT) is considered as one of the simplest and most effective image segmentation techniques. Traditional approaches apply histogram methods; however, these methods face some challenges. In recent years, swarm intelligence methods have been leveraged in MLT, which is considered an NP-hard problem. One of the main drawbacks of the SI methods is when searching for optimum solutions, and some may get stuck in local optima. This because during the run of SI methods, they create random sequences among different operators. In this study, we propose a hybrid SI based approach that combines the features of two SI methods, marine predators algorithm (MPA) and moth-?ame optimization (MFO). The proposed approach is called MPAMFO, in which, the MFO is utilized as a local search method for MPA to avoid trapping at local optima. The MPAMFO is proposed as an MLT approach for image segmentation, which showed excellent performance in all experiments. To test the performance of MPAMFO, two experiments were carried out. The first one is to segment ten natural gray-scale images. The second experiment tested the MPAMFO for a real-world application, such as CT images of COVID-19. Therefore, thirteen CT images were used to test the performance of MPAMFO. Furthermore, extensive comparisons with several SI methods have been implemented to examine the quality and the performance of the MPAMFO. Overall experimental results confirm that the MPAMFO is an efficient MLT approach that approved its superiority over other existing methods.","['Image segmentation', 'COVID-19', 'Optimization methods', 'Computed tomography', 'Biomedical imaging', 'Entropy']","['Image segmentation', 'multi-level thresholding', 'moth-?ame optimization (MFO)', 'marine predators algorithm (MPA)', 'COVID-19', 'swarm intelligence']"
"As the educational possibilities of AR (Augmented Reality) and VR (Virtual Reality) are getting more attention, understanding teachers’ readiness to integrate new technologies for instruction would help researchers and practitioners to plan how to support them. In this regard, the present study explores teachers’ willingness to integrate AR and VR technologies for teaching and learning practices. Employing an extended Technology Acceptance Model (eTAM), this study investigated whether technological pedagogical and content knowledge (TPACK), social norm (SN), and motivational support (MS) for teachers influence teachers’ intention to use the technologies. Analysis from 292 in-service teacher responses supported all of the eight hypotheses formulated in the study. TPACK was found to have a significant influence on perceived usefulness (PU) and perceived ease of use (PEU) while SN influenced PU. In addition, MS was found to have an influence on PEU, which ultimately affects attitudes toward technology use (ATU) and then behavioral intention (BI). The results imply the importance of providing technology professional development (PD) and support for teachers to promote the use of AR and VR in classrooms.","['Education', 'Technology acceptance model', 'Augmented reality', 'Predictive models', 'Computational modeling', 'Systematics']","['Technology integration', 'technology acceptance model (TAM)', 'TPACK', 'motivational support', 'social norm', 'emerging technology', 'augmented reality', 'virtual reality']"
"Compared to the traditional machine learning models, deep neural networks (DNN) are known to be highly sensitive to the choice of hyperparameters. While the required time and effort for manual tuning has been rapidly decreasing for the well developed and commonly used DNN architectures, undoubtedly DNN hyperparameter optimization will continue to be a major burden whenever a new DNN architecture needs to be designed, a new task needs to be solved, a new dataset needs to be addressed, or an existing DNN needs to be improved further. For hyperparameter optimization of general machine learning problems, numerous automated solutions have been developed where some of the most popular solutions are based on Bayesian Optimization (BO). In this work, we analyze four fundamental strategies for enhancing BO when it is used for DNN hyperparameter optimization. Specifically, diversification, early termination, parallelization, and cost function transformation are investigated. Based on the analysis, we provide a simple yet robust algorithm for DNN hyperparameter optimization - DEEP-BO (Diversified, Early-termination-Enabled, and Parallel Bayesian Optimization). When evaluated over six DNN benchmarks, DEEP-BO mostly outperformed well-known solutions including GP-Hedge, BOHB, and the speed-up variants that use Median Stopping Rule or Learning Curve Extrapolation. In fact, DEEP-BO consistently provided the top, or at least close to the top, performance over all the benchmark types that we have tested. This indicates that DEEP-BO is a robust solution compared to the existing solutions. The DEEP-BO code is publicly available at https://github.com/snu-adsl/DEEP-BO.","['Benchmark testing', 'Optimization', 'Tuning', 'Bayes methods', 'Task analysis', 'Training', 'Deep learning']","['Deep neural networks', 'hyperparameter optimization', 'Bayesian optimization', 'diversification', 'early termination', 'parallelization', 'cost function transformation']"
"Federated Learning (FL) has recently attracted considerable attention in internet of things, due to its capability of enabling mobile clients to collaboratively learn a global prediction model without sharing their privacy-sensitive data to the server. Despite its great potential, a main challenge of FL is that the training data are usually non-Independent, Identically Distributed (non-IID) on the clients, which may bring the biases in the model training and cause possible accuracy degradation. To address this issue, this paper aims to propose a novel FL algorithm to alleviate the accuracy degradation caused by non-IID data at clients. Firstly, we observe that the clients with different degrees of non-IID data present heterogeneous weight divergence with the clients owning IID data. Inspired by this, we utilize weight divergence to recognize the non-IID degrees of clients. Then, we propose an efficient FL algorithm, named CSFedAvg, in which the clients with lower degree of non-IID data will be chosen to train the models with higher frequency. Finally, we conduct simulations using publicly-available datasets to train deep neural networks. Simulation results show that the proposed FL algorithm improves the training performance compared with existing FL protocol.","['Data models', 'Training', 'Servers', 'Computational modeling', 'Internet of Things', 'Distributed databases', 'Degradation']","['Federated learning', 'mobile edge computing', 'client selection']"
"COVID-19 has affected all peoples’ lives. Though COVID-19 is on the rising, the existence of misinformation about the virus also grows in parallel. Additionally, the spread of misinformation has created confusion among people, caused disturbances in society, and even led to deaths. Social media is central to our daily lives. The Internet has become a significant source of knowledge. Owing to the widespread damage caused by fake news, it is important to build computerized systems to detect fake news. The paper proposes an updated deep neural network for identification of false news. The deep learning techniques are The Modified-LSTM (one to three layers) and The Modified GRU (one to three layers). In particular, we carry out investigations of a large dataset of tweets passing on data with respect to COVID-19. In our study, we separate the dubious claims into two categories: true and false. We compare the performance of the various algorithms in terms of prediction accuracy. The six machine learning techniques are decision trees, logistic regression, k nearest neighbors, random forests, support vector machines, and naïve Bayes (NB). The parameters of deep learning techniques are optimized using Keras-tuner. Four Benchmark datasets were used. Two feature extraction methods were used (TF-ID with N-gram) to extract essential features from the four benchmark datasets for the baseline machine learning model and word embedding feature extraction method for the proposed deep neural network methods. The results obtained with the proposed framework reveal high accuracy in detecting Fake and non-Fake tweets containing COVID-19 information. These results demonstrate significant improvement as compared to the existing state of art results of baseline machine learning models. In our approach, we classify the data into two categories: fake or nonfake. We compare the execution of the proposed approaches with Six machine learning procedures. The six machine learning procedures are Decision Tree (DT), Logistic Regression (LR), K Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB). The parameters of deep learning techniques are optimized using Keras-tuner. Four Benchmark datasets were used. Two feature extraction methods were used (TF-ID with N-gram) to extract essential features from the four benchmark datasets for the baseline machine learning model and word embedding feature extraction method for the proposed deep neural network methods. The results obtained with the proposed framework reveal high accuracy in detecting Fake and non-Fake tweets containing COVID-19 information. These results demonstrate significant improvement as compared to the existing state of art results of baseline machine learning models.","['COVID-19', 'Social networking (online)', 'Feature extraction', 'Deep learning', 'Blogs', 'Viruses (medical)', 'Organizations']","['Fake news', 'COVID-19', 'misleading information', 'pandemic', 'social media', 'deep learning']"
"Maximum power point tracking (MPPT) is essential in Photovoltaic (PV) systems, which has drawn significant research effort in the past. The operation is to adjust the power interfaces so that the operating characteristics of the consumption and the PV generator match at the ideal level in term of generation. A comprehensive review is essential to help readers understand the latest developments and inform research directions. Unlike the other review papers, this paper focuses on the operational principles of MPPT methods. Therefore, a different review angle is presented in this paper to provide a clear image of the technology of MPPT.","['Maximum power point trackers', 'Resistance', 'Photovoltaic systems', 'Temperature sensors', 'DC-DC power converters']","['Photovoltaic (PV) system', 'maximum power point tracking (MPPT)', 'review']"
"Responding to the unprecedented challenges imposed by the 5G communications ecosystem, emerging heterogeneous network architectures allow for improved integration between multiple radio access technologies. When combined with advanced cloud infrastructures, they bring to life a novel paradigm of heterogeneous cloud radio access network (H-CRAN). The novel H-CRAN architecture opens door to improved network-wide management, including coordinated cross-cell radio resource allocation. In this paper, emphasizing the lack of theoretical performance analysis, we specifically address the problem of cooperative radio resource management in H-CRAN by providing a comprehensive mathematical methodology for its real-time performance optimization. Our approach enables flexible balance between throughput and fairness metrics, as may be desired by the network operator, and demonstrates attractive benefits when compared against the state-of-the-art multiradio resource allocation strategies. The resulting algorithms are suitable for efficient online implementation, which principal feasibility is confirmed by our proof-of-concept prototype.","['5G mobile communication', 'Heterogeneous networks', 'Cloud computing', 'Radio access networks', 'Resource management', 'Radio commuincation', 'Prototypes', 'Mathematical model']","['Heterogeneous network', 'cloud infrastructure', 'heterogeneous cloud radio access network', 'cooperative radio resource management', 'mathematical methodology', 'prototyping']"
"Plant disease, especially crop plants, is a major threat to global food security since many diseases directly affect the quality of the fruits, grains, and so on, leading to a decrease in agricultural productivity. Farmers have to observe and determine whether a leaf was infected by naked eyes. This process is unreliable, inconsistent, and error prone. Several works on deep learning techniques for detecting leaf diseases had been proposed. Most of them built their models based on limited resolution images using convolutional neural networks (CNNs). In this research, we aim at detecting early disease on plant leaves with small disease blobs, which can only be detected with higher resolution images, by an artificial neural network (ANN) approach. After a pre-processing step using a contrast enhancement method, all the infested blobs are segmented for the whole dataset. A list of several measurement-based features that represents the blobs are chosen and then selected based on their influences on the model's performance using a wrapper-based feature selection algorithm, which is built based on a hybrid metaheuristic. The chosen features are used as inputs for an ANN. We compare the results obtained using our methods with another approach using popular CNN models (AlexNet, VGG16, ResNet-50) enhanced with transfer learning. The ANN's results are better than those of CNNs using a simpler network structure (89.41% vs 78.64%, 79.92%, and 84.88%, respectively). This shows that our approach can be implemented on low-end devices such as smartphones, which will be of great assistance to farmers on the field.","['Diseases', 'Feature extraction', 'Training', 'Agriculture', 'Artificial neural networks', 'Plants (biology)']","['Neural network', 'image classification', 'plant disease', 'feature selection', 'precision agriculture']"
"Content caching at network edge nodes, such as base stations (BSs) and user equipments (UEs), can significantly reduce the traffic load in future cellular networks. Considering the limited caching space, the contents cached at BSs should be selected carefully for improving caching efficiency. In this paper, we study the edge caching at BSs to minimize the transmission cost by considering traffic offloading via the device-to-device (D2D) communications. The traffic offloading reduces the traffic via cellular transmission and thus changes the utility achieved by content caching at BSs. We model the edge caching problem as a Markov decision process and propose a distributed cache replacement strategy based on Q-learning. The proposed strategy further needs the calculations of the following two key parameters: 1) To describe the effect of D2D offloading to the cellular traffic, we define the cellular serving ratio, which is calculated by the iterative maximum weighted independent sets problem for static networks and the stochastic geometry for high-dynamic networks; 2) The cache replacement rewards are calculated by analyzing the relationship between the requested and cached amounts of content data, which are obtained from the messages of the previous data request and transmissions, ignoring any extra information exchange between the BSs. Furthermore, the convergence of the proposed distributed cache replacement strategy is proved by the sequential stage game model. Simulation results verify the convergence of the proposed cache replacement strategy and show its performance gain compared with conventional strategies.","['Device-to-device communication', 'Cellular networks', 'Base stations', 'Convergence', 'Servers', 'Markov processes', 'Information exchange']","['Mobile communications', 'content caching', 'device-to-device communications', 'Markov decision process']"
"A blockchain as a trustworthy and secure decentralized and distributed network has been emerged for many applications such as in banking, finance, insurance, healthcare and business. Recently, many communities in blockchain networks want to deploy machine learning models to get meaningful knowledge from geographically distributed large-scale data owned by each participant. To run a learning model without data centralization, distributed machine learning (DML) for blockchain networks has been studied. While several works have been proposed, privacy and security have not been sufficiently addressed, and as we show later, there are vulnerabilities in the architecture and limitations in terms of efficiency. In this paper, we propose a privacy-preserving DML model for a permissioned blockchain to resolve the privacy, security, and performance issues in a systematic way. We develop a differentially private stochastic gradient descent method and an error-based aggregation rule as core primitives. Our model can treat any type of differentially private learning algorithm where non-deterministic functions should be defined. The proposed error-based aggregation rule is effective to prevent attacks by an adversarial node that tries to deteriorate the accuracy of DML models. Our experiment results show that our proposed model provides stronger resilience against adversarial attacks than other aggregation rules under a differentially private scenario. Finally, we show that our proposed model has high usability because it has low computational complexity and low transaction latency.","['Blockchain', 'Computational modeling', 'Security', 'Privacy', 'Machine learning', 'Computer architecture', 'Fabrics']","['Adversarial node', 'differential privacy', 'machine learning', 'permissioned blockchain']"
"This paper presents a review of the electrical and electronic technologies investigated in more-electric aircraft (MEA). In order to change the current situation of low power efficiency, serious pollution, and high operating cost in conventional aircraft, the concept of MEA is proposed. By converting some hydraulic, mechanical, and pneumatic power sources into electrical ones, the overall power efficiency is greatly increased, and more flexible power regulation is achieved. The main components in an MEA power system are electrical machines and power electronics devices. The design and control methods for electrical machines and various topologies and control strategies for power electronic converters have been widely researched. Besides, several studies are carried out regarding energy management strategies that intend to optimize the operation of MEA power distribution systems. Furthermore, it is necessary to investigate the system stability and reliability issues in an MEA, since they are directly related to the safety of passengers. In terms of machine technologies, power electronics techniques, energy management strategies, and the system stability and reliability, a review is carried out for the contributions in the literature to MEA.","['Aircraft', 'Aerospace electronics', 'Reliability', 'Power system stability', 'Hydraulic systems', 'Power system reliability', 'Power electronics']","['More-electric aircraft', 'machine technologies', 'power electronics techniques', 'energy management strategies', 'system stability and reliability']"
"The health condition of rolling bearing possesses a significant impact on the safety and efficiency of rotating machinery. Accordingly, to diagnose the faults in rolling bearings effectively and accurately, a novel hybrid approach coupling variational mode decomposition (VMD), composite multiscale fine-sorted dispersion entropy (CMFSDE) and support vector machine (SVM) optimized by mutation sine cosine algorithm and Harris hawks optimization (MSCAHHO) is proposed in the paper. Firstly, VMD is employed to decompose raw vibration signals with various fault types into different sets of intrinsic mode functions (IMFs) to weaken the non-stationarity of signals, before which the parameter K of VMD is decided through central frequency observation method. Subsequently, CMFSDE is put forward in this paper to analyze the complexity of fault signals by fully considering the relationship between neighboring elements based on composite multiscale technique, with which the representative features of different fault samples are extracted to construct feature vectors. Later, an enhanced hybrid optimization approach called MSCAHHO is proposed by integrating sine cosine algorithm (SCA) and a periodic mutation strategy to improve Harris hawks optimization (HHO). Then, MSCAHHO is employed to optimize the parameters of SVM, after which the optimal SVM model is utilized for fault classification. Finally, the performance of the proposed methodology is evaluated with four validity indices through comparative experiments. The experimental results reveal that the proposed VMD-CMFSDE-MSCAHHO-SVM method achieves favorable diagnosis results comparing with other relevant methods.","['Support vector machines', 'Feature extraction', 'Entropy', 'Optimization', 'Fault diagnosis', 'Rolling bearings', 'Dispersion']","['Fault diagnosis', 'variational mode decomposition', 'composite multiscale fine-sorted dispersion entropy', 'support vector machine', 'hybrid mutation SCA-HHO']"
"This paper investigates a fixed-time leader-following formation control method for a set of autonomous underwater vehicles (AUVs) with event-triggered acoustic communications. First, an event-triggering communication strategy is developed to govern the communications between leader AUV and follower AUVs. Then, using a fixed-time control theory and a Lyapunov functional method, a compensator-based command filtered formation control algorithm is proposed, with which the follower AUVs can track the leader AUV in a given fixed time. Namely, the control method can guarantee all the signals in the formation control system to be globally fixed-time stabilized. With the presented fixed-time control scheme, the predesignated AUVs formation can be achieved within a fixed settling time under arbitrary initial system states, which is otherwise impossible under any existing methods including finite-time control. Furthermore, the compensator-based command filtered control technique makes the designed formation control law simple and easy to implement in practice. Simulation results demonstrate the effectiveness of the method.","['Convergence', 'Underwater autonomous vehicles', 'Acoustic communication (telecommunication)', 'Gold', 'Vehicle dynamics', 'Data communication', 'Fuels']","['Autonomous underwater vehicles (AUVs)', 'event-triggered', 'leader-follower', 'formation control', 'fixed-time']"
"In this paper, fractional Zernike moments (FrZMs) for complex signals are generalized to fractional quaternion Zernike moments (FrQZMs) for quaternion signal processing in a holistic manner by the quaternion algebra. We first present the definition of FrQZMs and an efficient implementation algorithm for speeding up the computation of FrQZMs through FrZMs of each component of the quaternion signal. The performance of the proposed FrQZMs is evaluated by considering robust color image copy-move forgery detection. The proposed robust copy-move forgery-detection algorithm considers the FrQZMs as a feature and a modified PatchMatch algorithm as a feature matching algorithm. Experimental results on two publicly available data sets (FAU and GRIP data set) have demonstrated that the proposed FrQZM-based algorithm can achieve an overall better performance than the state-of-the-art algorithms, especially in some additional operation cases.","['Quaternions', 'Transforms', 'Feature extraction', 'Forgery', 'Color', 'Signal processing algorithms', 'Robustness']","['Quaternion', 'color image', 'fractional Zernike moments', 'image forgery detection']"
"This paper implements and compares a symmetric hybridized cascaded multilevel inverter and an asymmetric multilevel inverter utilizing a switched capacitor unit for 17 level inverters. The symmetric hybridized multilevel inverter topology consists of a modified H-bridge inverter, which results in an increase in the output voltage to five level from the three level by using a bi-directional switch at the midpoint of a dual-input dc source. In the proposed asymmetric multilevel inverter, dc sources are replaced with the switched capacitor unit, which in turn boosts the output voltage and produces twice the voltage levels at the loads. The proposed topology with the staircase modulation technique has been verified using MATLAB-SIMULINK, and the results are experimentally executed with prototype models, which are interfaced with dSPACE RTI 1104. The results of the proposed topologies are experimentally obtained for steady state, and the performance of the same is tested under different resistive and inductive load disturbance conditions. The results substantiate that these multilevel inverter topologies are better stabilized during load disturbance conditions with low total harmonic distortion, a lesser number of switches, and increased output voltage levels, and these topologies well suit for renewable energy applications.","['Switches', 'Inverters', 'Topology', 'Capacitors', 'Pulse width modulation', 'Discharges (electric)']","['Multilevel inverter (MLI)', 'staircase pulse width modulation technique (SPWM)', 'switched capacitor unit (SCU)', 'total harmonic distortion (THD)', 'high output voltage levels']"
"The use of hyperspectral imaging for medical applications is becoming more common in recent years. One of the main obstacles that researchers find when developing hyperspectral algorithms for medical applications is the lack of specific, publicly available, and hyperspectral medical data. The work described in this paper was developed within the framework of the European project HELICoiD ( HypErspectraL Imaging Cancer Detection ), which had as a main goal the application of hyperspectral imaging to the delineation of brain tumors in real-time during neurosurgical operations. In this paper, the methodology followed to generate the first hyperspectral database of in-vivo human brain tissues is presented. Data was acquired employing a customized hyperspectral acquisition system capable of capturing information in the Visual and Near InfraRed (VNIR) range from 400 to 1000 nm. Repeatability was assessed for the cases where two images of the same scene were captured consecutively. The analysis reveals that the system works more efficiently in the spectral range between 450 and 900 nm. A total of 36 hyperspectral images from 22 different patients were obtained. From these data, more than 300 000 spectral signatures were labeled employing a semi-automatic methodology based on the spectral angle mapper algorithm. Four different classes were defined: normal tissue, tumor tissue, blood vessel, and background elements. All the hyperspectral data has been made available in a public repository.","['Tumors', 'Hyperspectral imaging', 'Brain', 'Surgery', 'Hospitals', 'Magnetic resonance imaging']","['Hyperspectral imaging', 'cancer detection', 'biomedical imaging', 'medical diagnostic imaging', 'image databases']"
"One key challenging issues of facial expression recognition (FER) in video sequences is to extract discriminative spatiotemporal video features from facial expression images in video sequences. In this paper, we propose a new method of FER in video sequences via a hybrid deep learning model. The proposed method first employs two individual deep convolutional neural networks (CNNs), including a spatial CNN processing static facial images and a temporal CN network processing optical flow images, to separately learn high-level spatial and temporal features on the divided video segments. These two CNNs are fine-tuned on target video facial expression datasets from a pre-trained CNN model. Then, the obtained segment-level spatial and temporal features are integrated into a deep fusion network built with a deep belief network (DBN) model. This deep fusion network is used to jointly learn discriminative spatiotemporal features. Finally, an average pooling is performed on the learned DBN segment-level features in a video sequence, to produce a fixed-length global video feature representation. Based on the global video feature representations, a linear support vector machine (SVM) is employed for facial expression classification tasks. The extensive experiments on three public video-based facial expression datasets, i.e., BAUM-1s, RML, and MMI, show the effectiveness of our proposed method, outperforming the state-of-the-arts.",[],[]
"Online social networks (ONSs) such as Twitter have grown to be very useful tools for the dissemination of information. However, they have also become a fertile ground for the spread of false information, particularly regarding the ongoing coronavirus disease 2019 (COVID-19) pandemic. Best described as an infodemic, there is a great need, now more than ever, for scientific fact-checking and misinformation detection regarding the dangers posed by these tools with regards to COVID-19. In this article, we analyze the credibility of information shared on Twitter pertaining the COVID-19 pandemic. For our analysis, we propose an ensemble-learning-based framework for verifying the credibility of a vast number of tweets. In particular, we carry out analyses of a large dataset of tweets conveying information regarding COVID-19. In our approach, we classify the information into two categories: credible or non-credible. Our classifications of tweet credibility are based on various features, including tweet- and user-level features. We conduct multiple experiments on the collected and labeled dataset. The results obtained with the proposed framework reveal high accuracy in detecting credible and non-credible tweets containing COVID-19 information.","['Twitter', 'Diseases', 'Feature extraction', 'Tools', 'Machine learning', 'Organizations']","['Classification', 'COVID-19', 'machine learning', 'misinformation', 'Twitter']"
"Although the blockchain technology was first introduced through Bitcoin, extending its usage to non-financial applications, such as managing electronic medical records, is an attractive mission for recent research to balance the needs for increasing data privacy and the regular interaction among patients and health providers. Various systems that adopts the blockchain in managing medical records have been proposed. However, there is a need for more work to better characterize, understand and evaluate the employment of blockchain technology in the healthcare industry. In this paper, a design of blockchain based system, namely MedChain, for managing medical records is proposed. MedChain is designed to improve the current systems as it provides interoperable, secure, and effective access for medical records by patients, health care providers, and other third parties, while keeping the patients' privacy. MedChain employs timed-based smart contracts for governing transactions and controlling accesses to electronic medical records. It adopts advanced encryption techniques for providing further security. This work proposes a new incentive mechanism that leverages the degree of health providers regarding their efforts on maintaining medical records and creating new blocks. Extensive experiments are conducted to evaluate the MedChain performance, and results indicate the efficiency of our proposal in handling a large dataset at low latency.","['Blockchain', 'Medical services', 'Smart contracts', 'Access control', 'Medical diagnostic imaging', 'Bitcoin']","['Blockchain', 'electronic medical records', 'incentive mechanism', 'smart contracts']"
"To explore the advantages of adversarial learning and deep learning, we propose a novel network intrusion detection model called SAVAER-DNN, which can not only detect known and unknown attacks but also improve the detection rate of low-frequent attacks. SAVAER is a supervised variational auto-encoder with regularization, which uses WGAN-GP instead of the vanilla GAN to learn the latent distribution of the original data. SAVAER's decoder is used to synthesize samples of low-frequent and unknown attacks, thereby increasing the diversity of training samples and balancing the training data set. SAVAER's encoder is used to initialize the weights of the hidden layers of the DNN and explore high-level feature representations of the original samples. The benchmark NSL-KDD (KDDTest+), NSL-KDD (KDDTest-21) and UNSW-NB15 datasets are used to evaluate the performance of the proposed model. The experimental results show that the proposed SAVAER-DNN is more suitable for data augmentation than the other three well-known data oversampling methods. Moreover, the proposed SAVAER-DNN outperforms eight well-known classification models in detection performance and is more effective in detecting low-frequent and unknown attacks. Furthermore, compared with other state-of-the-art intrusion detection models reported in the IDS literature, the proposed SAVAER-DNN offers better performance in terms of overall accuracy, detection rate, F1 score, and false positive rate.","['Intrusion detection', 'Machine learning', 'Feature extraction', 'Training', 'Gallium nitride', 'Neural networks']","['Intrusion detection', 'supervised adversarial variational auto-encoder', 'regularization', 'WGAN-GP', 'deep learning']"
"With the development of modern manufacturing industry, the application scenarios of industrial robot are becoming more and more complex. Manual programming of industrial robot requires a great deal of effort and time. Therefore, an autonomous path planning is an important development direction of industrial robot. Among the path planning methods, the rapidly-exploring random tree (RRT) algorithm based on random sampling has been widely applied for a high-dimensional robotic manipulator because of its probability completeness and outstanding expansion. However, especially in the complex scenario, the existing RRT planning algorithms still have a low planning efficiency and some are easily fall into a local minimum. To tackle these problems, this paper proposes an autonomous path planning method for the robotic manipulator based on an improved RRT algorithm. The method introduces regression mechanism to prevent over-searching configuration space. In addition, it adopts an adaptive expansion mechanism to continuously improve reachable spatial information by refining the boundary nodes in joint space, avoiding repeatedly searching for extended nodes. Furthermore, it avoids the unnecessary iteration of the robotic manipulator forward kinematics solution and its time-consuming collision detection in Cartesian space. The method can rapidly plan a path to a target point and can be accelerated out of a local minimum area to improve path planning efficiency. The improved RRT algorithm proposed in this paper is simulated in a complex environment. The results reveal that the proposed algorithm can significantly improve the success rate and efficiency of the planning without losing other performance.","['Path planning', 'Collision avoidance', 'Manipulators', 'Service robots', 'Heuristic algorithms', 'Planning']","['Rapidly-exploring random tree (RRT)', 'path planning', 'industrial robot', 'obstacle avoidance', 'collision-free']"
"Photonic solutions are today a mature industrial reality concerning high speed, high throughput data communication and switching infrastructures. It is still a matter of investigation to what extent photonics will play a role in next-generation computing architectures. In particular, due to the recent outstanding achievements of artificial neural networks, there is a big interest in trying to improve their speed and energy efficiency by exploiting photonic-based hardware instead of electronic-based hardware. In this work we review the state-of-the-art of photonic artificial neural networks. We propose a taxonomy of the existing solutions (categorized into multilayer perceptrons, convolutional neural networks, spiking neural networks, and reservoir computing) with emphasis on proof-of-concept implementations. We also survey the specific approaches developed for training photonic neural networks. Finally we discuss the open challenges and highlight the most promising future research directions in this field.","['Photonics', 'Biological neural networks', 'Neurons', 'Computer architecture', 'Taxonomy', 'Nonlinear optics']","['Artificial neural networks', 'neural network hardware', 'photonics', 'neuromorphic computing', 'photonic neural networks']"
"Breast cancer is type of tumor that occurs in the tissues of the breast. It is most common type of cancer found in women around the world and it is among the leading causes of deaths in women. This article presents the comparative analysis of machine learning, deep learning and data mining techniques being used for the prediction of breast cancer. Many researchers have put their efforts on breast cancer diagnoses and prognoses, every technique has different accuracy rate and it varies for different situations, tools and datasets being used. Our main focus is to comparatively analyze different existing Machine Learning and Data Mining techniques in order to find out the most appropriate method that will support the large dataset with good accuracy of prediction. The main purpose of this review is to highlight all the previous studies of machine learning algorithms that are being used for breast cancer prediction and this article provides the all necessary information to the beginners who want to analyze the machine learning algorithms to gain the base of deep learning.","['Breast cancer', 'Machine learning', 'Prediction algorithms', 'Machine learning algorithms', 'Data mining', 'Clustering algorithms']","['Machine learning', 'breast cancer prediction', 'deep learning', 'data mining', 'ensemble techniques']"
"With the rapid expansion in the number of Unmanned Aircraft Vehicles (UAVs) available and the development of modern technologies, the commercial applications of UAVs in urban areas, such as urban remote sensing (RS), express services, urban road traffic monitoring, urban police security, urban air shows and so on, have increased greatly. However, most UAVs, especially light and small civil UAVs, have been operating in low-altitude airspace, and a conflict may exist between increasing the number of UAVs and the limited low airspace. To promote low-altitude airspace resource development and to standardize the operation and management of UAVs in urban regions, some global laws and regulations and key technologies for urban low-altitude applications of UAVs have been implemented. This paper reviews the development of current policies and key technologies concerning safe and efficient operations of the light-and-small civil UAVs in low altitude in urban areas. Discussions are made progressively on measures and methods of airspace restriction, airspace structuring and air route planning in China primarily and the rest of world. After surveying the practical industry tests and the initial studies of air routes, the survey results indicate that the construction of air route networks is a scientific and effective measure to standardize and improve the efficiency of low-altitude UAV operations. From the view point of safety and efficiency, the most valuable direction for UAV regulation in urban regions involves deepening the research which largely relies on urban RS and Geographic Information System (GIS) technology, and application demonstrations of low-altitude public air route networks.","['Unmanned aerial vehicles', 'Regulation', 'Urban areas', 'Aircraft', 'Safety', 'Geographic information systems', 'Planning']","['Low-altitude airspace', 'RS and GIS for UAV regulation', 'UAV regulation technology and policy', 'Urban region', 'UAV low-altitude air routes']"
"Rolling bearings are one of the essential components in rotating machinery. Efficient bearing fault diagnosis is necessary to ensure the regular operation of the mechanical system. Traditional fault diagnosis methods usually rely on a complex artificial feature extraction process, which requires a lot of human expertise. Emerging deep learning methods can reduce the dependence of the feature extraction process on manual intervention effectively. However, its training requires a large number of fault signals, which is difficult to obtain in actual engineering. In this paper, a rolling bearing fault diagnosis method based on Convolutional Neural Network and Support Vector Machine is proposed to solve the above problems. Firstly, the Continuous Wavelet Transform is used to convert one-dimensional original vibration signals into two-dimensional time-frequency images. Secondly, the obtained time-frequency images are input for training the constructed model. Finally, the diagnosis of the fault location and severity is completed. The method is verified on the CWRU data set and the MFPT data set. The results demonstrate that the proposed method achieves higher diagnostic accuracy and stability than other advanced techniques.","['Feature extraction', 'Support vector machines', 'Continuous wavelet transforms', 'Fault diagnosis', 'Time-frequency analysis', 'Rolling bearings']","['Convolutional neural network', 'continuous wavelet transform', 'fault diagnosis', 'rolling bearing', 'support vector machine']"
"The explosive rise of intelligent devices with ubiquitous connectivity have dramatically increased Internet of Things (IoT) traffic in the cloud environment and created potential attack surfaces for cyber-attacks. Traditional security approaches are insufficient and inefficient to address security threats in cloud-based IoT networks. In this vein, software defined networking (SDN), network function virtualization (NFV), and machine learning techniques introduce numerous advantages that can effectively resolve cybersecurity matters for cloud-based IoT systems. In this paper, we propose a collaborative and intelligent network-based intrusion detection system (NIDS) architecture, namely SeArchfor SDN-based cloud IoT networks. It composes a hierarchical layer of intelligent IDS nodes working in collaboration to detect anomalies and formulate policy into the SDN-based IoT gateway devices to stop malicious traffic as fast as possible. We first describe a new NIDS architecture with a comprehensive analysis in terms of the system resource and path selection optimizations. Next, the system process logic is extensively investigated through main consecutive procedures, including initialization, runtime operation, and database update. Afterward, we conduct a detailed implementation of the proposed solution in an SDN-based environment and perform a variety of experiments. Finally, evaluation results of the SeArcharchitecture yield outstanding performance in anomaly detection and mitigation as well as bottleneck problem handling in the SDN-based cloud IoT networks in comparison with existing solutions.","['Cloud computing', 'Internet of Things', 'Security', 'Edge computing', 'Computer architecture', 'Collaboration', 'Logic gates']","['Internet of Things security', 'software defined networking', 'network function virtualization', 'machine learning', 'intrusion detection system', 'distributed cloud computing']"
"Due to the development of the computer vision, machine learning, and deep learning technologies, the research community focuses not only on the traditional SLAM problems, such as geometric mapping and localization, but also on semantic SLAM. In this paper, we propose a Semantic SLAM system which builds the semantic maps with object-level entities, and it is integrated into the RGB-D SLAM framework. The system combines object detection module that is realized by the deep-learning method, and localization module with RGB-D SLAM seamlessly. In the proposed system, object detection module is used to perform object detection and recognition, and localization module is utilized to get the exact location of the camera. The two modules are integrated together to obtain the semantic maps of the environment. Furthermore, to improve the computational efficiency of the framework, an improved Octomap based on the Fast Line Rasterization Algorithm is constructed. Meanwhile, for the sake of accuracy and robustness of the semantic map, conditional random field is employed to do the optimization. Finally, we evaluate our Semantic SLAM through three different tasks, i.e., localization, object detection, and mapping. Specifically, the accuracy of localization and the mapping speed is evaluated on TUM data set. Compared with ORB-SLAM2 and original RGB-D SLAM, our system, respectively, got 72.9% and 91.2% improvements in dynamic environments localization evaluated by root-mean-square error. With the improved Octomap, the proposed Semantic SLAM is 66.5% faster than the original RGB-D SLAM. We also demonstrate the efficiency of object detection through quantitative evaluation in an automated inventory management task on a real-world data sets recorded over a realistic office.","['Semantics', 'Simultaneous localization and mapping', 'Three-dimensional displays', 'Object detection', 'Cameras', 'Feature extraction']","['CRF', 'Octomap', 'semantic messages', 'SLAM']"
"Precise estimation of state of health (SOH) are of great importance for proper operation of lithium-ion batteries equipped in electric vehicles. For real applications, it is however difficult to estimate battery SOH due to stochastic operation, which in turn speeds up aging process of the battery. To attain the precise SOH estimation, an efficient estimation manner based on machine learning is proposed in this study. Firstly, the voltage profile during charging and discharging process and incremental capacity variation are acquired through the cycle life test, and the healthy features correlating to battery degradation are extracted. Secondly, the grey relation analysis and entropy weight method are employed to analyze the healthy features. Finally, the long short-term memory is established to achieve the SOH estimation of battery. The experimental results highlight that the proposed method can effectively predict the battery SOH with preferable accuracy, stability and robustness.","['Degradation', 'Hafnium', 'Estimation', 'Logic gates', 'Adaptation models', 'Lithium-ion batteries']","['Healthy features (HFs)', 'grey relational analysis (GRA)', 'entropy weight method (EWM)', 'long short-term memory (LSTM)', 'state of health (SOH)']"
"In this paper, we provide a comprehensive review of diverse index modulation (IM) architectures that operate in the space, time, and frequency domains, as well as their related technologies. We clarify that several IM-specific characteristics have explicit advantages over those of the conventional bandwidthefficient counterparts, such as spatial multiplexing, orthogonal frequency division multiplexing, and singlecarrier frequency division multiple access, which have been widely employed in the current wireless standards. While, for the next-generation wireless systems, multiple performance requirements that conflict with each other have been imposed, IM schemes have the potential of satisfying part of the requirements, in addition to enhancing bandwidth efficiency. More specifically, we characterize operational scenarios and system settings that specifically benefit from IM schemes versus their non-IM counterparts while clarifying the fundamental limitations and the open issues for IM schemes that have not been sufficiently explored previously. Furthermore, we also present the rationale of the recent novel IM scheme that amalgamates the time-domain IM scheme and the concept of faster-than-Nyquist signaling and attains a rate enhancement together with a low peak-to-average power ratio.",[],[]
"In recent years, research on Twitter sentiment analysis, which analyzes Twitter data (tweets) to extract user sentiments about a topic, has grown rapidly. Many researchers prefer the use of machine learning algorithms for such analysis. This study aims to perform a detailed sentiment analysis of tweets based on ordinal regression using machine learning techniques. The proposed approach consists of first pre-processing tweets and using a feature extraction method that creates an efficient feature. Then, under several classes, these features scoring and balancing. Multinomial logistic regression (SoftMax), Support Vector Regression (SVR), Decision Trees (DTs), and Random Forest (RF) algorithms are used for sentiment analysis classification in the proposed framework. For the actual implementation of this system, a twitter dataset publicly made available by the NLTK corpora resources is used. Experimental findings reveal that the proposed approach can detect ordinal regression using machine learning methods with good accuracy. Moreover, results indicate that Decision Trees obtains the best results outperforming all the other algorithms.","['Sentiment analysis', 'Twitter', 'Machine learning', 'Feature extraction', 'Machine learning algorithms', 'Classification algorithms', 'Support vector machines']","['Machine learning technique', 'twitter', 'sentiment analysis', 'ordinal regression']"
"This study applies statistical process control and machine learning techniques to diagnose wind turbine faults and predict maintenance needs by analyzing 2.8 million sensor data collected from 31 wind turbines from 2015 to 2017 in Taiwan. Unlike previous studies that only relied on historical wind turbine data, this study analyzed the sensor data with practitioners' insight by incorporating maintenance check list items into the data mining processes. We used Pareto analyses, scatter plots, and the cause and effect diagram to cluster and classify the failure types of wind turbines. In addition, control charts were used to establish a monitoring mechanism to track whether operation data are deviated from the controls (i.e., standard deviations) as a mean to detect wind turbine abnormalities. While statistical process control was applied to fault diagnosis, machine learning algorithms were used to predict maintenance needs of wind turbines. First, the density-based spatial clustering of applications with noise algorithm was used to classify abnormal-state wind turbine data from normal-state data. Then, random forest and decision tree algorithms were employed to construct the predictive models for wind turbine anomalies and tested with K-fold cross-validation. The results indicate a high level of accuracy: 92.68% for the decision tree model, and 91.98% for the random forest model. The study demonstrates that, by data mining and modeling, the failures of wind turbines can be detected, and the maintenance needs of parts can be predicted. Model results may provide technicians early warnings, improve equipment efficient, and decrease system downtime of wind turbine operation.","['Wind turbines', 'Fault diagnosis', 'Monitoring', 'Process control', 'Neural networks', 'Predictive maintenance']","['Decision trees', 'fault diagnosis', 'machine learning', 'predictive maintenance', 'random forest', 'statistical process control', 'wind energy']"
"This paper presents a smartphone app that performs real-time voice activity detection based on convolutional neural network. Real-time implementation issues are discussed showing how the slow inference time associated with convolutional neural networks is addressed. The developed smartphone app is meant to act as a switch for noise reduction in the signal processing pipelines of hearing devices, enabling noise estimation or classification to be conducted in noise-only parts of noisy speech signals. The developed smartphone app is compared with a previously developed voice activity detection app as well as with two highly cited voice activity detection algorithms. The experimental results indicate that the developed app using convolutional neural network outperforms the previously developed smartphone app.","['Speech', 'Frequency-domain analysis', 'Real-time systems', 'Filter banks', 'Spectrogram', 'Voice activity detection', 'Convolutional neural networks']","['Smartphone app for real-time voice activity detection', 'convolutional neural network voice activity detector', 'real-time implementation of convolutional neural network']"
"This paper introduces a novel control system with maximum power point tracker (MPPT) for the photovoltaic system with grid integration. Hybrid adaptive neuro-fuzzy inference system (ANFIS) and artificial bee colony (ABC) algorithm employed to optimize the membership function. Hence, for minimizing the root mean square error (RMSE), this controls the SEPIC-based MPPT algorithm to achieve rapid PV power tracking. The system performance is improved by fuzzy logic control (FLC), which generates the switching signal to the power switches of the inverter. A dSPACE (DS1104) control board employed for experimental validation of MPPT and inverter control strategies. The novelty of the proposed hybrid MPPT controller is the optimal tuning of ANFIS membership function with the ABC algorithm and been neither discussed before for PV power applications. The experimental responses completely validate the reliability of the PV grid integration with anti-islanding protection. The recentness of this research work is PV MPPT functioning using the hybrid ANFIS-ABC-based algorithm, been not described practically by any researchers in the past works.","['Maximum power point trackers', 'Inverters', 'Fuzzy logic', 'Meteorology', 'Control systems', 'Artificial neural networks', 'Particle swarm optimization']","['ANFIS-ABC', 'dSPACE', 'fuzzy logic controller', 'MPPT', 'photovoltaic', 'SEPIC']"
"Localization plays an important role in the field of Wireless Sensor Networks (WSNs) and robotics. Currently, localization is a very vibrant scientific research field with many potential applications. Localization offers a variety of services for the customers, for example, in the field of WSN, its importance is unlimited, in the field of logistics, robotics, and IT services. Particularly localization is coupled with the case of human-machine interaction, autonomous systems, and the applications of augmented reality. Also, the collaboration of WSNs and distributed robotics has led to the creation of Mobile Sensor Networks (MSNs). Nowadays there has been an increasing interest in the creation of MSNs and they are the preferred aspect of WSNs in which mobility plays an important role while an application is going to execute. To overcome the issues regarding localization, the authors developed a framework of three algorithms named Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF) and Particle Filter (PF) Localization algorithms. In our previous study, the authors only focused on EKF-based localization. In this paper, the authors present a modified Kalman Filter (KF) for localization based on UKF and PF Localization. In the paper, all these algorithms are compared in very detail and evaluated based on their performance. The proposed localization algorithms can be applied to any type of localization approach, especially in the case of robot localization. Despite the harsh physical environment and several issues during localization, the result shows an outstanding localization performance within a limited time. The robustness of the proposed algorithms is verified through numerical simulations. The simulation results show that proposed localization algorithms can be used for various purposes such as target tracking, robot localization, and can improve the performance of localization.","['Wireless sensor networks', 'Kalman filters', 'Simultaneous localization and mapping', 'Jacobian matrices', 'Mathematical model']","['Extended Kalman filter', 'localization', 'particle filter', 'robot', 'unscented Kalman filter', 'wireless sensor networks']"
"During mobile edge computing, due to the movement of nodes and the exhaustion of node energy, link failure occurs thus reducing the network lifetime in the mobile ad-hoc network. When the route fails, because the single-path protocols need to restart the route discovery process, the delay of the network is greatly increased. Therefore, the multi-path routing protocol is proposed, saving the cost of route discovery. In this paper, we propose an ad hoc on-demand multi-path distance vector (AOMDV) routing protocol based on link lifetime and energy consumption prediction (named LLECP-AOMDV) for mobile edge computing. In the route discovery phase, the energy grading strategy is adopted. When the node energy is lower than the threshold, it no longer participates in the route discovery. In the routing selected phase, the path is selected based on the lifetime of the route link and the minimum energy consumption of the route. According to energy consumption, packet delivery rate, end-to-end delay performance indicators, we evaluate the comparison results. The result shows that under most network performance indicators and parameters, the proposed LLECP-AOMDV is superior to the other three protocols, which improves the network lifetime, reduces the node’s energy consumption and the average end-to-end delay. The protocol is very useful for mobile edge computing.","['Routing protocols', 'Energy consumption', 'Edge computing', 'Routing', 'Mobile ad hoc networks', 'Computational modeling']","['Mobile edge computing', 'MANET', 'AOMDV', 'energy threshold', 'link lifetime', 'energy consumption']"
"With the increasing popularity of social media, people has changed the way they access news. News online has become the major source of information for people. However, much information appearing on the Internet is dubious and even intended to mislead. Some fake news are so similar to the real ones that it is difficult for human to identify them. Therefore, automated fake news detection tools like machine learning and deep learning models have become an essential requirement. In this paper, we evaluated the performance of five machine learning models and three deep learning models on two fake and real news datasets of different size with hold out cross validation. We also used term frequency, term frequency-inverse document frequency and embedding techniques to obtain text representation for machine learning and deep learning models respectively. To evaluate models' performance, we used accuracy, precision, recall and F1-score as the evaluation metrics and a corrected version of McNemar's test to determine if models' performance is significantly different. Then, we proposed our novel stacking model which achieved testing accuracy of 99.94% and 96.05 % respectively on the ISOT dataset and KDnugget dataset. Furthermore, the performance of our proposed method is high as compared to baseline methods. Thus, we highly recommend it for fake news detection.","['Support vector machines', 'Machine learning', 'Social networking (online)', 'Deep learning', 'Feature extraction', 'Stacking', 'Neural networks']","['Deception detection', 'deep learning', 'fake news', 'machine learning', 'McNemar’s test', 'performance evaluation', 'stacking']"
"The use of simulators in robotics research is widespread, underpinning the majority of recent advances in the field. There are now more options available to researchers than ever before, however navigating through the plethora of choices in search of the right simulator is often non-trivial. Depending on the field of research and the scenario to be simulated there will often be a range of suitable physics simulators from which it is difficult to ascertain the most relevant one. We have compiled a broad review of physics simulators for use within the major fields of robotics research. More specifically, we navigate through key sub-domains and discuss the features, benefits, applications and use-cases of the different simulators categorised by the respective research communities. Our review provides an extensive index of the leading physics simulators applicable to robotics researchers and aims to assist them in choosing the best simulator for their use case.","['Robots', 'Robot sensing systems', 'Mobile robots', 'Physics', 'Sensors', 'Legged locomotion', 'Navigation']","['Simulation', 'review', 'robotics', 'field robotics', 'soft robotics', 'aerial robotics', 'marine robotics', 'manipulation', 'robotic learning', 'surgical robotics']"
"Context: GitHub, nowadays the most popular social coding platform, has become the reference for mining Open Source repositories, a growing research trend aiming at learning from previous software projects to improve the development of new ones. In the last years, a considerable amount of research papers have been published reporting findings based on data mined from GitHub. As the community continues to deepen in its understanding of software engineering thanks to the analysis performed on this platform, we believe that it is worthwhile to reflect on how research papers have addressed the task of mining GitHub and what findings they have reported. Objective: The main objective of this paper is to identify the quantity, topic, and empirical methods of research works, targeting the analysis of how software development practices are influenced by the use of a distributed social coding platform like GitHub. Method: A systematic mapping study was conducted with four research questions and assessed 80 publications from 2009 to 2016. Results: Most works focused on the interaction around coding-related tasks and project communities. We also identified some concerns about how reliable were these results based on the fact that, overall, papers used small data sets and poor sampling techniques, employed a scarce variety of methodologies and/or were hard to replicate. Conclusions: This paper attested the high activity of research work around the field of Open Source collaboration, especially in the software domain, revealed a set of shortcomings and proposed some actions to mitigate them. We hope that this paper can also create the basis for additional studies on other collaborative activities (like book writing for instance) that are also moving to GitHub.","['Software', 'Conferences', 'Software engineering', 'Libraries', 'Systematics', 'Data mining', 'Collaboration']","['GitHub', 'open source software', 'systematic mapping study']"
"Visual traffic surveillance systems play important roles in intelligent transport systems nowadays. The first step of a visual traffic surveillance system usually needs to correctly detect objects from images or videos and classify them into different categories (e.g., car, truck, and bus). This paper aims to introduce a new vehicle type classification scheme on the images acquired from multi-view visual traffic surveillance sensors. Most image classification algorithms focus on maximizing the percentage of the correct predictions, which have a deficiency that the images from minority categories are prone to be misclassified as the dominant categories. To address this challenge of classifying imbalanced data acquired from visual traffic surveillance sensors, we propose a method, which integrates deep neural networks with balanced sampling in this paper. The proposed method consists of two main stages. In the first stage, data augmentation with balanced sampling is applied to alleviate the unbalanced data set problem. In the second stage, an ensemble of convolutional neural network models with different architectures is constructed with parameters learned on the augmented training data set. Experiments on the MIOvision traffic camera dataset classification challenge data set demonstrate that the proposed method is able to enhance the mean precision of all categories, in the condition of high overall accuracy, compared with the baseline algorithms.","['Surveillance', 'Visualization', 'Neural networks', 'Machine learning', 'Training', 'Sensors']","['Traffic data', 'traffic surveillance systems', 'intelligent transport systems', 'image classification', 'ensemble learning', 'imbalanced data']"
"The “factory-in-a-box” concept involves assembling production modules (i.e., factories) in containers and transporting the containers to different customer locations. Such a concept could be highly effective during emergencies, when there is an urgent demand for products (e.g., the COVID-19 pandemic). The “factory-in-a-box” planning problem can be divided into two sub-problems. The first sub-problem deals with the assignment of raw materials to suppliers, sub-assembly decomposition, assignment of sub-assembly modules to manufacturers, and assignment of tasks to manufacturers. The second sub-problem focuses on the transport of sub-assembly modules between suppliers and manufacturers by assigning vehicles to locations, deciding the order of visits for suppliers, manufacturers, and customers, and selecting the appropriate routes within the transportation network. This study addresses the second sub-problem, which resembles the vehicle routing problem, by developing an optimization model and solution algorithms in order to optimize the “factory-in-a-box” supply chain. A mixed-integer linear programming model, which aims to minimize the total cost of the “factory-in-a-box” supply chain, is presented in this study. CPLEX is used to solve the model to the global optimality, while four metaheuristic algorithms, including the Evolutionary Algorithm, Variable Neighborhood Search, Tabu Search, and Simulated Annealing, are employed to solve the model for large-scale problem instances. A set of numerical experiments, conducted for a case study of “factory-in-a-box”, demonstrate that the Evolutionary Algorithm outperforms the other metaheuristic algorithms developed for the model. Some managerial insights are outlined in the numerical experiments as well.","['Supply chains', 'Vehicle routing', 'Production facilities', 'Raw materials', 'Companies', 'Containers']","['Factory-in-a-box', 'metaheuristics', 'supply chains', 'urgent demand', 'vehicle routing problem']"
"Sustainable agricultural development is a significant solution with fast population development through the use of information and communication (ICT) in precision agriculture, which produced new methods for making cultivation further productive, proficient, well-regulated while preserving the climate. Big data (machine learning, deep learning, etc.) is amongst the vital technologies of ICT employed in precision agriculture for their huge data analytical capabilities to abstract significant information and to assist agricultural practitioners to comprehend well farming practices and take precise decisions. The main goal of this article is to acquire an awareness of the Big Data latest applications in smart agriculture and be acquainted with related social and financial challenges to be concentrated on. This article features data creation methods, accessibility of technology, accessibility of devices, software tools, and data analytic methods, and appropriate applications of big data in precision agriculture. Besides, there are still a few challenges that come across the widespread implementation of big data technology in agriculture.","['Agriculture', 'Big Data', 'Artificial intelligence', 'Production', 'Soil', 'Diseases', 'Libraries']","['Precision agriculture', 'big data analytics', 'machine learning', 'sustainable agriculture', 'smart farming', 'digital agriculture']"
"COVID-19 has emerged as a highly contagious disease which has caused a devastating impact across the world with a very large number of infections and deaths. Timely and accurate testing is paramount to an effective response to this pandemic as it helps identify infections and therefore mitigate (isolate/cure) them. In this paper, we investigate this challenge and contribute by presenting a blockchain-based solution that incorporates self-sovereign identity, re-encryption proxies, and decentralized storage, such as the interplanetary file systems (IPFS). Our solution implements digital medical passports (DMP) and immunity certificates for COVID-19 test-takers. We present smart contracts based on the Ethereum blockchain written and tested successfully to maintain a digital medical identity for test-takers that help in a prompt trusted response directly by the relevant medical authorities. We reduce the response time of the medical facilities, alleviate the spread of false information by using immutable trusted blockchain, and curb the spread of the disease through DMP. We present a detailed description of the system design, development, and evaluation (cost and security analysis) for the proposed solution. Since our code leverages the use of the on-chain events, the cost of our design is almost negligible. We have made our smart contract codes publicly available on Github.","['COVID-19', 'Blockchain', 'Smart contracts', 'Diseases', 'Testing', 'Immune system', 'Medical diagnostic imaging']","['COVID-19', 'blockchain', 'Ethereum', 'smart contracts', 'security', 'tracking', 'traceability', 'immunity certificates', 'digital medical passports']"
"Detecting anomaly of chest X-ray images by advanced technologies, such as deep learning, is an urgent need to improve the work efficiency and diagnosis accuracy. Fine-tuning existing deep learning networks for medical image processing suffers from over-fitting and low transfer efficiency. To overcome such limitations, we design a hierarchical convolutional neural network (CNN) structure for ChestX-ray14 and propose a new network CXNet-m1, which is much shorter, thinner but more powerful than fine-tuning. We also raise a novel loss function sin-loss, which can learn discriminative information from misclassified and indistinguishable images. Besides, we optimize the convolutional kernels of CXNet-m1 to achieve better classification accuracy. The experimental results show that our light model CXNet-m1 with sin-loss function achieves better accuracy rate, recall rate, F1-score, and AUC value. It illustrates that designing a proper CNN is better than fine-tuning deep networks, and the increase of training data is vital to enhance the performance of CNN.","['X-rays', 'Feature extraction', 'Support vector machines', 'Biomedical imaging', 'Convolutional neural networks', 'Diseases']","['Chest X-Rays image', 'anomaly detection', 'deep neural network', 'self-adapting loss function']"
"Flexible regulation of smart grid is vital for grid operation. This paper proposes a smart grid data aggregation and regulation mechanism based on consortium blockchain, and its signcryption algorithm can be applied to multidimensional data acquisition and multiple receivers in the consortium blockchain. In the process of regulation, the control center, the grid operator, and the equipment supplier receive fixed-height blocks from the blockchain and obtain plaintext from the decryption. Each receiver analyzes the multidimensional data and formulates corresponding control policies for individual users. Grid operators implement user power regulation by feedback on smart contracts. The security analysis and performance comparison show that the proposed scheme has advantages in computing and communication costs while meeting security requirements for confidentiality and data integrity.","['Blockchain', 'Smart grids', 'Data aggregation', 'Smart contracts', 'Encryption']","['Consortium blockchain', 'smart contract', 'smart grid', 'signcryption']"
"Digital twins are quickly becoming a popular tool in several domains, taking advantage of recent advancements in the Internet of Things, Machine Learning and Big Data, while being used by both the industry sector and the research community. In this paper, we review the current research landscape as regards digital twins in the field of smart cities, while also attempting to draw parallels with the application of digital twins in Industry 4.0. Although digital twins have received considerable attention in the Industrial Internet of Things domain, their utilization in smart cities has not been as popular thus far. We discuss here the open challenges in the field and argue that digital twins in smart cities should be treated differently and be considered as cyber-physical “systems of systems”, due to the vastly different system size, complexity and requirements, when compared to other recent applications of digital twins. We also argue that researchers should utilize established tools and methods of the smart city community, such as co-creation, to better handle the specificities of this domain in practice.","['Digital twin', 'Smart cities', 'Smart manufacturing', 'Tools', 'Technological innovation', 'Real-time systems', 'Production']","['Digital twin', 'smart cities', 'industry 4.0', 'society 5.0', 'IoT', 'smart manufacturing', 'cyber-physical systems', 'open challenges']"
"In order to realize peer-to-peer (P2P) transactions between electric vehicles (EVs) in vehicle-to-grid (V2G) networks, we propose an EV power trading model based on blockchain and smart contract. Firstly, based on the blockchain and smart contract technology, a decentralized power trading model is proposed to realize the information equivalence and transparent openness of power trading. Then, considering the randomness and uncertainty of EV charging and discharging, the EV trading parties use the reverse auction mechanism based on dynamic pricing strategy to complete the transaction matching, which can not only improve the profit of the less competitive power seller, but also it can reduce the cost of the electricity purchaser. Finally, in order to verify the feasibility of our proposed scheme, V2G's EV power trading smart contract was designed, and the smart contract was released to Ethereum and simulated experiments were carried out. The effectiveness of the proposed scheme is verified by simulation experiments and comparison with traditional power trading schemes.","['Blockchain', 'Power markets', 'Vehicle-to-grid', 'Smart contracts', 'Peer-to-peer computing']","['Blockchain', 'decentralization', 'reverse auctions', 'smart contract', 'V2G']"
"The fifth generation (5G) research and development has been fueled by many new breakthroughs in various areas. The recent progress in carrier aggregation (CA), licensed assisted access (LAA), massive MIMO (MaMi), beamforming techniques, cooperative spectrum sensing (CSS), compressive sensing (CS), machine learning, etc., has provided inspiring and promising approaches to address 5G and beyond challenges. However, at the user equipment (UE) end, limited design budget and hardware resources bring along a series of challenging implementation issues when delivering multi-standard and multi-functional wireless communications. In this paper, we first review recent advances in technical standards and critical enabling techniques, accompanied with several case studies of product developments. After the classification of typical 5G application and deployment scenarios, we propose and analyze a novel hardware reuse and multiplexing solution to facilitate cost-effective and energy-efficient UE design, followed by an investigation of state-of-the-art hardware development from the systems and circuits standpoint. Moreover, wireless UE hardware solutions, UE proof-of-concept (PoC) implementation and field test are proposed and discussed. Finally, the new trends of UE design and terahertz technologies for 5G and beyond applications are investigated and envisioned.","['5G mobile communication', 'MIMO communication', 'Hardware', 'Wireless communication', '3GPP', 'NOMA', 'Reliability', 'Tutorials']","['5G', 'user equipment', 'millimeter wave (mmWave)', 'beamforming', 'massive MIMO (MaMi)', 'beam management', 'distributed phased arrays MIMO (DPA-MIMO)', 'carrier aggregation (CA)', 'licensed-assisted access (LAA)', 'machine learning', 'deep learning', 'terahertz (THz)', '6G', 'smartphone']"
"The Internet of Energy (IoE) impacts on smart cities' power sector. IoE is an implementation of the Internet of Things technology (IoT) into distributed energy systems and aims to achieve energy efficiency, to avoid energy wasting, and improve environmental conditions. IoE technology includes, among others, utilizing smart sensors and renewable energy integration. Therefore, the IoE is becoming a legal science tool to serve the purpose of a smart city. In this paper, we refer to the reasons that led the European Union to compile Regulations for facilitating transformation of existing cities, starting from existing buildings, into smart buildings. We propose a smart building template that manages the performance of all technical systems through IoT technology with the view of achieving energy efficiency. In addition, in order to improve the certification of existing buildings, as for energy performance, we propose an automated remote, control method supported by cloud interface. This method minimizes time consuming procedures and stores, on a cloud platform the energy performance of each building, for the purpose of drawing conclusion and applying measures.","['Europe', 'Sensors', 'Smart cities', 'Smart buildings', 'Monitoring', 'Phase change materials']","['Energy efficiency', 'energy performance of existing buildings', 'Internet of Things', 'smart building template', 'smart energy management']"
"Traditionally employed human-to-human and human-to-machine communication has recently been replaced by a new trend known as the Internet of things (IoT). IoT enables device-to-device communication without any human intervention, hence, offers many challenges. In this paradigm, machine's self-sustainability due to limited energy capabilities presents a great challenge. Therefore, this paper proposed a low-cost energy harvesting device using rectenna to mitigate the problem in the areas where battery constraint issues arise. So, an energy harvester is designed, optimized, fabricated, and characterized for energy harvesting and IoT applications which simply recycles radio-frequency (RF) energy at 2.4 GHz, from nearby Wi-Fi/WLAN devices and converts them to useful dc power. The physical model comprises of antenna, filters, rectifier, and so on. A rectangular patch antenna is designed and optimized to resonate at 2.4 GHz using the well-known transmission-line model while the band-pass and low-pass filters are designed using lumped components. Schottky diode (HSMS-2820) is used for rectification. The circuit is designed and fabricated using the low-cost FR4 substrate (h = 16 mm and ε r = 4.6) having the fabricated dimensions of 285 mm × 90 mm. Universal software radio peripheral and GNU Radio are employed to measure the received RF power, while similar measurements are carried out using R&S spectrum analyzer for validation. The received measured power is -64.4 dBm at the output port of the rectenna circuit. Hence, our design enables a pervasive deployment of self-operable next-generation IoT devices.","['Rectennas', 'Band-pass filters', 'Energy harvesting', 'Internet of Things', 'Radio frequency', 'Rectifiers']","['Internet of things (IoT)', 'energy harvesting', 'antenna', 'rectenna', 'Wi-Fi', 'WLAN', 'universal software radio peripheral (USRP)', 'GNU radio']"
"An efficient energy management system for a small-scale hybrid wind-solar-battery based microgrid is proposed in this paper. The wind and solar energy conversion systems and battery storage system have been developed along with power electronic converters, control algorithms and controllers to test the operation of hybrid microgrid. The power balance is maintained by an energy management system for the variations of renewable energy power generation and also for the load demand variations. This microgrid operates in standalone mode and provides a testing platform for different control algorithms, energy management systems and test conditions. A real-time control is performed by rapid control prototyping to test and validate the control algorithms of microgrid system experimentally. The proposed small-scale renewable energy based microgrid can be used as a test bench for research and testing of algorithms in smart grid applications.","['Batteries', 'Microgrids', 'Renewable energy sources', 'State of charge', 'Real-time systems']","['Energy management system', 'hybrid system', 'microgrid', 'solar energy', 'standalone system', 'wind energy']"
"Dynamic networks are used in a wide range of fields, including social network analysis, recommender systems and epidemiology. Representing complex networks as structures changing over time allow network models to leverage not only structural but also temporal patterns. However, as dynamic network literature stems from diverse fields and makes use of inconsistent terminology, it is challenging to navigate. Meanwhile, graph neural networks (GNNs) have gained a lot of attention in recent years for their ability to perform well on a range of network science tasks, such as link prediction and node classification. Despite the popularity of graph neural networks and the proven benefits of dynamic network models, there has been little focus on graph neural networks for dynamic networks. To address the challenges resulting from the fact that this research crosses diverse fields as well as to survey dynamic graph neural networks, this work is split into two main parts. First, to address the ambiguity of the dynamic network terminology we establish a foundation of dynamic networks with consistent, detailed terminology and notation. Second, we present a comprehensive survey of dynamic graph neural network models using the proposed terminology.","['Graph neural networks', 'Terminology', 'Task analysis', 'Context modeling', 'Predictive models', 'Taxonomy', 'Heuristic algorithms']","['Dynamic network models', 'graph neural networks', 'link prediction', 'temporal networks']"
"Social media platforms and microblogging websites have gained accelerated popularity during the past few years. These platforms are used for expressing views and opinions about products, personalities, and events. Often during discussions and debates, fights take place on social media platforms which involves using rude, disrespectful, and hateful comments called toxic comments. The identification of toxic comments has been regarded as an essential element for social media platforms. This study introduces an ensemble approach, called regression vector voting classifier (RVVC), to identify the toxic comments on social media platforms. The ensemble merges the logistic regression and support vector classifier under soft voting criteria. Several experiments are performed on the imbalanced and balanced dataset to analyze the performance of the proposed approach. For data balance, the synthetic minority oversampling technique (SMOTE) is used on the imbalanced dataset. Furthermore, two feature extraction approaches are utilized to investigate their suitability such as term frequency-inverse document frequency (TF-IDF) and bag-of-words (BoW). The performance of the proposed approach is compared with several machine learning classifiers using accuracy, precision, recall, and F1-score. Results suggest that RVVC outperforms all other individual models when TF-IDF features are used with SMOTE balanced dataset and achieves an accuracy of 0.97.","['Social networking (online)', 'Support vector machines', 'Blogs', 'Feature extraction', 'Deep learning', 'Machine learning', 'Logistics']","['Toxic comments classification', 'ensemble classifier', 'synthetic minority oversampling technique', 'TF-IDF', 'BoW', 'text classification', 'data re-sampling']"
"As the number of Internet of Things (IoT) devices proliferates, the magnitude and velocity of data continues to increase rapidly. IoT systems rely primarily on using messaging protocols for exchanging IoT data and there exists several protocols or frameworks that support distinct types of messaging patterns. Given that IoT devices typically have limited computational resources and processing power, choosing a lightweight, reliable, scalable, interoperable, extensible and secure messaging protocol becomes a very challenging task. As a result, it is not uncommon that IoT systems may employ multiple messaging protocols for supporting device heterogeneity and different message exchange patterns. In addition, basic similarities among existing several messaging protocols or frameworks that exist today for exchanging IoT data within IoT systems suggest the potential of interoperability. Given that IoT systems help facilitate the interconnectivity among distributed, heterogeneous entities, interoperability among existing messaging protocols will play an increasingly important role in simplifying the development and deployment of IoT systems. In this paper, we present a comprehensive review of the existing messaging protocols that can be used in deploying IoT systems. Throughout this paper, we highlight the protocols' distinctive approaches and applicability of using them across various IoT environments. In addition, we highlight challenges, strengths and weaknesses of these messaging protocols in the context of IoT.","['Protocols', 'Internet of Things', 'Object recognition', 'Open systems', 'Middleware', 'Wireless sensor networks', 'Hardware']","['Internet of Things', 'IoT', 'HTTP', 'MQTT', 'CoAP', 'AMQP', 'XMPP', 'DDS', 'data distribution service', 'constrained application protocol', 'message queuing telemetry transport', 'extensible messaging and presence protocol', 'HyperText transfer protocol', 'edge computing', 'fog computing', 'cloud applications']"
"Melanoma remains the most harmful form of skin cancer. Convolutional neural network (CNN) based classifiers have become the best choice for melanoma detection in the recent era. The research has indicated that classifiers based on CNN classify skin cancer images equivalent to dermatologists, which has allowed a quick and life-saving diagnosis. This study provides a systematic literature review of the latest research on melanoma classification using CNN. We restrict our study to the binary classification of melanoma. In particular, this research discusses the CNN classifiers and compares the accuracies of these classifiers when tested on non-published datasets. We conducted a systematic review of existing literature, identifying the literature through a systematic search of the IEEE, Medline, ACM, Springer, Elsevier, and Wiley databases. A total of 5112 studies were identified out of which 55 well-reputed studies were selected. The main objective of this study is to collect state of the art research which identify the recent research trends, challenges and opportunities for melanoma diagnosis and investigate the existing solutions for the diagnosis of melanoma detection using deep learning. Moreover, proposed taxonomy for melanoma detection has been presented that summarizes the broad variety of existing melanoma detection solutions. Lastly, proposed model, challenges and opportunities have been presented which helps the researchers in the domain of melanoma detection.","['Melanoma', 'Deep learning', 'Systematics', 'Skin', 'Lesions']","['Deep learning', 'CNN', 'skin cancer', 'melanoma', 'detection', 'diagnosis']"
"With the development of artificial intelligence and integrated sensor technologies, unmanned aerial vehicles (UAVs) are more and more applied in the air combats. A bottleneck that constrains the capability of UAVs against manned vehicles is the autonomous maneuver decision, which is a very challenging problem in the short-range air combat undergoing highly dynamic and uncertain maneuvers of enemies. In this paper, an autonomous maneuver decision model is proposed for the UAV short-range air combat based on reinforcement learning, which mainly includes the aircraft motion model, one-to-one short-range air combat evaluation model and the maneuver decision model based on deep Q network (DQN). However, such model includes a high dimensional state and action space which requires huge computation load for DQN training using traditional methods. Then, a phased training method, called “basic-confrontation”, which is based on the idea that human beings gradually learn from simple to complex is proposed to help reduce the training time while getting suboptimal but efficient results. Finally, one-to-one short-range air combats are simulated under different target maneuver policies. Simulation results show that the proposed maneuver decision model and training method can help the UAV achieve autonomous decision in the air combats and obtain an effective decision policy to defeat the opponent.","['Atmospheric modeling', 'Aircraft', 'Reinforcement learning', 'Training', 'Unmanned aerial vehicles', 'Aerospace control', 'Optimization']","['Deep reinforcement learning', 'maneuver decision', 'independent decision', 'deep Q network', 'network training']"
"Considered as a key technology in 5G networks, mobile edge computing (MEC) can support intensive computation for energy-constrained and computation-limited mobile users (MUs) through offloading various computation and service functions to the edge of mobile networks. In addition to MEC, wireless heterogeneous networks will play an important role in providing high transmission capacity for MUs in 5G, where wireless backhaul is a cost-effective and viable solution to solve the expensive backhaul deployment issue. In this paper, we consider a setting, where MUs can offload their computations to the MEC server through a small cell base station (SBS), the SBS connects to the macro BS through a wireless backhaul, and computation resource at the MEC server is shared among offloading MUs. First, we formulate a joint optimization problem with the goal of minimizing the system-wide computation overhead. This is a mixed-integer problem and hard to derive the optimal solution. To solve this problem, we propose to decompose it into two subproblems, namely the offloading decision subproblem and the joint backhaul bandwidth and computation resource allocation subproblem. An algorithm, namely JOBCA, is proposed to obtain a feasible solution to the original problem by solving two subproblems iteratively. Finally, numerical results are conducted to verify the performance improvement of the proposed algorithm over two baseline algorithms and the close performance of the proposed algorithm compared with the centralized exhaustive search.","['Wireless communication', 'Edge computing', 'Servers', 'Resource management', 'Cloud computing', 'Mobile handsets', 'Optimization']","['Computation offloading', 'heterogeneous networks', 'mobile edge computing', 'resource allocation', 'wireless backhaul']"
"Accurate beam alignment is essential for the beam-based millimeter wave communications. The conventional beam sweeping solutions often have large overhead, which is unacceptable for mobile applications, such as a vehicle to everything. The learning-based solutions that leverage the sensor data (e.g., position) to identify the good beam directions are one approach to reduce the overhead. Most existing solutions, though, are supervised learning, where the training data are collected beforehand. In this paper, we use a multi-armed bandit framework to develop the online learning algorithms for beam pair selection and refinement. The beam pair selection algorithm learns coarse beam directions in some predefined beam codebook, e.g., in discrete angles, separated by the 3 dB beamwidths. The beam refinement fine-tunes the identified directions to match the peak of the power angular spectrum at that position. The beam pair selection uses the upper confidence bound with a newly proposed risk-aware feature, while the beam refinement uses a modified optimistic optimization algorithm. The proposed algorithms learn to recommend the good beam pairs quickly. When using16×16arrays at both transmitter and receiver, it can achieve, on average, 1-dB gain over the exhaustive search (over271×271beam pairs) on the unrefined codebook within 100 time steps with a training budget of only 30 beam pairs.","['Training', 'Transportation', 'Optimization', 'Millimeter wave technology', 'Databases', 'Array signal processing', 'Heating systems']","['Millimeter wave', 'beam alignment', 'beam refinement', 'position-aided', 'online learning', 'multi-armed bandit', 'risk-aware learning']"
"Optimal planning of renewable energy-based DG units (RE-DGs) in active distribution systems (ADSs) has many positive technical and economical implications and aim to increase the overall system performance. The optimal allocation and sizing of RE-DGs, particularly photovoltaic (PV) and wind turbine (WT), is still a challenging task due to the stochastic behavior of renewable resources. This paper proposed a novel methodology to solve the problem of RES-DGs planning optimization based on improved Harris Hawks Optimizer (HHO) using Particle Swarm Optimization (PSO). The uncertainties associated with the intermittent behaviour of PV and WT output powers are considered using appropriate probability distribution functions. The optimization problem is formulated as a non-linear constrained optimization problem with multiple objectives, where power loss reduction, voltage improvement, system stability, and yearly economic saving have been taken as the optimization objectives taken into account various operational constraints. The proposed methodology, namely HHO-PSO, has validated on three test systems; standard IEEE 33 bus and 69 bus systems and 94 bus practical distribution system located in Portuguese. The obtained results reveal that the HHO-PSO provide better solutions and maximizes the techno-economic benefits of the distribution systems for all considered cases and scenarios. Furthermore, simulation results are evaluated by comparing to those well-known approaches reported in the recent literature.","['Planning', 'Optimization', 'Stability criteria', 'Reactive power', 'Thermal stability', 'Power system stability', 'Wind turbines']","['Renewable energy', 'distributed generation', 'distribution system planning', 'uncertainties', 'Harris hawks optimizer', 'particle swarm optimization']"
"Facial Expression Recognition (FER) is a challenging task that improves natural human-computer interaction. This paper focuses on automatic FER on a single in-the-wild (ITW) image. ITW images suffer real problems of pose, direction, and input resolution. In this study, we propose a pyramid with super-resolution (PSR) network architecture to solve the ITW FER task. We also introduce a prior distribution label smoothing (PDLS) loss function that applies the additional prior knowledge of the confusion about each expression in the FER task. Experiments on the three most popular ITW FER datasets showed that our approach outperforms all the state-of-the-art methods.","['Task analysis', 'Image resolution', 'Face recognition', 'Feature extraction', 'Hidden Markov models', 'Training', 'Network architecture']","['Emotion recognition', 'image resolution', 'human computer interaction']"
"This article presents a rehabilitation technique based on a lower-limb exoskeleton integrated with a human-machine interface (HMI). HMI is used to record and process multimodal signals collected using a foot motor imagery (MI)-based brain-machine interface (BMI) and multichannel electromyographic (EMG) signals recorded from leg muscles. Current solutions of HMI-equipped rehabilitation assistive technologies tested under laboratory conditions demonstrated a great deal of success, but faced several difficulties caused by the limited accuracy of detecting MI electroencephalography (EEG) and the reliability of online control when executing a movement by patients dressed in an exoskeleton. In the case of lower-limb representation, there is still the problem of reliably distinguishing leg movement intentions and differentiating them in BMI systems. Targeting the design of a rehabilitation technique replicating the natural mode of motor control in exoskeleton walking patients, we have shown how the combined use of multimodal signals can improve the accuracy, performance, and reliability of HMI. The system was tested on healthy subjects operating the exoskeleton under different conditions. The study also resulted in algorithms of multimodal HMI data collection, processing, and classification. The developed system can analyze up to 15 signals simultaneously in real-time during a movement. Foot MI is extracted from EEG signals (seven channels) using the event-related (de)synchronization effect. Supplemented by EMG signals reflecting motor intention, the control system can initiate and differentiate the movement of the right and left legs with a high degree of reliability. The classification and control system permits one to work online when the exoskeleton is executing a movement.","['Exoskeletons', 'Electroencephalography', 'Electromyography', 'Legged locomotion', 'Control systems', 'Electrodes', 'Real-time systems']","['Brain–computer interfaces', 'human–robot interaction', 'electroencephalography', 'electromyography', 'exoskeletons']"
"We adopted actual intelligent production requirements and proposed a tiny part defect detection method to obtain a stable and accurate real-time tiny part defect detection system and solve the problems of manually setting conveyor speed and industrial camera parameters in defect detection for factory products. First, we considered the important influences of the properties of tiny parts and the environmental parameters of a defect detection system on its stability. Second, we established a correlation model between the detection capability coefficient of the part system and the moving speed of the conveyor. Third, we proposed a defect detection algorithm for tiny parts that are based on a single short detector network (SSD) and deep learning. Finally, we combined an industrial real-time detection platform with the missed detection algorithm for mechanical parts based on intermediate variables to address the problem of missed detections. We used a 0.8 cm darning needle as the experimental object. The system defect detection accuracy was the highest when the speed of the conveyor belt was 7.67 m/min.","['Real-time systems', 'Deep learning', 'Cameras', 'Object detection', 'Feature extraction', 'Manufacturing', 'Detection algorithms']","['Defect detection', 'tiny parts', 'deep learning', 'SSD', 'missing detection rate']"
"In recent years, with the increase of computer computing power, Deep Learning has begun to be favored. Its learning of non-linear feature combinations has played a role that traditional machine learning cannot reach in almost every field. The application of Deep Learning has also driven the advancement of Factorization Machine (FM) in the field of recommendation systems, because Deep Learning and FM can learn high-order and low-order features combinations respectively, and FM's hidden vector system enables it to learn information from sparse data. The integration of them has attracted the attention of many scholars. They have researched many classic models such as Factorization-supported Neural Network (FNN), Product-based Neural Networks (PNN), Inner PNN (IPNN), Wide&Deep, Deep&Cross, DeepFM, etc. for the Click-Through-Rate (CTR) problem, and their performance is getting better and better. This kind of model is also suitable for agriculture, meteorology, disease prediction and other fields due to the above advantages. Based on the DeepFM model, we predicts the incidence of hepatitis in each sample in the structured disease prediction data of the 2020 Artificial Intelligence Challenge Preliminary Competition, and make minor improvements and parameter adjustments to DeepFM. Compared with other models, the improved DeepFM has excellent performance in AUC. This research can be applied to electronic medical records to reduce the workload of doctors and make doctors focus on the samples with higher predicted incidence rates. For some changing data, such as blood pressure, height, weight, cholesterol, etc., we can introduce the Internet of Medical Things (IoMT). IoMT's sensors can be used to conduct transmission to ensure that the disease can be predicted in time, just in case. After joining IoMT, a healthcare system is formed, which is superior in forecasting and time performance.","['Frequency modulation', 'Deep learning', 'Diseases', 'Data models', 'Neurons', 'Computational modeling', 'Cloud computing']","['Deep learning', 'factorization machine', 'hepatitis', 'Internet of Medical Things']"
"This paper provides the design and implementation of an L 1 -optimal control of a quadrotor unmanned aerial vehicle (UAV). The quadrotor UAV is an underactuated rigid body with four propellers that generate forces along the rotor axes. These four forces are used to achieve asymptotic tracking of four outputs, namely the position of the center of mass of the UAV and the heading. With perfect knowledge of plant parameters and no measurement noise, the magnitudes of the errors are shown to exponentially converge to zero. In the case of parametric uncertainty and measurement noise, the controller yields an exponential decrease of the magnitude of the errors in an L 1 -optimal sense. In other words, the controller is designed so that it minimizes the L ∞ -gain of the plant with respect to disturbances. The performance of the controller is evaluated in experiments and compared with that of a related robust nonlinear controller in the literature. The experimental data shows that the proposed controller rejects persistent disturbances, which is quantified by a very small magnitude of the mean error.","['Mathematical model', 'Unmanned aerial vehicles', 'Robustness', 'Feedback', 'Aerospace electronics', 'Optimal control', 'Computational modeling', 'Robust control', 'Rotors']","['Feedback linearization', 'optimal control', 'quadrotor', 'robust control', 'unmanned aerial vehicle']"
"Software-Defined Networking (SDN) and Blockchain are leading technologies used worldwide to establish safe network communication as well as build secure network infrastructures. They provide a robust and reliable platform to address threats and face challenges such as security, privacy, flexibility, scalability, and confidentiality. Driven by these assumptions, this paper presents an optimized energy-efficient and secure Blockchain-based software-defined IoT framework for smart networks. Indeed, SDN and Blockchain technologies have proven to be able to suitably manage resource utilization and to develop secure network communication across the IoT ecosystem. However, there is a lack of research works that present a comprehensive definition of such a framework that can meet the requirements of the IoT ecosystem (i.e. efficient energy utilization and reduced end-to-end delay). Therefore, in this research, we present a layered hierarchical architecture for the deployment of a distributed yet efficient Blockchain-enabled SDN-IoT framework that ensures efficient cluster-head selection and secure network communication via the identification and isolation of rouge switches. Besides, the Blockchain-enabled flow-rules record keeps track of the rules enforced in the switches and maintains the consistency within the controller cluster. Finally, we assess the performance of the proposed framework in a simulation environment and show that it can achieve optimized energy-utilization, end-to-end delay, and throughput compared to considered baselines, thus being able to achieve efficiency and security in the smart network.","['Blockchain', 'Internet of Things', 'Electronic mail', 'Security', 'Wireless sensor networks', 'Clustering algorithms', 'Resource management']","['IoT', 'Software-Defined Networking (SDN)', 'blockchain', 'cluster head selection', 'smart technology', 'flow-rule management', 'network security', 'privacy', 'artificial intelligence (AI)']"
"This paper develops an effective two-stage stochastic post-hurricane recovery framework to improve networked microgrid resilience using mobile emergency resources (MERs) and a proposed reconfiguration strategy. In the first stage, network reconfiguration actively alters the local power flow path and provides opportunities for restoring critical loads, thus reducing the energy not supplied to electric consumers. The optimal schedule determined in the first stage problem is also used to determine the islanded loads that need MERs for restoration. In the second stage, truck-mounted MERs will deliver power to islanded loads, observing the shortest path and post-hurricane transportation infrastructure constraints. Dijkstra’s algorithm is used to produce the shortest path and avoid possible out-of-service roads. In order to model the uncertainties of the problem, a stochastic framework based on unscented transform is employed. The proposed problem is formulated as a two-stage stochastic single-objective optimization problem maximizing system resilience. Simulation results on a test networked microgrid demonstrate the effectiveness and satisfying performance of the proposed model.","['Microgrids', 'Hurricanes', 'Resilience', 'Stochastic processes', 'Load modeling', 'Load flow', 'Fault tolerance']","['Stochastic resilient framework', 'networked microgrids', 'feeder reconfiguration', 'mobile emergency resources']"
"Heat removal capabilities and radiation performances of several sparse antenna array topologies are studied for cooling enhancement in 5G millimeter-wave base station antennas. Both electromagnetic (EM) and thermal aspects are jointly considered for the first time in array layout optimization, and a novel connection between layout sparsity and thermal management is presented. Two types of active electronically scanned arrays (AESAs), based on the traditional and planar approaches, are examined. Thermal management in AESAs is discussed, with a focus on cooling challenges at millimeter waves. Being relatively low cost and low profile while supporting flexible beamforming, passively cooled planar AESAs with fanless CPU coolers are proposed, for the first time, to be used in 5G base stations. Additional cooling for such arrays is achieved by increasing the inter-element distances in the layout. Linear irregular arrays, spiral arrays, thinned arrays, circular ring arrays, and heat sink antenna arrays are revisited with a critical discussion on their EM and thermal performance. The results are compared with regular and square layouts that are used as benchmarks throughout this paper.","['Antenna arrays', 'Cooling', '5G mobile communication', 'Layout', 'Heating systems', 'Array signal processing', 'Base stations']","['Antenna synthesis', 'base station antennas', 'fifth generation (5G)', 'millimeter-wave communications', 'passive cooling', 'sparse arrays']"
"State of Charge (SOC) is a key parameter for battery management and vehicle energy management. Recently used SOC estimation methods for lithium-ion battery for vehicles have problems of too simple a base model for the battery and large sampling noise in both the voltage and current signals. To improve the accuracy of SOC estimation and consider that the extended Kalman filter algorithm needs linear approximation of the system equation, the unscented Kalman filter (UKF) algorithm was used to reduce the influence of sampling noise, and an improved algorithm with better filtering effect and SOC estimation accuracy was proposed. Based on the SOC estimation and battery model, the peak power prediction method for the battery is proposed and used in the power distribution strategy for Series HEV. Considering the frequent changes in load current and sampling noise, an experiment was designed to verify the effectiveness and robustness of the algorithm. The experimental results show that the UKF algorithm and the improved UKF algorithm can achieve 6% and 1.5% estimation error. The power distribution strategy based on battery SOC estimation and peak power prediction is tested and validated.","['Batteries', 'State of charge', 'Integrated circuit modeling', 'Mathematical model', 'Estimation', 'Computational modeling', 'Prediction algorithms']","['Lithium-ion battery', 'SOC estimation', 'unscented Kalman filter', 'noise suppression', 'peak power prediction']"
"With growing dependence of industrial robots, a failure of an industrial robot may interrupt current operation or even overall manufacturing workflows in the entire production line, which can cause significant economic losses. Hence, it is very essential to maintain industrial robots to ensure high-level performance. It is widely desired to have a real-time technique to constantly monitor robots by collecting time series data from robots, which can automatically detect incipient failures before robots totally shut down. Model-based methods are typically used in anomaly detection for robots, yet explicit domain knowledge and accurate mathematical models are required. Data-driven techniques can overcome these limitations. However, a major difficulty for them is the lack of sufficient fault data of industrial robots. Besides, the used technique for anomaly detection of robots should be required to not only capture the temporal dependency in collected time series data, but also the inter-correlations between different metrics. In this paper, we introduce an unsupervised anomaly detection for industrial robots, sliding-window convolutional variational autoencoder (SWCVAE), which can realize real-time anomaly detection spatially and temporally by coping with multivariate time series data. This method has been verified by a KUKA KR6R 900SIXX industrial robot, and the results prove that the proposed model can successfully detect anomaly in the robot. Thus, this work presents a promising tool for condition-based maintenance of industrial robots.","['Service robots', 'Anomaly detection', 'Time series analysis', 'Mathematical model', 'Real-time systems', 'Robot sensing systems']","['Anomaly detection', 'industrial robots', 'sliding window', 'variational autoencoder', 'convolutional neural network']"
"Drones can be used in agriculture applications to monitor crop yield and climate conditions and to extend the communication range of wireless sensor networks in monitoring areas. However, monitoring the climate conditions in agriculture applications faces challenges and limitations, such as drone flight time, power consumption, and communication distance, which are addressed in this study. Wireless power transfer (WPT) can be used to charge drone batteries. WPT using a magnetic resonant coupling (MRC) technique was considered in this study because it allows high transfer power and efficiency with tens of centimeters, power transfers can be achieved in misalignment situations, charging several devices simultaneously, and unaffected by weather conditions. WPT was practically implemented based on a solar cell using a proposed flat spiral coil (FSC) in the transmitter circuit and multiturn coil (MTC) in a receiver circuit (drone) for the alignment and misalignment of two coils at different distances. FSC and MTC improved power transfer and efficiency to 20.46 W and 85.25%, respectively, at 0 cm with the loaded system under alignment condition. In addition, the two coils achieved appropriate transfer efficiencies and power for charging the drone battery under misaligned conditions. The maximum power transfer and efficiency were 17.1 W and 71% for the misalignment condition, at an air gap of 1 cm between two coils when the system was loaded with the drone battery. Moreover, the battery life of the drone was extended to 851 minutes based on the proposed sleep/active strategy relative to the traditional operation (i.e., 25.84 minutes). Consequently, a 96.9% battery power saving was achieved based on this strategy. Comparison results showed that the proposed system outperformed some present techniques in terms of the transfer power, transfer efficiency, and drone battery life. The proposed WPT technique developed in this study has been proven to solve the misalignment issue. Thus it offers a great opportunity as a key deployment component for the automation of farming practices toward the Internet of Farming applications.","['Drones', 'Batteries', 'Agriculture', 'Meteorology', 'Transmitters', 'Receivers', 'Couplings']","['Battery life', 'drone', 'energy efficiency', 'farming', 'flat spiral coil', 'flight time', 'multiturn coil', 'power consumption', 'wireless sensor network', 'solar panel']"
"To solve object detection issues in infrared images, such as a low recognition rate and a high false alarm rate caused by long distances, weak energy, and low resolution, we propose a region-free object detector named YOLO-FIR for infrared (IR) images with YOLOv5 core by compressing channels, optimizing parameters, etc. An improved infrared image object detection network, YOLO-FIRI, is further developed. Specifically, while designing the feature extraction network, the cross-stage-partial-connections (CSP) module in the shallow layer is expanded and iterated to maximize the use of shallow features. In addition, an improved attention module is introduced in residual blocks to focus on objects and suppress background. Moreover, multiscale detection is added to improve small object detection accuracy. Experimental results on the KAIST and FLIR datasets show that YOLO-FIRI demonstrates a qualitative improvement compared with the state-of-the-art detectors. Compared with YOLOv4, the mean average precision (mAP50) of YOLO-FIRI is increased by 21% on the KAIST dataset, the speed is reduced by 62%, the parameters are decreased by 89%, the weight size is reduced by more than 94%, and the computational costs are reduced by 84%. Compared with YOLO-FIR, YOLO-FIRI has an approximately 5% to 20% improvement in AP, AR (average recall), mAP50, F1, and mAP50:75. Furthermore, due to the shortcomings of high noise and weak features, image fusion can be applied to image preprocessing as a data enhancement method by fusing visible and infrared images based on a convolutional neural network.","['Feature extraction', 'Object detection', 'Detectors', 'Real-time systems', 'Convolutional neural networks', 'Proposals', 'Task analysis']","['Attention mechanism', 'infrared image', 'image fusion', 'object detection', 'YOLOv5']"
"Images captured under outdoor scenes usually suffer from low contrast and limited visibility due to suspended atmospheric particles, which directly affects the quality of photographs. Despite numerous image dehazing methods have been proposed, effective hazy image restoration remains a challenging problem. Existing learning-based methods usually predict the medium transmission by convolutional neural networks (CNNs), but ignore the key global atmospheric light. Different from previous learning-based methods, we propose a flexible cascaded CNN for single hazy image restoration, which considers the medium transmission and global atmospheric light jointly by two task-driven subnetworks. Specifically, the medium transmission estimation subnetwork is inspired by the densely connected CNN while the global atmospheric light estimation subnetwork is a light-weight CNN. Besides, these two subnetworks are cascaded by sharing the common features. Finally, with the estimated model parameters, the hazefree image is obtained by the atmospheric scattering model inversion, which achieves more accurate and effective restoration performance. Qualitatively and quantitatively experimental results on the synthetic and real-world hazy images demonstrate that the proposed method effectively removes haze from such images, and outperforms several state-of-the-art dehazing methods.","['Atmospheric modeling', 'Estimation', 'Image restoration', 'Learning systems', 'Scattering', 'Feature extraction', 'Task analysis']","['Image dehazing', 'image degradation', 'image restoration', 'convolutional neural networks']"
"Human activity recognition from multimodal body sensor data has proven to be an effective approach for the care of elderly or physically impaired people in a smart healthcare environment. However, traditional machine learning techniques are mostly focused on a single sensing modality, which is not practical for robust healthcare applications. Therefore, recently increasing attention is being given by the researchers on the development of robust machine learning techniques that can exploit multimodal body sensor data and provide important decision making in Smart healthcare. In this paper, we propose an effective multi-sensors-based framework for human activity recognition using a hybrid deep learning model, which combines the simple recurrent units (SRUs) with the gated recurrent units (GRUs) of neural networks. We use the deep SRUs to process the sequences of multimodal input data by using the capability of their internal memory states. Moreover, we use the deep GRUs to store and learn how much of the past information is passed to the future state for solving fluctuations or instability in accuracy and vanishing gradient problems. The system has been compared against the conventional approaches on a publicly available standard dataset. The experimental results show that the proposed approach outperforms the available state-of-the-art methods.","['Logic gates', 'Deep learning', 'Activity recognition', 'Robot sensing systems', 'Computer architecture', 'Recurrent neural networks', 'Data models']","['Multi-modal body sensor data', 'activity recognition', 'deep recurrent neural networks (RNNs)', 'simple recurrent unit (SRU)', 'gated recurrent unit (GRU)', 'robust healthcare']"
"In this paper, we propose a fully ear-worn long-term blood pressure (BP) and heart rate (HR) monitor to achieve a higher wearability. Moreover, to enable practical application scenarios, we present a machine learning framework to deal with severe motion artifacts induced by head movements. We suggest situating all electrocardiogram (ECG) and photoplethysmography (PPG) sensors behind two ears to achieve a super wearability, and successfully acquire weak ear-ECG/PPG signals using a semi-customized platform. After introducing head motions toward real-world application scenarios, we apply a support vector machine classifier to learn and identify raw heartbeats from motion artifacts-impacted signals. Furthermore, we propose an unsupervised learning algorithm to automatically filter out residual distorted/faking heartbeats, for ECG-to-PPG pulse transit time (PTT) and HR estimation. Specifically, we introduce a dynamic time warping-based learning approach to quantify distortion conditions of raw heartbeats referring to a high-quality heartbeat pattern, which are then compared with a threshold to perform purification. The heartbeat pattern and the distortion threshold are learned by a K-medoids clustering approach and a histogram triangle method, respectively. Afterward, we perform a comparative analysis on ten PTT or PTT&HR-based BP learning models. Based on an acquired data set, the BP and HR estimation using the proposed algorithm has an error of -1.4±5.2 mmHg and 0.8±2.7 beats/min, respectively, both much lower than the state-of-the-art approaches. These results demonstrate the capability of the proposed machine learning-empowered system in ear-ECG/PPG acquisition and motion-tolerant BP/HR estimation. This proof-of-concept system is expected to illustrate the feasibility of ear-ECG/PPG-based motion-tolerant BP/HR monitoring.","['Heart beat', 'Biomedical monitoring', 'Electrocardiography', 'Sensors', 'Estimation', 'Monitoring']","['Wearable computers', 'blood pressure', 'heart rate', 'photoplethysmogram', 'electrocardiography', 'pulse transit time', 'fitness', 'signal processing', 'machine learning']"
"One-dimensional (1-D) chaotic maps have been considered as prominent pseudo-random source for the design of different cryptographic primitives. They have the advantages of simplicity, easy to implement, and low computation. This paper proposes a new 1-D discrete-chaotic map which holds better dynamical behavior, lyapunov exponent, bifurcation, and larger chaotic range compared with the chaotic logistic map. We propose a method to construct cryptographically efficient substitution-boxes (S-boxes) using an improved chaotic map and β-hill climbing search technique. S-boxes are used in block ciphers as nonlinear components to bring strong confusion and security. Constructing optimal S-boxes has been a prominent topic of interest for security experts. To begin, the anticipated method generates initial S-box using the improved chaotic map. Then, β-hill climbing search is applied to obtain notable configuration of S-box that optimally satisfies the fitness function. The simulation results are compared with some recent S-boxes approaches to demonstrate that the proposed approach is more proficient in generating strong nonlinear component of block encryption systems.","['Logistics', 'Ciphers', 'Optimization', 'Chaotic communication']","['β-hill climbing', 'block ciphers', 'improved chaotic map', 'substitution-box']"
"Power versus voltage curves of partial shading photovoltaic (PV) systems contain several local peaks (LPs) and one global peak (GP). Most conventional maximum power point tracker (MPPT) techniques may not follow the GP under partial shading conditions (PSC). The use of metaheuristic techniques such as the bat algorithm (BA) and particle swarm optimization (PSO) can overcome these obstacles. All problems inherent in the using of BA as MPPT of PV systems has been discussed and solved in this paper. The first problem is the random initial values of bats that may cause premature convergence. Therefore, the initial values of bats were modified to be close to the anticipated positions of peaks to reduce the convergence time and improve the chance of capturing the GP. The second problem occurs when shading pattern changes the value and position of the GP which is not configurable because all bats are concentrated at the previous GP; this can be resolved by BA re-initialization. The the third problem is the GP memorized in the execution of the BA code forces the PV system to work at the duty ratio of the highest GP ever seen, which may not be the real GP. This problem is solved by updating the memorized GP. This paper also proposes a new criterion for selecting the optimal swarm size against number of peaks to reduce the convergence time and improve the chance of capturing the GP. To the authors' knowledge, most of these problems inherent in the BA have hitherto not been addressed in the literature. The simulation and experimental results obtained from the proposed modified BA (MBA) with re-initialization have been compared to the PSO and grey wolf optimization (GWO) techniques which show the superiority of using MBA strategy in the MPPT of partial shading PV systems.","['Convergence', 'Maximum power point trackers', 'Heuristic algorithms', 'Optimization', 'Pulse width modulation', 'Photovoltaic systems']","['Bat algorithm', 'boost converter', 'dynamic global peak', 'maximum power point tracker', 'partial shading conditions', 'PV system']"
"The problem of electric vehicle (EV) charging scheduling in commercial parking lots has become a meaningful study in recent years, especially for the parking lots near the workplace that serve fixed users. This paper focuses on the optimization of the EV charging in the parking lot integrating energy storage system (ESS) and photovoltaic (PV) system. A smart charging management system is first established. The charging optimization problem is formulated as a cost minimization problem. Then, grey wolf optimizer (GWO) is introduced as a method to find the optimal solution. Considering the constraint conditions in the optimization problem, an improved binary grey wolf optimizer (IBGWO) is proposed, which can improve the convergence speed and optimization accuracy. Finally, a real-time EV charging scheduling strategy based on short-term PV power prediction and IBGWO is proposed. Several cases are simulated to analyze the performance of the proposed strategy. The experimental results show that the proposed IBGWO is superior in solving the proposed charging scheduling problem compared with other meta-heuristic algorithms. Moreover, the proposed strategy can effectively improve the utilization rate of the PV power and reduce the electricity cost of operators.","['Electric vehicle charging', 'Real-time systems', 'Employment', 'Optimal scheduling', 'Dynamic scheduling']","['Electric vehicle', 'charging management', 'real-time strategy', 'grey wolf optimizer']"
"This paper reviews the use of outlier detection approaches in urban traffic analysis. We divide existing solutions into two main categories: flow outlier detection and trajectory outlier detection. The first category groups solutions that detect flow outliers and includes statistical, similarity and pattern mining approaches. The second category contains solutions where the trajectory outliers are derived, including off-line processing for trajectory outliers and online processing for sub-trajectory outliers. Solutions in each of these categories are described, illustrated, and discussed, and open perspectives and research trends are drawn. Compared to the state-of-the-art survey papers, the contribution of this paper lies in providing a deep analysis of all the kinds of representations in urban traffic data, including flow values, segment flow values, trajectories, and sub-trajectories. In this context, we can better understand the intuition, limitations, and benefits of the existing outlier urban traffic detection algorithms. As a result, practitioners can receive some guidance for selecting the most suitable methods for their particular case.","['Trajectory', 'Anomaly detection', 'Roads', 'Global Positioning System', 'Taxonomy', 'Sensors']","['Urban traffic analysis', 'outlier detection', 'machine learning', 'data mining']"
"Over the last few years, interference has been a major hurdle for successfully implementing various end-user applications in the fifth-generation (5G) of wireless networks. During this era, several communication protocols and standards have been developed and used by the community. However, interference persists, keeping given quality of service (QoS) provision to end-users for different 5G applications. To mitigate the issues mentioned above, in this paper, we present an in-depth survey of state-of-the-art non-orthogonal multiple access (NOMA) variants having power and code domains as the backbone for interference mitigation, resource allocations, and QoS management in the 5G environment. These are future smart communication and supported by device-to-device (D2D), cooperative communication (CC), multiple-input and multiple-output (MIMO), and heterogeneous networks (HetNets). From the existing literature, it has been observed that NOMA can resolve most of the issues in the existing proposals to provide contention-based grant-free transmissions between different devices. The key differences between the orthogonal multiple access (OMA) and NOMA in 5G are also discussed in detail. Moreover, several open issues and research challenges of NOMA-based applications are analyzed. Finally, a comparative analysis of different existing proposals is also discussed to provide deep insights to the readers.","['NOMA', '5G mobile communication', 'Cooperative communication', 'Wireless networks', 'Quality of service', 'Interference', 'Device-to-device communication']","['NOMA', 'OMA', 'uplink', 'downlink', 'device-to-device', 'machine-to-machine']"
"Cloud computing has become the de facto computing platform for application processing in the era of the Internet of Things (IoT). However, limitations of the cloud model, such as the high transmission latency and high costs are giving birth to a new computing paradigm called edge computing (a.k.a fog computing). Fog computing aims to move the data processing close to the network edge so as to reduce Internet traffic. However, since the servers at the fog layer are not as powerful as the ones in the cloud, there is a need to balance the data processing in between the fog and the cloud. Moreover, besides the data offloading issue, the energy efficiency of fog computing nodes has become an increasing concern. Densely deployed fog nodes are a major source of carbon footprint in IoT systems. To reduce the usage of the brown energy resources (e.g. powered by energy produced through fossil fuels), green energy is an alternative option. In this paper, we propose employing dual energy sources for supporting the fog nodes, where solar power is the primary energy supply and grid power is the backup supply. Based on that, we present a comprehensive analytic framework for incorporating green energy sources to support the running of IoT and fog computingbased systems, and to handle the tradeoff in terms of average response time, average monetary, and energy costs in the IoT. This paper describes an online algorithm, Lyapunov optimization on time and energy cost (LOTEC), based on the technique of Lyapunov optimization. LOTEC is a quantified near optimal solution and is able to make control decision on application offloading by adjusting the two-way tradeoff between average response time and average cost. We evaluate the performance of our proposed algorithm by a number of experiments. Rigorous analysis and simulations have demonstrated its performance.","['Servers', 'Cloud computing', 'Logic gates', 'Edge computing', 'Time factors', 'Green products', 'Delays']","['Internet of things', 'fog computing', 'Lyapunov optimization', 'green energy']"
"In recent years, researches are concentrating on the effectiveness of Transfer Learning (TL) and Ensemble Learning (EL) techniques in cervical histopathology image analysis. However, there have been very few investigations that have described the stages of differentiation of cervical histopathological images. Therefore, in this article, we propose an Ensembled Transfer Learning (ETL) framework to classify well, moderate and poorly differentiated cervical histopathological images. First of all, we have developed Inception-V3, Xception, VGG-16, and Resnet-50 based TL structures. Then, to enhance the classification performance, a weighted voting based EL strategy is introduced. After that, to evaluate the proposed algorithm, a dataset consisting of 307 images, stained by three immunohistochemistry methods (AQP, HIF, and VEGF) is considered. In the experiment, we obtain the highest overall accuracy of 97.03% and 98.61% on AQP staining images and poor differentiation of VEGF staining images, individually. Finally, an additional experiment for classifying the benign cells from the malignant ones is carried out on the Herlev dataset and obtains an overall accuracy of 98.37%.","['Cervical cancer', 'Feature extraction', 'Biomedical imaging', 'Image analysis', 'Training', 'Image segmentation']","['Cervical cancer', 'differentiation stages', 'histopathology images', 'transfer learning', 'ensemble learning', 'classification']"
"Concept drift techniques aim at learning patterns from data streams that may change over time. Although such behavior is not usually expected in controlled environments, real-world scenarios can face changes in the data, such as new classes, clusters, and features. Traditional classifiers can be easily fooled in such situations, resulting in poor performances. Common concept drift domains include recommendation systems, energy consumption, artificial intelligence systems with dynamic environment interaction, and biomedical signal analysis (e.g., neurogenerative diseases). In this paper, we surveyed several works that deal with concept drift, as well as we presented a comprehensive study of public synthetic and real datasets that can be used to cope with such a problem. In addition, we considered a review of different types of drifts and approaches to handling such changes in the data. We considered different learners employed in classification tasks and the use of drift detection mechanisms, among other characteristics.","['Training', 'Heuristic algorithms', 'Support vector machines', 'Memory management', 'Noise measurement', 'Bayes methods', 'Finance']","['Concept drift', 'machine learning', 'pattern recognition']"
"Automatic extraction of buildings from remote sensing imagery plays a significant role in many applications, such as urban planning and monitoring changes to land cover. Various building segmentation methods have been proposed for visible remote sensing images, especially state-of-the-art methods based on convolutional neural networks (CNNs). However, high-accuracy building segmentation from high-resolution remote sensing imagery is still a challenging task due to the potentially complex texture of buildings in general and image background. Repeated pooling and striding operations used in CNNs reduce feature resolution causing a loss of detailed information. To address this issue, we propose a light-weight deep learning model integrating spatial pyramid pooling with an encoder-decoder structure. The proposed model takes advantage of a spatial pyramid pooling module to capture and aggregate multi-scale contextual information and of the ability of encoder-decoder networks to restore losses of information. The proposed model is evaluated on two publicly available datasets; the Massachusetts roads and buildings dataset and the INRIA Aerial Image Labeling Dataset. The experimental results on these datasets show qualitative and quantitative improvement against established image segmentation models, including SegNet, FCN, U-Net, Tiramisu, and FRRN. For instance, compared to the standard U-Net, the overall accuracy gain is 1.0% (0.913 vs. 0.904) and 3.6% (0.909 vs. 0.877) with a maximal increase of 3.6% in model-training time on these two datasets. These results demonstrate that the proposed model has the potential to deliver automatic building segmentation from high-resolution remote sensing images at an accuracy that makes it a useful tool for practical application scenarios.","['Buildings', 'Feature extraction', 'Remote sensing', 'Image segmentation', 'Semantics', 'Data mining', 'Earthquakes']","['Deep learning', 'high-resolution remote sensing imagery', 'building extraction', 'fully convolutional networks', 'encoder-decoder']"
"To solve the problem of low efficiency, the complexity of the interactive operation, and the high degree of manual intervention in existing methods, we propose a novel approach based on the sparse voxel octree and 3D convolution neural networks (CNNs) for segmenting and classifying tooth types on the 3D dental models. First, the tooth classification method capitalized on the two-level hierarchical feature learning is proposed to solve the misclassification problem in highly similar tooth categories. Second, we exploit an improved three-level hierarchical segmentation method based on the deep convolution features to conduct segmentation of teeth-gingiva and inter-teeth, respectively, and the conditional random field model is used to refine the boundary of the gingival margin and the inter-teeth fusion region. The experimental results show that the classification accuracy in Level_1 network is 95.96%, the average classification accuracy in Level_2 network is 88.06%, and the accuracy of tooth segmentation is 89.81%. Compared with the existing state-of-the-art methods, the proposed method has higher accuracy and universality, and it has great application potential in the computer-assisted orthodontic treatment diagnosis.","['Teeth', 'Dentistry', 'Solid modeling', 'Three-dimensional displays', 'Computational modeling', 'Octrees', 'Data models']","['Tooth segmentation', 'CNN', 'sparse voxel octrees', 'hierarchical classification']"
"Due to recent developments in highway research and increased utilization of vehicles, there has been significant interest paid on latest, effective, and precise Intelligent Transportation System (ITS). The process of identifying particular objects in an image plays a crucial part in the fields of computer vision or digital image processing. Vehicle License Plate Recognition (VLPR) process is a challenging process because of variations in viewpoint, shape, color, multiple formats and non-uniform illumination conditions at the time of image acquisition. This paper presents an effective deep learning-based VLPR model using optimal K-means (OKM) clustering-based segmentation and Convolutional Neural Network (CNN) based recognition called OKM-CNN model. The proposed OKM-CNN model operates on three main stages namely License Plate (LP) detection, segmentation using OKM clustering technique and license plate number recognition using CNN model. During first stage, LP localization and detection process take place using Improved Bernsen Algorithm (IBA) and Connected Component Analysis (CCA) models. Then, OKM clustering with Krill Herd (KH) algorithm get executed to segment the LP image. Finally, the characters in LP get recognized with the help of CNN model. An extensive experimental investigation was conducted using three datasets namely Stanford Cars, FZU Cars and HumAIn 2019 Challenge dataset. The attained simulation outcome ensured effective performance of the OKM-CNN model over other compared methods in a considerable way.","['Image segmentation', 'Character recognition', 'License plate recognition', 'Clustering algorithms', 'Lighting', 'Analytical models', 'Automobiles']","['Intelligent transportation system', 'convolutional neural network', 'K-means', 'traffic management', 'vehicle license plate recognition', 'character recognition']"
"Cervical cancer is the fourth most common malignant disease in women’s worldwide. In most cases, cervical cancer symptoms are not noticeable at its early stages. There are a lot of factors that increase the risk of developing cervical cancer like human papilloma virus, sexual transmitted diseases, and smoking. Identifying those factors and building a classification model to classify whether the cases are cervical cancer or not is a challenging research. This study aims at using cervical cancer risk factors to build classification model using Random Forest (RF) classification technique with the synthetic minority oversampling technique (SMOTE) and two feature reduction techniques recursive feature elimination and principle component analysis (PCA). Most medical data sets are often imbalanced because the number of patients is much less than the number of non-patients. Because of the imbalance of the used data set, SMOTE is used to solve this problem. The data set consists of 32 risk factors and four target variables: Hinselmann, Schiller, Cytology, and Biopsy. After comparing the results, we find that the combination of the random forest classification technique with SMOTE improve the classification performance.","['Cervical cancer', 'Radio frequency', 'Forestry', 'Principal component analysis', 'Support vector machines', 'Vegetation']","['Cervical cancer', 'random forest', 'risk factors', 'SMOTE']"
"The classification of fresh fruits according to their visual ripeness is typically a subjective and tedious task; consequently, there is a growing interest in the use of non-contact techniques to automate this process. Machine learning techniques, such as artificial neural networks, support vector machines (SVMs), decision trees, and K-nearest neighbor algorithms, have been successfully applied for classification problems in the literature, particularly for images of fruit. However, the particularities of each classification problem make it difficult, if not impossible, to select a general technique that is applicable to all types of fruit. In this paper, the combinations of four machine learning techniques and three color spaces ( RGB , HSV , and L*a*b* ) were evaluated with regard to their ability to classify Cape gooseberry fruits. To this end, 925 Cape gooseberry fruit samples were collected, and each fruit was manually classified into one of seven different classes according to its level of ripeness. The color values of each fruit image in the three color spaces and their corresponding ripening stages were organized for training and validation following a fivefold cross-validation strategy in an iterative process repeated 100 times. According to the results, the classification of Cape gooseberry fruits by their ripeness level was sensitive to both the color space and the classification technique used. The models based on the L*a*b* color space and the SVM classifier showed the highest f-measure regardless of the color space, and the principal component analysis combination of color spaces improved the performance of the models at the expense of increased complexity.","['Image color analysis', 'Aerospace electronics', 'Support vector machines', 'Visualization', 'Image segmentation', 'Inspection', 'Instruments']","['Cape gooseberry', 'artificial neural networks', 'support vector machines', 'decision trees', 'K-nearest neighbors', 'color spaces', 'PCA', 'multiclass confusion matrix']"
"Recently, high dynamic range (HDR) imaging has attracted much attention as a technology to reflect human visual characteristics owing to the development of the display and camera technology. This paper proposes a novel deep neural network model that reconstructs an HDR image from a single low dynamic range (LDR) image. The proposed model is based on a convolutional neural network composed of dilated convolutional layers and infers LDR images with various exposures and illumination from a single LDR image of the same scene. Then, the final HDR image can be formed by merging these inference results. It is relatively simple for the proposed method to find the mapping between the LDR and an HDR with a different bit depth because of the chaining structure inferring the relationship between the LDR images with brighter (or darker) exposures from a given LDR image. The method not only extends the range but also has the advantage of restoring the light information of the actual physical world. The proposed method is an end-to-end reconstruction process, and it has the advantage of being able to easily combine a network to extend an additional range. In the experimental results, the proposed method shows quantitative and qualitative improvement in performance, compared with the conventional algorithms.","['Image restoration', 'Dynamic range', 'Neural networks', 'Cameras', 'Brightness', 'Image reconstruction']","['High dynamic range imaging', 'image restoration', 'computational photography', 'convolutional neural network']"
"Hand gesture recognition is an attractive research field with a wide range of applications, including video games and telesurgery techniques. Another important application of hand gesture recognition is the translation of sign language, which is a complicated structured form of hand gestures. In sign language, the fingers' configuration, the hand's orientation, and the hand's relative position to the body are the primitives of structured expressions. The importance of hand gesture recognition has increased due to the prevalence of touchless applications and the rapid growth of the hearing-impaired population. However, developing an efficient recognition system needs to overcome the challenges of hand segmentation, local hand shape representation, global body configuration representation, and gesture sequence modeling. In this paper, a novel system is proposed for dynamic hand gesture recognition using multiple deep learning architectures for hand segmentation, local and global feature representations, and sequence feature globalization and recognition. The proposed system is evaluated on a very challenging dataset, which consists of 40 dynamic hand gestures performed by 40 subjects in an uncontrolled environment. The results show that the proposed system outperforms state-of-the-art approaches, demonstrating its effectiveness.",[],[]
"With the advent of global 5G networks, the Internet of Things will no longer be limited by network speed and traffic. With the large-scale application of the Internet of Things, people pay more and more attention to the security of the Internet of Things. Once the Internet of Things system suffers from malicious attacks, not only the serious loss of information will lead to the paralysis of the Internet of Things equipment. Aiming at the security problem of the Internet of Things, this paper puts forward the LM-BP neural network model. The LM-BP neural network model is applied to an intrusion detection system, and the intrusion detection flow under LM-BP algorithm is given. LM algorithm has the characteristics of fast optimization speed and strong robustness and uses this characteristic to optimize the weight threshold of traditional BP neural network. Through establishing LM-BP neural network classifier, KDD CUP 99 intrusion detection data set is imported into an LM-BP neural network classifier, and the best results are obtained through continuous training. Finally, the experimental simulation results show that this model has higher detection rate and lower false alarm rate than the traditional BP neural network model and PSO-BP neural network model for DOS, R2L, U2L, and Probing, thus this modified model has certain promotion value.","['Intrusion detection', 'Internet of Things', 'Biological neural networks', 'Training', '5G mobile communication']","['Intrusion detection system', 'KDD CUP 99 dataset', 'LM-BP neural network model']"
"This paper investigates the problem of proportionally fair double-sided energy auction involving buying and selling agents. The grid is assumed to be operating under islanded mode. A distributed auction algorithm that can be implemented by an aggregator, as well as a possible approach by which the agents may approximate price anticipation is considered. Equilibrium conditions arising due to price anticipation is analyzed. A modified auction to mitigate the resulting loss in efficiency due to such behavior is suggested. This modified auction allows the aggregate social welfare of the agents to be arbitrarily close to that attainable with price taking agents. Next, equilibrium conditions when the aggregator collects a surcharge price per unit of energy traded is examined. A bi-objective optimization problem is identified that takes into account both the agents' social welfare as well as the aggregator's revenue from the surcharge. The results of extensive simulations, which corroborate the theoretical analysis, are reported.","['Power grids', 'Aggregators', 'Algorithm design and analysis', 'Distributed processing', 'Trading auctions', 'Microgrids', 'Pricing']","['Energy grid', 'microgrid', 'aggregator', 'agents', 'trading', 'auction', 'bid', 'social welfare']"
"A novel method of using the spiking neural networks (SNNs) and the electroencephalograph (EEG) processing techniques to recognize emotion states is proposed in this paper. Three algorithms including discrete wavelet transform (DWT), variance and fast Fourier transform (FFT) are employed to extract the EEG signals, which are further taken by the SNN for the emotion classification. Two datasets, i.e., DEAP and SEED, are used to validate the proposed method. For the former dataset, the emotional states include arousal, valence, dominance and liking where each state is denoted as either high or low status. For the latter dataset, the emotional states are divided into three categories (negative, positive and neutral). Experimental results show that by using the variance data processing technique and SNN, the emotion states of arousal, valence, dominance and liking can be classified with accuracies of 74%, 78%, 80% and 86.27% for the DEAP dataset, and an overall accuracy is 96.67% for the SEED dataset, which outperform the FFT and DWT processing methods. In the meantime, this work achieves a better emotion classification performance than the benchmarking approaches, and also demonstrates the advantages of using SNN for the emotion state classifications.","['Electroencephalography', 'Biological neural networks', 'Feature extraction', 'Emotion recognition', 'Videos', 'Data processing', 'Physiology']","['Emotion classification', 'spiking neural network', 'EEG signal']"
"The unmanned aerial vehicle (UAV) communication is a potential technology to meet the excessive next-generation cellular users’ demand due to its reliable connectivity and cost-effective deployment. However, UAV communications have to be energy efficient so that it can save energy. Thus, the UAV flies sufficiently long enough time to serve the ground users with limited on-board energy. In this paper, we investigate an energy-efficient UAV communication via designing the UAV trajectory path. We consider throughput and the UAV propulsion energy consumption jointly. We assume that the UAV flies at a fixed altitude such that it can avoid tall obstacles. A binary decision variable is assigned to schedule UAV-to-user communication. First, we derive the UAV-to-user channel model based on the line of sight and non-line of sight communication links and jointly optimize the trajectory, transmit power, and the speed of UAV; and UAV-to-user scheduling to maximize throughput. Then, we apply the UAV propulsion energy consumption, which is a function of the UAV trajectory and speed. Finally, we formulate the UAV energy-efficiency maximization problem, which is defined as the total bits of information sent to the ground users by consuming the UAV energy for a given UAV flight duration. The formulated energy-efficiency maximization problem is non-convex, fractional, and mixed-integer non-linear programming in nature. We propose an efficient algorithm based on successive convex approximation and classical Dinkelbach method to achieve the optimal solution of energy-efficient UAV. We present simulation results to validate the efficacy of our proposed algorithms. The results show a significant performance improvement compared to the benchmark methods.","['Unmanned aerial vehicles', 'Throughput', 'Trajectory', 'Wireless networks', 'Channel models', 'Propulsion']","['UAV', 'throughput', 'UAV propulsion energy', 'energy-efficiency', 'UAV-user scheduling']"
"Heterogeneous Internet of Things (IoT) and multi-access mobile edge computing (MA-MEC) are believed as supporting technologies for building a smart city. The advancement and flourish of IoT are facilitating the entry of human society into the Internet of Everything era, which lay the foundation of the smart city. To address the conflict between computation capability and low-cost mobile devices in IoT, the MA-MEC is available for supporting the resource-limited and computation-sensitive services and applications by computation offloading and distributed content delivery/caching. However, deploying cloud computing capability within the radio access network may face serious security threats, which stem from not only the existing technologies and networks but also the MA-MEC-based IoT itself. Therefore, in this paper, the solutions to address the security threats are investigated from physical layer perspectives, since physical layer security technologies have the advantages of achieving perfect secrecy, low-computational complexity, and resource consumption, and good adaptation for channel changes. Specifically, we investigate the secure wiretap coding, resource allocation, signal processing, and multi-node cooperation, along with physical layer key generation and authentication, to cope with the emerging security challenges. Finally, the paper is concluded with some possible future research directions.","['Smart cities', 'Information security', 'Physical layer security', 'Cryptography', 'Internet of Things']","['Physical layer security', 'encryption-based security', 'multi-access mobile edge computing (MA-MEC)', 'heterogeneous Internet of Things (IoT)', 'smart city']"
"In this paper, the performance of a promising technology for the next generation wireless communications, non-orthogonal multiple access (NOMA), is investigated. In particular, the bit error rate (BER) performance of downlink NOMA systems over Nakagami-m flat fading channels, is presented. Under various conditions and scenarios, the exact BER of downlink NOMA systems considering successive interference cancellation (SIC) is derived. The transmitted signals are randomly generated from quadrature phase shift keying (QPSK) and two NOMA systems are considered; two users' and three users' systems. The obtained BER expressions are then used to evaluate the optimum power allocation for two different objectives, achieving fairness and minimizing average BER. The two objectives can be used in a variety of applications such as satellite applications with constrained transmitted power. Numerical results and Monte Carlo simulations perfectly match with the derived BER analytical results and provide valuable insight into the advantages of optimum power allocation which show the full potential of downlink NOMA systems.","['NOMA', 'Bit error rate', 'Fading channels', 'Downlink', 'Resource management', 'Silicon carbide', 'Phase shift keying']","['NOMA', 'BER', 'SIC', 'optimum power allocation', 'fairness', 'minimum average BER', 'Nakagami-m']"
"WFSM are included in the majority of large power generating units and special high-power motor drives, due to their high efficiency, flexible field excitation and intrinsic flux weakening capability. Moreover, they are employed in a wide range of high-end solutions in the low-to-medium power range. This contribution presents a comprehensive survey of classical and modern methods and technologies for excitation systems (ESs) of (WFSMs). The work covers the fundamental theory, typical de-excitation methods and all the modern excitation equipment topologies in detail. It also includes a description of the state-of-the-art and the latest trends in the ESs of wound-field synchronous motors and generators. The purpose of the paper is to provide a useful and up-to-date reference for practitioners and researchers in the field.","['Windings', 'Market research', 'Synchronous motors', 'Generators', 'Demagnetization']","['Brushless exciters', 'de-excitation methods', 'excitation systems', 'exciterless excitation', 'harmonic excitation', 'rotating exciters', 'static exciters', 'synchronous machines', 'synchronous generators', 'synchronous motors']"
"Smart grids have become susceptible to cyber-attacks, being one of the most diversified cyber–physical systems. Measurements collected by the supervisory control and data acquisition system can be compromised by a smart hacker, who can cheat a bad-data detector during state estimation by injecting biased values into the sensor-collected measurements. This may result in false control decisions, compromising the security of the smart grid, and leading to financial losses, power network disruptions, or a combination of both. To overcome these problems, we propose a novel approach to cyber-attacks detection, based on an extremely randomized trees algorithm and kernel principal component analysis for dimensionality reduction. A performance evaluation of the proposed scheme is done by using the standard IEEE 57-bus and 118-bus systems. Numerical results show that the proposed scheme outperforms state-of-art approaches while improving the accuracy in detection of stealth cyber-attacks in smart-grid measurements.","['Power measurement', 'Sensors', 'Smart grids', 'Transmission line measurements', 'Meters', 'Principal component analysis']","['Machine learning', 'KPCA', 'extra-trees', 'cyber-attacks', 'cyber-security']"
"Suffering from complex sideslip angles, path following control of an under actuated surface vehicle (USV) becomes significantly challenging and remains unresolved. In this paper, a finite-time observer based guidance and control (FOGC) scheme for path following of an USV with time-varying and large sideslip angles and unknown external disturbances is proposed. The salient features of the proposed FOGC scheme are as follows: 1) time-varying large sideslip angle is exactly estimated by a finite-time sideslip observer, and thereby contributing to the sideslip-tangent line-of-sight guidance law which significantly enhances the robustness of the guidance system to unknown sideslip angles which are significantly large and time-varying; 2) a finite-time disturbance observer (FDO) is devised to exactly observe unknown external disturbances, and thereby implementing FDO-based surge and heading robust tracking controllers, which possess remarkable tracking accuracy and precise disturbance rejection, simultaneously; and 3) by virtue of cascade analysis and Lyapunov approach, global asymptotic stability of the integrated guidance-control system is rigorously ensured. Simulation studies and comparisons are conducted to demonstrate the effectiveness and superiority of the proposed FOGC scheme.","['Surges', 'Marine vehicles', 'Robustness', 'Disturbance observers', 'Navigation', 'Sea surface']","['Finite-time sideslip observer', 'sideslip-tangent line-of-sight guidance', 'integrated guidance and control', 'underactuated surface vehicles', 'path following']"
"This paper presents a generalized state space average model (GSSAM) for multi-phase interleaved buck, boost and buck-boost converters. The GSSAM can model the switching behavior of the current and voltage waveforms, unlike the conventional average model which can model only the average value. The GSSAM is used for the converters with dominant oscillatory behavior such as resonant converters, high current ripple converters, and multi-converter systems. The maximum current and voltage through the system can be predicted by modeling the switching behavior of voltage and current. The GSSAM in the literature is introduced for single-phase converters only, and it is not introduced for multi-phase converters due to the high complexity associated with it. Hence, the GSSAM for multi-phase buck, boost and buck-boost converters are introduced in this paper and the proposed models can fit with converters of any number of phases. The number of operating phases in the multi-phase interleaved converters is proportional with the output power to achieve the maximum efficiency over the operating range. Therefore, the proposed GSSAMs can describe the operation at any number of operating phases with switching dynamics of phases. The proposed GSSAM is validated by comparing the transient and steady-state dynamics between the GSSAM and a switching model from PLECS.","['Switches', 'Buck converters', 'Harmonic analysis', 'Power system dynamics', 'Load modeling', 'Inductors']","['Interleaved multi-phase dc-dc Converters', 'generalized state space average model', 'buck converter', 'boost converter', 'buck-boost converter']"
"An operative and versatile household energy management system is proposed to develop and implement demand response (DR) projects. These are under the hybrid generation of the energy storage system (ESS), photovoltaic (PV), and electric vehicles (EVs) in the smart grid (SG). Existing household energy management systems cannot offer its users a choice to ensure user comfort (UC) and not provide a sustainable solution in terms of reduced carbon emission. To tackle these problems, this research work proposes a heuristic-based programmable energy management controller (HPEMC) to manage the energy consumption in residential buildings to minimize electricity bills, reduce carbon emissions, maximize UC and reduce the peak-to-average ratio (PAR). We used our proposed hybrid genetic particle swarm optimization (HGPO) algorithm and existing algorithms like a genetic algorithm (GA), binary particle swarm optimization algorithm (BPSO), ant colony optimization (ACO), wind-driven optimization algorithm (WDO), bacterial foraging algorithm (BFA) to schedule smart appliances optimally to attain our desired objectives. In the proposed model, consumers use solar panels to produce their energy from microgrids. We also perform MATLAB simulations to validate our proposed HGPO-HPEMC (HHPEMC), and results confirm the efficiency and productivity of our proposed HPEMC based strategy. The proposed algorithm reduced the electricity cost by 25.55%, PAR by 36.98%, and carbon emission by 24.02% as compared to the case of without scheduling.","['Energy management', 'Home appliances', 'Peak to average power ratio', 'Carbon dioxide', 'Hybrid power systems', 'Scheduling', 'Heuristic algorithms']","['Smart grid', 'energy management', 'efficient energy utilization', 'energy storage system', 'heuristic algorithms', 'energy management controller', 'renewable energy sources', 'carbon emissions']"
"Human action monitoring can be advantageous to remotely monitor the status of patients or elderly person for intelligent healthcare. Human action recognition enables efficient and accurate monitoring of human behaviors, which can exhibit multifaceted complexity attributed to disparities in viewpoints, personality, resolution and motion speed of individuals, etc. The spatial-temporal information plays an important role in the human action recognition. In this paper, we proposed a novel deep learning architecture named as recurrent 3D convolutional neural network (R3D) to extract effective and discriminative spatial-temporal features to be used for action recognition, which enables the capturing of long-range temporal information by aggregating the 3D convolutional network entries to serve as an input to the LSTM (Long Short-Term Memory) architecture. The 3D convolutional network and LSTM are two effective methods for extracting the temporal information. The proposed R3D network integrated these two methods by sharing a shared 3D convolutional network in sliding windows on video streaming to capturing short-term spatial-temporal features into the LSTM. The output features of LSTM encapsulate the longrange spatial-temporal information representing high-level abstraction of the human actions. The proposed algorithm is compared to traditional and the-state-of-the-art and deep learning algorithms. The experimental results demonstrated the effectiveness of the proposed system, which can be used as smart monitoring for remote healthcare.","['Three-dimensional displays', 'Feature extraction', 'Convolution', 'Data mining', 'Monitoring', 'Medical services', 'Kernel']","['Action recognition', '3D convolutional network', 'LSTM']"
"It is considerable to solve practical fault diagnosis task of gearbox under variable working conditions by introducing sufficient auxiliary data. For this purpose, a new approach called improved deep transfer auto-encoder is proposed for intelligent diagnosis of gearbox faults under variable working conditions with small training samples. First, multi-wavelet is employed as activation function for effectively learning useful features hidden in the non-stationary vibration data. Second, correntropy is used to modify the cost function to enhance the reconstruction quality. Third, pre-train an improved deep auto-encoder using sufficient auxiliary data in the source domain, and transfer its parameters to the target model. Finally, the improved deep transfer should be fine-tuned by small training samples in the target domain to adapt to the characteristics of the rest testing data. The proposed approach is used to analyze two sets of experimental vibration data collected from gearbox under variable working conditions. The results show that the proposed approach can accurately diagnose different faults of gearbox even the working conditions have significant changes, which is superior to the existing methods.","['Employee welfare', 'Fault diagnosis', 'Training', 'Vibrations', 'Cost function', 'Data models', 'Testing']","['Improved deep transfer auto-encoder', 'gearbox fault diagnosis', 'variable working conditions', 'multi-wavelet activation function', 'modified cost function']"
"The rapid increase in data volume and features dimensionality have a negative influence on machine learning and many other fields, such as decreasing classification accuracy and increasing computational cost. Feature selection technique has a critical role as a preprocessing step in reducing these issues. It works by eliminating the features that may negatively influence the classifiers' performance, such as irrelevant, redundant and less informative features. This paper aims to introduce an improved Harris hawks optimization (IHHO) by utilizing elite opposite-based learning and proposing a new search mechanism. Harris hawks optimization (HHO) is a novel metaheuristic general-purpose algorithm recently introduced to solve continuous search problems. Compared to conventional HHO, the proposed IHHO can avoid trapping in local optima and has an enhanced search mechanism, relying on mutation, mutation neighborhood search, and rollback strategies to raise the search capabilities. Moreover, it improves population diversity, computational accuracy, and accelerates convergence rate. To evaluate the performance of IHHO, we conducted a series of experiments on twenty benchmark datasets collected from the UCI repository and the scikit-feature project. The datasets represent different levels of feature dimensionality, such as low, moderate, and high. Further, four criteria were adopted to determine the superiority of IHHO: classification accuracy, fitness value, number of selected features, and statistical tests. Furthermore, a comparison between IHHO and other well-known algorithms such as Generic algorithm (GA), Grasshopper Optimization Algorithm (GOA), Particle Swarm Optimization (PSO), Ant Lion Optimizer (ALO), Whale Optimization Algorithm (WOA), Butterfly Optimization Algorithm (BOA) and Slime Mould Algorithm (SMA) was performed. The experimental results have confirmed the dominance of IHHO over the other optimization algorithms in different aspects, such as accuracy, fitness value, and feature selection.","['Optimization', 'Feature extraction', 'Convergence', 'Search problems', 'Machine learning', 'Sociology', 'Statistics']","['Harris Hawks optimization', 'optimization', 'feature selection', 'elite opposite based-learning', 'mutation', 'mutation neighborhood search']"
"As the roll-out of the fifth generation (5G) of mobile telecommunications is well underway, standardized methods to assess the human exposure to radiofrequency electromagnetic fields from 5G base station radios are needed in addition to existing numerical models and preliminary measurement studies. Challenges following the introduction of 5G New Radio (NR) include the utilization of new spectrum bands and the widespread use of technological advances such as Massive MIMO (Multiple-Input Multiple-Output) and beamforming. We propose a comprehensive and ready-to-use exposure assessment methodology for use with common spectrum analyzer equipment to measure or calculate in-situ the time-averaged instantaneous exposure and the theoretical maximum exposure from 5G NR base stations. Besides providing the correct method and equipment settings to capture the instantaneous exposure, the procedure also comprises a number of steps that involve the identification of the Synchronization Signal Block, which is the only 5G NR component that is transmitted periodically and at constant power, the assessment of the power density carried by its resources, and the subsequent extrapolation to the theoretical maximum exposure level. The procedure was validated on site for a 5G NR base station operating at 3.5 GHz, but it should be generally applicable to any 5G NR signal, i.e., as is for any sub-6 GHz signal and after adjustment of the proposed measurement settings for signals in the millimeter-wave range.","['5G mobile communication', 'Base stations', 'Amplitude modulation', 'OFDM', 'Frequency measurement', 'Telecommunications', 'Bandwidth']","['5G', 'radiofrequency electromagnetic fields (RF-EMF)', 'exposure assessment', 'measurement', 'massive MIMO', 'mobile telecommunications', 'new radio', 'spectrum analyzer']"
"Powering cellular base stations with renewable energy are one of the long-term strategies for achieving green networks and reducing their operational costs. As an energy provider, the power grid is evolving into a smarter one, which allows more energy-efficient cellular networks and enables cooperation and interaction with the smart grid. On one hand, cellular networks can use harvested renewable energy and on-site energy storage to reduce their energy costs. On the other hand, the price of electricity depends on the energy load, which will eventually contribute to decreasing the peak consumption and global energy cost. In this paper, we propose new integration architecture for renewable energy-powered cellular networks and the smart grid. The proposed architecture is designed based on the classification and the analysis of the existing proposals and the requirements of the smart grid, renewable energy systems, and cellular networks.","['Smart grids', 'Renewable energy sources', 'Green products', 'Mobile communication', 'Base stations', 'Energy consumption']","['Cellular networks', 'Smart Grid', 'Energy efficiency', 'Renewable energy', 'Integration architecture']"
"Interactive multiobjective optimization (IMO) aims at finding the most preferred solution of a decision maker with the guidance of his/her preferences which are provided progressively. During the process, the decision maker can adjust his/her preferences and explore only interested regions of the search space. In recent decades, IMO has gradually become a common interest of two distinct communities, namely, the multiple criteria decision making (MCDM) and the evolutionary multiobjective optimization (EMO). The IMO methods developed by the MCDM community usually use the mathematical programming methodology to search for a single preferred Pareto optimal solution, while those which are rooted in EMO often employ evolutionary algorithms to generate a representative set of solutions in the decision maker’s preferred region. This paper aims to give a review of IMO research from both MCDM and EMO perspectives. Taking into account four classification criteria including the interaction pattern, preference information, preference model, and search engine (i.e., optimization algorithm), a taxonomy is established to identify important IMO factors and differentiate various IMO methods. According to the taxonomy, state-of-the-art IMO methods are categorized and reviewed and the design ideas behind them are summarized. A collection of important issues, e.g., the burdens, cognitive biases and preference inconsistency of decision makers, and the performance measures and metrics for evaluating IMO methods, are highlighted and discussed. Several promising directions worthy of future research are also presented.","['Pareto optimization', 'Taxonomy', 'Decision making', 'Evolutionary computation', 'STEM', 'Search engines']","['Evolutionary multiobjective optimization', 'interactive multiobjective optimization', 'multiple criteria decision making', 'preference information', 'preference models']"
"Electroencephalogram (EEG) signal-based emotion recognition has attracted wide interests in recent years and has been broadly adopted in medical, affective computing, and other relevant fields. However, the majority of the research reported in this field tends to focus on the accuracy of classification whilst neglecting the interpretability of emotion progression. In this paper, we propose a new interpretable emotion recognition approach with the activation mechanism by using machine learning and EEG signals. This paper innovatively proposes the emotional activation curve to demonstrate the activation process of emotions. The algorithm first extracts features from EEG signals and classifies emotions using machine learning techniques, in which different parts of a trial are used to train the proposed model and assess its impact on emotion recognition results. Second, novel activation curves of emotions are constructed based on the classification results, and two emotion coefficients, i.e., the correlation coefficients and entropy coefficients. The activation curve can not only classify emotions but also reveals to a certain extent the emotional activation mechanism. Finally, a weight coefficient is obtained from the two coefficients to improve the accuracy of emotion recognition. To validate the proposed method, experiments have been carried out on the DEAP and SEED dataset. The results support the point that emotions are progressively activated throughout the experiment, and the weighting coefficients based on the correlation coefficient and the entropy coefficient can effectively improve the EEG-based emotion recognition accuracy.","['Electroencephalography', 'Feature extraction', 'Emotion recognition', 'Brain modeling', 'Physiology', 'Computational modeling', 'Human computer interaction']","['EEG', 'emotion activation', 'emotion recognition', 'machine learning']"
"Two novel microstrip patch antennas with multiple parasitic patches and shorting vias have been presented for the bandwidth enhancement. Based on the conventional triangular patch antenna, two more resonances can be obtained with the introduction of multiple parasitic patches, and consequently, the antenna bandwidth can be broadened. Parametric analysis of the patches has been studied for the verification of bandwidth enhancement. An example of the proposed antenna with multiple parasitic patches is designed, fabricated, and tested. The measured bandwidth with \vert S_{11}\vert < -10 dB ranges from 5.46 to 6.27 GHz (13.8%), and good far-field radiation patterns can be obtained within the frequency band. In addition, two shorting vias are inserted into the above proposed antenna to decrease the input impedance, resulting in further bandwidth enhancement of the antenna. This antenna is fabricated and tested as well, which achieves a measured 10-dB impedance bandwidth of 17.4% from 5.5 to 6.55 GHz.","['Bandwidth', 'Microstrip antennas', 'Microstrip', 'Patch antennas', 'Impedance', 'Antenna measurements']","['Bandwidth enhancement', 'microstrip patch antennas', 'parasitic patch', 'shorting vias']"
"The mHealth trend, which uses mobile devices and associated technology for health interventions, offers unprecedented opportunity to transform the health services available to people across the globe. In particular, the mHealth transformation can be most disruptive in the developing countries, which is often characterized by a dysfunctional public health system. Despite this opportunity, the growth of mHealth in developing countries is rather slow and no existing studies have conducted an in-depth search to identify the reasons. We present a comprehensive report about the factors hindering the growth of mHealth in developing countries. Most importantly, we outline future strategies for making mHealth even more effective. We are also the first to conduct a case study on the public health system of Pakistan showing that mHealth can offer tremendous opportunities for a developing country with a severe scarcity of health infrastructure and resources. The findings of this paper will guide the development of policies and strategies for the sustainable adoption of mHealth not only in Pakistan but also for any developing country in general.","['Diseases', 'Mobile handsets', 'Mobile communication', 'Sensors', 'Education', 'Accelerometers']","['mHealth', 'mobile health', 'developing countries', 'remote monitoring', 'clinical decision support systems', 'epidemic outbreaks', 'mHealth challenges', 'mHealth for Pakistan']"
"An efficient physical layer security technique, referred to as OFDM with subcarrier index selection (OFDM-SIS), is proposed for safeguarding the transmission of OFDM-based waveforms against eavesdropping in 5G and beyond wireless networks. This is achieved by developing a joint optimal subcarrier index selection (SIS) and adaptive interleaving (AI) design, which enables providing two levels (sources) of security in time division duplexing (TDD) mode: one is generated by the optimal selection of the subcarrier indices that can maximize the signal-to-noise ratio at only the legitimate receiver, while the other is produced by the AI performed based on the legitimate user's channel that is different from that of the eavesdropper. The proposed scheme not only provides a remarkable secrecy gap, but also enhances the reliability performance of the legitimate user compared with the standard OFDM scheme. Particularly, a gain of 5-10 dB is observed at a bit error rate value of 10 -3 compared with standard OFDM as a result of using the adaptive channel-based subcarrier selection mechanism. Moreover, the proposed technique saves power, considers no knowledge of the eavesdropper's channel, and provides secrecy even in the worst security scenario, where the eavesdropper can know the channel of the legitimate link when an explicit channel feedback is used as is the case in frequency division duplexing systems. This is achieved while maintaining low complexity and high reliability at the legitimate user, making the proposed scheme a harmonious candidate technique for secure 5G ultra reliable and low latency communications (URLLC) services.","['OFDM', 'Indexes', 'Security', '5G mobile communication', 'Receivers', 'Physical layer', 'Bit error rate']","['OFDM with subcarrier index selection (OFDM-SIS)', 'physical layer security', 'eavesdropping', 'interleaving', '5G', 'adaptive subcarrier selection', 'URLLC', 'FDD', 'TDD']"
"In this paper, network function virtualization (NFV) is identified as a promising key technology, which can contribute to energy-efficiency improvement in 5G networks. An optical network supported architecture is proposed and investigated in this paper to provide the wired infrastructure needed in 5G networks and to support NFV toward an energy efficient 5G network. In this paper, the mobile core network functions, as well as baseband function, are virtualized and provided as VMs. The impact of the total number of active users in the network, backhaul/fronthaul configurations, and VM inter-traffic are investigated. A mixed integer linear programming (MILP) optimization model is developed with the objective of minimizing the total power consumption by optimizing the VMs location and VMs servers' utilization. The MILP model results show that virtualization can result in up to 38% (average 34%) energy saving. The results also reveal how the total number of active users affects the baseband virtual machines (BBUVMs) optimal distribution whilst the core network virtual machines (CNVMs) distribution is affected mainly by the inter-traffic between the VMs. For real-time implementation, two heuristics are developed, an energy efficient NFV without CNVMs inter-traffic (EENFVnoITr) heuristic and an energy efficient NFV with CNVMs inter-traffic (EENFVwithITr) heuristic, both produce comparable results to the optimal MILP results. Finally, a genetic algorithm is developed for further verification of the results.","['5G mobile communication', 'Energy efficiency', 'Network function virtualization', 'Bandwidth', 'Long Term Evolution', 'Baseband', 'Virtual machining']","['5G networks', 'backhaul', 'BBU', 'energy efficiency', 'fronthaul', 'genetic algorithm', 'IP over WDM', 'network function virtualization', 'NFV']"
"Optical remote sensing (RS) data suffer from the limitation of bad weather and cloud contamination, whereas synthetic aperture radar (SAR) can work under all weather conditions and overcome this disadvantage of optical RS data. However, due to the imaging mechanism of SAR and the speckle noise, untrained people are difficult to recognize the land cover types visually from SAR images. Inspired by the excellent image-to-image translation performance of Generative Adversarial Networks (GANs), a supervised Cycle-Consistent Adversarial Network (S-CycleGAN) was proposed to generate large optical images from the SAR images. When the optical RS data are unavailable or partly unavailable, the generated optical images can be alternative data that aid in land cover visual recognition for untrained people. The main steps of SAR-to-optical image translation were as follows. First, the large SAR image was split to small patches. Then S-CycleGAN was used to translate the SAR patches to optical image patches. Finally, the optical image patches were stitched to generate the large optical image. A paired SAR-optical image dataset which covered 32 Chinese cities was published to evaluate the proposed method. The dataset was generated from Sentinel-1 (SEN-1) SAR images and Sentinel-2 (SEN-2) multi-spectral images. S-CycleGAN was applied to two experiments, which were SAR-to-optical image translation and cloud removal, and the results showed that S-CycleGAN could keep both the land cover and structure information well, and its performance was superior to some famous image-to-image translation models.","['Radar polarimetry', 'Optical imaging', 'Clouds', 'Optical sensors', 'Adaptive optics', 'Optical polarization', 'Gallium nitride']","['SAR-to-optical image translation', 'visualization', 'GAN', 'Sentinel', 'cloud removal']"
"Simultaneous Localization and Mapping (SLAM) plays an important role in the computer vision and robotics field. The traditional SLAM framework adopts a strong static world assumption for analysis convenience. How to cope with dynamic environments is of vital importance and attracts more attentions. Existing SLAM systems toward dynamic scenes either solely utilize semantic information, solely utilize geometry information, or naively combine the results from them in a loosely coupled way. In this paper, we present SOF-SLAM: Semantic Optical Flow SLAM, a visual semantic SLAM system toward dynamic environments, which is built on RGB-D mode of ORB-SLAM2. A new dynamic features detection approach called semantic optical flow is proposed, which is a kind of tightly coupled way and can fully take advantage of feature's dynamic characteristic hidden in semantic and geometry information to remove dynamic features effectively and reasonably. The pixel-wise semantic segmentation results generated by SegNet serve as mask in the proposed semantic optical flow to get a reliable fundamental matrix, which is then used to filter out the truly dynamic features. Only the remaining static features are reserved in the tracking and optimization module to achieve accurate camera pose estimation in dynamic environments. Experiments on public TUM RGB-D dataset and in real-world environment are conducted. Compared with ORB-SLAM2, the proposed SOF-SLAM achieves averagely 96.73% improvements in high-dynamic scenarios. It also outperforms the other four state-of-the-art SLAM systems which cope with the dynamic environments.","['Semantics', 'Simultaneous localization and mapping', 'Feature extraction', 'Geometry', 'Visualization', 'Dynamics', 'Cameras']","['Computer vision', 'robotics', 'semantic', 'simultaneous localization and mapping']"
"The vast development of the Internet of Things (IoT) and cloud-enabled data processing solutions provide the opportunity to build novel and fascinating smart, connected healthcare systems. Smart healthcare systems analyze the IoT-generated patient data to both enhance the quality of patient care and reduce healthcare costs. A major challenge for these systems is how the Cloud of Things can handle the data generated from billions of connected IoT devices. Edge computing infrastructure offers a promising solution by operating as a middle layer between the IoT devices and cloud computing. The Edge of Things (EoT) can offer small-scale real-time computing and storage capabilities that ensures low latency and optimal utilization of the IoT resources. However, the EoT has privacy-preservation issues, which is a significant concern for the healthcare systems that contain sensitive patient data. This paper introduces a novel EoT computing framework for secure and smart healthcare surveillance services. Fully homomorphic encryption preserves data privacy and is stored and processed within an EoT framework. A distributed approach for clustering-based techniques is developed for the proposed EoT framework with the scalability to aggregate and analyze the large-scale and heterogeneous data in the distributed EoT devices independently before it is sent to the cloud. We demonstrate the proposed framework by evaluating a case study for the patient biosignal data. Our framework rapidly accelerates the analysis response time and performance of the encrypted data processing while preserving a high level of analysis accuracy and data privacy.","['Medical services', 'Cloud computing', 'Internet of Things', 'Logic gates', 'Bioinformatics', 'Cryptography', 'Wireless sensor networks']","['Smart healthcare', 'Internet of Things', 'edge computing', 'homomorphic encryption']"
"The widespread adoption of the Internet of Things (IoT) technologies has drastically increased the breadth and depth of attack surfaces in networked systems, providing new mechanisms for the intrusion. In the context of smart-world critical infrastructures and cyber-physical systems, the rapid adoption of the IoT systems and infrastructures without thorough consideration for the risks and vulnerabilities has the potential for catastrophic damage to the privacy, safety, and security of individuals and corporations. While the IoT systems have the potential to increase productivity, accountability, traceability, and efficiency, their potential weaknesses are also more abundant. In this paper, we provide critical consideration of the security of the IoT systems as applied to smart-world critical infrastructures. Particularly, we carry out a detailed assessment of vulnerabilities in IoT-based critical infrastructures from the perspectives of applications, networking, operating systems, software, firmware, and hardware. In addition, we highlight the three key critical infrastructure IoT-based cyber-physical systems, namely the smart transportation, smart manufacturing, and smart grid. Moreover, we provide a broad collection of attack examples upon each of the key applications. Furthermore, we introduce a case study, in which we assess the impacts of potential attacks on critical IoT-based systems, using the smart transportation system as an example. Finally, we provide a set of best practices and address the necessary steps to enact countermeasures for any generic IoT-based critical infrastructure system.","['Internet of Things', 'Smart transportation', 'Smart grids', 'Critical infrastructure', 'Security', 'Smart manufacturing', 'Software']","['Cyber-physical systems', 'Internet of Things', 'security', 'critical infrastructure', 'case study', 'computing infrastructure']"
"Recent decades have seen significant progress in the field of artificial hands. Most of the surveys, which try to capture the latest developments in this field, focused on actuation and control systems of these devices. In this paper, our goal is to provide a comprehensive survey of the sensors for artificial hands. In order to present the evolution of the field, we cover five year periods starting at the turn of the millennium. At each period, we present the robot hands with a focus on their sensor systems dividing them into categories, such as prosthetics, research devices, and industrial end-effectors. We also cover the sensors developed for robot hand usage in each era. Finally, the period between 2010 and 2015 introduces the reader to the state of the art and also hints to the future directions in the sensor development for artificial hands.","['Hands', 'Prosthetics', 'Robots', 'Sensors', 'Robot sensing systems']","['Artificial hands', 'prosthetics', 'industrial robotics', 'robotic hands', 'robot end effectors', 'sensors', 'robot sensing', 'review']"
"Traditional satellite networks depend on the closed and planned architecture. Thus, there are many challenges such as configuration update, new communication and networking technologies introduction, truly-differentiated services provision, satellite network device interoperability, and the integration of satellite and terrestrial networks. Software-defined networking (SDN) has the features of flexibility, programmability, and logical centralization, which increases network resource utilization, simplifies network management, reduces operating cost, and promotes the evolution and innovation. In this paper, a new software-defined architecture for next-generation satellite networks, called SoftSpace, is presented. The concepts of network function virtualization, network virtualization, and software-defined radio are exploited in the SoftSpace to facilitate the incorporation of new applications, services, and satellite communication technologies. This can not only reduce the capital expenditures and operational expenditures but also integrate satellite networks with terrestrial networks seamlessly, as well as can improve the interoperability of satellite network devices. In addition, we discuss the challenges and solutions for network management. The necessary network management instruments including multi-layer controller architecture, cooperative traffic classification, and utility-optimal network virtualization are presented. Finally, we discuss the challenges and solutions for space networking. The software-defined space networking solutions including quality of experience-aware space routing, SDN-enabled hybrid fault recovery mechanism, and software-defined space mobility management are developed.","['Satellite broadcasting', 'Virtualization', 'Resource management', 'Aerospace electronics', 'Next generation networking', 'Space vehicles', 'Network architecture']","['Next-generation satellite networks', 'software-defined networking', 'virtualization', 'network management instruments', 'space networking solutions']"
"As air pollution becomes an increasing concern globally, governments, and research institutions have attached great importance to air quality prediction to help give early warnings and prevent the impacts of air pollution. The existing prediction methods for air quality forecasting include deterministic methods, statistical methods, machine learning, and deep learning methods. Deep learning-based prediction methods have attracted much attention these years due to its high performance and powerful modeling capability. However, the majority of the deep learning methods only focus on the prediction of the places where there have monitoring stations, and limited studies have integrated deep learning to predict places without monitoring stations. To address the limitations, this paper proposes a new methodology framework combining a deep learning network, namely, bi-directional long short-term memory (BLSTM) network and the inverse distance weighting (IDW) technique for the spatiotemporal predictions of air pollutants at different time granularities. The BLSTM can effectively capture the long-term temporal mechanism of air pollution. The IDW layer, on the other hand, can consider the spatial correlation of air pollution and interpolate the spatial distribution. A case study is conducted to validate the effectiveness of the proposed methodology. The PM2.5 concentration at Guangdong, China is forecasted. Prediction performances of the LSTM network at hourly, daily, and weekly granularities and over different time spans are presented. Spatial distribution of the predicted PM2.5 concentrations and the prediction errors are analyzed. The experimental results demonstrate that the proposed method can achieve better prediction performance for the PM2.5 concentration compared with other models.","['Air pollution', 'Atmospheric modeling', 'Artificial neural networks', 'Predictive models', 'Deep learning', 'Monitoring']","['Air pollution', 'machine learning', 'neural networks', 'spatiotemporal phenomena', 'deep learning', 'long short-term memory', 'inverse distance weighting']"
"The continuous development in the construction of transportation infrastructure has brought enormous pressure to traffic control. Accurate and detailed traffic flow information is valuable for an effective traffic control strategy. This paper proposes a video-based vehicle counting framework using a three-component process of object detection, object tracking, and trajectory processing to obtain the traffic flow information. First, a dataset for vehicle object detection (VDD) and a standard dataset for verifying the vehicle counting results (VCD) were established. The object detection was then completed by deep learning with VDD. Using this detection, a matching algorithm was designed to perform multi-object tracking in combination with a traditional tracking method. Trajectories of the moving objects were obtained using this approach. Finally, a trajectory counting algorithm based on encoding is proposed. The vehicles were counted according to the vehicle categories and their moving route to obtain detailed traffic flow information. The results demonstrated that the overall accuracy of our method for vehicle counting can reach more than 90%. The running rate of the proposed framework is 20.7 frames/s on the VCD. Therefore, the proposed vehicle counting framework is capable of acquiring reliable traffic flow information, which is likely applicable to intelligent traffic control and dynamic signal timing.","['Feature extraction', 'Object detection', 'Trajectory', 'Object tracking', 'Roads', 'Reliability', 'Magnetic sensors']","['Object detection', 'object tracking', 'trajectory processing', 'vehicle counting']"
"Students' feedback is an effective mechanism that provides valuable insights about teaching-learning process. Handling opinions of students expressed in reviews is a quite labour-intensive and tedious task as it is typically performed manually by the human intervention. While this task may be viable for small-scale courses that involve just a few students' feedback, it is unpractical for large-scale cases as it applies to online courses in general, and MOOCs, in particular. Therefore, to address this issue, we propose in this paper a framework to automatically analyzing opinions of students expressed in reviews. Specifically, the framework relies on aspect-level sentiment analysis and aims to automatically identify sentiment or opinion polarity expressed towards a given aspect related to the MOOC. The proposed framework takes advantage of weakly supervised annotation of MOOC-related aspects and propagates the weak supervision signal to effectively identify the aspect categories discussed in the unlabeled students' reviews. Consequently, it significantly reduces the need for manually annotated data which is the main bottleneck for all deep learning techniques. A large-scale real-world education dataset containing around 105k students' reviews collected from Coursera and a dataset comprising of 5989 students' feedback in traditional classroom settings are used to perform experiments. The experimental results indicate that our proposed framework attains inspiring performance with respect to both the aspect category identification and the aspect sentiment classification. Moreover, the results suggest that the framework leads to more accurate results than the expensive and labour-intensive sentiment analysis techniques relying heavily on manually labelled data.","['Sentiment analysis', 'Education', 'Object recognition', 'Task analysis', 'Deep learning', 'Neural networks', 'Computer science']","['Aspect identification', 'aspect sentiment classification', 'course evaluation', 'CNN', 'data mining', 'deep learning', 'eLearning', 'LSTM', 'MOOC', 'opinion mining', 'online course reviews', 'sentiment analysis', 'students’ feedback', 'weak supervision']"
"This paper presents a wideband, low-profile and semi-flexible antenna for wearable biomedical telemetry applications. The antenna is designed on a semi-flexible material of RT/duroid 5880 (E r = 2.2, tanδ = 0.0004) with an overall dimensions of 17 mm × 25 mm × 0.787 mm (0.2λ 0 × 0.29λ 0 × 0.009λ 0 ). A conventional rectangular patch is modified by adding rectangular slots to lower the resonant frequency, and the partial ground plane is modified to enhance the operational bandwidth. The final antenna model operates at 2.4 GHz with a 10-dB bandwidth (fractional bandwidth) of 1380 MHz (59.7 % at the centre frequency of 2.4 GHz). The proposed antenna maintains high gain (2.50 dBi at 2.4 GHz) and efficiency (93 % at 2.4 GHz). It is proved from the simulations and experimental results that the antenna has negligible effects in terms of reflection coefficient, bandwidth, gain, and efficiency when it is bent. Moreover, the antenna is simulated and experimentally tested in proximity of the human body, which shows good performance. The proposed wideband antenna is a promising candidate for compact wearable biomedical devices.","['Broadband antennas', 'Biomedical monitoring', 'Wideband', 'Resonant frequency', 'Antenna radiation patterns']","['On-body antenna', 'wideband antenna', 'wearable antenna', 'SAR', 'flexible antenna', 'biomedical antenna']"
"The complexity of the electronics supply chain has grown significantly due to the expansion of globalization in the 21st century. Electronic parts are now manufactured, distributed, and sold globally. Ensuring the security and integrity of the supply chain has become extremely challenging due to the widespread infiltration of untrusted hardware, specifically, counterfeit and cloned parts. Especially, the provenance of microelectronics and commercial off-the-shelf (COTS) parts becomes prohibitively difficult to track and calls for immediate solutions. In this paper, we present a non-destructive way of ensuring the traceability of electronic parts in the supply chain. We have implemented a blockchain-based framework, which helps to track and trace every chip while they are circulating in the supply chain. The proposed framework is built upon a permissioned blockchain. Hyperledger is used for implementing this framework. A detailed analysis is carried out to present the feasibility of our proposed approach.","['Supply chains', 'Blockchain', 'Security', 'Integrated circuits', 'Smart contracts', 'Receivers']","['Internet of Things (IoT)', 'cyber-physical systems (CPS)', 'physically unclonable functions (PUF)', 'edge device', 'cloning', 'blockchains', 'device identity', 'track and trace']"
"Mobile edge computing (MEC) has shown tremendous potential as a means for computationally intensive mobile applications by partially or entirely offloading computations to a nearby server to minimize the energy consumption of user equipment (UE). However, the task of selecting an optimal set of components to offload considering the amount of data transfer as well as the latency in communication is a complex problem. In this paper, we propose a novel energy-efficient deep learning based offloading scheme (EEDOS) to train a deep learning based smart decision-making algorithm that selects an optimal set of application components based on remaining energy of UEs, energy consumption by application components, network conditions, computational load, amount of data transfer, and delays in communication. We formulate the cost function involving all aforementioned factors, obtain the cost for all possible combinations of component offloading policies, select the optimal policies over an exhaustive dataset, and train a deep learning network as an alternative for the extensive computations involved. Simulation results show that our proposed model is promising in terms of accuracy and energy consumption of UEs.","['Deep learning', 'Energy consumption', 'Servers', 'Decision making', 'Cost function', 'Mathematical model', 'Task analysis']","['Computational offloading', 'deep learning', 'energy efficient offloading', 'mobile edge computing', 'user equipment']"
"In this paper, an extremely compact two-element linear polarized multiple-input-multiple-output (MIMO) antenna array with a metasurface superstrate is proposed. Instead of using periodic square split-ring resonators which occupy larger space and which are incident angle variant, double-layer short wire is utilized as the unit cell of the metasurface. The metasurface is compact in size and effective in decoupling two nearby Bowtie antennas strongly coupled in the H-plane with the spacing of only 0.27 wavelength. After decoupling, the isolation between the two antennas has been improved from around 10 dB to more than 25 dB within the band of 2300 to 2690 MHz while their reflection remained below −15 dB. Moreover, the radiation pattern after adding the metasurface superstrate is well maintained with total efficiency improvement by about 10%, and the envelope correlation coefficient between the two antennas is reduced from 0.35 to below 0.12 within the whole band of interest. The proposed method can find plenty of applications in MIMO and 5G communication systems.","['Wires', 'MIMO communication', 'Dipole antennas', 'Antenna radiation patterns', 'Mutual coupling', 'Antenna feeds']","['Antenna array mutual coupling', 'base station', 'decoupling', 'multiple-input-multiple-output (MIMO)', 'metamaterial', 'meta-surface', '5G']"
"Indoor localization techniques are becoming popular in order to provide a seamless indoor positioning system enhancing the traditional GPS service that is only suitable for outdoor environments. Though there are proprietary and costly approaches targeting high accuracy positioning, Wi-Fi and BLE networks are widely deployed in many public and private buildings (e.g. shopping malls, airports, universities, etc.). These networks are accessible through mobile phones resulting in an effective commercial off-the-self basic infrastructure for an indoor service. The obtained positioning accuracy is still being improved and there is ongoing research on algorithms adapted for Wi-Fi and BLE and also for the particularities of indoor environments. This paper focuses not only on indoor positioning techniques, but also on a multimodal approach. Traditional proposals employ only one network technology whereas this paper integrates two different technologies in order to provide improved accuracy. It also sets the basis for combining (merging) additional technologies, if available. The initial results show that the positioning service performs better with a multimodal approach compared to individual (monomodal) approaches and even compared with Google's geolocation service in public spaces such as airports.","['Fingerprint recognition', 'Wireless fidelity', 'Global Positioning System', 'Airports', 'Buildings', 'Calibration', 'Estimation']","['BLE beacons', 'indoor location', 'indoor positioning', 'Internet of Things', 'Wi-Fi fingerprinting']"
"The advancement in the current communication technology makes it incumbent to analyze the conventional features of reflectarray antenna for future adaptability. This paper thoroughly reviews the design and experimental features of reflectarray antenna for its bandwidth improvement in microwave and millimeter wave frequency ranges. The paper surveys the fundamental and advanced topologies of reflectarray design implementations, which are needed particularly for its broadband features. The realization of its design approaches has been studied at unit cell and full reflectarray levels for its bandwidth enhancement. Various design configurations have also been critically analyzed for the compatibility with the high-frequency 5G systems.","['Bandwidth', '5G mobile communication', 'Feeds', 'Computer architecture', 'Antenna arrays', 'Dielectrics']","['Reflectarrays', 'bandwidth', 'unit cell', 'multi-resonance', 'millimeter wave', '5G']"
"Generative Adversarial Networks (GANs) have achieved impressive results in various image synthesis tasks, and are becoming a hot topic in computer vision research because of the impressive performance they achieved in various applications. In this paper, we introduce the recent research on GANs in the field of image processing, including image synthesis, image generation, image semantic editing, image-to-image translation, image super-resolution, image inpainting, and cartoon generation. We analyze and summarize the methods used in these applications which have improved the generated results. Then, we discuss the challenges faced by GANs and introduce some methods to deal with these problems. We also preview some likely future research directions in the field of GANs, such as video generation, facial animation synthesis and 3D face reconstruction. The purpose of this review is to provide insights into the research on GANs and to present the various applications based on GANs in different scenarios.","['Image synthesis', 'Generative adversarial networks', 'Training', 'Face', 'Task analysis', 'Generators']","['Generative adversarial networks', 'image synthesis', 'image-to-image translation', 'image editing', 'cartoon generation']"
"Emergency decision making is critically important for countries or communities to enhance the effectiveness and validity of the emergency response, which can greatly lower environmental damage, casualties, and economic loss. In the case of emergency decision evaluation, the essential problems that arise serious inexactness, fuzziness, and ambiguity. Interval-valued Pythagorean fuzzy set (IVPFS), portrayed by membership and non-membership with the interval form, is an effective and flexible way to seize indeterminacy. In this paper, primarily, a novel score function for an interval-valued Pythagorean fuzzy number is initiated for managing some comparative issues. Then, a new distance measure for IVPFSs with multiple parameters is studied for solving the counter-intuitive situations. The interesting properties among the developed similarity measures, distance measures, and entropy have also been derived. Then, the objective weights of diverse attributes are ascertained by a novel entropy approach. Also, we explore the combination weight, which can reveal both objective preference and subjective preference. In addition, two interval-valued Pythagorean fuzzy decision making methods based on weighted distance-based approximation and multiparametric similarity measure are presented. Later, the validity of the algorithms is illustrated by a mine emergency decision making issue with the influence of diverse parameters on the ordering. Finally, a comparison with some existing decision making methods has been executed by the counter-intuitive phenomena and discrimination problems for verifying their effectiveness.","['Decision making', 'Fuzzy sets', 'Entropy', 'Weight measurement', 'Emergency services', 'Economics', 'Software measurement']","['Interval-valued Pythagorean fuzzy set', 'score function', 'similarity measures', 'entropy', 'WDBA']"
"Currently, the popularity of the Internet of Things (IoT) has brought about an increase in the amount of data, so multi-server distributed cloud computing has been widely used in various applications that have brought convenience to our daily lives. At the same time, the development of the fifth generation (5G) of mobile communication technology has gradually become the main driving force for the popularization of the IoT. Because the 5G network is a heterogeneous network with multiple servers and small cells, the mutual authentication protocol under multiple servers is also applicable to the 5G network environment. However, much of the data will have serious storage and security issues during transmission. Aiming at the security issues in a multi-server (M-S) architecture, in 2018, Wu et al. proposed an authentication protocol in a distributed cloud environment. They claimed that their protocol is secure and resistant to various known types of attacks. However, we found that their protocol does not guarantee perfect forward secrecy (PFS) and suffers from privileged insider (PI) attacks. Such attacks will cause data to be out of sync. Therefore, we improved Wu et al.'s protocol and proposed an improvement in the 5G network environment. Finally, we performed a security analysis on the proposed protocol, including the automatic encryption protocol tool ProVerif, BAN logic, and informal security analysis, which proved that our protocol is secure. Compared with similar existing schemes, we have proved the efficiency of the scheme and achieved higher security standards.","['Protocols', '5G mobile communication', 'Authentication', 'Cloud computing', 'Servers', 'Nickel']","['Authentication', 'multi-server', '5G networks', 'cryptanalysis', 'lightweight']"
"Recently, several multimedia encryption techniques with permutation-diffusion architecture have been developed. The traditional architecture applies the diffusion and permutation functions as two separate phases. This separable design enables the attacker to launch several forms of attacks in addition to the degradation of the encryption speed. Furthermore, during the diffusion phase, the image pixels are masked in a static order, which may expose significant information about the encryption technique to the attacker. Accordingly, to remedy these problems, this paper suggests an efficient image cryptosystem based on simultaneous permutation and diffusion functions that process the image pixels in a dynamic order fashion. Specifically, the proposed method employs the Chebyshev-Chebyshev map to horizontally and vertically mix the plain-image information. Then, it utilizes the modified Logistic map to mask the image pixels and shuffle the masked values simultaneously. Meanwhile, the control parameters of the employed chaos systems are directly correlated to the plain-image to assure that different key-streams are created for distinct plain-images. Simulation results and security scrutiny confirm that the suggested cipher has several brilliant characteristics, including the robustness against various types of attacks.","['Ciphers', 'Encryption', 'Logistics', 'Chaos', 'Streaming media']","['Chaos system', 'cryptography', 'image encryption', 'security analysis', 'simultaneous permutation–diffusion']"
"Networked music performance (NMP) is a potential game changer among Internet applications, as it aims at revolutionizing the traditional concept of musical interaction by enabling remote musicians to interact and perform together through a telecommunication network. Ensuring realistic performance conditions, however, constitutes a significant engineering challenge due to the extremely strict requirements in terms of network delay and audio quality, which are needed to maintain a stable tempo, a satisfying synchronicity between performers and, more generally, a high-quality interaction experience. In this paper, we offer a review of the psycho-perceptual studies conducted in the past decade, aimed at identifying latency tolerance thresholds for synchronous real-time musical performance. We also provide an overview of hardware/software enabling technologies for NMP, with a particular emphasis on system architecture paradigms, networking configurations, and applications to real use cases.","['Music', 'Audio systems', 'Performance evaluatoin', 'Internet', 'Computer generated music', 'Audio visual systems']","['Music', 'audio systems', 'audio-visual systems', 'networked music performance', 'network latency']"
"Deploying unmanned aerial vehicle (UAV) swarms in delivery systems are still in its infancy with regard to the technology, safety, and aviation rules and regulations. Optimal use of UAVs in dynamic environments is important in many aspects, e.g., increasing efficacy and reducing the air traffic, resulting in a safer environment, and it requires new techniques and robust approaches based on the capabilities of UAVs and constraints. This paper analyzes several delivery schemes within a platform, such as delivery with and without using air highways and delivery using a hybrid scheme along with several delivery methods (i.e., optimal, premium, and first-in first-out) to explore the use of UAV swarms as part of the logistics operations. In this platform, a dimension reduction technique, “dynamic multiple assignments in multi-dimensional space,” and several other new techniques along with Hungarian and cross-entropy Monte Carlo techniques are forged together to assign tasks and plan 3D routes dynamically. This particular approach is performed in such a way that UAV swarms in several warehouses are deployed optimally given the delivery scheme, method, and constraints. Several scenarios are tested on the simulator using small and big data sets. The results show that the distribution and the characteristics of data sets and constraints affect the decision on choosing the optimal delivery scheme and the method. The findings are expected to guide the aviation authorities in their decisions before dictating rules and regulations regarding effective, efficient, and safe use of UAVs. Furthermore, the companies that produce UAVs are going to take the demonstrated results into account for their functional design of UAVs along with other companies that aim to deliver their products using UAVs. Additionally, private industries, logistics operators, and municipalities are expected to benefit from the potential adoption of the simulator in strategic decisions before embarking on the practical implementation of UAV delivery systems.","['Drones', 'Task analysis', 'Optimization', 'Three-dimensional displays', 'Path planning', 'Companies']","['Unmanned aerial vehicle swarms', 'UAV delivery', 'logistics', 'cross-entropy Monte-Carlo', 'Hungarian route optimization', 'simulation']"
"One of the most challenging areas of Future Smart Cities Research is the Smart Energy domain. Critical issues related to optimization, provision of smart customizable networks and sophisticated computational techniques and methods enabled by artificial intelligence and machine learning need further investigation. The renewable energy (RE) is a powerful resource for the future global development in the context of climate change and resources depletion. Artificial intelligence (AI) implies new rules of organizing the activities in order to respond to these new requirements. It is necessary to improve the design of the energy infrastructure, the deployment and production of RE in order to face the multiple challenges that will affect the sector’s growth and resilience.. In this research work we exploit the recent developments on the AI adoption for RE sector in European Union (EU). In this respect, we analysed (i) the efficiency of the transformation processes of the RE within the energy chain from Gross Inland Consumption to Final Energy Consumption, (ii) its implications on the structure of renewable energy by source (solar, wind, biomass etc.), (iii) the labour productivity in RE sector compared to the economy as a whole and its correlation with investments level, (iv) the implication of the adoption of AI for RE towards Future Smart Cities Research. The main contribution of this research is the development of a framework for understanding the contribution of AI in the RE sector in Europe. Another bold contribution of this work is the discussion of the implications for Future Smart Cities Research and future research directions.","['Smart cities', 'Renewable energy sources', 'Europe', 'Economics', 'Machine learning', 'Climate change']","['Future smart cities research', 'smart grids', 'optimization', 'machine learning', 'artificial intelligence', 'renewable energy', 'energy sector', 'innovation', 'energy grid']"
"The accuracy of retinal vessels segmentation is of great significance for the diagnosis of cardiovascular diseases such as diabetes and hypertension. Especially, the segmentation accuracy of the end of vessels will be affected by the area outside the retinal in fundus image. In this paper, we propose an attention guided U-Net with atrous convolution(AA-UNet), which guides the model to separate vessel and non-vessel pixels and reuses deep features. Firstly, AA-UNet regresses a boundary box to the retinal region to generate an attention mask, which was used as a weighting function to multiply the differential feature map in the model to make the model pay more attention to the vessels region. Secondly, atrous convolution replaces ordinary convolution in feature layer, which can increase the receptive field and reduce the amount of computation. Then, we add two shortcuts to the atrous convolution in order to reuse the features, so that the details of vessel are more prominent. We test our model with the accuracy are 0.9558/0.9640/0.9608 and AUC are 0.9847/0.9824/0.9865 on DRIVE, STARE and CHASE_DB1 datasets, respectively. The results show that our method has improvement in the accuracy of retinal vessels segmentation, and exceeded other representative retinal vessels segmentation methods.","['Biomedical imaging', 'Blood vessels', 'Image segmentation', 'Feature extraction', 'Retinal vessels', 'Convolution']","['Atrous convolution', 'attention module', 'retinal vessels segmentation', 'shortcut']"
"This paper proposes a smart real-time health monitoring structured for hospitals' distributor based on wearable health data sensors. Health data were received from multiple heterogeneous wearable sensors, such as electrocardiogram (ECG), oxygen saturation sensor (SpO2), blood pressure monitor, and non-sensory measurement (text frame), from 500 patients with different symptoms. Triage level and healthcare services were identified based on the new four-level remote triage and package localization (4LRTPL). The numbers of healthcare services that represent hospital status were collected from 12 hospitals located in Baghdad city. This study constructed a decision matrix based on the crossover of “multi-healthcare services” and “hospital list” within Tier 4. The hospitals were then ranked using multi-criteria decision-making (MCDM) techniques, namely, integrated analytic hierarchy process (AHP) and vlsekriterijumskaoptimizacija i kompromisnoresenje (VIKOR). Mean ± standard deviation was computed to ensure that the hospital ranking undergoes systematic ranking for objective validation. This research provided scenarios and checklist benchmarking to evaluate the proposed and existing health recommender frameworks. Results corroborated that: 1) the integration of AHP and VIKOR effectively solved hospital selection problems; 2) in the objective validation, significant differences were recognized between the scores of groups, indicating that the ranking results were identical; 3) in evaluation, the proposed framework exhibited an advantage over the benchmark framework with a percentage of 56.25%; and 4) hospitals with multiple healthcare services received the highest ranks, whereas hospitals with fewer healthcare services received low ranks.","['Hospitals', 'Heart', 'Biomedical monitoring', 'Diseases', 'Decision making', 'Monitoring', 'Telemedicine']","['Real-time remote monitoring', 'hospital management', 'hospital selection', 'chronic heart', 'healthcare services', 'triage', 'wearable health sensor']"
"Intelligent fault diagnosis of bearings has been a heated research topic in the prognosis and health management of rotary machinery systems, due to the increasing amount of available data collected by sensors. This has given rise to more and more business desire to apply data-driven methods for health monitoring of machines. In recent years, various deep learning algorithms have been adapted to this field, including multi-layer perceptrons, autoencoders, convolutional neural networks, and so on. Among these methods, autoencoder is of particular interest for us because of its simple structure and its ability to learn useful features from data in an unsupervised fashion. Previous studies have exploited the use of autoencoders, such as denoising autoencoder, sparsity aotoencoder, and so on, either with one layer or with several layers stacked together, and they have achieved success to certain extent. In this paper, a bearing fault diagnosis method based on fully-connected winner-take-all autoencoder is proposed. The model explicitly imposes lifetime sparsity on the encoded features by keeping only k% largest activations of each neuron across all samples in a mini-batch. A soft voting method is implemented to aggregate prediction results of signal segments sliced by a sliding window to increase accuracy and stability. A simulated data set is generated by adding white Gaussian noise to original signals to test the diagnosis performance under noisy environment. To evaluate the performance of the proposed method, we compare our methods with some state-of-the-art bearing fault diagnosis methods. The experiments result show that, with a simple two-layer network, the proposed method is not only capable of diagnosing with high precision under normal conditions, but also has better robustness to noise than some deeper and more complex models.","['Fault diagnosis', 'Robustness', 'Noise reduction', 'Training', 'Feature extraction', 'Noise measurement', 'Robots']","['Autoencoder', 'fault diagnosis', 'lifetime sparsity', 'signal processing', 'signal representations', 'supervised learning', 'vibrations']"
"A supply chain consists of many stakeholders such as suppliers, carriers and customers. It is often complex due to the rapid development of economic globalization and the intense competition pressure in the market which resulted in information sharing within a supply chain to be fragmented. Blockchain technology can solve this problem by having only a “one trusted ledger” that could reshape the element of data trust. The goal of this paper is to identify and understand the impact of blockchain technology for information sharing within a supply chain. The decentralized nature of blockchain technology offers a high level of transparency and has gained the attention from various sectors to deploy this technology. A systematic literature review in the academic literature was conducted using different databases. Blockchain-enabled information sharing can add value to enhance collaborative work in different types of supply chains such as health and medical, construction and smart city. From our findings, one potential impact of deploying blockchain-enabled information sharing within a supply chain is that it ensures all members in the chain can obtain verified information which enhances collaborative partnerships. Through this in-depth research, we highlighted potential barriers that could impede the development of blockchain technology in supply chain such as the lack of understanding of blockchain technology in businesses and conflict of interests. Future work such as information hiding, in parallel with information sharing, could close the gap in deploying this technology within a supply chain. Understanding the nature of different supply chain is also important to better prepare the deployment of blockchain. We acknowledge that our approach in selecting literatures in our systematic review may exclude certain literatures. Nonetheless, we tried to include as many relevant literatures as possible, to develop a roadmap on the current situation of blockchain-enabled information sharing within a supply chain.","['Supply chains', 'Information management', 'Systematics', 'Contracts', 'Bibliographies']","['Blockchain', 'smart contract', 'supply chain management', 'information sharing']"
"Collision avoidance algorithms are essential for safe and efficient robot operation among pedestrians. This work proposes using deep reinforcement (RL) learning as a framework to model the complex interactions and cooperation with nearby, decision-making agents, such as pedestrians and other robots. Existing RL-based works assume homogeneity of agent properties, use specific motion models over short timescales, or lack a principled method to handle a large, possibly varying number of agents. Therefore, this work develops an algorithm that learns collision avoidance among a variety of heterogeneous, non-communicating, dynamic agents without assuming they follow any particular behavior rules. It extends our previous work by introducing a strategy using Long Short-Term Memory (LSTM) that enables the algorithm to use observations of an arbitrary number of other agents, instead of a small, fixed number of neighbors. The proposed algorithm is shown to outperform a classical collision avoidance algorithm, another deep RL-based algorithm, and scales with the number of agents better (fewer collisions, shorter time to goal) than our previously published learning-based approach. Analysis of the LSTM provides insights into how observations of nearby agents affect the hidden state and quantifies the performance impact of various agent ordering heuristics. The learned policy generalizes to several applications beyond the training scenarios: formation control (arrangement into letters), demonstrations on a fleet of four multirotors and on a fully autonomous robotic vehicle capable of traveling at human walking speed among pedestrians.","['Collision avoidance', 'Robots', 'Reinforcement learning', 'Vehicle dynamics', 'Robot sensing systems', 'Heuristic algorithms', 'Dynamics']","['Collision avoidance', 'deep reinforcement learning', 'motion planning', 'multiagent systems', 'decentralized execution']"
"Prior 6LoWPAN intrusion detection system (IDS) utilized several features to detect various malicious activities. However, these IDS methods only detect specific attack but fails when the attacks are combined. In this paper, we propose an IDS known as compression header analyzer intrusion detection system (CHA-IDS) that analyzes 6LoWPAN compression header data to mitigate the individual and combination routing attacks. CHA-IDS is a multi-agent system framework that capture and manage raw data for data collection, analysis, and system actions. The proposed CHA-IDS utilize best first and greedy stepwise with correlation-based feature selection to determine only significant features needed for the intrusion detection. These features are then tested using six machine learning algorithms to find the best classification method that able to distinguish between an attack and non-attack and then from the best classification method, we devise a rule to be implemented in Tmote Sky. To ensure the reliability of our proposed method, we evaluate the CHA-IDS with three types of combination attacks known as hello flood, sinkhole, and wormhole. We also compare our results in term of accuracy of detection, energy overhead, and memory consumption with the prior 6LoWPAN-IDS implementation such as SVELTE and Pongle’s IDS. The results show that CHA-IDS performs better than the aforementioned methods with 99% true positive rate and consumed low energy overhead and memory that fit in constrained device such Tmote Sky.","['Protocols', 'Machine learning algorithms', 'Intrusion detection', 'Routing', 'Feature extraction', 'Floods', 'Wireless sensor networks']","['Internet of Things', 'security', 'machine learning', 'compression header', '6LoWPAN', 'RPL', 'routing attack']"
"Deep learning has recently been applied to automatically classify the modulation categories of received radio signals without manual experience. However, training deep learning models requires massive volume of data. An insufficient training data will cause serious overfitting problem and degrade the classification accuracy. To cope with small dataset, data augmentation has been widely used in image processing to expand the dataset and improve the robustness of deep learning models. However, in wireless communication areas, the effect of different data augmentation methods on radio modulation classification has not been studied yet. In this paper, we evaluate different data augmentation methods via a state-of-the-art deep learning-based modulation classifier. Based on the characteristics of modulated signals, three augmentation methods are considered, i.e., rotation, flip, and Gaussian noise, which can be applied in both training phase and inference phase of the deep learning-based classifier. Numerical results show that all three augmentation methods can improve the classification accuracy. Among which, the rotation augmentation method outperforms the flip method, both of which achieve higher classification accuracy than the Gaussian noise method. Given only 12.5% of training dataset, a joint rotation and flip augmentation policy can achieve even higher classification accuracy than the baseline with initial 100% training dataset without augmentation. Furthermore, with data augmentation, radio modulation categories can be successfully classified using shorter radio samples, leading to a simplified deep learning model and a shorter classification response time.","['Deep learning', 'Training', 'Wireless communication', 'Data models', 'Gaussian noise', 'Frequency modulation']","['Data augmentation', 'deep learning', 'modulation classification', 'wireless communication']"
"Deep learning has attracted growing interest for application to medical imaging, such as positron emission tomography (PET), due to its excellent performance. Convolutional neural networks (CNNs), a facet of deep learning requires large training-image datasets. This presents a challenge in a clinical setting because it is difficult to prepare large, high-quality patient-related datasets. Recently, the deep image prior (DIP) approach has been devised, based on the fact that CNN structures have the intrinsic ability to solve inverse problems such as denoising without pre-training and do not require the preparation of training datasets. Herein, we proposed the dynamic PET image denoising using a DIP approach, with the PET data itself being used to reduce the statistical image noise. Static PET data were acquired for input to the network, with the dynamic PET images being handled as training labels, while the denoised dynamic PET images were represented by the network output. We applied the proposed DIP method to computer simulations and also to real data acquired from a living monkey brain with 18 F-fluoro-2-deoxy-D-glucose ( 18 F-FDG). As a simulation result, our DIP method produced less noisy and more accurate dynamic images than the other algorithms. Moreover, using real data, the DIP method was found to perform better than other types of post-denoising method in terms of contrast-to-noise ratio, and also maintain the contrast-to-noise ratio when resampling the list data to 1/5 and 1/10 of the original size, demonstrating that the DIP method could be applied to low-dose PET imaging. These results indicated that the proposed DIP method provides a promising means of post-denoising for dynamic PET images.","['Positron emission tomography', 'Training', 'Electronics packaging', 'Noise reduction', 'Image denoising', 'Convolutional neural networks', 'Image reconstruction']","['Convolutional neural networks', 'deep image prior', 'deep learning', 'denoising', 'dynamic positron emission tomography']"
"This paper aims at recognizing emotions for a text-independent and speaker-independent emotion recognition system based on a novel classifier, which is a hybrid of a cascaded Gaussian mixture model and deep neural network (GMM-DNN). This hybrid classifier has been assessed for emotion recognition on “Emirati speech database (Arabic United Arab Emirates Database)” with six different emotions. The sequential GMM-DNN classifier has been contrasted with support vector machines (SVMs) and multilayer perceptron (MLP) classifiers, and its performance accuracy is indexed at 83.97%, while the other two perform at 80.33% and 69.78% using SVMs and MLP, respectively. These results demonstrate that the hybrid classifier significantly gives higher emotion recognition accuracy than SVMs and MLP classifiers. Our GMM-DNN model yields the results similar to those obtained by human judges in a subjective assessment context. Also, the performance of the classifier has been tested using two distinct emotional databases and in normal and noisy talking conditions. The dominant signal mask provided by the hybrid classifier offers better system performance in the presence of noisy signals.","['Emotion recognition', 'Databases', 'Hidden Markov models', 'Speech recognition', 'Feature extraction', 'Mel frequency cepstral coefficient', 'Neural networks']","['Deep neural network', 'emotion recognition', 'Gaussian mixture model']"
"Recently, automatic hand gesture recognition has gained increasing importance for two principal reasons: the growth of the deaf and hearing-impaired population, and the development of vision-based applications and touchless control on ubiquitous devices. As hand gesture recognition is at the core of sign language analysis a robust hand gesture recognition system should consider both spatial and temporal features. Unfortunately, finding discriminative spatiotemporal descriptors for a hand gesture sequence is not a trivial task. In this study, we proposed an efficient deep convolutional neural networks approach for hand gesture recognition. The proposed approach employed transfer learning to beat the scarcity of a large labeled hand gesture dataset. We evaluated it using three gesture datasets from color videos: 40, 23, and 10 classes were used from these datasets. The approach obtained recognition rates of 98.12%, 100%, and 76.67% on the three datasets, respectively for the signer-dependent mode. For the signer-independent mode, it obtained recognition rates of 84.38%, 34.9%, and 70% on the three datasets, respectively.","['Gesture recognition', 'Assistive technology', 'Feature extraction', 'Deep learning', 'Human computer interaction', 'Spatiotemporal phenomena', 'Data preprocessing']","['3DCNN', 'computer vision', 'deep learning', 'hand gesture recognition', 'sign language recognition', 'transfer learning']"
"Wi-Fi and magnetic field fingerprinting have been a hot topic in indoor positioning researches because of their ubiquity and location-related features. Wi-Fi signals can provide rough initial positions, and magnetic fields can further improve the positioning accuracies, therefore many researchers have tried to combine the two signals for high-accuracy indoor localization. Currently, state-of-the-art solutions design separate algorithms to process different indoor signals. Outputs of these algorithms are generally used as inputs of data fusion strategies. These methods rely on computationally expensive particle filters, labor-intensive feature analysis, and time-consuming parameter tuning to achieve better accuracies. Besides, particle filters need to estimate the moving directions of particles, limiting smartphone orientation to be stable, and aligned with the user's moving directions. In this paper, we adopted a convolutional neural network (CNN) to implement an accurate and orientation-free positioning system. Inspired by the state-of-the-art image classification methods, we design a novel hybrid location image using Wi-Fi and magnetic field fingerprints, and then a CNN is employed to classify the locations of the fingerprint images. In order to prevent the overfitting problem of the positioning CNN on limited training datasets, we also propose to divide the learning process into two steps to adopt proper learning strategies for different network branches. We show that the CNN solution is able to automatically learn location patterns, thus significantly lower the workforce burden of designing a localization system. Our experimental results convincingly reveal that the proposed positioning method achieves an accuracy of about 1 m under different smartphone orientations, users, and use patterns.","['Wireless fidelity', 'Magnetic fields', 'Fingerprint recognition', 'Training', 'Probabilistic logic', 'Image matching']","['Indoor positioning', 'indoor localization', 'neural networks', 'fingerprint', 'feature extraction']"
"Systems based on wireless gas sensor networks offer a powerful tool to observe and analyze data in complex environments over long monitoring periods. Since the reliability of sensors is very important in those systems, gas classification is a critical process within the gas safety precautions. A gas classification system has to react fast in order to take essential actions in the case of fault detection. This paper proposes a low latency real-time gas classification service system, which uses a multi-layer perceptron (MLP) artificial neural network to detect and classify the gas sensor data. An accurate MLP is developed to work with the data set obtained from an array of tin oxide (SnO2) gas sensor, based on convex micro hotplates. The overall system acquires the gas sensor data through radio-frequency identification (RFID), and processes the sensor data with the proposed MLP classifier implemented on a system on chip (SoC) platform from Xilinx. Hardware implementation of the classifier is optimized to achieve very low latency for real-time application. The proposed architecture has been implemented on a ZYNQ SoC using fixed-point format and the achieved results have shown that an accuracy of 97.4% has been obtained.","['Wireless sensor networks', 'Artificial neural networks', 'Gas detectors', 'Finite programmable gate array', 'System-on-chip', 'Sensor systems', 'Wireless communications', 'Radio frequency identification']","['Artificial neural network', 'gas identification', 'FPGA', 'system on chip (SoC)', 'ZYNQ']"
"Network function virtualization (NFV) is a new network architecture framework that implements network functions in software running on a pool of shared commodity servers. NFV can provide the infrastructure flexibility and agility needed to successfully compete in today's evolving communications landscape. Any service is represented by a service function chain (SFC) that is a set of VNFs to be executed according to a given order. The running of VNFs needs the instantiation of VNF instances (VNFIs) that are software modules executed on virtual machines. This paper deals with the migration problem of the VNFIs needed in the low traffic periods to turn OFF servers and consequently to save energy consumption. Though the consolidation allows for energy saving, it has also negative effects as the quality of service degradation or the energy consumption needed for moving the memories associated to the VNFI to be migrated. We focus on cold migration in which virtual machines are redundant and suspended before performing migration. We propose a migration policy that determines when and where to migrate VNFI in response to changes to SFC request intensity. The objective is to minimize the total energy consumption given by the sum of the consolidation and migration energies. We formulate the energy aware VNFI migration problem and after proving that it is NP-hard, we propose a heuristic based on the Viterbi algorithm able to determine the migration policy with low computational complexity. The results obtained by the proposed heuristic show how the introduced policy allows for a reduction of the migration energy and consequently lower total energy consumption with respect to the traditional policies. The energy saving can be on the order of 40% with respect to a policy in which migration is not performed.","['Servers', 'Virtual machining', 'Energy consumption', 'Quality of service', 'Network function virtualization', 'Routing', 'Viterbi algorithm']","['Network function virtualization', 'migration policy', 'power consumption', 'Viterbi algorithm']"
"Product dimensional variability is a crucial factor in the quality control of complex multistage manufacturing processes, where undetected defects can easily be propagated downstream. The recent advances in information technologies and consequently the increased volume of data that has become readily available provide an excellent opportunity for the development of automated defect detection approaches that are capable of extracting the implicit complex relationships in these multivariate data-rich environments. In this paper, several machine learning classifiers were trained and evaluated on varied metrics to predict dimensional defects in a real automotive multistage assembly line. The line encompasses two automated inspection stages with several human-operated assembly and pre-alignment stages in between. The results show that non-linear models like XGBoost and Random Forests are capable of modelling the complexity of such an environment, achieving a high true positive rate and showing promise for the improvement of existing quality control approaches, enabling defects and deviations to be addressed earlier and thus assist in reducing scrap and repair costs.","['Automobiles', 'Quality control', 'Automotive engineering', 'Industries', 'Machine learning', 'Inspection', 'Radio frequency']","['Machine learning', 'quality control', 'predictive manufacturing system', 'multistage', 'automotive industry', 'industry 40']"
"Notice of Violation of IEEE Publication Principles“Single-Image Super-Resolution Algorithm Based on Structural Self-Similarity and Deformation Block Features”by Yuantao Chen, Jin Wang, Xi Chen, Mingwei Zhu, Kai Yang, Zhi Wang, and Runlong Xia in IEEE Access, April 2019After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE’s Publication Principles.This paper is a translation and duplication of the content from the paper cited below. The original content was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.Due to the nature of this violation, reasonable effort should be made to remove all past references to this paper, and future references should be made to the following article:“Single image super resolution algorithm based on structural self-similarity and deformation block feature”by Wen Xiang, Ling Zhang, Yunhua Chen, Qiumin Jiin the Journal of Computer Applications (39) 1, June 2018To solve the problem of insufficient sample resources and poor noise immunity in single-image super-resolution (SR) restoration procedure, the paper has proposed the single-image SR algorithm based on structural self-similarity and deformation block features (SSDBF). First, the proposed method constructs a scale model, expands the search space as much as possible, and overcomes the shortcomings caused by the lack of a single-image SR training sample; Second, the limited internal dictionary size is increased by the geometric deformation of the sample block; Finally, in order to improve the anti-noise performance of the reconstructed picture, a group sparse learning dictionary is used to reconstruct the pending image. The experimental results show that, compared with state-of-the-art algorithms such as bicubic interpolation (BI), sparse coding (SC), deep recursive convolutional network (DRCN), multi-scale deep SR network (MDSR), super-resolution convolutional neural network (SRCNN) and second-order directional total generalized variation (DTGV). The SR images with more subjective visual effects and higher objective evaluation can be obtained through the proposed method. Compared with existing algorithms, the structural network converges more rapidly, the image edge and texture reconstruction effects are obviously improved, and the image quality evaluation, such as peak signal-noise ratio (PSNR), root mean square error (RMSE), and structural similarity (SSIM), are also superior and popular in image evaluation.",[],[]
"In the current WSN operation process, there are two major problems of data collection difficulty and network energy consumption, which seriously affects the reliability of the WSN. In this paper, the improved ant colony algorithm proposed is compared with other algorithms. Wireless sensor network nodes based on improved ant colony algorithm have lower energy consumption, and sensor nodes have more residual energy. In addition, the energy model, data transmission balance model is established and verified in the WSN transmission target function. The experimental results show that the WSN node after the improved ant colony algorithm is used to help in the determination of the location information of the public node, and then use the location information of the node to make the protocol have effective routing performance and effective target node location discrimination ability. Thus, the improved ant colony algorithm studied in this paper has important practical significance for improving the life cycle/energy consumption of wireless sensor networks. In addition, aiming at the characteristics and routing performance of wireless sensor networks, a low-power routing method based on location and direction is designed to make the message reach the target node accurately and safely, which effectively increases the data packet transmission rate.","['Wireless sensor networks', 'Energy consumption', 'Routing', 'Mobile nodes', 'Data collection', 'Optimization']","['Ant colony', 'WSN', 'residual energy', 'WSNs', 'distributed structure']"
"In this paper, we focus on the study of UAV ground target tracking under obstacle environments using deep reinforcement learning, and an improved deep deterministic policy gradient (DDPG) algorithm is presented. A reward function based on line of sight and artificial potential field is constructed to guide the behavior of UAV to achieve target tracking, and a penalty term of action makes the trajectory smooth. In order to improve the exploration ability, multiple UAVs, which controlled by the same policy network, are used to perform tasks in each episode. Taking into account that the history observations have a great degree of correlation with the policy, long short-term memory networks are used to approximate the state of environments, which improve the approximation accuracy and the efficiency of data utilization. The simulation results show that the propose method can make the UAV keep target tracking and obstacle avoidance effectively.","['Target tracking', 'Unmanned aerial vehicles', 'Collision avoidance', 'Path planning', 'Heuristic algorithms', 'Sensors', 'Reinforcement learning']","['DDPG', 'deep reinforcement learning', 'obstacle avoidance', 'target tracking', 'UAV']"
"Data mining applications are becoming a more common tool in understanding and solving educational and administrative problems in higher education. In general, research in educational mining focuses on modeling student's performance instead of instructors' performance. One of the common tools to evaluate instructors' performance is the course evaluation questionnaire to evaluate based on students' perception. In this paper, four different classification techniques - decision tree algorithms, support vector machines, artificial neural networks, and discriminant analysis - are used to build classifier models. Their performances are compared over a data set composed of responses of students to a real course evaluation questionnaire using accuracy, precision, recall, and specificity performance metrics. Although all the classifier models show comparably high classification performances, C5.0 classifier is the best with respect to accuracy, precision, and specificity. In addition, an analysis of the variable importance for each classifier model is done. Accordingly, it is shown that many of the questions in the course evaluation questionnaire appear to be irrelevant. Furthermore, the analysis shows that the instructors' success based on the students' perception mainly depends on the interest of the students in the course. The findings of this paper indicate the effectiveness and expressiveness of data mining models in course evaluation and higher education mining. Moreover, these findings may be used to improve the measurement instruments.","['Neural networks', 'Artificial neural networks', 'Classification algorithms', 'Performance evaluation', 'Support vector machines', 'Data mining', 'Analytical models', 'Algorithm design and analysis']","['Artificial neural networks', 'classification algorithms', 'decision trees', 'linear discriminant analysis', 'performance evaluation', 'support vector machines']"
"We present a robust adaptive second-order sliding mode controller that rejects external disturbances and uncertainties to improve the tracking performance of attitude and altitude in a quadcopter based on a Proportional–Integral–Derivative sliding surface. The algorithm provides a rapid adaptation and strict robustness of the flight control for the vehicle under the effect of perturbations. The proposed controller design is based on the theory of second order sliding mode technique that eliminates the chattering phenomenon present in first-order sliding mode controllers. In addition, we derive an adaptive law from the Lyapunov stability to ensure the robust control for the quadcopter even without knowing the upper bound for disturbances. Applying the same external disturbances, we use a numerical simulation to compare our algorithm to recent alternatives, such as normal adaptive sliding mode control, super-twisting sliding mode control, modified super-twisting sliding mode control, and nonsingular terminal sliding mode control. The results demonstrate the effectiveness of our proposed algorithm.","['Attitude control', 'Sliding mode control', 'Vehicle dynamics', 'Uncertainty', 'Perturbation methods', 'Position control', 'Mathematical model']","['PID sliding surface', 'second order sliding mode control', 'quadcopter', 'disturbance rejection', 'adaptive control']"
"The underlying fundaments of blockchain are cryptography and cryptographic concepts that provide reliable and secure decentralized solutions. Although many recent papers study the use-cases of blockchain in different industrial areas, such as finance, health care, legal relations, IoT, information security, and consensus building systems, only few studies scrutinize the cryptographic concepts used in blockchain. To the best of our knowledge, there is no Systematization of Knowledge (SoK) that gives a complete picture of the existing cryptographic concepts which have been deployed or have the potential to be deployed in blockchain. In this paper, we thoroughly review and systematize all cryptographic concepts which are already used in blockchain. Additionally, we give a list of cryptographic concepts which have not yet been applied but have big potentials to improve the current blockchain solutions. We also include possible instantiations of these cryptographic concepts in the blockchain domain. Last but not least, we explicitly postulate 21 challenging problems that cryptographers interested in blockchain can work on.","['Blockchain', 'Bitcoin', 'Hash functions', 'Proposals', 'Industries']","['Blockchain', 'cryptography', 'hash function', 'proof-of-work', 'consensus', 'signature', 'encryption', 'zero-knowledge proofs', 'access control', 'accumulator']"
"Since the 1G of mobile technology, mobile wireless communication systems have continued to evolve, bringing into the network architecture new interfaces and protocols, as well as unified services, high data capacity of data transmission, and packet-based transmission (4G). This evolution has also introduced new vulnerabilities and threats, which can be used to launch attacks on different network components, such as the access network and the core network. These drawbacks stand as a major concern for the security and the performance of mobile networks, since various types of attacks can take down the whole network and cause a denial of service, or perform malicious activities. In this survey, we review the main security issues in the access and core network (vulnerabilities and threats) and provide a classification and categorization of attacks in mobile network. In addition, we analyze major attacks on 4G mobile networks and corresponding countermeasures and current mitigation solutions, discuss limits of current solutions, and highlight open research areas.","['Mobile communication', 'Wireless networks', 'Mobile computing', 'Network architecture', 'Data communication', 'Network security', '4G mobile communications']","['Mobile network security', 'availability attacks', 'confidentiality attacks', 'integrity attacks', 'authentication attacks', 'impersonation attacks', 'trusted Computing', 'Intrusion Detection', 'signaling attacks', 'spoofing attacks', 'flooding attacks']"
"As COVID-19 spread worldwide, many major grain-producing countries have adopted measures to restrict their grain exports; food security has aroused great concern from various parties. How to improve grain production has become one of the most important issues facing all countries. However, crop diseases are a difficult problem for many farmers so it is important to master the severity of crop diseases timely and accurately to help staff take further intervention measures to minimize plants being further infected. In this paper, a restructured residual dense network was proposed for tomato leaf disease identification; this hybrid deep learning model combines the advantages of deep residual networks and dense networks, which can reduce the number of training process parameters to improve calculation accuracy as well as enhance the flow of information and gradients. The original RDN model was first used in image super resolution, so we need to restructure the network architecture for classification tasks through adjusted input image features and hyper parameters. Experimental results show that this model can achieve a top-1 average identification accuracy of 95% on the Tomato test dataset in AI Challenger 2018 datasets, which verifies its satisfactory performance. The restructured residual dense network model can obtain significant improvements over most of the state-of-the-art models in crop leaf identification, as well as requiring less computation to achieve high performance.","['Diseases', 'Agriculture', 'Feature extraction', 'Convolution', 'Support vector machines', 'Image segmentation', 'Machine learning algorithms']","['Residual dense network', 'leaf disease identification', 'agricultural artificial intelligence', 'tomato leaf diseases']"
"A wideband 8-antenna multiple-input and multiple-output (MIMO) system that can cover 3.3-5.0 GHz is proposed for the 5G new radio N77/N78/N79 application in mobile phones. The wide bandwidth of the MIMO antenna system is obtained by the proposed coupled-loop antenna, which has three coupling sections located separately at its top central and two sides. Due to this special arrangement, the coupled-loop antenna can support three resonance modes of loop antenna: 0.5λ, 0.75λ, and 1.0λ modes. The distinctive feature of the proposed coupled-loop antenna design is that it can excite the 0.75λ modes, which has not been reported before. The wide bandwidth is obtained by the combination of the three resonance modes. To evaluate the performance of the proposed 8 × 8 MIMO antenna system, the antenna isolation, envelope correlation coefficient (ECC), and channel capacity (CC) are all investigated. Antenna prototypes for an 8-antenna MIMO system located along the edge of mobile phones are fabricated and measured, and; quite good agreements between simulation and measurement are obtained.","['MIMO communication', 'Wideband', '5G mobile communication', 'Broadband antennas', 'Mobile antennas', 'Substrates']","['5G communication', 'coupled-loop antenna', 'mobile terminal', 'wideband MIMO antenna system']"
"Grey wolf optimizer (GWO) algorithm is a swarm intelligence optimization technique that is recently developed to mimic the hunting behavior and leadership hierarchy of grey wolves in nature. It has been successfully applied to many real world applications. In the GWO algorithm, “C”is an important parameter which favoring exploration. At present, the researchers are few study the parameter “C”in GWO algorithm. In addition, during the evolution process, the other individuals in the population move towards to the α, β, and δ wolves which are to accelerate convergence. However, GWO is easy to trap in the local optima. This paper presents a modified parameter “C”strategy to balance between exploration and exploitation of GWO. Simultaneously, a new random opposition-based learning strategy is proposed to help the population jump out of the local optima. The experiments on 23 widely used benchmark test functions with various features, 30 benchmark problems from IEEE CEC 2014 Special Session, and three engineering design optimization problems. The results reveal that the proposed algorithm shows better or at least competitive performance against other compared algorithms on not only global optimization but also engineering design optimization problems.","['Optimization', 'Sociology', 'Statistics', 'Benchmark testing', 'Standards', 'Mathematical model', 'Economics']","['Grey wolf optimizer', 'random opposition learning', 'global optimization', 'engineering design optimization', 'exploration', 'exploitation']"
"The Internet of Things (IoT) is playing a vital role in the rapid automation of the healthcare sector. The branch of IoT dedicated towards medical science is at times termed as Healthcare Internet of Things (H-IoT). The key elements of all H-IoT applications are data gathering and processing. Due to the large amount of data involved in healthcare, and the enormous value that accurate predictions hold, the integration of machine learning (ML) algorithms into H-IoT is imperative. This paper aims to serve both as a compilation as well as a review of the various state of the art applications of ML algorithms currently being integrated with H-IoT. Some of the most widely used ML algorithms have been briefly introduced and their use in various H-IoT applications has been analyzed in terms of their advantages, scope, and possible improvements. Applications have been divided into the domains of diagnosis, prognosis and spread control, assistive systems, monitoring, and logistics. In healthcare, practical use of a model requires it to be highly accurate and to have ample measures against security attacks. The applications of ML algorithms in H-IoT discussed in this paper have shown experimental evidence of accuracy and practical usability. The constraints and drawbacks of each of these applications have also been described.","['Medical services', 'Monitoring', 'Medical diagnostic imaging', 'Internet of Things', 'Computer architecture', 'Security', 'Machine learning algorithms']","['Healthcare', 'Internet of Things', 'machine learning', 'diagnosis', 'monitoring', 'cardiovascular', 'neurological']"
"This paper presents a comprehensive survey of the literature on self-interference management schemes required to achieve a single frequency full duplex (FD) communication in wireless communication networks. A single frequency FD system often referred to as in-band FD system has emerged as an interesting solution for the next generation mobile networks, where the scarcity of available radio spectrum is an important issue. Although studies on the mitigation of self-interference have been documented in the literature, this is the first holistic attempt at presenting not just the various techniques available for handling self-interference that arises when an FD device is enabled, as a survey, but it also discusses other system impairments that significantly affect the self-interference management of the system, and not only in terrestrial systems, but also on satellite communication systems. The survey provides a taxonomy of selfinterference management schemes and shows by means of comparisons the strengths and limitations of various self-interference management schemes. It also quantifies the amount of self-interference cancellation required for different access schemes from the first generation to the candidate fifth generation of mobile cellular systems. Importantly, the survey summarizes the lessons learnt, identifies and presents open research questions and key research areas for the future. This paper is intended to be a guide and take off point for further work on self-interference management in order to achieve FD transmission in mobile networks, including heterogeneous cellular networks, which is undeniably the network of the future wireless systems.","['Wireless communication', 'Mobile communication', 'High definition video', 'Interference', 'Mobile computing', 'Satellite communication']","['5G', 'active interference cancellation', 'full duplex', 'passive interference mitigation', 'remote radio heads', 'self-interference cancellation']"
"The incorporation of the cloud technology with the Internet of Things (IoT) is significant in order to obtain better performance for a seamless, continuous, and ubiquitous framework. IoT has many applications in the healthcare sector, one of these applications is voice pathology monitoring. Unfortunately, voice pathology has not gained much attention, where there is an urgent need in this area due to the shortage of research and diagnosis of lethal diseases. Most of the researchers are focusing on the voice pathology and their finding is only to differentiating either the voice is normal (healthy) or pathological voice, where there is a lack of the current studies for detecting a certain disease such as laryngeal cancer. In this paper, we present an extensive review of the state-of-the-art techniques and studies of IoT frameworks and machine learning algorithms used in the healthcare in general and in the voice pathology surveillance systems in particular. Furthermore, this paper also presents applications, challenges and key issues of both IoT and machine learning algorithms in the healthcare. Finally, this paper highlights some open issues of IoT in healthcare that warrant further research and investigation in order to present an easy, comfortable and effective diagnosis and treatment of disease for both patients and doctors.","['Internet of Things', 'Pathology', 'Monitoring', 'Diseases', 'Medical diagnostic imaging', 'Machine learning algorithms']","['Internet of Things', 'machine learning algorithms', 'the healthcare sector', 'voice pathology surveillance systems']"
"Insider attacks are becoming increasingly detrimental and frequent, affecting critical infrastructure at a massive scale. Recent attacks such as the U.K. National Health Service WannaCry ransomware attack which partly depends on internal users for initial infection highlight the increasing role of the malicious insiders in cyber-attack campaigns. The objective of this research is to ascertain the existing technological capability to mitigate insider threats within computer security systems by way of a mixed-method systematic review. Evidence was acquired from major sources of mainstream and grey literature by analyzing about 300 000 papers. Crude aggregated results were analyzed across the literature, and the results were TPR 0.75, FPR 0.32, σ 0.24 and 0.36, respectively, and σ2 0.06 and 0.13, respectively. In totality, the literature evidence suggests that there is high heterogeneity across crude data indicating that the effectiveness of security measures varies significantly. No solution is able to totally mitigate an insider threat. Themes when against that data suggest that most, if not all, security measures require breaches to occur before an analysis of malicious activity can prevent it in future through recall. Such a reactive approach is not effective protect our critical infrastructure including our healthcare systems. Consequently, there is a major theoretical shortfall in current cyber defence architecture.","['Systematics', 'Medical services', 'Critical infrastructure', 'Computer crime', 'Databases']","['Critical infrastructure security', 'personal data safety', 'healthcare', 'data breach', 'insider threat', 'meta-data', 'sabotage', 'systematic review', 'thematic analysis', 'unprivileged', 'untrusted', 'zero trust']"
"Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.","['Level set', 'Compressed sensing', 'TV', 'Convergence', 'Signal processing algorithms', 'Sparse matrices', 'Optimization']","['Nonconvex optimization', 'sparse regression', 'compressed sensing', 'LASSO', 'total variation regularization', 'matrix completion']"
"Deep Learning is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that deep learning is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013, it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In 2018, we published the first-ever review of the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses). Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of our first literature survey, this review article focuses on the advances in this area since 2018. We thoroughly discuss the first generation attacks and comprehensively cover the modern attacks and their defenses appearing in the prestigious sources of computer vision and machine learning research. Besides offering the most comprehensive literature review of adversarial attacks and defenses to date, the article also provides concise definitions of technical terminologies for the non-experts. Finally, it discusses challenges and future outlook of this direction based on the literature since the advent of this research direction.","['Computational modeling', 'Computer vision', 'Deep learning', 'Perturbation methods', 'Predictive models', 'Data models', 'Training']","['Adversarial examples', 'adversarial defense', 'adversarial machine learning', 'black-box attack', 'deep learning', 'perturbation', 'white-box attack']"
"Internet of Things (IoT) aims to connect the real world made up of devices, sensors and actuators to the virtual world of Internet in order to interconnect devices with each other generating information from the gathered data. Devices, in general, have limited computational power and limited storage capacity. Cloud Computing (CC) has virtually unlimited capacity in terms of storage and computing power, and is based on sharing resources. Therefore, the integration between IoT and CC seems to be one of the most promising solutions. In fact, many of the biggest companies that offer Cloud Services are focusing on the IoT world to offer services also in this direction to their users. In this paper we compare the three main Cloud Platforms (Amazon Web Services, Google Cloud Platform and Microsoft Azure) regarding to the services made available for the IoT. After describing the typical architecture of an IoT application, we map the Cloud-IoT Platforms services with this architecture analyzing the key points for each platform. At the same time, in order to conduct a comparative analysis of performance, we focus on a service made available by all platforms (MQTT middleware) building the reference scenarios and the metrics to be taken into account. Finally, we provide an overview of platform costs based on different loads. The aim is not to declare a winner, but to provide a useful tool to developers to make an informed choice of a platform depending on the use case.","['Internet of Things', 'Cloud computing', 'Computer architecture', 'Google', 'Performance evaluation', 'Architecture']","['AWS', 'Azure', 'Cloud Computing', 'Cloud-IoT', 'Google Cloud Platform', 'Internet of Things', 'MQTT']"
"With the development of artificial intelligence technology, data-driven fault diagnostics and prognostics in industrial systems have been a hot research area since the large volume of industrial data is being collected from the industrial process. However, imbalanced distributions exist pervasively between faulty and normal samples, which leads to imprecise fault diagnostics and prognostics. In this paper, an effective imbalance learning algorithm Easy-SMT is proposed. Easy-SMT is an integrated ensemble-based method, which comprises synthetic minority oversampling technique (SMOTE)-based oversampling policy to augment minority faulty classes and EasyEnsemble to transfer an imbalanced class learning problem into an ensemble-based balanced learning subproblem. We validate the feasibility and effectiveness of the proposed method in a real wind turbine failure forecast challenge, and our solution has won the third place among hundreds of teams. Moreover, we also evaluate the method on prognostics and health management 2015 challenge datasets, and the results show that the model could also achieve good performance on multiclass imbalance learning task compared with baseline classifiers.","['Data models', 'Feature extraction', 'Predictive models', 'Training', 'Wind turbines', 'Task analysis', 'Sampling methods']","['Industrial prognostics', 'class-imbalance learning', 'machine learning', 'ensemble learning']"
"Feature selection or dimensionality reduction can be considered as a multi-objective minimization problem with two objectives: minimizing the number of features and minimizing the error rate simultaneously. Despite being a multi-objective problem, most existing approaches treat feature selection as a single-objective optimization problem. Recently, Multi-objective Grey Wolf optimizer (MOGWO) was proposed to solve multi-objective optimization problem. However, MOGWO was originally designed for continuous optimization problems and hence, it cannot be utilized directly to solve multi-objective feature selection problems which are inherently discrete in nature. Therefore, in this research, a binary version of MOGWO based on sigmoid transfer function called BMOGW-S is developed to optimize feature selection problems. A wrapper based Artificial Neural Network (ANN) is used to assess the classification performance of a subset of selected features. To validate the performance of the proposed method, 15 standard benchmark datasets from the UCI repository are employed. The proposed BMOGWO-S was compared with MOGWO with a tanh transfer function and Non-dominated Sorting Genetic Algorithm (NSGA-II) and Multi-objective Particle Swarm Optimization (MOPSO). The results showed that the proposed BMOGWO-S can effectively determine a set of non-dominated solutions. The proposed method outperforms the existing multi-objective approaches in most cases in terms of features reduction as well as classification error rate while benefiting from a lower computational cost.","['Feature extraction', 'Optimization', 'Error analysis', 'Minimization', 'Transfer functions', 'Computational efficiency', 'Computational modeling']","['Feature selection', 'grey wolf optimizer', 'multi-objective optimization', 'classification']"
"DC arc faults, especially series arcing, can occur in photovoltaic (PV) systems and pose a challenging detection and protection problem. Machine learning-based methods are increasingly being used for fault diagnosis applications. However, the performance of such detection algorithms will degrade because of variations between the source domain data used during the development and the target domain data encountered in operation of the field. Furthermore, the fault's data in the target domain for model training are usually not available. In this paper, domain adaptation combined with deep convolutional generative adversarial network (DA-DCGAN)-based methodology is proposed, where DA-DCGAN first learns an intelligent normal-to-arcing transformation from the source-domain data. Then by generating dummy arcing data with the learned transformation using the normal data from the target domain and employing domain adaptation, a robust and reliable fault diagnosis scheme can be achieved for the target domain. The PV loop current is framed and arranged into a 2D matrix as input for cross-domain DC series arc fault diagnosis. The system is validated offline using pre-recorded PV loop current data from a real 1.5-kW grid-connected rooftop PV system. Also, the proposed method is implemented in an embedded system and tested in real-time according to UL-1699B standard. The experimental results clearly demonstrate benefits of DA-DCGAN and confirm the effectiveness of the proposed methodology for practical PV applications.","['Fault diagnosis', 'Fault detection', 'Gallium nitride', 'Detection algorithms', 'Real-time systems', 'Circuit faults', 'Training']","['Deep learning', 'domain adaptation', 'deep convolutional generative adversarial networks', 'DC series arc fault diagnosis', 'photovoltaic systems']"
"The elastic reconstruction of 5G network services is expected to provide the capability of network slice orchestration to access the network on demand, guarantee service experience on demand, and construct services on demand as well as to construct basic network services with lower costs. It is challenging to have different applications served independently with a proper resource allocation mechanism according to their own requirements. In this paper, we propose a dynamic resource reservation and deep reinforcement learning-based autonomous virtual resource slicing framework for the next generation radio access network. The infrastructure provider periodically reserves the unused resource to the virtual networks based on their ratio of minimum resource requirements. Then, the virtual networks autonomously control their resource amount using deep reinforcement learning based on the average quality of service utility and resource utilization of users. With the defined framework in this paper, virtual operators can customize their own utility function and objective function based on their own requirements. The simulation results show the performances on convergence rate, resource utilization, and satisfaction of the virtual networks.","['Resource management', '5G mobile communication', 'Virtualization', 'Quality of service', 'Reinforcement learning', 'Dynamic scheduling', 'Radio access networks']","['Resource slicing', 'network virtualization', 'deep reinforcement learning']"
"Cloud offloading is considered a promising approach for both energy conservation and storage/computation enhancement for resource-limited mobile devices. In this paper, we present a Lyapunov optimization-based scheme for cloud offloading scheduling, as well as download scheduling for cloud execution output, for multiple applications running in a mobile device with a multi-core CPU. We derive an online algorithm and prove performance bounds for the proposed algorithm with respect to average power consumption and average queue length, which is indicative of delay, and reveal the fundamental tradeoff between the two optimization goals. The performance of the proposed online scheduling scheme is validated with trace-driven simulations.","['Cloud computing', 'Energy efficiency', 'Job shop scheduling', 'Lyapunov optimization', 'Load management', 'Energy conservation', 'Storage management']","['Cloud computing', 'energy efficiency', 'job scheduling', 'Lyapunov optimization', 'offloading']"
"The use of freely available online data is rapidly increasing, as companies have detected the possibilities and the value of these data in their businesses. In particular, data from social media are seen as interesting as they can, when properly treated, assist in achieving customer insight into business decision making. However, the unstructured and uncertain nature of this kind of big data presents a new kind of challenge: how to evaluate the quality of data and manage the value of data within a big data architecture? This paper contributes to addressing this challenge by introducing a new architectural solution to evaluate and manage the quality of social media data in each processing phase of the big data pipeline. The proposed solution improves business decision making by providing real-time, validated data for the user. The solution is validated with an industrial case example, in which the customer insight is extracted from social media data in order to determine the customer satisfaction regarding the quality of a product.","['Big data', 'Social network services', 'Computer architecture', 'Meta data', 'Online services']","['architecture', 'big data', 'metadata', 'quality attribute', 'quality of data']"
"The automatic detection of an emotional state from human speech, which plays a crucial role in the area of human-machine interaction, has consistently been shown to be a difficult task for machine learning algorithms. Previous work on emotion recognition has mostly focused on the extraction of carefully hand-crafted and highly engineered features. Results from these works have demonstrated the importance of discriminative spatio-temporal features to model the continual evolutions of different emotions. Recently, spectrogram representations of emotional speech have achieved competitive performance for automatic speech emotion recognition (SER). How machine learning algorithms learn the effective compositional spatio-temporal dynamics for SER has been a fundamental problem of deep representations, herein denoted as deep spectrum representations. In this paper, we develop a model to alleviate this limitation by leveraging a parallel combination of attention-based bidirectional long short-term memory recurrent neural networks with attention-based fully convolutional networks (FCN). The extensive experiments were undertaken on the interactive emotional dyadic motion capture (IEMOCAP) and FAU aibo emotion corpus (FAU-AEC) to highlight the effectiveness of our approach. The experimental results indicate that deep spectrum representations extracted from the proposed model are well-suited to the task of SER, achieving a WA of 68.1% and a UA of 67.0% on IEMOCAP, and 45.4% for UA on FAU-AEC dataset. Key results indicate that the extracted deep representations combined with a linear support vector classifier are comparable in performance with eGeMAPS and COMPARE, two standard acoustic feature representations.","['Feature extraction', 'Spectrogram', 'Task analysis', 'Speech recognition', 'Emotion recognition', 'Data mining', 'Neural networks']","['Speech emotion recognition', 'bidirectional long short-term memory', 'fully convolutional networks', 'attention mechanism', 'spectrogram representation']"
"Cloud computing is becoming an increasingly popular platform for the execution of scientific applications such as scientific workflows. In contrast to grids and other traditional high-performance computing systems, clouds provide a customizable infrastructure where scientific workflows can provision desired resources ahead of the execution and set up a required software environment on virtual machines (VMs). Nevertheless, various challenges, especially its quality-of-service prediction and optimal scheduling, are yet to be addressed. Existing studies mainly consider workflow tasks to be executed with VMs having time-invariant, stochastic, or bounded performance and focus on minimizing workflow execution time or execution cost while meeting the quality-of-service requirements. This work considers time-varying performance and aims at minimizing the execution cost of workflow deployed on Infrastructure-as-a-Service clouds while satisfying Service-Level-Agreements with users. We employ time-series-based approaches to capture dynamic performance fluctuations, feed a genetic algorithm with predicted performance of VMs, and generate schedules at run-time. A case study based on real-world third-party IaaS clouds and some well-known scientific workflows show that our proposed approach outperforms traditional approaches, especially those considering time-invariant or bounded performance only.","['Cloud computing', 'Task analysis', 'Heuristic algorithms', 'Schedules', 'Optimal scheduling', 'Dynamic scheduling', 'Genetic algorithms']","['IaaS cloud', 'workflow', 'service-level-agreement', 'scheduling', 'quality-of-service (QoS)']"
"Tool condition monitoring systems are essential in micromilling applications. A tool's slenderness requires high-precision monitoring systems for online measurements. In most cases, tool health is indirectly estimated by processing and analyzing the cutting process parameters. In that sense, the main challenge lies in the proper selection of the process parameters and their processing techniques, so that a robust and accurate assessment of the tool's health is obtained. This paper proposes a frequencyand time-frequency-based analysis of cutting force and vibration signals for estimating the tool condition of a high-speed micromilling process. Measurements obtained from different cutting conditions were utilized in the analysis. The results indicate variations in the dominant frequencies, which result from tool wear. Furthermore, it is important to note that the analysis results obtained from the two process signals provide more reliable results and improve the sensing bandwidth.","['Tools', 'Time-frequency analysis', 'Vibrations', 'Force', 'Condition monitoring', 'Force measurement']","['Condition monitoring', 'cutting tools', 'fault detection', 'micromachining']"
"In this paper, we introduce a novel and efficient hybrid trajectory planning method for autonomous driving in highly constrained environments. The contributions of this paper are fourfold. First, we present a trajectory planning framework that is able to handle geometry constraints, nonholonomic constraints, and dynamics constraints of cars in a humanlike and layered fashion and generate curvature-continuous, kinodynamically feasible, smooth, and collision-free trajectories in real time. Second, we present a derivative-free global path modification algorithm to extract high-order state information in free space for state sampling. Third, we extend the regular state-space sampling method widely used in on-road autonomous driving systems to a multi-phase deterministic state-space sampling method that is able to approximate complex maneuvers. Fourth, we improve collision checking accuracy and efficiency by using a different car footprint approximation strategy and a two-phase collision checking routine. A range of challenging simulation experiments show that the proposed method returns high-quality trajectories in real time and outperforms existing planners, such as hybrid A* and conjugate-gradient descent path smoother in terms of path quality, efficiency, and computation resources used.","['Planning', 'Trajectory', 'Autonomous vehicles', 'Aerospace electronics', 'Geometry', 'Sampling methods', 'Roads']","['Trajectory planning', 'motion planning', 'autonomous driving', 'obstacle avoidance', 'kinodynamic constraints', 'collision checking']"
"Applying effective methods to identify important nodes in a complex network is highly invaluable. Recently, in a complex network, finding a powerful leader of the community to spread information quickly throughout the network is the concern of many researchers. In this paper, to identify influential nodes in a large and complex network, community-based mediator (CbM), which considers the entropy of a random walk from a node to each community is proposed as a metrics. CbM describes how the node is essential to connect two or more than two communities of the network. Correlations between CbM and other classical methods used to identify influential nodes are discussed. The performance of CbM is evaluated by susceptible-infected-recovered (SIR) model. In SIR model, the node is the most powerful node in the network, if the percentage of infected node is more while the node is used as the source of infection. Simulation results show that the proposed method performs better than the existing methods to spread information quickly and it can also introduce new influential nodes that other methods failed to identify.","['Complex networks', 'Entropy', 'Toy manufacturing industry', 'Weight measurement', 'Color', 'Object recognition', 'Intserv networks']","['Complex network', 'community-based mediator', 'influential nodes', 'susceptible-infected-recovered model']"
"The performance of the bio-inspired adaptive neuro-fuzzy inference system (ANFIS) models are proposed for forecasting highly non-linear streamflow of Pahang River, located in a tropical climatic region of Peninsular Malaysia. Three different bio-inspired optimization algorithms namely particle swarm optimization (PSO), genetic algorithm (GA), and differential evolution (DE) were individually used to tune the membership function of ANFIS model in order to improve the capability of streamflow forecasting. Different combination of antecedent streamflow was used to develop the forecasting models. The performance of the models was evaluated using a number of metrics including mean absolute error (MAE), root mean square error (RMSE), coefficient of determination (R 2 ), and Willmott's Index (WI) statistics. The results revealed that increasing number of inputs has a positive impact on the forecasting ability of both ANFIS and hybrid ANFIS models. The comparison of the performance of three optimization methods indicated PSO improved the capability of ANFIS model (RMSE = 7.96; MAE = 2.34; R 2 = 0.998 and WI = 0.994) more compared to GA and DE in forecasting streamflow. The uncertainty band of ANFIS-PSO forecast was also found the lowest (±0.217), which indicates that ANFIS-PSO model can be used for reliable forecasting of highly stochastic river flow in tropical environment.","['Forecasting', 'Predictive models', 'Rivers', 'Optimization', 'Genetic algorithms', 'Fuzzy logic', 'Artificial neural networks']","['Streamflow forecasting', 'fuzzy logic', 'evolutionary algorithm', 'uncertainty analysis', 'tropical environment']"
"Large-scale smart energy metering deployment worldwide and integration of smart meters within the smart grid will enable two-way communication between the consumer and energy network, thus ensuring improved response to demand. Energy disaggregation or non-intrusive load monitoring (NILM), namely disaggregation of the total metered electricity consumption down to individual appliances using purely algorithmic tools, is gaining popularity as an added-value that makes the most of meter data. However, NILM remains a challenging problem since NILM is susceptible to sensor noise, unknown load noise, transient spikes, and fluctuations. In this paper, we tackle this problem using novel graph signal processing (GSP) concepts, applied at both, physical signal level via graph-based filtering and data level, via effective semi-supervised GSP-based feature matching. The proposed GSP-based method is generic and can be used to improve results of various event-based NILM approaches. We demonstrate significant improvement in performance using three state-of-the-art NILM methods, both supervised and unsupervised, and real-world active power consumption readings from the REDD and REFIT 1 data sets, sampled at 1 and 8 s, respectively. 1The REFIT dataset used to generate the results can be accessed via DOI 10.15129/31da3ece-f902-4e95-a093-e0a9536983c4.","['Signal processing', 'Hidden Markov models', 'Signal processing algorithms', 'Transient analysis', 'Power measurement', 'Noise measurement', 'Feature extraction']","['Load disaggregation', 'non-intrusive load monitoring', 'smart metering', 'graph signal processing']"
"Terahertz (THz) communications recently attract significant attention and become an emerging technology pillar for sixth generation (6G) wireless systems. Due to the serious path attenuation of THz signals, THz communication is applicable for the short-distance indoor scenarios. However, the THz waves are easily blocked by obstacles, leading to a communication interruption. To this end, an intelligent reflecting surface (IRS), which interacts with incident THz waves in a controlled manner by adjusting the discrete phase shifts of the IRS elements, is considered as a promising technology to mitigate blockage vulnerability and enhance coverage capability for indoor scenarios. In light of graphene-enabled hardware structure of an IRS, the IRS-assisted THz multiple-input multiple-output (MIMO) system model is developed. Moreover, an iterative atom pruning based subspace pursuit (IAP-SP) scheme is developed for channel estimation. Compared to the classical subspace pursuit (SP) scheme, the proposed IAP-SP algorithm can substantially reduce the computational complexity while maintaining accurate channel recovery. With the estimated channel, a data rate maximization problem is formulated, which can be converted to a discrete phase shift search problem. The exhaustive search method is firstly proposed to obtain the optimal transmission rate but endure extremely high computational burden. Then, a local search method is proposed to decrease the number of possible discrete phase candidates of IRS while undergoes obvious performance loss. Interestingly, a novel feedforward fully connected structure based deep neural network (DNN) scheme is put forward, which has the ability to learn how to output the optimal phase shift configurations by inputting the features of estimated channel. Simulation results demonstrate that, in contrast with the exhaustive search scheme and the local search scheme, the proposed DNN-based scheme achieves a near-optimal communication rate performance. Meanwhile, the DNN-based scheme enormously alleviates the computational complexity and allows for dynamic parameter adaption in rapid-varying channel conditions.","['Channel estimation', 'Search methods', 'Hardware', 'Communication systems', 'Indexes', 'Graphene', 'Complexity theory']","['Terahertz (THz) communications', 'sixth generation (6G)', 'intelligent reflecting surface (IRS)', 'channel estimation', 'deep neural network (DNN)']"
"In this paper, we consider the down-link dynamic resource allocation in multi-cell virtualized wireless networks (VWNs) to support the users of different service providers (slices) within a specific region by a set of base stations (BSs) through orthogonal frequency division multiple access (OFDMA). In particular, we develop a joint BS assignment, sub-carrier, and power allocation algorithm to maximize the network sum rate, while satisfying the minimum required rate of each slice. Under the assumption that each user at each transmission instance can connect to no more than one BS, we introduce the user-association factor to represent the joint sub-carrier and BS assignment as the optimization variable vector in the problem formulation. Sub-carrier reuse is allowed in different cells, but not within one cell. As the proposed optimization problem is inherently non-convex and NP-hard, by applying the successive convex approximation (SCA) and complementary geometric programming (CGP), we develop an efficient two-step iterative approach with low computational complexity to solve the proposed problem. For a given problem, Step 1 derives the optimum user-association and subsequently, and for an obtained user-association, Step 2 finds the optimum power allocation. Simulation results demonstrate that the proposed iterative algorithm outperforms the traditional approach in which each user is assigned to the BS with the largest average value of signal strength, and then, joint sub-carrier and power allocation is obtained for the assigned users of each cell. Simulation results reveal a coverage improvement, offered by the proposed approach, of 57% and 71% for uniform and non-uniform users distribution, respectively, leading to higher spectrum efficiency for VWN.","['Convex programming', 'Wireless networks', 'Optimization', 'Quality of service', 'Iterative methods', 'Approximation methods', 'Programming', 'Resource management']","['Complementary geometric programming', 'successive convex approximation', 'joint user association and resource allocation', 'virtualized wireless networks']"
"The recent advances in wireless communication technologies allow mobile users to access various data services anytime and anywhere on land, while it is one of challenging issues to provide reliable data communications for maritime users due to the geographic features on the sea. Considering the increasing demands of maritime digital data services, we need to develop maritime communications supporting high-speed data rates and extended communication coverage. In this paper, we present the state-of-the-art works related to the data requirements of maritime services and the technical characteristics of existing maritime networks. Then, we introduce a long-term evolution for maritime (LTE-Maritime) that is an ongoing research project in South Korea. The objective of LTE-Maritime is to develop a maritime communication infrastructure supporting the data rates in the order of megabits per second within the communication coverage of 100 km. In order to confirm the feasibility of LTE-Maritime, we implemented a testbed for the LTE-Maritime which consisted of ships equipped with LTE-Maritime routers, base stations (BSs) along the coast, and an operation center. The experimental results show that the LTE-Maritime could be a practical solution for ship-to-shore data communication. Furthermore, we discuss a set of open issues related to the development of LTE-Maritime network.","['Long Term Evolution', 'Wireless communication', 'Satellites', 'Marine vehicles', 'Safety', 'Wireless fidelity']","['Long term evolution (LTE)', 'LTE-Maritime', 'maritime data service', 'maritime wireless communication', 'testbed implementation']"
"Chronic heart failure (CHF) affects over 26 million of people worldwide, and its incidence is increasing by 2% annually. Despite the significant burden that CHF poses and despite the ubiquity of sensors in our lives, methods for automatically detecting CHF are surprisingly scarce, even in the research community. We present a method for CHF detection based on heart sounds. The method combines classic Machine-Learning (ML) and end-to-end Deep Learning (DL). The classic ML learns from expert features, and the DL learns from a spectro-temporal representation of the signal. The method was evaluated on recordings from 947 subjects from six publicly available datasets and one CHF dataset that was collected for this study. Using the same evaluation method as a recent PhysoNet challenge, the proposed method achieved a score of 89.3, which is 9.1 higher than the challenge's baseline method. The method's aggregated accuracy is 92.9% (error of 7.1%); while the experimental results are not directly comparable, this error rate is relatively close to the percentage of recordings labeled as “unknown” by experts (9.7%). Finally, we identified 15 expert features that are useful for building ML models to differentiate between CHF phases (i.e., in the decompensated phase during hospitalization and in the recompensated phase) with an accuracy of 93.2%. The proposed method shows promising results both for the distinction of recordings between healthy subjects and patients and for the detection of different CHF phases. This may lead to the easier identification of new CHF patients and the development of home-based CHF monitors for avoiding hospitalizations.","['Heart', 'Phonocardiography', 'Feature extraction', 'Medical diagnostic imaging', 'Deep learning', 'Medical services']","['Chronic heart failure', 'deep learning', 'heart sounds', 'machine learning', 'PCG']"
"Due to the rapid rise of automated tools, the number of malware variants has increased dramatically, which poses a tremendous threat to the security of the Internet. Recently, some methods for quick analysis of malware have been proposed, but these methods usually require a large computational overhead and cannot classify samples accurately for large-scale and complex malware data set. Therefore, in this paper, we propose a new visualization method for characterizing malware globally and locally to achieve fast and effective fine-grained classification. We take a new approach to visualize malware as RGB-colored images and extract global features from the images. Gray-level co-occurrence matrix and color moments are selected to describe the global texture features and color features, respectively, which produces low-dimensional feature data to reduce the complexity of training model. Moreover, a series of special byte sequences are extracted from code sections and data sections of malware and are processed into feature vectors by Simhash as the local features. Finally, we merge the global features and local features to perform malware classification using random forest, K-nearest neighbor, and support vector machine. Experimental results show that our approach obtains the highest accuracy of 97.47% and the highest F-measure of 96.85% of 7087 samples from 15 families. Color features and the local features effectively assist in the classification based on texture features and enhance the F-measure by 3.4% and 1%, respectively. Overall, the combination of global features and local features can realize fine-grained malware classification with low computational cost.","['Malware', 'Feature extraction', 'Visualization', 'Image color analysis', 'Static analysis', 'Entropy', 'Data visualization']","['Malware visualization', 'fine-grained classification', 'RGB-colored image']"
"This paper presents a study of a planar antenna-array inspired by the metamaterial concept where the resonant elements have sub-wavelength dimensions for application in microwave medical imaging systems for detecting tumors in biological tissues. The proposed antenna consists of square-shaped concentric-rings which are connected to a central patch through a common feedline. The array structure comprises several antennas that are arranged to surround the sample breast model. One antenna at a time in the array is used in transmission-mode while others are in receive-mode. The antenna array operates over 2-12 GHz amply covering the frequency range of existing microwave imaging systems. Measured results show that compared to a standard patch antenna array the proposed array with identical dimensions exhibits an average radiation gain and efficiency improvement of 4.8 dBi and 18%, respectively. The average reflection-coefficient of the array over its operating range is better than S 11 ≤ -20 dB making it highly receptive to weak signals and minimizing the distortion encountered with the transmission of short duration pulse-trains. Moreover, the proposed antenna-array exhibits high-isolation on average of 30 dB between radiators. This means that antennas in the array (i) can be closely spaced to accommodate more radiators to achieve higher-resolution imaging scans, and (ii) the imagining scans can be done over a wider frequency range to ascertain better contrast in electrical parameters between malignant tumor-tissue and the surrounding normal breast-tissue to facilitate the detection of breast-tumor. It is found that short wavelength gives better resolution. In this experimental study a standard biomedical breast model that mimics a real-human breast in terms of dielectric and optical properties was used to demonstrate the viability of the proposed antenna over a standard patch antenna in the detection and the localization of tumor. These results are encouraging for clinical trials and further refinement of the antenna-array.","['Imaging', 'Biological tissues', 'Breast', 'Microwave antenna arrays', 'Cancer', 'Dielectrics']","['Array antenna', 'microstrip technology', 'metamaterial', 'microwave breast imaging systems', 'biosensor', 'tumor detection', 'cancer', 'medical imaging']"
"The proposed study evaluates the efficacy of knowledge transfer gained through an ensemble of modality-specific deep learning models toward improving the state-of-the-art in Tuberculosis (TB) detection. A custom convolutional neural network (CNN) and selected popular pretrained CNNs are trained to learn modality-specific features from large-scale publicly available chest x-ray (CXR) collections including (i) RSNA dataset (normal = 8851, abnormal = 17833), (ii) Pediatric pneumonia dataset (normal = 1583, abnormal = 4273), and (iii) Indiana dataset (normal = 1726, abnormal = 2378). The knowledge acquired through modality-specific learning is transferred and fine-tuned for TB detection on the publicly available Shenzhen CXR collection (normal = 326, abnormal = 336). The predictions of the best performing models are combined using different ensemble methods to demonstrate improved performance over any individual constituent model in classifying TB-infected and normal CXRs. The models are evaluated through cross-validation (n = 5) at the patient-level with an aim to prevent overfitting, improve robustness and generalization. It is observed that a stacked ensemble of the top-3 retrained models demonstrates promising performance (accuracy: 0.941; 95% confidence interval (CI): [0.899, 0.985], area under the curve (AUC): 0.995; 95% CI: [0.945, 1.00]). One-way ANOVA analyses show there are no statistically significant differences in accuracy (P = .759) and AUC (P = .831) among the ensemble methods. Knowledge transferred through modality-specific learning of relevant features helped improve the classification. The ensemble model resulted in reduced prediction variance and sensitivity to training data fluctuations. Results from their combined use are superior to the state-of-the-art.","['Diseases', 'Predictive models', 'Feature extraction', 'Radiography', 'Lung', 'Task analysis', 'Data models']","['Classification', 'confidence interval', 'convolutional neural network', 'deep learning', 'ensemble', 'knowledge transfer', 'modality-specific learning', 'tuberculosis']"
"Industrial wireless sensor networks (IWSNs) are used to acquire sensor data that need realtime processing, therefore they require predictable behavior and real-time guarantees. To be cost effective, IWSNs are also expected to be low cost and low power. In this context, Bluetooth low energy (BLE) is a promising technology, as it allows implementing low-cost industrial networks. As BLE is a shortrange technology, a multihop mesh network is needed to cover a large area. Nevertheless, the recently published Bluetooth mesh networking specifications do not provide support for real-time communications over multihop mesh networks. To overcome this limitation, this paper proposes the multihop real-time BLE (MRT-BLE) protocol, a real-time protocol developed on top of BLE, that allows for bounded packet delays over mesh networks. MRT-BLE also provides priority support. This paper describes in detail the MRT-BLE protocol and how to implement it on commercial-off-the-shelf devices. Two kinds of performance evaluation for the MRT-BLE protocol are provided. The first one is a worst case end-to-end delay analysis, while the second one is based on the experimental results obtained through measurements on a real testbed.","['Protocols', 'Real-time systems', 'Bluetooth', 'Delays', 'Spread spectrum communication', 'Mesh networks']","['Bluetooth low energy', 'industrial wireless sensor networks', 'real-time', 'wireless mesh networks']"
"A revolutionary effort to seek fundamental improvement of 802.11, known as IEEE 802.11ax, has been approved to deliver the next-generation wireless local area network (WLAN) technologies. In WLANs, medium access control protocol is the key component that enables efficient sharing the common radio channel while satisfying the quality of service (QoS) requirements for multimedia applications. With the new physical layer design and subsequent new medium access control functions under more demands on QoS and user experience, in this paper, we first survey the QoS support in legacy 802.11. Then, we summarize the IEEE 802.11ax standardization activities in progress and present an overview of current perspectives and expected features on medium access control protocol design to better support QoS and user experience in 802.11ax. We present the motivation behind, explain design principles, and identify new research challenges. To better satisfy customer needs on high bandwidth and low latency, emerging long-term evolution licensed-assisted access and its impacts to QoS provisioning in IEEE 802.11ax are further addressed given the collaboration between cellular and WLANs, and given the trend of 5G cellular over unlicensed bands.","['IEEE 802.11 Standard', 'Quality of service', 'Media Access Protocol', 'Wireless LAN', 'Next generation networking', 'Multimedia communication', 'Long Term Evolution', '5G mobile communication']","['Quality of service', 'IEEE 802.11ax', 'LTE-LAA', '5G', '5G-unlicensed', 'medium access control', 'wireless local area networks', 'WiFi', 'heterogeneous networks']"
"The fifth generation (5G) of the mobile networks is envisioned to feature two major service classes: ultra-reliable low-latency communications (URLLC) and enhanced mobile broadband (eMBB). URLLC applications require a stringent one-way radio latency of 1 ms with 99.999% success probability while eMBB services demand extreme data rates. The coexistence of the URLLC and eMBB quality of service (QoS) on the same radio spectrum leads to a challenging scheduling optimization problem, that is vastly different from that of the current cellular technology. This calls for the novel scheduling solutions which cross-optimize the system performance on a user-centric, instead of network-centric basis. In this paper, a null-space-based spatial preemptive scheduler for joint URLLC and eMBB traffic is proposed for the densely populated 5G networks. Proposed scheduler framework seeks for cross-objective optimization, where the critical URLLC QoS is guaranteed while extracting the maximum possible eMBB ergodic capacity. It utilizes the system spatial degrees of freedom in order to instantly offer an interference-free subspace for the critical URLLC traffic. Thus, a sufficient URLLC decoding ability is always preserved, and with the minimal impact on the eMBB performance. Analytical analysis and extensive system level simulations are conducted to evaluate the performance of the proposed scheduler against the state-of-the-art scheduler proposals from industry and academia. Simulation results show that the proposed scheduler offers extremely robust URLLC latency performance with a significantly improved ergodic capacity.","['5G mobile communication', 'Interference', 'Job shop scheduling', 'Quality of service', 'Reliability', 'Resource management', 'Signal to noise ratio']","['5G', 'radio resource management', 'scheduling', 'ultra-reliable low-latency communications (URLLC)', 'enhanced mobile broadband (eMBB)', 'MU-MIMO', 'preemptive', 'null space']"
"This paper investigates the optimal energy beamforming and time assignment in radio frequency (RF) energy harvesting (EH) wireless powered sensor networks for smart cities, where sensor nodes (SNs) first harvest energy from a sink node, and then transmit their collected data to the sink node via time-division-multiple-access (TDMA) manner by using the harvested energy. In order to achieve green system design, we formulate a problem to minimize the energy requirement of the sink node to support transmission between the sink node and the SNs under data amount constraint and EH constraint. For practical design, the energy consumed by circuit and information processing is also considered. Since the problem is non-convex, we use semidefinite relaxation (SDR) method to relax it into a convex optimization problem and then solve it efficiently. We theoretically prove that when the number of SNs are not greater than two, the relaxed problem guarantees rank-one constraint and when the number of SNs exceeds two, our obtained results are very close to the optimal ones. Simulation results show that when the data amount is relatively small, the energy consumed by circuit and information processing affects the system performance greatly, but for a relatively large data amount, the energy requirement of the sink node on its own signal processing is affected very limited and the system energy requirement is dominated by the transmit power consumption at the SNs. Furthermore, we also discuss the effects of the other parameters on the system performance, which provide some useful insights in future smart city planning.","['Wireless sensor networks', 'Wireless communication', 'Information processing', 'Radio frequency', 'Smart cities', 'Receivers', 'Antennas']","['RF energy harvesting', 'wireless powered networks', 'wireless sensor networks', 'resource allocation', 'energy beamforming', 'time assignment', 'smart city']"
"The generalized integrator (GI)-based filters can be categorized into two types: one is related to quadrature signal generator (QSG), and the other is related to sequence filter (SF). The QSG is used for generating the in-quadrature sinusoidal signals and the SF works for extracting the symmetrical sequence components. The signals generated by QSG and SF are useful in many applications, such as grid synchronization and harmonic estimation. However, the principles of QSG and SF are usually explained by either differential equations or transfer functions, which are not appropriate for analyzing some extended structures and thus restrict their applications. To overcome the drawback, this paper uses the first-order-system concept to re-investigate the GI-based filters, with which their working principles can be intuitively understood and their structure correlations can be easily discovered. Moreover, the proposed analysis method also provides the convenience for developing improved structures. To illustrate it, two improved filters are presented to enhance the performance of the basic QSG and SF. Finally, experimental results verify the effectiveness of the proposed method.","['Power grids', 'Synchronization', 'Harmonic analysis', 'Transfer functions', 'Signal generators', 'Power harmonic filters']","['Grid synchronization', 'signal processing', 'harmonic estimation', 'first-order system', 'generalized integrator', 'filter', 'quadrature-signal generator', 'sequence filter']"
"Predicting the remaining useful life (RUL) is an effective way to indicate the health of lithium-ion batteries, which can help to improve the reliability and safety of battery-powered systems. To predict the RUL, the line of research focuses on using the empirical degradation model followed by the particle filter (PF) algorithm, which is used for online updating the model's parameters. However, this works well for specific batteries under specific discharge conditions. When the degradation trends cannot be presented by the chosen empirical model or the standard PF encounters impoverishment and degeneracy problem, the RUL prediction would be inaccurate. To improve the RUL prediction accuracy, we propose a novel approach by enhancing the existing method from two aspects. First, we introduce a neural network (NN) to model battery degradation trends under various operation conditions. As NN's generalization and nonlinear representing ability, it outperforms the typical empirical degradation model. Second, the NN model's parameters are recursively updated by the bat-based particle filter. The bat algorithm is used to move the particles to the high likelihood regions, which optimizes the particle distribution and thus reduces the degeneracy and impoverishment of PF. In this paper, quantitative evaluation is presented using two datasets with different batteries under different aging conditions. The results indicate that the proposed the approach can achieve higher RUL prediction accuracy than conventional empirical model and standard PF.","['Degradation', 'Artificial neural networks', 'Predictive models', 'Lithium-ion batteries', 'Neurons', 'Load modeling']","['Lithium-ion batteries', 'neural network', 'capacity degradation', 'remaining useful life prediction', 'bat algorithm', 'particle filter']"
"To improve the prediction accuracy of traffic flow, a travel time prediction model based on gradient boosting decision tree (GBDT) is proposed. In order to test the applicability of GBDT, models with different prediction horizons (5 min ahead, 10 min ahead, and 15 min ahead) are established. The 11 variables are viewed as candidates in this paper. Different from other machine learning algorithms as black boxes, GBDT can provide interpretable results through variable importance. In the proposed model, the variable importance shows that for different prediction horizons, the most important influence variable is uniform, which is travel time in the current period. Traffic conditions in the current period have the greatest influence on the predicted travel time. Compared with the back propagation neural network model and the support vector machine model, the proposed GBDT model can produce more accurate prediction results, especially in multi-step prediction, indicating that GBDT is a promising method in travel time prediction.","['Predictive models', 'Mathematical model', 'Data models', 'Boosting', 'Decision trees', 'Computational modeling']","['Different prediction horizons', 'freeway', 'gradient boosting decision tree (GBDT)', 'machine learning', 'traffic flow', 'travel time prediction']"
"This paper proposes a robust position control scheme for a quadrotor UAV system under uncertainties. The proposed control algorithms combine integral sliding mode and backstepping sliding mode controllers in a double-loop control structure (i.e., inner-outer loop control). The design of the proposed controller is divided into two subcontrollers, namely, attitude and position controllers for the quadrotor. In this work, a nonsimplified six-degree-of-freedom quadrotor model is first established in the presence of disturbances. Afterward, we develop a robust backstepping sliding mode controller for the attitude control of the quadrotor. Next, a robust integral sliding mode controller is designed for the outer loop of the quadrotor to ensure the position trajectory tracking capability in the presence of disturbances. The stability and performance of the quadrotor is thoroughly investigated using Lyapunov stability analysis. Numerical simulations demonstrate the effectiveness of the developed solutions for a quadrotor.","['Backstepping', 'Attitude control', 'Uncertainty', 'Position control', 'Sliding mode control', 'Trajectory tracking', 'Feedback linearization']","['Backstepping control', 'sliding mode control', 'robustness', 'disturbance', 'quadrotor', 'unmanned aerial vehicle (UAV)', 'quadcopter']"
"Cervical cancer is the fourth most prevalent disease in women. Accurate and timely cancer detection can save lives. Automatic and reliable cervical cancer detection methods can be devised through the accurate segmentation and classification of Pap smear cell images. This paper presents an approach to whole cervical cell segmentation using a mask regional convolutional neural network (Mask R-CNN) and classifies this using a smaller Visual Geometry Group-like Network (VGG-like Net). ResNet10 is used to make full use of spatial information and prior knowledge as the backbone of the Mask R-CNN. We evaluate our proposed method on the Herlev Pap Smear dataset. In the segmentation phase, when Mask R-CNN is applied on the whole cell, it outperforms the previous segmentation method in precision (0.92±0.06), recall (0.91±0.05) and ZSI (0.91±0.04). In the classification phase, VGG-like Net is applied on the whole segmented cell and yields a sensitivity score of more than 96% with low standard deviation (±2.8%) for the binary classification problem and yields a higher result of more than 95% with low standard deviation (maximum 4.2% in accuracy measurement) for the 7-class problem in terms of sensitivity, specificity, accuracy, h-mean, and F1 score.","['Image segmentation', 'Deep learning', 'Cervical cancer', 'Training', 'Testing', 'Support vector machines']","['Mask R-CNN', 'VGG-like Net', 'cell segmentation', 'cell classification', 'pap smear']"
"Vehicular Ad-hoc Network (VANET) is a modern era of dynamic information distribution among societies. VANET provides an extensive diversity of applications in various domains, such as Intelligent Transport System (ITS) and other road safety applications. VANET supports direct communications between vehicles and infrastructure. These direct communications cause bandwidth problems, high power consumption, and other similar issues. To overcome these challenges, clustering methods have been proposed to limit the communication of vehicles with the infrastructure. In clustering, vehicles are grouped together to formulate a cluster based on certain rules. Every cluster consists of a limited number of vehicles/nodes and a cluster head (CH). However, the significant challenge for clustering is to preserve the stability of clusters. Furthermore, a secure mechanism is required to recognize malicious and compromised nodes to overcome the risk of invalid information sharing. In the proposed approach, we address these challenges using components of trust. A trust-based clustering mechanism allows clusters to determine a trustworthy CH. The novel features incorporated in the proposed algorithm includes trust-based CH selection that comprises of knowledge, reputation, and experience of a node. Also, a backup head is determined by analyzing the trust of every node in a cluster. The major significance of using trust in clustering is the identification of malicious and compromised nodes. The recognition of these nodes helps to eliminate the risk of invalid information. We have also evaluated the proposed mechanism with the existing approaches and the results illustrate that the mechanism is able to provide security and improve the stability by increasing the lifetime of CHs and by decreasing the computation overhead of the CH re-selection. The StabTrust also successfully identifies malicious and compromised vehicles and provides robust security against several potential attacks.","['Vehicular ad hoc networks', 'Clustering algorithms', 'Stability analysis', 'Leadership', 'Security', 'Computer science']","['Intelligent transport system', 'security', 'vehicular ad-hoc networks', 'trust-based clustering', 'VANET attacks']"
"Collecting precise real-time information on urban drainage system performance is essential to identify, predict, and manage critical loading situations, such as urban flash floods and sewer overflows. Although emerging low-power wireless communication techniques allow efficient data transfers with great above-ground performance, for underground or indoor applications in a large coverage range are difficult to achieve due to physical and topological limitations, particularly in dense urban areas. In this paper, we first discuss the range limitations of the LoRaWAN standard based on a systematic evaluation of a long-term operation of a sensor network monitoring in-sewer process dynamics. Analyses reveal an-on average-five-fold higher data packet loss for sub-surface nodes, which steadily grows with increasing distance to the gateway. Second, we present a novel LPWAN concept based on the LoRaR technology that enhances transmission reliability, efficiency, and flexibility in range-critical situations through meshed multi-hop routing and ensures a precise time-synchronization through optional GPS or DCF77 long-wave time signaling. Third, we illustrate the usefulness of the newly developed concept by evaluating the radio transmission performance for two independent full-scale field tests. Test results show that the synchronous LoRa mesh network approach clearly outperforms the standard LoRaWAN technique with regard to the reliability of packet delivery when transmitting from range-critical locations. Hence, the approach is expected to generally ease data collection from difficult-to-access locations such as underground areas.","['Logic gates', 'Monitoring', 'Standards', 'Data communication', 'Wireless sensor networks', 'Wireless communication', 'Reliability']","['Environmental engineering', 'Internet of Things', 'LoRaWAN', 'mesh networks', 'time-division multiple access', 'water pollution', 'wide area networks', 'wireless sensor networks', 'urban drainage']"
"A narrow-band metasurface absorber (MSA) based on InSb micro-cylinder arrays has been proposed and investigated numerically, which could be believed to be applicable for both temperature and refractive index (RI) sensing in terahertz (THz) region. Distinct from previous designs, the proposed narrow-band MSA is only consisted of a sub-wavelength periodic micro-cylinder array based on the InSb material possessing an extremely thermosensitive relative permittivity which varies with the external environment temperature, and a gold ground-plane deposited on a glass substrate. Numerical simulation results indicate that the proposed MSA can achieve an absorbance of 99.9% at 1.8985 THz and the corresponding Q-factor is about 120.9 at room temperature (300 K). It is inferred that the narrow-band perfect absorption of the MSA could be contributed to the surface plasmon polariton (SPP) resonance mode excitation. Furthermore, the absorption property of the designed MSA is found to be highly sensitive to the RI value variations of the surrounding mediums and fluctuations of external environment temperature. Thus, the proposed MSA can be not only operated as a temperature sensor with a sensitivity of 2.13 GHz/K, but also a RI sensor with a sensitivity of 960 GHz/RIU (refractive index unit). Due to its high sensing performance, it can be believed that the narrow-band MSA has great potential applications in chemical, biological or other optoelectronic related areas.","['Absorption', 'Plasma temperature', 'Temperature sensors', 'Temperature', 'Permittivity', 'Sensitivity']","['Metasurface absorber', 'narrow-band', 'InSb', 'terahertz region', 'sensing']"
"Previous research studies mostly focused on enhancing the security of radio frequency identification (RFID) protocols for various RFID applications that rely on a centralized database. However, blockchain technology is quickly emerging as a novel distributed and decentralized alternative that provides higher data protection, reliability, immutability, transparency, and lower management costs compared with a conventional centralized database. These properties make it extremely suitable for integration in a supply chain management system. In order to successfully fuse RFID and blockchain technologies together, a secure method of communication is required between the RFID tagged goods and the blockchain nodes. Therefore, this paper proposes a robust ultra-lightweight mutual authentication RFID protocol that works together with a decentralized database to create a secure blockchain-enabled supply chain management system. Detailed security analysis is performed to prove that the proposed protocol is secure from key disclosure, replay, man-in-the-middle, de-synchronization, and tracking attacks. In addition to that, a formal analysis is conducted using Gong, Needham, and Yahalom logic and automated validation of internet security protocols and applications tool to verify the security of the proposed protocol. The protocol is proven to be efficient with respect to storage, computational, and communication costs. In addition to that, a further step is taken to ensure the robustness of the protocol by analyzing the probability of data collision written to the blockchain.","['Blockchain', 'Supply chains', 'Radiofrequency identification', 'Security', 'Databases', 'Protocols', 'Supply chain management']","['Blockchain', 'distributed ledger technology', 'radio frequency identification']"
"Sidescan sonars are increasingly used in underwater search and rescue for drowning victims, wrecks and airplanes. Automatic object classification or detection methods can help a lot in case of long searches, where sonar operators may feel exhausted and therefore miss the possible object. However, most of the existing underwater object detection methods for sidescan sonar images are aimed at detecting mine-like objects, ignoring the classification of civilian objects, mainly due to lack of dataset. So, in this study, we focus on the multi-class classification of drowning victim, wreck, airplane, mine and seafloor in sonar images. Firstly, through a long-term accumulation, we built a real sidescan sonar image dataset named SeabedObjects-KLSG, which currently contains 385 wreck, 36 drowning victim, 62 airplane, 129 mine and 578 seafloor images. Secondly, considering the real dataset is imbalanced, we proposed a semisynthetic data generation method for producing sonar images of airplanes and drowning victims, which uses optical images as input, and combines image segmentation with intensity distribution simulation of different regions. Finally, we demonstrate that by transferring a pre-trained deep convolutional neural network (CNN), e.g. VGG19, and fine-tuning the deep CNN using 70% of the real dataset and the semisynthetic data for training, the overall accuracy on the remaining 30% of the real dataset can be eventually improved to 97.76%, which is the highest among all the methods. Our work indicates that the combination of semisynthetic data generation and deep transfer learning is an effective way to improve the accuracy of underwater object classification.","['Sonar', 'Airplanes', 'Training', 'Task analysis', 'Search problems', 'Feature extraction', 'Fuel processing industries']","['Object classification', 'underwater search and rescue', 'sidescan sonar image', 'semisynthetic data generation', 'deep transfer learning']"
"Data are being generated and used to support all aspects of healthcare provision, from policy formation to the delivery of primary care services. Particularly, with the change of emphasis from curative to preventive medicine, the importance of data-based research such as data mining and machine learning has emphasized the issues of class distributions in datasets. In typical predictive modeling, the inability to effectively address a class imbalance in a real-life dataset is an important shortcoming of the existing machine learning algorithms. Most algorithms assume a balanced class in their design, resulting in poor performance in predicting the minority target class. Ironically, the minority target class is usually the focus in predicting processes. The misclassification of the minority target class has resulted in serious consequences in detecting chronic diseases and detecting fraud and intrusion where positive cases are erroneously predicted as not positive. This paper presents a new attribute selection technique called variance ranking for handling imbalance class problems in a dataset. The results obtained were compared to two well-known attribute selection techniques: the Pearson correlation and information gain technique. This paper uses a novel similarity measurement technique ranked order similarity-ROS to evaluate the variance ranking attribute selection compared to the Pearson correlations and information gain. Further validation was carried out using three binary classifications: logistic regression, support vector machine, and decision tree. The proposed variance ranking and ranked order similarity techniques showed better results than the benchmarks. The ROS technique provided an excellent means of grading and measuring the similarities where other similarity measurement techniques were inadequate or not applicable.","['Diseases', 'Prediction algorithms', 'Data mining', 'Training data', 'Measurement techniques', 'Data models', 'Machine learning']","['Imbalanced dataset', 'class distribution', 'binary class', 'imbalance ratio', 'majority class', 'minority class', 'oversampling', 'under sampling', 'logistic regression', 'support vector machine', 'decision tree', 'ranked order similarity', 'peak threshold accuracy']"
"We propose a backstepping global fast terminal sliding mode control for trajectory tracking control of industrial robotic manipulators in this article. An integral of the global fast terminal sliding mode surface is firstly suggested to improve the dynamic performance and fast convergence of Sliding Mode Control (SMC) and Terminal SMC (TSMC), which also obtains a finite-time convergence. A controller is then developed from the proposed sliding surface using the backstepping control method and High-Order SMC (HOSMC) to ensure the global stability of the control system. Thanks to this proposed method, the controller provides small position and velocity control errors with less oscillation, smooth control torque, and convergence of the control errors in the short time. The stability and convergence also are guaranteed with Lyapunov theory. Finally, computer simulation verifies the effectiveness of the designed controller.","['Convergence', 'Robots', 'Sliding mode control', 'Uncertainty', 'Backstepping', 'Torque', 'Transient response']","['Backstepping control', 'robotic manipulators', 'sliding mode control', 'global fast terminal sliding mode control', 'high-order sliding mode control']"
"An early and reliable estimation of crop yield is essential in quantitative and financial evaluation at the field level for determining strategic plans in agricultural commodities for import-export policies and doubling farmer's incomes. Crop yield predictions are carried out to estimate higher crop yield through the use of machine learning algorithms which are one of the challenging issues in the agricultural sector. Due to this developing significance of crop yield prediction, this article provides an exhaustive review on the use of machine learning algorithms to predict crop yield with special emphasis on palm oil yield prediction. Initially, the current status of palm oil yield around the world is presented, along with a brief discussion on the overview of widely used features and prediction algorithms. Then, the critical evaluation of the state-of-the-art machine learning-based crop yield prediction, machine learning application in the palm oil industry and comparative analysis of related studies are presented. Consequently, a detailed study of the advantages and difficulties related to machine learning-based crop yield prediction and proper identification of current and future challenges to the agricultural industry is presented. The potential solutions are additionally prescribed in order to alleviate existing problems in crop yield prediction. Since one of the major objectives of this study is to explore the future perspectives of machine learning-based palm oil yield prediction, the areas including application of remote sensing, plant's growth and disease recognition, mapping and tree counting, optimum features and algorithms have been broadly discussed. Finally, a prospective architecture of machine learning-based palm oil yield prediction has been proposed based on the critical evaluation of existing related studies. This technology will fulfill its promise by performing new research challenges in the analysis of crop yield prediction and the development of an extremely effective model for the prediction of palm oil yields with the most minimal computational difficulty.","['Agriculture', 'Indexes', 'Oils', 'Vegetation mapping', 'Machine learning', 'Machine learning algorithms', 'Regression tree analysis']","['Artificial intelligence', 'crop yield prediction', 'deep learning', 'machine learning', 'palm oil yield']"
"While software defined network (SDN) brings more innovation to the development of future networks, it also faces a more severe threat from DDoS attacks. In order to deal with the single point of failure on SDN controller caused by DDoS attacks, we propose a framework for detection and defense of DDoS attacks in the SDN environment. Firstly, we deploy a trigger mechanism of DDoS attack detection on data plane to screen for abnormal flows in the network. Then, we use a combined machine learning algorithm based on K-Means and KNN to exploit the rate characteristics and asymmetry characteristics of the flows and to detect the suspicious flows determined by the detection trigger mechanism. Finally, the controller will take corresponding actions to defense against the attacks. In this paper, we propose a new framework of cooperative detection methods of control plane and data plane, which effectively improve the detection accuracy and efficiency, and prevent DDoS attacks on SDN.","['Computer crime', 'Machine learning algorithms', 'Control systems', 'Software defined networking', 'IP networks', 'Protocols', 'Process control']","['Software defined network', 'distributed denial of service (DDoS)', 'collaborative detection', 'traffic characteristics', 'detection trigger']"
"The scope, scale, and intensity of real, as well as potential attacks, on the Smart Grid have been increasing and thus gaining more attention. An important component of Smart Grid cybersecurity efforts addresses the availability and access to the power and related information and communications infrastructures. We overload the term, Denial-of-Service (DoS), to refer to these attacks in the Smart Grid. In this paper, we provide a holistic and methodical presentation of the DoS attack taxonomies as well as a survey of potential solution techniques to help draw a more concerted and coordinated research into this area, lack of which may have profound consequences. To the best of our knowledge, the literature does not have such a comprehensive survey study of the DoS attacks and solutions for the Smart Grid.","['Smart grids', 'Protocols', 'Denial-of-service attack', 'IEC Standards', 'Economics']","['Denial-of-service attacks', 'smart grid security', 'cybersecurity']"
"Numerous important events happen everyday and everywhere but are reported in different media sources with different narrative styles. How to detect whether real-world events have been reported in articles and posts is one of the main tasks of event extraction. Other tasks include extracting event arguments and identifying their roles, as well as clustering and tracking similar events from different texts. As one of the most important research themes in natural language processing and understanding, event extraction has a wide range of applications in diverse domains and has been intensively researched for decades. This article provides a comprehensive yet up-to-date survey for event extraction from text. We not only summarize the task definitions, data sources and performance evaluations for event extraction, but also provide a taxonomy for its solution approaches. In each solution group, we provide detailed analysis for the most representative methods, especially their origins, basics, strengths and weaknesses. Last, we also present our envisions about future research directions.","['Task analysis', 'Data mining', 'Natural language processing', 'Machine learning', 'Knowledge based systems', 'Social network services', 'Feature extraction']","['Event extraction', 'event extraction tasks', 'event corpus', 'natural language processing']"
"Rising popularity of 5G communications is making tremendous demands on the cellular network operators for providing true 5G services to the users. With limited numbers of 5G users initially, the investments for 5G services can be very high. In the early stage of 5G deployments, the 5G cells would not be lavishly spread and there would be 5G coverage holes. The operators can provide seamless services to the 5G users by inter working with the existing 4G Long-Term Evolution (LTE) network. The 5G inter working with fully deployed LTE would not only provide fast and seamless coverage but would also provide economic viability to the network operators. In this paper we survey and consolidate the 4G-5G inter working solutions that can assist in attaining the insight about various inter working possibilities and their challenges. It is important that a network operator is able to optimize its deployed infrastructure while being able to guarantee fast and seamless transition to 5G for its subscribers. To this regard, we evaluate the performance and radio resource management challenges for different 4G-5G dual connectivity options proposed by 3rd Generation Partnership Project (3GPP) standardization. We also discuss spectrum sharing possibilities between 4G and 5G wireless networks. Finally, various research challenges and discussions on path for migration to 5G standalone networks are also presented.","['5G mobile communication', 'Long Term Evolution', '3GPP', 'Resource management', 'Standardization', 'Base stations', 'Throughput']","['4G', '5G', 'new radio (NR)', 'dual connectivity', 'spectrum sharing', 'deployment options']"
"State-of-charge (SoC) estimation is indispensable for battery management systems (BMSs). Accurate SoC estimation can improve the efficiency of battery utilization, especially for electric vehicles (EVs). Several kinds of battery SoC estimation approaches have been developed, but a simple and efficient method for battery SoC estimation that can adapt to a variety of lithium-ion batteries is worth exploring. To this end, a recurrent neural network (RNN) model based on a gated recurrent unit (GRU) is presented for battery SoC estimation. The GRU-RNN model can rapidly learn its own parameters by means of an ensemble optimization method based on the Nadam and AdaMax optimizers. The Nadam optimizer is used in the model pre-training phase to find the minimum optimized value as soon as possible, and then the AdaMax optimizer is used in the model fine-tuning phase to further determine the model parameters. To validate the effectiveness and robustness of the proposed method, the GRU-RNN model was trained and tested with three kinds of dynamic loading profiles and compared with existing SoC estimation methods. The experimental results show that the proposed method dramatically reduces the model training time and increases estimation accuracy.","['Batteries', 'Estimation', 'Adaptation models', 'Training', 'Logic gates', 'Integrated circuit modeling', 'Computational modeling']","['Lithium-ion batteries', 'state of charge', 'gated recurrent unit', 'ensemble optimizer']"
"In this paper, an Improved Ant Colony Optimization (IACO) algorithm optimized fuzzy PID (FPID) controller is proposed for Load Frequency Control of multi area systems. The nonlinear incremental evaporation rate and improvement of pheromone increment updating are proposed in the IACO algorithm to improve the quality of solution. And, a modified objective function using integral time multiply absolute error (ITAE), overshoot, undershoot and settling time with appropriate weight coefficients is proposed to improve the performance of the controller. Initially, a two-area non-reheat thermal system is applied and the FPID controller parameters are optimized by the IACO algorithm with five different objective functions. The modified objective function has better performances than four conventional objective functions. To demonstrate the robustness of the proposed control method, sensitivity analysis is implemented under wide variation of operating conditions and system parameters. Further, the proposed approach is also extended to two-area four-sources hydro thermal power system with/without High Voltage Direct Current (HVDC) link. The superiority of the proposed approach is shown by comparing the results with ZN, GA and hPSO-PS algorithms. The robustness of the proposed method is verified under random load disturbances. Finally, the proposed approach is extended to a two-area power system with governor dead band nonlinearity and results show that the proposed approach can cope with nonlinearity well. The results obtained from all simulations show that the proposed algorithm and modified objective function achieves better performances, such as minimum objective values (ITAE = 0.0255, ITSE = 9.30e-5, ISE = 1.91e-4 and IAE = 0.0273) obtained for the two-area non-reheat thermal system.","['Power systems', 'Linear programming', 'Frequency control', 'Generators', 'Heuristic algorithms', 'Optimization', 'Ant colony optimization']","['Ant colony optimization (ACO)', 'fuzzy logic controller (FLC)', 'governor dead band (GDB)', 'Load frequency control (LFC)']"
"A rapid increase in the percentage of elderly people over the past few years has been a cause of serious concern among the research fraternity worldwide. Active research is being carried out to leverage the benefits of information and communication technologies that enable them to live independently and promote a sense of overall well-being. Smart-homes are often employed to assist this group of people. However, there is a serious lack of relevant exploratory research that tries to measure and explain the intention of these people toward using such a service. In this paper, we propose and validate a new comprehensive research model called the elderly smart home technology acceptance model by extending the original technology acceptance model that can explain the elderly intention to use the smart-homes. An online questionnaire survey is conducted for this purpose, the results of which are analyzed using the Partial least squares Structural Equation Modeling approach on data collected from 254 subjects. Subjective norm, compatibility, automation, self-capability, and satisfaction are positively related to the elderly intention in using smarthomes, whereas there is a negative association between affordability, security/privacy, and usage intention. Two other factors, namely universal connectivity and enjoyment, have no effect on the behavioral intention. The present study is a first empirical attempt that tries to explore the adoption of smart-homes among the elderly, as all other previous research has focused only on the technical aspects and implementation issues rather than the actual usage intention.","['Senior citizens', 'Bibliographies', 'Statistics', 'Monitoring', 'Intelligent sensors']","['Behavioral intention', 'elderly', 'quality of life', 'smart-homes']"
"A quiet revolution that impacts several sectors, ranging over transport, home automation, energy, industrial control, and health services is undergoing with addition of new networked devices leading to enhanced services. In this paper, we aim to identify information security requirements that are common over several (vertical) sectors, and in particular, ones that impact critical societal services, namely, the energy, water, and health management systems. We present the results of an interview-based study where actors in these sectors were asked about their perceptions and attitudes on the security of Internet of Things (IoT). We set these perceptions and attitudes in context through a literature review of IoT security, and relate to current challenges in this area. This paper demonstrates that despite an overall optimistic view on IoT in critical societal services, there is a lack of consensus on risks related to IoT security.","['Security', 'Internet of things', 'Context modeling', 'Computer security', 'Smart grids', 'Risk management', 'Medical services']","['Internet of Things', 'Security', 'Risk', 'Critical infrastructure', 'Health']"
"The discounted {0-1} knapsack problem (DKP) extends the classical 0-1 knapsack problem (0-1 KP) in which a set of item groups is included and each group consists of three items, whereas at most one of the three items can be packed into the knapsack. Therefore, the DKP is more complicated and computationally difficult than 0-1 KP. The DKP has been found many applications in real economic problems and other areas. In this paper, the influence of Lévy flights operator and fly straightly operator in the moth search (MS) algorithm is verified. Nine types of new mutation operator based on the global harmony search are specially devised to replace Lévy flights operator. Then, nine novel MS-based algorithms for DKP are proposed (denoted by MS1-MS9). Extensive experiments on three sets of 30 DKP instances demonstrate the remarkable performance of the proposed nine new MS-based approaches. In particular, it discovers that MS1-MS3 show better comprehensive performance among 10 algorithms. A variety of analyses indicate the important contribution of the individual of memory consideration in MS1-MS9.","['Optimization', 'Search problems', 'Sociology', 'Statistics', 'Particle swarm optimization', 'Standards', 'Silicon']","['Discounted {0-1} knapsack problem', 'harmony search', 'moth search', 'swarm intelligence']"
"In critical applications, such as medical diagnosis, security related systems, and so on, the cost or risk of action taking based on incorrect classification can be very high. Hence, combining expert opinions before taking decision can substantially increase the reliability of such systems. Such pattern recognition systems base their final decision on evidence collected from different classifiers. Such evidence can be of data type, feature type, or classifier type. Common problems in pattern recognition, such as curse of dimensionality, and small sample data size, among others, have also prompted researchers into seeking new approaches for combining evidences. This paper presents a criteria-based framework for multiclassifiers combination techniques and their areas of applications. The criteria discussed here include levels of combination, types of thresholding, adaptiveness of the combination, and ensemble-based approaches. The strengths and weaknesses of each of these categories are discussed in details. Following this analysis, we provide our perspective on the outlook of this area of research and open problems. The lack of a well-formulated theoretical framework for analyzing the performance of combination techniques is shown to provide a fertile ground for further research. In addition to summarizing the existing work, this paper also updates and complements the latest developments in this area of research.","['Pattern recognition', 'Classification algorithms', 'Probability density function', 'Feature extraction', 'Bayes methods', 'Sensor fusion']","['Pattern recognition', 'classifier combination', 'classifier ensembles', 'multi-classifiers', 'dimensionality reduction']"
"In wireless sensor networks (WSNs), the benefits of exploiting the sink mobility to prolong network lifetime have been well recognized. In physical environments, all kinds of obstacles could exit in the sensing field. Therefore, a research challenge is how to efficiently dispatch the mobile sink to find an obstacle-avoiding shortest route. This paper presents an energy-efficient routing mechanism based on the cluster-based method for the mobile sink in WSNs with obstacles. According to the cluster-based method, the nodes selected as cluster heads collect data from their cluster members and transfer the data collected to the mobile sink. In this paper, the mobile sink starts the data-gathering route periodically from the starting site, then directly collects data from these cluster heads in a single-hop range, and finally returns to the starting site. However, due to the complexity of the scheduling problem in WSNs with obstacles, the conventional algorithms are difficult to resolve. To remedy this issue, we propose an efficient scheduling mechanism based on spanning graphs in this paper. Based on the spanning graph, we present a heuristic tour-planning algorithm for the mobile sink to find the obstacle-avoiding shortest route. Simulation results verify the effectiveness of our method.","['Sensors', 'Wireless sensor networks', 'Mobile computing', 'Mobile nodes', 'Base stations', 'Cluster approximation', 'Energy efficiency']","['Wireless Sensor Networks', 'Obstacles', 'Energy- Efficient Routing', 'Cluster-Based', 'Mobile Sink', 'Spanning Graph']"
"Software maintainability predicts changes or failures that may occur in software after it has been deployed. Since it deals with the degree to which an application may be understood, repaired, or enhanced, it also takes into account the overall cost of the project. In the past, several measures have been taken into account for predicting metrics that influence software maintainability. However, deep learning is yet to be explored for the same. In this paper, we perform deep learning for software maintainability metrics' prediction on a large number of datasets. Unlike the previous research works, we have relied on large datasets from 299 software and subsequently applied various metrics and functions to the same; 29 object-oriented metrics have been considered along with their impact on software maintainability of open source software. Several metrics have been analyzed and descriptive statistics of these metrics have been pointed out. The proposed long short term memory has been evaluated using measures, such as mean absolute error, root mean square error and accuracy. Five machine learning algorithms, namely, ridge regression with variable selection, decision tree, quantile regression forest, support vector machine, and principal component analysis have been applied to the original datasets, as well as, to the refined datasets. It was found that this paper provides results in the form of metrics that may be used in the prediction of software maintenance and the proposed deep learning model outperforms all of the other methods that were considered. Furthermore, the results of experiment affirm the efficiency of the proposed deep learning model for software maintainability prediction.","['Software', 'Deep learning', 'Cloning', 'Machine learning algorithms', 'Software measurement']","['Deep learning', 'machine learning', 'software metrics', 'software maintainability', 'prediction']"
"Three-factor mutually authenticated key agreement protocols for multi-server environments have gained momentum in recent times due to advancements in wireless technologies and associated constraints. Several authors have put forward various authentication protocols for multi-server environment during the past decade. Wang et al. recently proposed a biometric-based authentication with key agreement protocol for multi-server environment and claimed that their protocol is efficient and resistant to prominent security attacks. The careful investigation of this paper shows that Wang et al. protocol's users are sharing personal identifiable information with the application servers during the registration and authentication process. This nature of disclosing credentials leads to severe threats particularly insider attacks, user impersonation attacks, and server impersonation attacks. As a remedy of the aforementioned problems, this paper proposes a novel biometric-based mutually authenticated key agreement protocols for multi-server architecture based on elliptic curve cryptography. We prove that the proposed protocol achieves secure mutual authentication property using the broadly used Burrows-Abadi-Needham logic. The formal security of the proposed protocol is verified using the widely accepted automated validation of Internet security protocols and applications tool to show that our protocol can withstand active and passive attacks including the replay and man-in-the-middle attacks. The proposed protocol is robust and efficient compared with the existing related protocols.","['Protocols', 'Authentication', 'Servers', 'Elliptic curve cryptography', 'Robustness']","['Authentication', 'key-agreement', 'multi-server', 'security', 'impersonation attacks', 'BAN logic', 'AVISPA']"
"It is very important to understand the input features and the neural network parameters required for optimal path loss prediction in wireless communication channels. In this paper, an extensive investigation was conducted to determine the most appropriate neural network parameters for path loss prediction in Very High Frequency (VHF) band. Field measurements were conducted in an urban propagation environment to obtain relevant geographical and network information about the receiving mobile equipment and quantify the path losses of radio signals transmitted at 189.25 MHz and 479.25 MHz. Different neural network architectures were trained with varying kinds of input parameters, number of hidden neurons, activation functions, and learning algorithms to accurately predict corresponding path loss values. At the end of the experimentations, the performance of the developed Artificial Neural Network (ANN) models are evaluated using the following statistical metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Standard Deviation (SD) and Regression coefficient (R). Results obtained show that the ANN model that yielded the best performance employed four input variables (latitude, longitude, elevation, and distance), nine hidden neurons, hyperbolic tangent sigmoid (tansig) activation function, and the Levenberg-Marquardt (LM) learning algorithm with MAE, MSE, RMSE, SD and R values of 0.58 dB, 0.66 dB, 0.81 dB, 0.56 dB and 0.99 respectively. Finally, a comparative analysis of the developed model with Hata, COST 231, ECC-33 and Egli models showed that ANN-based path loss model has better prediction accuracy and generalization ability than the empirical models.","['Predictive models', 'Wireless communication', 'Biological system modeling', 'Artificial neural networks', 'Computational modeling', 'Propagation losses']","['Artificial neural network', 'path loss', 'radio propagation', 'wireless channel', 'machine learning']"
"Diabetic retinopathy (DR) is a diabetes complication that affects the eye and can cause damage from mild vision problems to complete blindness. It has been observed that the eye fundus images show various kinds of color aberrations and irrelevant illuminations, which degrade the diagnostic analysis and may hinder the results. In this research, we present a methodology to eliminate these unnecessary reflectance properties of the images using a novel image processing schema and a stacked deep learning technique for the diagnosis. For the luminosity normalization of the image, the gray world color constancy algorithm is implemented which does image desaturation and improves the overall image quality. The effectiveness of the proposed image enhancement technique is evaluated based on the peak signal to noise ratio (PSNR) and mean squared error (MSE) of the normalized image. To develop a deep learning based computer-aided diagnostic system, we present a novel methodology of stacked generalization of convolution neural networks (CNN). Three custom CNN model weights are fed on the top of a single meta-learner classifier, which combines the most optimum weights of the three sub-neural networks to obtain superior metrics of evaluation and robust prediction results. The proposed stacked model reports an overall test accuracy of 97.92% (binary classification) and 87.45% (multi-class classification). Extensive experimental results in terms of accuracy, F-measure, sensitivity, specificity, recall and precision reveal that the proposed methodology of illumination normalization greatly facilitated the deep learning model and yields better results than various state-of-art techniques.","['Image color analysis', 'Retina', 'Lighting', 'Feature extraction', 'Image processing', 'Diabetes', 'Deep learning']","['Convolutional neural networks', 'diabetic retinopathy', 'early diagnosis', 'fundus images', 'gray world algorithm', 'ensemble learning']"
"Cloud computing has become a significant research area in large-scale computing, because it can share globally distributed resources. Cloud computing has evolved with the development of large-scale data centers, including thousands of servers around the world. However, cloud data centers consume vast amounts of electrical energy, contributing to high-operational costs, and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) using live migration and putting idle nodes in sleep mode allows cloud providers to optimize resource utilization and reduce energy consumption. However, aggressive VM consolidation may degrade the performance. Therefore, an energy-performance tradeoff between providing high-quality service to customers and reducing power consumption is desired. In this paper, several novel algorithms are proposed for the dynamic consolidation of VMs in cloud data centers. The aim is to improve the utilization of computing resources and reduce energy consumption under SLA constraints regarding CPU, RAM, and bandwidth. The efficiency of the proposed algorithms is validated by conducting extensive simulations. The results of the evaluation clearly show that the proposed algorithms significantly reduce energy consumption while providing a high level of commitment to the SLA. Based on the proposed algorithms, energy consumption can be reduced by up to 28%, and SLA can be improved up to 87% when compared with the benchmark algorithms.","['Cloud computing', 'Servers', 'Energy consumption', 'Heuristic algorithms', 'Algorithm design and analysis', 'Energy efficiency', 'Resource management']","['Cloud computing', 'energy efficiency', 'service level agreement', 'virtual machine consolidation', 'data center']"
"Wireless Sensor Networks (WSNs) are a type of self-organizing networks with limited energy supply and communication ability. One of the most crucial issues in WSNs is to use an energy-efficient routing protocol to prolong the network lifetime. We therefore propose the novel Energy-Efficient Load Balancing Ant-based Routing Algorithm (EBAR) for WSNs. EBAR adopts a pseudo-random route discovery algorithm and an improved pheromone trail update scheme to balance the energy consumption of the sensor nodes. It uses an efficient heuristic update algorithm based on a greedy expected energy cost metric to optimize the route establishment. Finally, in order to reduce the energy consumption caused by the control overhead, EBAR utilizes an energy-based opportunistic broadcast scheme. We simulate WSNs in different application scenarios to evaluate EBAR with respect to performance metrics such as energy consumption, energy efficiency, and predicted network lifetime. The results of this comprehensive study show that EBAR provides a significant improvement in comparison to the state-of-the-art approaches EEABR, SensorAnt, and IACO.","['Wireless sensor networks', 'Routing', 'Routing protocols', 'Energy consumption', 'Clustering algorithms', 'Heuristic algorithms']","['Ant colony optimization', 'energy efficiency', 'load balancing', 'routing algorithm', 'wireless sensor networks']"
"Aspect-level sentiment classification is an interesting but challenging research problem, namely, the prediction of the sentiment polarity toward a specific aspect term of an opinionated sentence. Previous attention-based recurrent neural networks have been proposed to address this problem because attention mechanism is capable of finding out those words contributing more to the prediction than others and have shown great promise. However, the major drawback of these attention-based approaches is that the explicit position context is ignored. Drawing inspirations from the manner modeling the position context in information retrieval and question answering, we hypothesize that we should pay much more attention to the context words neighboring to the aspect than those far away, especially when one review sentence is a long sequence or contains multiple aspect terms. Based on this conjecture, in this paper, we put forward a new attentive LSTM model, dubbed PosATT-LSTM, which not only takes into account the importance of each context word but also incorporates the position-aware vectors, which represents the explicit position context between the aspect and its context words. We conduct substantial experiments on the SemEval 2014 datasets, and the encouraging results indicate the efficacy of our proposed approach.","['Sentiment analysis', 'Computational modeling', 'Context modeling', 'Recurrent neural networks', 'Task analysis']","['Data analysis', 'natural language processing', 'sentiment classification', 'aspect-level', 'recurrent neural networks', 'long short-term memory', 'position context', 'attention mechanism']"
"Object detection is a fundamental but challenging issue in the field of generic image analysis; it plays an important role in a wide range of applications and has been receiving special attention in recent years. Although there are enomerous methods exist, an in-depth review of the literature concerning generic detection remains. This paper provides a comprehensive survey of recent advances in visual object detection with deep learning. Covering about 300 publications that we survey 1) region proposal-based object detection methods such as R-CNN, SPPnet, Fast R-CNN, Faster R-CNN, Mask RCN, RFCN, FPN, 2) classification/regression base object detection methods such as YOLO(v2 to v5), SSD, DSSD, RetinaNet, RefineDet, CornerNet, EfficientDet, M2Det 3) Some latest detectors such as, relation network for object detection, DCN v2, NAS FPN. Moreover, five publicly available benchmark datasets and their standard evaluation metrics are also discussed. We mainly focus on the application of deep learning architectures to five major applications, namely Object Detection in Surveillance, Military, Transportation, Medical, and Daily Life. In the survey, we cover a variety of factors affecting the detection performance in detail, such as i) a wide range of object categories and intra-class variations, ii) limited storage capacity and computational power. Finally, we finish the survey by identifying fifteen current trends and promising direction for future research.","['Object detection', 'Machine learning', 'Face detection', 'Computer architecture', 'Feature extraction', 'Market research', 'Face']","['Object detection and recognition', 'deep learning', 'convolutional neural networks (CNN)', 'neural network']"
"This article proposes a fast reaching finite time synchronization approach for chaotic systems along with its application to medical image encryption. First, an adaptive terminal sliding mode tracking approach with fast reaching condition is designed to synchronize the chaotic systems at the transmitter and receiver ends in finite time. Then, a chaotic cryptosystem, using synchronized chaotic systems as secret keys generator, is proposed to enhance the security of medical image transmission and/or storage. The applicability and efficiency of the proposed synchronization approach is assessed using a simulation as well as an analytical study. The analysis encompassed security tools such as histogram analysis, correlation test, and information entropy change the rate of the number of pixels and unified average changing intensity. The obtained results confirmed the robustness and fast convergence rate of the proposed synchronization approach. The security analysis also shows that the proposed cryptosystem displays acceptable levels of resistance to various attacks.","['Synchronization', 'Chaotic communication', 'Encryption', 'Biomedical imaging', 'Convergence', 'Trajectory', 'Sliding mode control']","['Chaos synchronization', 'fast reaching condition', 'medical image encryption', 'MORE method encryption']"
"Fossil fuels and other conventional energy sources used to generate electricity are finite. Therefore, alternative energy sources should be pursued to meet present and future energy demands. The photovoltaic (PV) is a promising renewable energy source, especially for the remote areas. The PV is a DC power source that needs to be converted into usable AC power using an inverter. However, its nonlinearity and output fluctuation pose challenges in the design of PV based inverter. In this paper, a PV inverter controller system with the fundamentals of a fuzzy logic controller (FLC) and its applications and execution are reviewed. The different fuzzy controllers, inverter control algorithms, and switching techniques are studied. The findings indicate that the fuzzy logic controls have been gaining attention in the area of power control engineering, especially in inverter controller design for PV applications and generation. The FLC has a flexible and intelligent design, expedient user interface, easy computation and learning system, and combinations of different control algorithms. The FLC is also verifiable for completeness, redundancy, and consistency. However, finding the boundaries of membership functions and other rules of FLC requires manual tuning, long computation time, and considerable effort. This paper comprehensively reviews the FLC-based inverter control system to minimize PV output fluctuations, which cause inverter issues related to output harmonics, power factor, switching schemes, losses, and system implementation. The inverter system and its control strategy for future PV applications and generation require further research and development. Consequently, this review focuses on many factors and challenges and provides recommendations for designing capable and efficient inverter control systems for converting PV power to usable AC power. All the highlighted insights of this review will hopefully lead to increased efforts toward the development of the advanced inverter control systems for PV applications for AC loads and the utility grid.","['Inverters', 'Control systems', 'Fuzzy logic', 'Voltage control', 'Renewable energy sources', 'Harmonic analysis', 'Power system harmonics']","['Power converter', 'fuzzy logic', 'fuzzy logic controller', 'inverter', 'photovoltaic system']"
"The existing buffers algorithms cannot effectively to meet the demands of high accuracy of buffer analysis in practice although many efforts have been made in the past 60 years. A generalized buffering algorithm (GBA) is presented, which considers the geometric distance and the attribute characteristics of all instances within buffer zone. The proposed algorithm includes three major steps: (1) select and initialize target instance; (2) determine buffer boundary points through mining homogeneous pattern; (3) “smoothly” connect buffer boundary points to generate the generalized buffer zone. The details for the generations of the generalized point buffer (GPIB) zone, the generalized line buffer (GLB) zone, and the generalized polygon buffer (GPLB) zone are discussed. Two dataset are used to validate the performances of the proposed GBA. Six parameters are applied as indexes to evaluate the proposed algorithm. The experimental results discovered that (1) the GBA is close to the tradition buffering algorithm (TBA) when the angle increment (Δφ) in GPIB, line increment (ΔL) in GLB, and arc length increment (ΔS) in GPLB approach to zero, respectively; (2) the proposed GBA can accurately reflect the real situation of the buffering zone, and improve the deficiency and accuracy of TBA in real application.","['Classification algorithms', 'Shape', 'Research and development', 'Graphics processing units', 'Geomagnetism', 'Feature extraction']","['Buffering zone', 'data mining', 'geographic information science', 'homogeneous pattern', 'spatial analysis']"
"The fast-growing healthcare big data plays an important role in healthcare service providing. Healthcare big data comprise data from different structured, semi-structured, and unstructured sources. These data sources vary in terms of heterogeneity, volume, variety, velocity, and value that traditional frameworks, algorithms, tools, and techniques are not fully capable of handling. Therefore, a framework is required that facilitates collection, extraction, storage, classification, processing, and modeling of this vast heterogeneous volume of data. This paper proposes a healthcare big data framework using voice pathology assessment (VPA) as a case study. In the proposed VPA system, two robust features, MPEG-7 low-level audio and the interlaced derivative pattern, are used for processing the voice or speech signals. The machine learning algorithms in the form of a support vector machine, an extreme learning machine, and a Gaussian mixture model are used as the classifier. In the experiments, the proposed VPA system shows its efficiency in terms of accuracy and time requirement.","['Medical services', 'Big data', 'Feature extraction', 'Pathology', 'Data mining', 'Biomedical monitoring', 'Machine learning algorithms', 'Classification']","['Healthcare big data', 'voice pathology', 'classification', 'feature extraction']"
"Smart cities are a future reality for municipalities around the world. Healthcare services play a vital role in the transformation of traditional cities into smart cities. In this paper, we present a ubiquitous and quality computer-aided blood analysis service for the detection and counting of white blood cells (WBCs) in blood samples. WBCs also called leukocytes or leucocytes are the cells of the immune system that are involved in protecting the body against both infectious disease and foreign invaders. Analysis of leukocytes provides valuable information to medical specialists, helping them in diagnosing different important hematic diseases, such as AIDS and blood cancer (Leukaemia). However, this task is prone to errors and can be time-consuming. A mobile-cloud-assisted detection and classification of leukocytes from blood smear images can enhance accuracy and speed up the detection of WBCs. In this paper, we propose a smartphone-based cloud-assisted resource aware framework for localization of WBCs within microscopic blood smear images using a trained multi-class ensemble classification mechanism in the cloud. In the proposed framework, nucleus is first segmented, followed by extraction of texture, statistical, and wavelet features. Finally, the detected WBCs are categorized into five classes: basophil, eosinophil, neutrophil, lymphocyte, and monocyte. Experimental results on numerous benchmark databases validate the effectiveness and efficiency of the proposed system in comparison to the other state-of-the-art schemes.","['Smart cities', 'Medical services', 'Image classification', 'Feature extraction', 'White blood cells', 'Medical image processing', 'Cloud computing', 'Hematology']","['Healthcare in smart cities', 'haematology', 'image classification', 'image segmentation', 'leukocytes classification', 'mobile-cloud computing', 'medical image analysis']"
"The grid-connected inverter with virtual synchronous generator (VSG) control technology can improve the friendliness of a distributed power supply to the power grid. However, its low-voltage ridethrough (LVRT) capability is insufficient, which results in difficulties in limiting the current and provide reactive power support. A new LVRT control strategy based on the smooth switching is proposed in this paper. In this strategy, the voltage source mode of VSG is transformed into current source mode to limit the output current and provide reactive power support through the proportional resonance current control algorithm under grid fault. Furthermore, the feedback tracking synchronization strategy of the phase angle is employed to realize the smooth switching between two modes. When the grid fault recovers, it can directly switch back to grid-connected operation mode through a delay module without an additional algorithm. The simulation results verify the correctness and feasibility of the proposed control strategy.","['Inverters', 'Reactive power', 'Circuit faults', 'Regulators', 'Switches', 'Resonant frequency']","['Grid fault', 'low-voltage ride through', 'smooth switching', 'VSG']"
"As the smart city applications are moving from conceptual models to development phase, smart transportation is one of smart cities applications and it is gaining ground nowadays. Electric Vehicles (EVs) are considered one of the major pillars of smart transportation applications. EVs are ever growing in popularity due to their potential contribution in reducing dependency on fossil fuels and greenhouse gas emissions. However, large-scale deployment of EV charging stations poses multiple challenges to the power grid and public infrastructure. To overcome the issue of prolonged charging time, the simple solution of deploying more charging stations to increase charging capacity does not work due to the strain on power grids and physical space limitations. Therefore, researchers have focused on developing smart scheduling algorithms to manage the demand for public charging using modeling and optimization. More recently, there has been a growing interest in data-driven approaches in modeling EV charging. Consequently, researchers are looking to identify consumer charging behavior pattern that can provide insights and predictive analytics capability. The purpose of this article is to provide a comprehensive review for the use of supervised and unsupervised Machine Learning as well as Deep Neural Networks for charging behavior analysis and prediction. Recommendations and future research directions are also discussed.","['Electric vehicle charging', 'Charging stations', 'Prediction algorithms', 'Machine learning', 'Smart cities', 'Optimization']","['Electric vehicles', 'machine learning', 'smart city', 'smart transportation', 'big data']"
"The advancement of the Internet of Things (IoT) has allowed for unprecedented data collection, automation, and remote sensing and actuation, transforming autonomous systems and bringing smart command and control into numerous cyber physical systems (CPS) that our daily lives depend on. Simultaneously, dramatic improvements in machine learning and deep neural network architectures have enabled unprecedented analytical capabilities, which we see in increasingly common applications and production technologies, such as self-driving vehicles and intelligent mobile applications. Predictably, these technologies have seen rapid adoption, which has left many implementations vulnerable to threats unforeseen or undefended against. Moreover, such technologies can be used by malicious actors, and the potential for cyber threats, attacks, intrusions, and obfuscation that are only just being considered, applied, and countered. In this paper, we consider the good, the bad, and the ugly use of machine learning for cybersecurity and CPS/IoT. In detail, we consider the numerous benefits (good use) that machine learning has brought, both in general, and specifically for security and CPS/IoT, such as the improvement of intrusion detection mechanisms and decision accuracy in CPS/IoT. More pressing, we consider the vulnerabilities of machine learning (bad use) from the perspectives of security and CPS/IoT, including the ways in which machine learning systems can be compromised, misled, and subverted at all stages of the machine learning life-cycle (data collection, pre-processing, training, validation, implementation, etc.). Finally, the most concerning, a growing trend has been the utilization of machine learning in the execution of cyberattacks and intrusions (ugly use). Thus, we consider existing mechanisms with the potential to improve target acquisition and existing threat patterns, as well as those that can enable novel attacks yet to be seen.","['Machine learning', 'Computer security', 'Internet of Things', 'Training', 'Data collection']","['Security', 'machine learning', 'cyber physical systems', 'Internet of Things', 'applications', 'distributed environments']"
"In this paper, a novel planar waveguide based on spoof surface plasmon polaritons (SSPPs) using fish-bone corrugated slot structure is first proposed in the microwave region. Low-dispersion band can be realized by such structure with tight field confinement of SSPPs, resulting in size miniaturization of the proposed waveguide. The high frequency stopband of the proposed ultra-wideband bandpass filter (BPF) is created by using this proposed waveguide, while the low frequency stopband is properly designed through introducing the microstrip-to-slotline transition. The 2-D E-fields distribution, surface current flow, and energy flow patterns are all calculated and illustrated to demonstrate the electromagnetic (EM) characteristics of the proposed ultra-wideband BPF. The BPF tuning characteristics is explored to provide a guideline for facilitating the design process. To validate the predicted performance, the proposed filter is finally designed, fabricated, and measured. Measured results illustrate high performance of the filter, in which the reflection coefficient is better than -10 dB from 2.1 to 8 GHz with the smallest insertion loss of 0.37 dB at 4.9 GHz, showing good agreement with numerical simulations. The proposed surface plasmon polariton waveguides are believed to be significantly promising for further developing plasmonic functional devices and integrated 2-D circuits with enhanced confinement of SSPPs in microwave and even terahertz bands.","['Dispersion', 'Plasmons', 'Microwave filters', 'Band-pass filters', 'Surface waves', 'Microwave circuits', 'Optical surface waves']","['Bandpass filter', 'surface plasmon polaritons', 'ultra-wideband']"
"Traditionally, a grid-interactive inverter providing ancillary services is called a smart inverter. However, broader features will be required for the next generation of inverters that can be categorized as self-governing, self-adapting, self-security, and self-healing. For grid-interactive inverters, the self-governing feature can be identified as the capability of inverters to operate in grid-following and grid-forming control modes, where the self-adapting is referred to as more flexibility realized by adaptive controllers for stable dynamics of inverters under various grid conditions. Moreover, for supervisory control and economic dispatch in a grid with high-penetration of inverter-based power generators, a minimum communication might be necessary, but it can place grid-interactive inverters in danger of being hacked when self-security becomes essential to identify malicious setpoints. Furthermore, the self-healing is defined as fault-tolerance and stress reduction under abnormal conditions. It suggests that after realizing these features, an inverter is called a smart inverter. In this paper, the advancements toward achieving these features for grid-interactive inverters are reviewed.","['Inverters', 'Reactive power', 'Smart grids', 'Power quality', 'Microgrids', 'Voltage control']","['Smart inverters', 'self-security', 'self-adapting', 'self-governing', 'self-healing', 'cyberattacks']"
"Orthogonal frequency division multiplexing (OFDM) offers spectral efficiency advantage, however, it is limited by peak-to-average power (PAPR) problem. The PAPR can be reduced using iterative clipping and filtering (ICF) scheme but requires that the same signals are iteratively clipped with a fixed clipping threshold at different clipping iterations. This method warrants that fast-Fourier transform (FFT)/inverse FFT (IFFT) blocks must be driven in the order of iterations many times to attain a desired PAPR threshold which expends the system power and expands the processing time. Using a second order cone program, the number of iterations required to attain the desired PAPR threshold was reduced. This optimized ICF (OICF) was later simplified using Lagrange multiplier (LM). In this paper, we apply an adaptive clipping threshold to the LM scheme to improve the performance of the simplified OICF (SOICF). Our results show significant reduction of the PAPR problem compared with the earlier SOICF scheme albeit with some degradation in the bit error ratio (BER) performance that can be under 1.0 dB depending on the chosen clipping threshold. In addition, we also illustrate the results of the performances and the theoretical relationships between the error vector magnitude (EVM) and PAPR, between clipping ratio (CR) and EVM, and lastly the inter-dependencies of EVM, PAPR, the number of OFDM subcarriers, and the CR.","['Peak to average power ratio', 'Optimization', 'Frequency-domain analysis', 'Discrete Fourier transforms', 'Distortion', 'Performance evaluation']","['PAPR', 'OFDM', 'Optimization', 'Iterative clipping and Filtering (ICF)', 'Adaptive', 'Lagrange Multiplier']"
"Considering the internal and external disturbances in wind energy conversion systems, a predictive active disturbance rejection control (PADRC) strategy for a direct-driven permanent magnet synchronous generator (PMSG)-based wind energy conversion system, is proposed to maximize the wind power extraction in this paper. First, the proposed PADRC method can successfully deal with the effects of the uncertainties in the internal dynamics, modeling error, external forces and the variety of wind speeds, since it inherits the merits of active disturbance rejection control (ADRC). Second, the introduction of Smith Predictor can overcome the time delay in wind turbine system to guarantee the maximum power tracking performance for different wind speeds. Finally, simulation studies are conducted to evaluate power tracking performances of the proposed control strategy. It is shown that the proposed PADRC strategy exhibits significant improvements in both maximum power tracking performance and anti-disturbance ability compared with the traditional ADRC approach.","['Wind turbines', 'Wind speed', 'Wind energy', 'Delay effects', 'Mathematical model', 'Torque', 'Optimized production technology']","['Permanent magnet synchronous generator', 'wind energy conversion system', 'active disturbance rejection controller', 'smith Predictor', 'maximum power tracking']"
"The artificial potential field approach is an efficient path planning method. However, to deal with the local-stable-point problem in complex environments, it needs to modify the potential field and increases the complexity of the algorithm. This study combines improved black-hole potential field and reinforcement learning to solve the problems which are scenarios of local-stable-points. The black-hole potential field is used as the environment in a reinforcement learning algorithm. Agents automatically adapt to the environment and learn how to utilize basic environmental information to find targets. Moreover, trained agents adopt variable environments with the curriculum learning method. Meanwhile, the visualization of the avoidance process demonstrates how agents avoid obstacles and reach the target. Our method is evaluated under static and dynamic experiments. The results show that agents automatically learn how to jump out of local stability points without prior knowledge.","['Path planning', 'Learning (artificial intelligence)', 'Gravity', 'Potential energy', 'Mobile agents', 'Real-time systems']","['Reinforcement learning', 'neural network', 'potential field', 'path planning']"
"A novel Peer-to-peer (P2P) energy trading scheme for a Virtual Power Plant (VPP) is proposed by using Smart Contracts on Ethereum Blockchain Platform. The P2P energy trading is the recent trend the power society is keen to adopt carrying out several trial projects as it eases to generate and share the renewable energy sources in a distributed manner inside local community. Blockchain and smart contracts are the up-and-coming phenomena in the scene of the information technology used to be considered as the cutting-edge research topics in power systems. Earlier works on P2P energy trading including and excluding blockchain technology were focused mainly on the optimization algorithm, Information and Communication Technology, and Internet of Things. Therefore, the financial aspects of P2P trading in a VPP framework is focused and in that regard a P2P energy trading mechanism and bidding platform are developed. The proposed scheme is based on public blockchain network and auction is operated by smart contract addressing both cost and security concerns. The smart contract implementation and execution in a VPP framework including bidding, withdrawal, and control modules developments are the salient feature of this work. The proposed architecture is validated using realistic data with the Ethereum Virtual Machine (EVM) environment of Ropsten Test Network.","['Contracts', 'Microgrids', 'Peer-to-peer computing', 'Information and communication technology', 'Power generation']","['Bidding system', 'blockchain', 'Ethereum', 'peer-to-peer (P2P) energy trading', 'smart contract', 'virtual power plant (VPP)']"
"Prior to the innovation of information communication technologies (ICT), social interactions evolved within small cultural boundaries such as geo spatial locations. The recent developments of communication technologies have considerably transcended the temporal and spatial limitations of traditional communications. These social technologies have created a revolution in user-generated information, online human networks, and rich human behavior-related data. However, the misuse of social technologies such as social media (SM) platforms, has introduced a new form of aggression and violence that occurs exclusively online. A new means of demonstrating aggressive behavior in SM websites are highlighted in this paper. The motivations for the construction of prediction models to fight aggressive behavior in SM are also outlined. We comprehensively review cyberbullying prediction models and identify the main issues related to the construction of cyberbullying prediction models in SM. This paper provides insights on the overall process for cyberbullying detection and most importantly overviews the methodology. Though data collection and feature engineering process has been elaborated, yet most of the emphasis is on feature selection algorithms and then using various machine learning algorithms for prediction of cyberbullying behaviors. Finally, the issues and challenges have been highlighted as well, which present new research directions for researchers to explore.","['Predictive models', 'Machine learning algorithms', 'Social networking (online)', 'Big Data', 'Computer science', 'Communications technology', 'Prediction algorithms']","['Big data', 'cyberbullying', 'cybercrime', 'human aggressive behavior', 'machine learning', 'online social network', 'social media', 'text classification']"
"The scene rigidity is a strong assumption in typical visual Simultaneous Localization and Mapping (vSLAM) algorithms. Such strong assumption limits the usage of most vSLAM in dynamic real-world environments, which are the target of several relevant applications such as augmented reality, semantic mapping, unmanned autonomous vehicles, and service robotics. Many solutions are proposed that use different kinds of semantic segmentation methods (e.g., Mask R-CNN, SegNet) to detect dynamic objects and remove outliers. However, as far as we know, such kind of methods wait for the semantic results in the tracking thread in their architecture, and the processing time depends on the segmentation methods used. In this paper, we present RDS-SLAM, a real-time visual dynamic SLAM algorithm that is built on ORB-SLAM3 and adds a semantic thread and a semantic-based optimization thread for robust tracking and mapping in dynamic environments in real-time. These novel threads run in parallel with the others, and therefore the tracking thread does not need to wait for the semantic information anymore. Besides, we propose an algorithm to obtain as the latest semantic information as possible, thereby making it possible to use segmentation methods with different speeds in a uniform way. We update and propagate semantic information using the moving probability, which is saved in the map and used to remove outliers from tracking using a data association algorithm. Finally, we evaluate the tracking accuracy and real-time performance using the public TUM RGB-D datasets and Kinect camera in dynamic indoor scenarios. Source code and demo: https://github.com/yubaoliu/RDS-SLAM.git.","['Semantics', 'Vehicle dynamics', 'Simultaneous localization and mapping', 'Heuristic algorithms', 'Cameras', 'Real-time systems', 'Visualization']","['Dynamic SLAM', 'ORB SLAM', 'Mask R-CNN', 'SegNet', 'real-time']"
"Decades of heavy investment in laboratory-based brain imaging and neuroscience have led to foundational insights into how humans sense, perceive, and interact with the external world. However, it is argued that fundamental differences between laboratory-based and naturalistic human behavior may exist. Thus, it remains unclear how well the current knowledge of human brain function translates into the highly dynamic real world. While some demonstrated successes in real-world neurotechnologies are observed, particularly in the area of brain-computer interaction technologies, innovations and developments to date are limited to a small science and technology community. We posit that advancements in real-world neuroimaging tools for use by a broad-based workforce will dramatically enhance neurotechnology applications that have the potential to radically alter human–system interactions across all aspects of everyday life. We discuss the efforts of a joint government-academic-industry team to take an integrative, interdisciplinary, and multi-aspect approach to translate current technologies into devices that are truly fieldable across a range of environments. Results from initial work, described here, show promise for dramatic advances in the field that will rapidly enhance our ability to assess brain activity in real-world scenarios.","['Neuroimaging', 'Wearable sensors', 'Electroencephalography', 'Neuroscience', 'Research and development', 'Medical image processing', 'Biomedical monitoring', 'Maximum likelihood decoding', 'Brain modeling', 'Behavioral science', 'Investments', 'Brain-computer interfaces']","['Behavioral science', 'biomarkers', 'body sensor networks', 'brain computer interaction', 'brain computer interfaces', 'data acquisition', 'electroencephalography', 'monitoring', 'translational research', 'wearable sensors']"
"With more consumers using online opinion reviews to inform their service decision making, opinion reviews have an economical impact on the bottom line of businesses. Unsurprisingly, opportunistic individuals or groups have attempted to abuse or manipulate online opinion reviews (e.g., spam reviews) to make profits and so on, and that detecting deceptive and fake opinion reviews is a topic of ongoing research interest. In this paper, we explain how semi-supervised learning methods can be used to detect spam reviews, prior to demonstrating its utility using a data set of hotel reviews.",[],[]
"One of the barriers for the adoption of electric vehicles (EVs) is the anxiety around the limited driving range. Recent proposals have explored charging EVs on the move, using dynamic wireless charging which enables power exchange between the vehicle and the grid while the vehicle is moving. In this paper, we focus on the intelligent routing of EVs in need of charging so that they can make most efficient use of the so-called mobile energy disseminators (MEDs) which operate as mobile charging stations. We present a method for routing EVs around MEDs on the road network, which is based on constraint logic programming and optimization using a graph-based shortest path algorithm. The proposed method exploits inter-vehicle communications in order to eco-route electric vehicles. We argue that combining modern communications between vehicles and state of the art technologies on energy transfer, the driving range of EVs can be extended without the need for larger batteries or overtly costly infrastructure. We present extensive simulations in city conditions that show the driving range and consequently the overall travel time of electric vehicles is improved with intelligent routing in the presence of MEDs.","['Electric vehicles', 'Vehicle dynamics', 'Inductive charging', 'Optimization', 'Charging stations', 'Roads', 'Batteries']","['Constraint solving', 'dynamic wireless charging', 'electric vehicles', 'inductive power transfer', 'optimization', 'vehicular communications routing']"
"Internet of Things (IoT) enables modern improvements in smart sensors, RFID, Internet technologies, and communication protocols. Sensor nodes are treated as smart devices and widely used to gather and forward sensed information. However, besides intrinsic constraints on sensor nodes, they are vulnerable to a variety of security threats. This paper presents an energy-aware and secure multi-hop routing (ESMR) protocol by using a secret sharing scheme to increase the performance of energy efficiency with multi-hop data security against malicious actions. The proposed protocol comprises three main aspects. First, the network field is segmented into inner and outer zones based on the node location. Furthermore, in each zone, numerous clusters are generated on the basis of node neighborhood vicinity. Second, the data transmission from cluster heads in each zone towards the sink node is secured using the proposed efficient secret sharing scheme. In the end, the proposed solution evaluates the quantitative analysis of data links to minimize the routing disturbance. The presented work provides a lightweight solution with secure data routing in multi-hop approach for the IoT-based constrained wireless sensor networks (WSNs). The experimental results demonstrate the efficacy of proposed energy-aware and secure multi-hop routing protocol in terms of network lifetime by 38%, network throughput by 34%, energy consumption by 34%, average end-to-end delay by 28%, and routing overhead by 36% in comparison with the existing work.","['Routing', 'Routing protocols', 'Wireless sensor networks', 'Cryptography', 'Energy efficiency']","['WSN', 'clusters formation', 'multi-hop', 'secret sharing', 'secure routing', 'route maintenance']"
"Due to the development of short-range radar with high-resolution, the radar sensor has a high potential to be used in real human-computer interaction (HCI) applications. The radar sensor has advantages over optical cameras in that it is unaffected by illumination and it is able to detect the objects in an occluded environment. This paper proposes a hand gesture recognition system for a real-time application of HCI using 60 GHz frequency-modulated continuous wave (FMCW) radar, Soli, developed by Google. The overall system includes signal processing part that generates range-Doppler map (RDM) sequences without clutter and machine learning part including a long short-term memory (LSTM) encoder to learn the temporal characteristics of the RDM sequences. A set of data is collected from 10 participants for the experiment. The proposed hand gesture recognition system successfully distinguishes 10 gestures with a high classification accuracy of 99.10%. It also recognizes the gestures of a new participant with an accuracy of 98.48%.","['Gesture recognition', 'Clutter', 'Doppler effect', 'Signal processing', 'Doppler radar', 'Laser radar']","['FMCW radar', 'gesture recognitio', 'LSTM encoder', 'machine learning', 'real-time interaction']"
"Smart contract security is an emerging research area that deals with security issues arising from the execution of smart contracts in a blockchain system. Generally, a smart contract is a piece of executable code that automatically runs on the blockchain to enforce an agreement preset between parties involved in the transaction. As an innovative technology, smart contracts have been applied in various business areas, such as digital asset exchange, supply chains, crowdfunding, and intellectual property. Unfortunately, many security issues in smart contracts have been reported in the media, often leading to substantial financial losses. These security issues pose new challenges to security research because the execution environment of smart contracts is based on blockchain computing and its decentralized nature of execution. Thus far, many partial solutions have been proposed to address specific aspects of these security issues, and the trend is to develop new methods and tools to automatically detect common security vulnerabilities. However, smart contract security is systematic engineering that should be explored from a global perspective, and a comprehensive study of issues in smart contract security is urgently needed. To this end, we conduct a literature review of smart contract security from a software lifecycle perspective. We first analyze the key features of blockchain that can cause security issues in smart contracts and then summarize the common security vulnerabilities of smart contracts. To address these vulnerabilities, we examine recent advances in smart contract security spanning four development phases: 1) security design; 2) security implementation; 3) testing before deployment; and 4) monitoring and analysis. Finally, we outline emerging challenges and opportunities in smart contract security for blockchain engineers and researchers.","['Smart contracts', 'Security', 'Blockchain', 'Software', 'Fabrics', 'Computer bugs']","['Blockchain', 'Ethereum', 'information security', 'smart contract', 'software engineering', 'software lifecycle']"
"With the popularity of social network-based services, the unprecedented growth of mobile date traffic has brought a heavy burden on the traditional cellular networks. Device-to-device (D2D) communication, as a promising solution to overcome wireless spectrum crisis, can enable fast content delivery based on user activities in social networks. In this paper, we address the content delivery problem related to optimization of peer discovery and resource allocation by combining both the social and physical layer information in D2D underlay networks. The social relationship, which is modeled as the probability of selecting similar contents and estimated by using the Bayesian nonparametric models, is used as a weight to characterize the impact of social features on D2D pair formation and content sharing. Next, we propose a 3-D iterative matching algorithm to maximize the sum rate of D2D pairs weighted by the intensity of social relationships while guaranteeing the quality of service requirements of both cellular and D2D links simultaneously. Moreover, we prove that the proposed algorithm converges to a stable matching and is weak Pareto optimal, and also provide the theoretical complexity. Simulation results show that the algorithm is able to achieve more than 90% of the optimum performance with a computation complexity 1000 times lower than the exhaustive matching algorithm. It is also demonstrated that the satisfaction performance of D2D receivers can be increased significantly by incorporating social relationships into the resource allocation design.","['Device-to-device communication', 'Resource management', 'Receivers', 'Cellular networks', 'Transmitters', 'Quality of service', 'Social network services']","['Social network', 'device-to-device communication', 'content delivery', 'Bayesian nonparametric models', 'matching theory']"
"Recent developments in technology have introduced dramatic changes to the practice of the accounting profession. This paper provides a comprehensive review of current developments in big data, machine learning, artificial intelligence, and blockchain utilized in general business practice and by specialized practitioners in the accounting profession worldwide. This paper explores the evolution of the accounting profession following these recent technological developments and assesses the impact of future developments. Inherent challenges and opportunities posed by these new technologies pertaining to accounting professionals and accounting educators are also examined, including an increased demand for IT professionals with accounting experience as opposed to accounting major graduates. Considering the dramatic changes and developments of AI applications in accounting, this paper reflects how all these technologies and the associated requirements of job candidates will affect the desired capabilities of accounting graduates and provides further discussion regarding what higher institutions and their accounting graduates can do to adopt such changes.","['Big Data', 'Blockchain', 'Machine learning', 'Finance']","['Accounting profession', 'artificial intelligence', 'big data', 'blockchain', 'machine learning']"
"When a single-phase ground fault occurs in a distribution network, it is generally allowed to operate with faults for one to two hours, which may lead to further development of the fault and even threaten the safe operation of the power system. Therefore, when a small current system has a ground fault, it must be quickly diagnosed to shorten the time of operation with fault. In this paper, an adaptive convolutional neural network (ACNN)-based fault line selection method is proposed for a distribution network. This method improves the feature extraction ability of the network by improving the pooling model. Compared with deep belief network (DBN), it can improve the accuracy of fault classification by 7.86% and reduce the training time by 42.7%. On this basis, the secondary fault location is identified using the principle of two-terminal fault location. In this research, fault data obtained by Simulink simulation is used as training set, and ACNN model is built based on TensorFlow framework. The analysis of results proves that the model has a high fault recognition rate and fast convergence speed. It can be used as an auxiliary hand for fault diagnosis in distribution networks.","['Fault location', 'Adaptation models', 'Circuit faults', 'Feature extraction', 'Training', 'Data models']","['Convolutional neural network', 'adaptive pooling model', 'two-terminal fault location', 'distribution network', 'single-phase ground fault']"
"Critical technological systems exhibit complex dynamic characteristics such as time-dependent behavior, functional dependencies among events, sequencing and priority of causes that may alter the effects of failure. Dynamic fault trees (DFTs) have been used in the past to model the failure logic of such systems, but the quantitative analysis of DFTs has assumed the existence of precise failure data and statistical independence among events, which are unrealistic assumptions. In this paper, we propose an improved approach to reliability analysis of dynamic systems, allowing for uncertain failure data and statistical and stochastic dependencies among events. In the proposed framework, DFTs are used for dynamic failure modeling. Quantitative evaluation of DFTs is performed by converting them into generalized stochastic Petri nets. When failure data are unavailable, expert judgment and fuzzy set theory are used to obtain reasonable estimates. The approach is demonstrated on a simplified model of a cardiac assist system.","['Fault trees', 'Stochastic processes', 'Discrete Fourier transforms', 'Statistical analysis', 'Reliability theory', 'Logic gates']","['Dynamic systems', 'fault tree analysis', 'fuzzy set theory', 'Petri nets', 'reliability analysis']"
"This study introduces an explainable artificial intelligence (XAI) approach of convolutional neural networks (CNNs) for classification in vibration signals analysis. First, vibration signals are transformed into images by short-time Fourier transform (STFT). A CNN is applied as classification model, and Gradient class activation mapping (Grad-CAM) is utilized to generate the attention of model. By analyzing the attentions, the explanation of classification models for vibration signals analysis can be carried out. Finally, the verifications of attention are introduced by neural networks, adaptive network-based fuzzy inference system (ANFIS), and decision trees to demonstrate the proposed results. By the proposed methodology, the explanation of model using highlighted attentions is carried out.","['Vibrations', 'Machine learning', 'Signal analysis', 'Frequency-domain analysis', 'Fault diagnosis', 'Feature extraction', 'Contracts']","['Convolutional neural network', 'vibration signal', 'explainable AI', 'fault diagnosis']"
"The issue of virtual network (VN) embedding constitutes an important aspect of network virtualization, which is considered to be one of the most crucial techniques to overcome the Internet ossification problem. The main purpose of VN embedding is to efficiently utilize the limited physical network resources to offer the supporting of virtual nodes and virtual links from the VNs. Due to the fact that the VN embedding problem is proved to be NP-hard, previous works have put forward some of heuristic algorithms to solve this VN embedding problem. However, most of the existing research works only consider the local resources of nodes, ignoring the topological attributes of its neighborhood nodes, and lead to lower resource utilization of the substrate network. To address this issue, we proposed an approach of VN embedding algorithm called VNE-DCC, which based on the node degree and the clustering coefficient information, we adopted the technique of node importance metric to rank the substrate nodes aim to select the node with the most embedding potential for every virtual node in each VN requests, and exploited the breadth-first-search algorithm to embed the virtual nodes aiming at reducing the resource utilization of substrate links so as to increase the acceptance ratio of VN requests and increase the revenues of operational providers. Extensive simulations have shown that the efficiency of our algorithm is better than the other state-of-the-art algorithms in terms of Revenue/Cost ratio and acceptance ratio.","['Substrates', 'Clustering algorithms', 'Resource management', 'Heuristic algorithms', 'Virtualization', 'Internet', 'Virtual networks']","['Virtual network embedding', 'degree and clustering coefficient', 'network virtualization', 'virtual node mapping', 'virtual link mapping']"
"Nowadays, the use of mobile devices in the healthcare sector is increasing significantly. Mobile technologies offer not only forms of communication for multimedia content (e.g. clinical audio-visual notes and medical records) but also promising solutions for people who desire the detection, monitoring, and treatment of their health conditions anywhere and at any time. Mobile health systems can contribute to make patient care faster, better, and cheaper. Several pathological conditions can benefit from the use of mobile technologies. In this paper we focus on dysphonia, an alteration of the voice quality that affects about one person in three at least once in his/her lifetime. Voice disorders are rapidly spreading, although they are often underestimated. Mobile health systems can be an easy and fast support to voice pathology detection. The identification of an algorithm that discriminates between pathological and healthy voices with more accuracy is necessary to realize a valid and precise mobile health system. The key contribution of this paper is to investigate and compare the performance of several machine learning techniques useful for voice pathology detection. All analyses are performed on a dataset of voices selected from the Saarbruecken voice database. The results obtained are evaluated in terms of accuracy, sensitivity, specificity, and receiver operating characteristic area. They show that the best accuracy in voice diseases detection is achieved by the support vector machine algorithm or the decision tree one, depending on the features evaluated by using opportune feature selection methods.","['Pathology', 'Databases', 'Support vector machines', 'Mel frequency cepstral coefficient', 'Feature extraction', 'Monitoring', 'Machine learning algorithms']","['Mobile health systems', 'machine learning techniques', 'voice disorders', 'classification accuracy']"
"Massive amount of water level data has been collected by using Internet of Things (IoT) techniques in the Yangtze River and other rivers. In this paper, utilizing these data to construct deep neural network models for water level prediction is focused. To achieve higher accuracy, both the factors of time and locations of data collection sensors are considered to perform prediction. And the network structures of gated recurrent unit (GRU) and convolutional neural network (CNN) are combined to build a CNN-GRU model in which the GRU part learns the changing trend of water level, and the CNN part learns the spatial correlation among water level data observed from adjacent water stations. The CNN-GRU model that using data from multiple locations to predict the water level of the middle location has higher accuracy than the model only based on GRU and other state-of-the-art methods including autoregressive integrated moving average model (ARIMA), wavelet-based artificial neural network (WANN) and long-short term memory model (LSTM), because of its ability to decrease the affections of abnormal value and data randomness of a single water station to some extent. The results are verified on an experiment dataset that including 30-year observed data of water level at several collection stations in the Yangtze River. For forecasting the 8-o'clock water levels of future 5 days, accuracy of the CNN-GRU model is better than that of ARIMA, WANN and LSTM models with three evaluation factors including Nash-Sutcliffe efficiency coefficient (NSE), average relative error (MRE) and root mean square error (RMSE).","['Predictive models', 'Rivers', 'Data models', 'Time series analysis', 'Adaptation models', 'Neural networks', 'Forecasting']","['CNN', 'GRU', 'water level prediction']"
"Convolutional Neural Networks (CNN) achieves perfection in traffic sign identification with enough annotated training data. The dataset determines the quality of the complete visual system based on CNN. Unfortunately, databases for traffic signs from the majority of the world's nations are few. In this scenario, Generative Adversarial Networks (GAN) may be employed to produce more realistic and varied training pictures to supplement the actual arrangement of images. The purpose of this research is to describe how the quality of synthetic pictures created by DCGAN, LSGAN, and WGAN is determined. Our work combines synthetic images with original images to enhance datasets and verify the effectiveness of synthetic datasets. We use different numbers and sizes of images for training. Likewise, the Structural Similarity Index (SSIM) and Mean Square Error (MSE) were employed to assess picture quality. Our study quantifies the SSIM difference between the synthetic and actual images. When additional images are used for training, the synthetic image exhibits a high degree of resemblance to the genuine image. The highest SSIM value was achieved when using 200 total images as input and 32×32 image size. Further, we augment the original picture dataset with synthetic pictures and compare the original image model to the synthesis image model. For this experiment, we are using the latest iterations of Yolo, Yolo V3, and Yolo V4. After mixing the real image with the synthesized image produced by LSGAN, the recognition performance has been improved, achieving an accuracy of 84.9% on Yolo V3 and an accuracy of 89.33% on Yolo V4.","['Generative adversarial networks', 'Training', 'Image recognition', 'Data models', 'Feature extraction', 'Detectors', 'Training data']","['DCGAN', 'LSGAN', 'synthetic images', 'traffic sign', 'WGAN', 'Yolo V3', 'Yolo V4']"
"While 5G is being deployed and the economy and society begin to reap the associated benefits, the research and development community starts to focus on the next, 6 th Generation (6G) of wireless communications. Although there are papers available in the literature on visions, requirements and technical enablers for 6G from various academic perspectives, there is a lack of joint industry and academic work towards 6G. In this paper a consolidated view on vision, values, use cases and key enabling technologies from leading industry stakeholders and academia is presented. The authors represent the mobile communications ecosystem with competences spanning hardware, link layer and networking aspects, as well as standardization and regulation. The second contribution of the paper is revisiting and analyzing the key concurrent initiatives on 6G. A third contribution of the paper is the identification and justification of six key 6G research challenges: (i) “connecting”, in the sense of empowering, exploiting and governing, intelligence; (ii) realizing a network of networks, i.e., leveraging on existing networks and investments, while reinventing roles and protocols where needed; (iii) delivering extreme experiences, when/where needed; (iv) (environmental, economic, social) sustainability to address the major challenges of current societies; (v) trustworthiness as an ingrained fundamental design principle; (vi) supporting cost-effective global service coverage. A fourth contribution is a comprehensive specification of a concrete first-set of industry and academia jointly defined use cases for 6G, e.g., massive twinning, cooperative robots, immersive telepresence, and others. Finally, the anticipated evolutions in the radio, network and management/orchestration domains are discussed.","['6G mobile communication', 'Europe', '5G mobile communication', 'Industries', 'Sustainable development', 'Stakeholders', 'Wireless networks']","['6G', 'communication systems', 'wireless communication', 'Tbps', 'AI/ML', 'network architecture']"
"With the rapid development of the peer-to-peer lending industry in China, it has been a crucial task to evaluate the default risk of each loan. Motivated by the research in natural language processing, we make use of the online operation behavior data of borrowers and propose a consumer credit scoring method based on attention mechanism LSTM, which is a novel application of deep learning algorithm. Inspired by the idea of Word2vec, we treat each type of event as a word, construct the Event2vec model to convert each type of event transformation into a vector and, then, use an attention mechanism LSTM network to predict the probability of user default. The method is evaluated on the real dataset, and the results show that the proposed solution can effectively increase the predictive accuracy compared with the traditional artificial feature extraction method and the standard LSTM model.","['Feature extraction', 'Industries', 'Natural language processing', 'Neural networks', 'Mathematical model', 'Predictive models']","['P2P lending', 'credit scoring', 'machine learning', 'deep learning', 'LSTM', 'attention mechanism']"
"Different from the traditional quaternary tree (QT) structure utilized in the previous generation video coding standard H.265/HEVC, a brand new partition structure named quadtree with nested multi-type tree (QTMT) is applied in the latest codec H.266/VVC. The introduction of QTMT brings in superior encoding performance at the cost of great time-consuming. Therefore, a fast intra partition algorithm based on variance and Sobel operator is proposed in this paper. The proposed method settles the novel asymmetrical partition issue in VVC by well balancing the reduction of computational complexity and the loss of encoding quality. To be more concrete, we first terminate further splitting of a coding unit (CU) when the texture of it is judged as smooth. Then, we use Sobel operator to extract gradient features to decide whether to split this CU by QT, thus terminating further MT partitions. Finally, a completely novel method to choose only one partition from five QTMT partitions is applied. Obviously, homogeneous area tends to use a larger CU as a whole to do prediction while CUs with complicated texture are prone to be divided into small sub-CUs and these sub-CUs usually have different textures from each other. We calculate the variance of variance of each sub-CU to decide which partition will distinguish the sub-textures best. Our method is embedded into the latest VVC official reference software VTM-7.0. Comparing to anchor VTM-7.0, our method saves the encoding time by 49.27% on average at the cost of only 1.63% BDBR increase. As a traditional scheme based on variance and gradient to decrease the computational complexity in VVC intra coding, our method outperforms other relative existing state-of-the-art methods, including traditional machine learning and convolution neural network methods.","['Encoding', 'Computational complexity', 'Feature extraction', 'Copper', 'Vegetation', 'Support vector machines', 'Video coding']","['Asymmetric block size', 'fast partition decision', 'intra prediction', 'quadtree with multi-type tree', 'versatile video coding']"
"Digital twin is a virtual entity that is linked to a real-world entity. Both the link and the virtual representation can be realized in several different ways. However, the ambiguous meanings associated with the term digital twin are causing unnecessary miscommunications as people have different interpretations of what can be accomplished with it. To provide clarity around the concept, we introduce a general approach to analyze and construct digital twins in various applications. We identify the common features of digital twins from earlier literature and propose an analysis method that compares digital twin instances based on these features. The method is used to verify the existence of the features and can be further enhanced. We formulate the observations to a feature-based digital twin framework (FDTF) to universally define and structure digital twins. The framework consists of three main principles: i) the idea that all digital twins consist of a definite set of features, ii) the features can be used to compare digital twin instances to each other, and iii) the features can be combined via a data link feature to construct future digital twins more efficiently. As key contributions, we found that the features can be identified in existing digital twin implementations and the feature combinations of the implementations are diverse. We suggest that the features should be leveraged to provide clarity and efficiency in digital twin discussion and implementation. We further propose a general procedure for building digital twins.","['Diffusion tensor imaging', 'Terminology', 'Atmospheric modeling', 'Internet of Things', 'Tools']","['Digital twin', 'enterprise systems', 'Industrial Internet of Things', 'cyber-physical systems']"
"Imbalanced time series are universally found in industrial applications, where the number of normal samples is far larger than that of abnormal cases. Traditional machine learning algorithms, such as support vector machine and convolutional neural networks, are struggling to attain high classification accuracies for class-imbalanced problems, because they tend to ensure the accuracy of the majority class. Hereby, this paper proposes a novel anomaly detection approach based on generative adversarial networks (GAN) to overcome this problem. In particular, an encoder-decoder-encoder three-sub-network generator is trained involving the elaborately extracted features from normal samples alone. Anomaly scores for anomaly detection are made up of apparent loss and latent loss. Without having any knowledge of the abnormal samples, our approach can diagnose faults by generating much higher anomaly scores when a fault sample is fed into the trained model. Experimental studies are conducted to verify the validity and feasibility of our approach, including a benchmark rolling bearing dataset acquired by Case Western Reserve University and another rolling bearing dataset which is acquired by our laboratory. Our approach can distinguish abnormal samples from normal samples with 100% accuracies on both datasets.","['Feature extraction', 'Anomaly detection', 'Generative adversarial networks', 'Time series analysis', 'Generators', 'Training', 'Rolling bearings']","['Anomaly detection', 'generative adversarial networks', 'imbalanced industrial time series', 'rolling bearings']"
"Internet of Things (IoT) based application requires integration with the wireless communication technology to make the application data readily available. In this paper, a modified meander shape microstrip patch antenna has been proposed for IoT applications at 2.4 GHz ISM (Industrial, Scientific and Medical) band. The dimension of the antenna is40×10×1.6mm 3 . The antenna design is comprised of an inverse S-shape meander line connected with a slotted rectangular box. A capacitive load (C-load) and parasitic patch with the shaped ground are applied to the design. Investigations show that the antenna designed with an inverse S-shape patch and connecting rectangular box in the microstrip line has a higher efficiency and gain compare to the conventional meander shape antenna. The C-load is applied to the feed line to match the impedance. Moreover, parametric studies are carried out to investigate the flexibility of the antenna. Results show that, the gain and efficiency can be improved through adjusting the rectangular box with applying parasitic element and the shaped ground. The parasitic element has high impact on the bandwidth of the antenna of 12.5%. The finalized antenna has a peak gain of −0.256 dBi (measured) and 1.347 dBi (Simulated) with 79% radiation efficiency at 2.4 GHz. To prove the efficiency and eligibility in IoT applications, the measurement of the power delivered and received by the antenna at 2.4 GHz is performed and compared with the results of a dipole antenna. The antenna is integrated with 2.4 GHz radio frequency module and IoT sensors to validate the performance. The antenna novelty relies on the size compactness with high fractional bandwidth that is validated through the IoT application environment.","['Bandwidth', 'Gain', 'Internet of Things', 'Microstrip antennas', 'Antenna measurements', 'Reflection coefficient']","['Internet of Things', 'meander line', 'capacitive load', 'parasitic patch', 'bandwidth']"
"The amount of biomedical literature is vast and growing quickly, and accurate text mining techniques could help researchers to efficiently extract useful information from the literature. However, existing named entity recognition models used by text mining tools such as tmTool and ezTag are not effective enough, and cannot accurately discover new entities. Also, the traditional text mining tools do not consider overlapping entities, which are frequently observed in multi-type named entity recognition results. We propose a neural biomedical named entity recognition and multi-type normalization tool called BERN. The BERN uses high-performance BioBERT named entity recognition models which recognize known entities and discover new entities. Also, probability-based decision rules are developed to identify the types of overlapping entities. Furthermore, various named entity normalization models are integrated into BERN for assigning a distinct identifier to each recognized entity. The BERN provides a Web service for tagging entities in PubMed articles or raw text. Researchers can use the BERN Web service for their text mining tasks, such as new named entity discovery, information retrieval, question answering, and relation extraction. The application programming interfaces and demonstrations of BERN are publicly available at https://bern.korea.ac.kr .","['Biological system modeling', 'Text mining', 'Tools', 'Text recognition', 'Diseases', 'Web services', 'Chemicals']","['Biomedical text mining', 'decision rules', 'multi-type', 'named entity recognition', 'neural networks', 'normalization', 'Web service']"
"Internet of Things (IoT) devices play a crucial role in the overall development of IoT in providing countless applications in various areas. Due to the increasing interest and rapid technological growth of sensor technology, which have certainly revolutionized the way we live today, a need to provide a detailed analysis of the embedded platforms and boards is consequential. This paper presents a comprehensive survey of the recent and most-widely used commercial and research embedded systems and boards in different classification emphasizing their key attributes including processing and memory capabilities, security features, connectivity and communication interfaces, size, cost and appearance, operating system support, power specifications, and battery life and listing some interesting projects for each device. Through this exploration and discussion, readers can have an overall understanding on this area and foster more subsequent studies.","['Random access memory', 'Hardware', 'Protocols', 'Internet of Things', 'Embedded systems', 'Security']","['Internet of Things', 'embedded systems', 'hardware platform', 'microcontrollers', 'microprocessors', 'operating systems']"
"Maximum power point tracking (MPPT) techniques have been vastly researched and developed in order to obtain the maximum terminal power of photovoltaic (PV) arrays in the solar renewable energy system. The aim of this paper is to present a new principal scheme-based review of the categorised MPPT methods (conventional, novel, and hybrid) with respect to the deployment of their input variables (solar irradiance, PV arrays' temperature, and PV arrays' terminal voltage and current), where MPPT methods are categorised to six different schemes. For each scheme, previous MPPT studies are extracted from literature and analysed. Then the critical benefits and limitations of the six presented MPPT schemes are compared and discussed. It is concluded that those MPPT schemes deploying the measured external variables would be able to track the global maximum power point with high reliability; however, their implementation cost and applicability remains as a challenge due to increasing the sensor deployment cost and complexity. The conclusion of this paper will help new researchers to deliberately select an appropriate MPPT scheme based on their projects' objectives and limitations, prior to selecting an optimisation algorithm for MPPT.","['Maximum power point trackers', 'Optimization', 'Input variables', 'Complexity theory', 'Heuristic algorithms', 'Temperature measurement', 'Renewable energy sources']","['Solar photovoltaic', 'maximum power point tracking (MPPT)', 'solar renewable energy system', 'power conversion efficiency']"
"Among other security concerns, the reliable device to device direct communication is an important research aspect in sensor cloud system application of Internet of things (IoT). The access control mechanism can ensure the reliability through secure communication among two IoT devices without mediation of intermediate agent. Mainly, it requires twofold strategy involving the authentication of each other and session key establishment. Quite recently, in 2019, Das et al. proposed a certificate based lightweight access control and key agreement scheme for IoT devices (LACKA-IoT) to ensure smooth and secure access control and claimed LACKA-IoT to withstand the several attacks. Specifically, it is claimed that LACKA-IoT can resist device impersonation and man in middle attacks. However, the proof in this article refutes their claim and it is shown here, that LACKA-IoT is insecure against both device impersonation and man in middle attacks. An adversary just by using public parameters and by listening the communication channel can impersonate any device. Moreover, the same can also launch successful man in middle attack using public parameters and listened messages from public channel. An improved protocol iLACKA-IoT is then proposed in the paper. The iLACKA-IoT provides resistance against various types of threats and provides the required level of security, for evidence both formal validation through random or real (ROR) model as well as the informal validation through discussion on attack resilience is provided. The iLACKA-IoT is not only better in security but also provides performance efficiency as compared with LACKA-IoT and related schemes.","['Access control', 'Authentication', 'Internet of Things', 'Reliability', 'Cloud computing']","['Device access control', 'device impersonation', 'forged message', 'IoT access', 'reliability']"
"Automatically predicting age group and gender from face images acquired in unconstrained conditions is an important and challenging task in many real-world applications. Nevertheless, the conventional methods with manually-designed features on in-the-wild benchmarks are unsatisfactory because of incompetency to tackle large variations in unconstrained images. This difficulty is alleviated to some degree through convolutional neural networks (CNN) for its powerful feature representation. In this paper, we propose a new CNN-based method for age group and gender estimation leveraging residual networks of residual networks (RoR), which exhibits better optimization ability for age group and gender classification than other CNN architectures. Moreover, two modest mechanisms based on observation of the characteristics of age group are presented to further improve the performance of age estimation. In order to further improve the performance and alleviate over-fitting problem, RoR model is pre-trained on ImageNet first, and then it is fune-tuned on the IMDB-WIKI-101 data set for further learning the features of face images, finally, it is used to fine-tune on Adience data set. Our experiments illustrate the effectiveness of RoR method for age and gender estimation in the wild, where it achieves better performance than other CNN methods. Finally, the RoR-152+IMDB-WIKI-101 with two mechanisms achieves new state-of-the-art results on Adience benchmark.","['Estimation', 'Benchmark testing', 'Data models', 'Face', 'Manuals', 'Optimization', 'Power systems']","['Age and gender estimation', 'Adience', 'RoR', 'weighted loss', 'pre-training', 'ImageNet', 'IMDB-WIKI']"
"The mobility and resource limitation of nodes are the critical factors that affect the performance of Mobile AD hoc network (MANET). The mobility of nodes will affect the stability of links, and the limitation of node resources will lead to congestion, so it is very difficult to design a routing protocol that supports quality of service (QoS) in MANET. Especially in the scenario of high-speed node movement, frequent link interruption will damages QoS performance, so it is necessary to design MANET routing protocol that can adapt to network topology changes to support QoS. In this paper, we propose a Topological change Adaptive Ad hoc On-demand Multipath Distance Vector (TA-AOMDV) routing protocol, which can adapt to high-speed node movement to support QoS. In this protocol, a stable path selection algorithm is designed, which not only takes node resources (residual energy, available bandwidth and queue length) as the path selection parameters, but also considers the link stability probability between nodes. Furthermore, in order to adapt to the rapid change of topology, link interrupt prediction mechanism is integrated into the protocol, which updates the routing strategy based on periodic probabilistic estimates of link stability. Different scenarios with node speed in the range of 10-50m/s, data rate in the range of 4-40kbps and number of nodes in the range of 10-100 are simulated on NS2 platform. Our results show that the QoS metrics (packet delivery rate, end-to-end delay, and throughput) of the proposed protocol are significantly improved when the node speed is higher than 30m/s although it is slightly better when the node speed is lower than 30m/s. Our on-demand multipath routing protocol demonstrates high potential to support QoS for high-speed MANET.","['Quality of service', 'Routing protocols', 'Routing', 'Mobile ad hoc networks', 'Stability criteria', 'Bandwidth', 'Network topology']","['Mobile ad hoc network', 'link stability', 'QoS', 'multipath routing', 'cross layer']"
"The beginning of 2020 has seen the emergence of coronavirus outbreak caused by a novel virus called SARS-CoV-2. The sudden explosion and uncontrolled worldwide spread of COVID-19 show the limitations of existing healthcare systems in timely handling public health emergencies. In such contexts, innovative technologies such as blockchain and Artificial Intelligence (AI) have emerged as promising solutions for fighting coronavirus epidemic. In particular, blockchain can combat pandemics by enabling early detection of outbreaks, ensuring the ordering of medical data, and ensuring reliable medical supply chain during the outbreak tracing. Moreover, AI provides intelligent solutions for identifying symptoms caused by coronavirus for treatments and supporting drug manufacturing. Therefore, we present an extensive survey on the use of blockchain and AI for combating COVID-19 epidemics. First, we introduce a new conceptual architecture which integrates blockchain and AI for fighting COVID-19. Then, we survey the latest research efforts on the use of blockchain and AI for fighting COVID-19 in various applications. The newly emerging projects and use cases enabled by these technologies to deal with coronavirus pandemic are also presented. A case study is also provided using federated AI for COVID-19 detection. Finally, we point out challenges and future directions that motivate more research efforts to deal with future coronavirus-like epidemics.","['COVID-19', 'Blockchain', 'Artificial intelligence', 'Coronaviruses', 'Pandemics', 'Medical services', 'Diseases']","['Blockchain', 'Artificial Intelligence (AI)', 'security', 'privacy', 'machine learning', 'deep learning', 'coronavirus (COVID-19)', 'SARS-CoV-2', 'epidemic']"
"Electroencephalography (EEG) signals can reflect activities of the human brain and represent different emotional states. However, recognizing emotions based on full-channel EEG signals will lead to redundant data and hardware complexity, thus it is not suitable for designing wearable devices for daily-life emotion recognition. This paper proposes a channel selection method to select an optimal subset of EEG channels by using normalized mutual information (NMI). Compared with other methods, the proposed method solves the problem of obtaining a higher recognition rate while reducing EEG channels sharply. First, EEG signals are sliced into fixed-length pieces with a sliding window, and short-time Fourier transform is adopted to capture EEG spectrogram. Then inter-channel connection matrix is calculated based on NMI, and channel reduction is conducted by using thresholding and connection matrix analysis. The experiments are based on the widely-used emotion recognition database DEAP. It can be derived from the experimental results that the proposed method can select optimal EEG channel subsets to a certain number while maintaining high accuracy of 74.41% for valence and 73.64% for arousal with support vector machines. Further analysis also reveals that the distribution of the selected channels is consistent with cortical areas for general emotion tasks.","['Electroencephalography', 'Emotion recognition', 'Mutual information', 'Spectrogram', 'Support vector machines', 'Classification algorithms', 'Brain modeling']","['Channel selection', 'electroencephalography', 'emotion recognition', 'normalized mutual information', 'support vector machine']"
"Financial fraud, such as money laundering, is known to be a serious process of crime that makes illegitimately obtained funds go to terrorism or other criminal activity. This kind of illegal activities involve complex networks of trade and financial transactions, which makes it difficult to detect the fraud entities and discover the features of fraud. Fortunately, trading/transaction network and features of entities in the network can be constructed from the complex networks of the trade and financial transactions. The trading/transaction network reveals the interaction between entities, and thus anomaly detection on trading networks can reveal the entities involved in the fraud activity; while features of entities are the description of entities, and anomaly detection on features can reflect details of the fraud activities. Thus, network and features provide complementary information for fraud detection, which has potential to improve fraud detection performance. However, the majority of existing methods focus on networks or features information separately, which does not utilize both information. In this paper, we propose a novel fraud detection framework, CoDetect, which can leverage both network information and feature information for financial fraud detection. In addition, the CoDetect can simultaneously detecting financial fraud activities and the feature patterns associated with the fraud activities. Extensive experiments on both synthetic data and real-world data demonstrate the efficiency and the effectiveness of the proposed framework in combating financial fraud, especially for money laundering.","['Feature extraction', 'Companies', 'Sparse matrices', 'Electronic mail', 'Complex networks', 'Automation']","['Anomaly feature detection', 'CoDetect', 'financial fraud']"
"Progresses in the areas of artificial intelligence, machine learning, and medical imaging technologies have allowed the development of the medical image processing field with some astonishing results in the last two decades. These innovations enabled the clinicians to view the human body in high-resolution or three-dimensional cross-sectional slices, which resulted in an increase in the accuracy of the diagnosis and the examination of patients in a non-invasive manner. The fundamental step for magnetic resonance imaging (MRI) brain scans classifiers is their ability to extract meaningful features. As a result, many works have proposed different methods for features extraction to classify the abnormal growths in the brain MRI scans. More recently, the application of deep learning algorithms to medical imaging leads to impressive performance enhancements in classifying and diagnosing complicated pathologies, such as brain tumors. In this paper, a deep learning feature extraction algorithm is proposed to extract the relevant features from MRI brain scans. In parallel, handcrafted features are extracted using the modified gray level co-occurrence matrix (MGLCM) method. Subsequently, the extracted relevant features are combined with handcrafted features to improve the classification process of MRI brain scans with support vector machine (SVM) used as the classifier. The obtained results proved that the combination of the deep learning approach and the handcrafted features extracted by MGLCM improves the accuracy of classification of the SVM classifier up to 99.30%.","['Feature extraction', 'Magnetic resonance imaging', 'Tumors', 'Deep learning', 'Biomedical imaging', 'Pathology', 'Image resolution']","['Deep learning', 'MGLCM', 'MRI brain scans', 'feature extraction', 'SVM classifier']"
"In this paper, we modify the Sprott M chaotic system to provide infinitely many co-existing attractors by replacing the offset boosting parameter with a periodic function giving what we call a self-reproducing system. Consequently, a chaotic signal with either polarity can be obtained by selecting different initial conditions. Various periodic functions are introduced in the same offset-boostable system for producing coexisting attractors. We used a field programmable analog array to construct a programmable chaotic circuit, and the predicted attractors were observed on an oscilloscope.","['Chaotic communication', 'Field programmable analog arrays', 'Boosting', 'Eigenvalues and eigenfunctions', 'Hardware', 'Aerospace electronics']","['Field programmable analog array (FPAA)', 'infinitely many attractors', 'offset boosting', 'polarity control']"
"The indoor location technique plays a essential role during the application of quadrotor unmanned aerial vehicle (UAV). However, the control design problem for the quadrotor UAV is quite difficult in the indoor environment due to the weak GPS signal. Based on Ultra Wide Band (UWB), the related positioning issues can be solved of UAV through base station with known coordinate position and equipment with location tag, but it is difficult to meet the high-precision operation requirements. In this paper, an indoor positioning design method combined with the Inertial Measurement Unit (IMU) and UWB positioning technology is proposed, which can effectively suppress the error accumulation of the IMU and further improve the positioning accuracy. Moreover, the system architecture for a class of quadrotor UAV is designed. The multisensor fusion technology based on unscented Kalman filter (UKF) is used to avoid neglecting the high-order terms of the nonlinear observation equations of UWB and IMU, which can effectively improve the accuracy of solving the nonlinear equations. Finally, a hardware-in-the-loop simulation platform is designed to verify the effectiveness of the indoor positioning method and improve the positioning accuracy.","['Kalman filters', 'Unmanned aerial vehicles', 'Base stations', 'Estimation', 'Laser radar', 'Data integration', 'Simultaneous localization and mapping']","['Ultra wide band (UWB)', 'inertial measurement unit (IMU)', 'data fusion', 'indoor localization', 'quadrotor UAV']"
"By considering the different cumulant combinations of the 2FSK, 4FSK, 2PSK, 4PSK, 2ASK, and 4ASK, this paper established new identification parameters to achieve the recognition of those digital modulations. The deep neural network (DNN) was also employed to improve the recognition rate, which was designed to classify the signal based on the distinct feature of each signal type that was extracted with high order cumulants. The extensive simulations demonstrated the exceptional classification performance for new key features based on high order cumulants. The overall success rate of the proposed algorithm was over 99% at the signal to noise ratio (SNR) of −5 dB and 100% at the SNR of −2 dB. The results of the experiments also showed the robustness of the proposed method for a variety of conditions, such as frequency offset, multi-path, and so on.","['Signal to noise ratio', 'Feature extraction', 'Deep learning', 'Digital modulation', 'Neural networks', 'Binary phase shift keying']","['Modulation recognition', 'high order cumulants', 'deep learning', 'wireless communications']"
"Long Range (LoRa) network is emerging as one of the most promising low-power wide-area (LPWA) networks, since it enables the energy-constraint devices distributed over wide areas to establish affordable connectivity. However, how to implement a cost-effective and flexible LoRa network is still an open challenge. This paper aims at exposing a feasible solution of design and implementation, allowing users to conveniently build a private LoRa network for various IoT applications. First, several typical application scenarios of LoRa network are discussed. Then, the LoRa system architecture is presented with the functionality of each component. We address the hardware design and implementation of LoRa Gateway, which is the bridge between LoRa nodes and LoRa network server. Especially, this paper contributes by proposing an improved software architecture of LoRa network server whose source codes are open on GitHub. Under the architecture, LoRa network server is divided into four decoupled modules and uses the messaging system based on streaming data for the interaction between modules to guarantee scalability and flexibility. Finally, the extensive experiments are conducted to evaluate the performance of LoRa networks in typical environments.","['Network servers', 'Logic gates', 'Servers', 'Internet of Things', 'Hardware', 'Computer architecture', 'Sensors']","['LoRa', 'LPWA', 'IoT', 'microservice', 'open source']"
"This paper describes how distributed ledger technologies (DLTs) can be used to enforce social contracts and to orchestrate the behavior of agents trying to access a shared resource. The first part of this paper analyzes the advantages and disadvantages of using DLTs architectures to implement certain control systems in an Internet of Things (IoT) setting and then focuses on a specific type of DLT based on a directed acyclic graph. In this setting, we propose a set of delay differential equations to describe the dynamical behavior of the Tangle, an IoT-inspired directed acyclic graph designed for the cryptocurrency IOTA. The second part proposes an application of DLTs as a mechanism for dynamic deposit pricing, wherein the deposit of digital currency is used to orchestrate access to a network of shared resources. The pricing signal is used as a mechanism to enforce the desired level of compliance according to a predetermined set of rules. After presenting an illustrative example, we analyze the control system and provide sufficient conditions for the stability of the network.","['Automobiles', 'Batteries', 'Smart cities', 'Contracts']","['Distributed ledger technology', 'social compliance', 'smart cities']"
"Motor fault diagnosis based on deep learning frameworks has gained much attention from academic research and industry to guarantee motor reliability. Those methods are commonly under two default assumptions: 1) massive labeled training samples and 2) the training and test data share a similar distribution under unvarying working conditions. Unfortunately, these assumptions are nearly invalid in a real-world scenario, where the signals are unlabeled and the working condition changes constantly, resulting in the diagnosis models of the previous studies that always fail in classifying the unlabeled data in real applications. To deal with those issues, in this paper, we propose a novel feature adaptive motor fault diagnosis using deep transfer learning to improve the performance by transferring the knowledge learned from labeled data under invariant working conditions to the unlabeled data under constantly changing working conditions. A convolutional neural network (CNN) is adopted as the base framework to extract multi-level features from raw vibration signals. Then, the regularization term of maximum mean discrepancy (MMD) is incorporated in the training process to impose constraints on the CNN parameters to reduce the distribution mismatch between the features in the source and target domains. To verify the effectiveness of our proposal, data from the motor tests of European driving cycle (NEDC) for simulating the real working scenario and the motor tests under invariant working conditions are, respectively, conducted as the target domain and the source domain. The results show that the proposal presents higher diagnosis accuracy for the unlabeled target data than other methods, and it is of applicability to bridge the discrepancy between different domains.","['Employee welfare', 'Feature extraction', 'Fault diagnosis', 'Kernel', 'Deep learning', 'Induction motors', 'Training']","['Motor fault diagnosis', 'transfer learning', 'domain adaptation', 'convolutional neural network (CNN)']"
"Millimeter-wave (mmWave) communication operated in frequency bands between 30 and 300 GHz has attracted extensive attention due to the potential ability of offering orders of magnitude greater bandwidths combined with further gains via beamforming and spatial multiplexing from multi-element antenna arrays. mmwave system may exploit the hybrid analog and digital precoding to achieve simultaneously the diversity, array and multiplexing gain with a lower cost of implementation. Motivated by this, in this paper, we investigate the design of hybrid precoder and combiner with sub-connected architecture, where each radio frequency chain is connected to only a subset of base station antennas from the perspective of energy efficient transmission. The problem of interest is a non-convex and NP-hard problem that is difficult to solve directly. In order to address it, we resort to design a two-layer optimization method to solve the problem of interest by exploiting jointly the interference alignment and fractional programming. First, the analog precoder and combiner are optimized via the alternating-direction optimization method where the phase shifter can be easily adjusted with an analytical structure. Then, we optimize the digital precoder and combiner based on an effective multiple-input multiple-output channel coefficient. The convergence of the proposed algorithms is proved using the monotonic boundary theorem and fractional programming theory. Extensive simulation results are given to validate the effectiveness of the presented method and to evaluate the energy efficiency performance under various system configurations.","['Radio frequency', 'MIMO', 'Antenna arrays', 'Receivers', 'Precoding', 'Wireless communication', 'Transmitters', 'Energy efficiency']","['Millimeter-wave communication', 'multiple-input multiple-output (MIMO) system', 'analog precoding and combining', 'interference alignment', 'energy efficiency']"
"Transfer learning and ensemble learning are the new trends for solving the problem that training data and test data have different distributions. In this paper, we design an ensemble transfer learning framework to improve the classification accuracy when the training data are insufficient. First, a weightedresampling method for transfer learning is proposed, which is named TrResampling. In each iteration, the data with heavy weights in the source domain are resampled, and the TrAdaBoost algorithm is used to adjust the weights of the source data and target data. Second, three classic machine learning algorithms, namely, naive Bayes, decision tree, and SVM, are used as the base learners of TrResampling, where the base learner with the best performance is chosen for transfer learning. To illustrate the performance of TrResampling, the TrAdaBoost and decision tree are used for evaluation and comparison on 15 UCI data sets, TrAdaBoost, ARTL, and SVM are used for evaluation and comparison on five text data sets. According to the experimental results, our proposed TrResampling is superior to the state-of-the-art learning methods on UCI data sets and text data sets. In addition, TrResampling, bagging-based transfer learning algorithm, and MultiBoosting-based transfer learning algorithm (TrMultiBoosting) are assembled in the framework, and we compare the three ensemble transfer learning algorithms with TrAdaBoost to illustrate the framework's effective transfer ability.","['Training data', 'Boosting', 'Machine learning algorithms', 'Bagging', 'Support vector machines', 'Training']","['Transfer learning', 'bagging', 'boosting', 'ensemble learning']"
"Finger-vein recognition has the advantages of high immutability, as finger veins are located under the skin, high user convenience, as a non-invasive and contactless capture device, is used, and high readability even when one of the fingers is damaged or not available for recognition. However, there is an issue of recognition performance degradation caused by finger positional variation, misalignment, and shading from uneven illumination. The existing hand-crafted feature-based methods have exhibited varied performance depending on how these issues were handled by pre-processing. To overcome this shortcoming of hand-crafted feature-based methods, convolutional neural network (CNN)-based recognition methods have been researched. The existing systems based on a CNN use two methods: using a difference image as the input to the network and calculating the distance between feature vectors extracted from the CNN. Difference images can be susceptible to noise as they are generated by differences in pixel values. Also, the method for calculating the distance between feature vectors cannot employ all layers of the trained network and has less accuracy than the method employing difference images. To address these issues, this paper examined a method less susceptible to noise and which uses the entire network; a composite image of two finger-vein images was used as the input to a deep, densely-connected convolutional network (DenseNet). Two open databases, namely Shandong University homologous multi-modal traits (SDUMLA-HMT) finger-vein database and The Hong Kong Polytechnic University finger image database (version 1), were used for experiments and the results show that the proposed method has greater performance than the existing methods.","['Feature extraction', 'Image recognition', 'Gabor filters', 'Veins', 'Support vector machines', 'Shape', 'Performance evaluation']","['Finger-vein recognition', 'composite image', 'deep DenseNet']"
"Mining methods use cemented tailings backfill (CTB) for filling mined-out voids and make operations safer since employees are working under it. Hence, the durability behavior of CTB is of great importance in applications, for example, in the assessment of slope stability when extracting ore left in neighboring stopes. Addition of cement content would increase the strength of CTB but creates extra costs to mines. To cut cement-related costs as well as improve durability, different types of fibers are added to CTB samples. This paper aims to analyze flexural behavior of fiber reinforced CTB samples under three-point bending loading. To do so, a comprehensive laboratory work was undertaken to explore the effect of fiber reinforcement on bending resistance of CTB samples, based on orthogonal experimental design. The effect of fiber type (FT), fiber content (FC), solid content (SC) and cement-to-tailings ratio (c/t) on bending characteristics was investigated. Results indicate that the addition of fiber enhances the bending strength of fiber reinforced CTB samples and the bearing capacity after the peak in the load-deflection curve. Fibers help correct the faintness of CTB samples by mobilizing tensile strength along the failure planes. The crack resistance of fiber is reflected in the crack propagation stage. Secondly, the order of the sensitivity of four factors on bending strength of fiber reinforced CTB samples is as follows: c/t > SC > FT > FC. Lastly, the main findings of this study can provide a major reference for CTB's last design in underground mining.","['Optical fiber testing', 'Optical fiber theory', 'Water pollution', 'Mechanical factors', 'Loading', 'Metals']","['Cemented tailings backfill', 'fiber types and properties', 'bending strength testing', 'load-deflection analysis', 'microstructural characteristics']"
"Over the last two decades, Artificial Intelligence (AI) approaches have been applied to various applications of the smart grid, such as demand response, predictive maintenance, and load forecasting. However, AI is still considered to be a “black-box” due to its lack of explainability and transparency, especially for something like solar photovoltaic (PV) forecasts that involves many parameters. Explainable Artificial Intelligence (XAI) has become an emerging research field in the smart grid domain since it addresses this gap and helps understand why the AI system made a forecast decision. This article presents several use cases of solar PV energy forecasting using XAI tools, such as LIME, SHAP, and ELI5, which can contribute to adopting XAI tools for smart grid applications. Understanding the inner workings of a prediction model based on AI can give insights into the application field. Such insight can provide improvements to the solar PV forecasting models and point out relevant parameters.","['Tools', 'Predictive models', 'Forecasting', 'Smart grids', 'Random forests']","['Explainable artificial intelligence (XAI)', 'solar PV power generation forecasting', 'explainability and transparency']"
"The heated 5G network deployment race has already begun with the rapid progress in standardization efforts, backed by the current market availability of 5G-enabled network equipment, ongoing 5G spectrum auctions, early launching of non-standalone 5G network services in a few countries, among others. In this paper, we study current and future wireless networks from the viewpoint of energy efficiency (EE) and sustainability to meet the planned network and service evolution toward, along, and beyond 5G, as also inspired by the findings of the EU Celtic-Plus SooGREEN Project. We highlight the opportunities seized by the project efforts to enable and enrich this green nature of the network as compared to existing technologies. In specific, we present innovative means proposed in SooGREEN to monitor and evaluate EE in 5G networks and beyond. Further solutions are presented to reduce energy consumption and carbon footprint in the different network segments. The latter spans proposed virtualized/cloud architectures, efficient polar coding for fronthauling, mobile network powering via renewable energy and smart grid integration, passive cooling, smart sleeping modes in indoor systems, among others. Finally, we shed light on the open opportunities yet to be investigated and leveraged in future developments.","['Energy consumption', '5G mobile communication', 'Green products', 'Optimization', 'Sustainable development', 'Cooling', 'Quality of service']","['CRAN', 'DAS', 'energy efficiency', 'monitoring', 'storage', 'green mobile networks', 'passive cooling', 'renewable energy', 'sleep modes', 'smart grid', 'virtualization', 'Wi-Fi']"
"This paper describes the flight path planning for unmanned aerial vehicles (UAVs) based on the advanced swarm optimization algorithm of the bat algorithm (BA) in a static environment. The main purpose of this work is that the UAVs can obtain an accident-free, shorter, and safer flight path between the starting point and the endpoint in the complex three-dimensional battlefield environment. Based on the characteristics of the standard BA and the artificial bee colony algorithm (ABC), a new modification of the BA algorithm is proposed in this work, namely, the improved bat algorithm integrated into the ABC algorithm (IBA). The IBA mainly uses ABC to modify the BA and solves the problem of poor local search ability of the BA. This article demonstrates the convergence of the IBA and performs simulations in MATLAB environment to verify its effectiveness. The simulations showed that the time required for the IBA to obtain the optimum solution is approximately 50% lower than the BA, and that the quality of the optimum solution is about 14% higher than the ABC. Furthermore, by comparing with other traditional and improved swarm intelligent path planning algorithms, the IBA can plan a faster, shorter, safer, accident-free flight path for UAVs. Finally, this article proves that IBA also has good performance in optimizing functions and has broad application potential.","['Path planning', 'Optimization', 'Heuristic algorithms', 'Planning', 'Convergence', 'Radar', 'Particle swarm optimization']","['Battlefield environment', 'path planning', 'improved bat algorithm', 'convergence', 'local search']"
"Feature selection (FS), an important pre-processing step in the fields of machine learning and data mining, has immense impact on the outcome of the corresponding learning models. Basically, it aims to remove all possible irrelevant as well as redundant features from a feature vector, thereby enhancing the performance of the overall prediction or classification model. Over the years, meta-heuristic optimization techniques have been applied for FS, as these are able to overcome the limitations of traditional optimization approaches. In this work, we introduce a binary variant of the recently-proposed Sailfish Optimizer (SFO), named as Binary Sailfish (BSF) optimizer, to solve FS problems. Sigmoid transfer function is utilized here to map the continuous search space of SFO to a binary one. In order to improve the exploitation ability of the BSF optimizer, we amalgamate another recently proposed meta-heuristic algorithm, namely adaptive β-hill climbing (AβHC) with BSF optimizer. The proposed BSF and AβBSF algorithms are applied on 18 standard UCI datasets and compared with 10 state-of-the-art meta-heuristic FS methods. The results demonstrate the superiority of both BSF and AβBSF algorithms in solving FS problems. The source code of this work is available in https://github.com/Rangerix/MetaheuristicOptimization.","['Optimization', 'Heuristic algorithms', 'Sociology', 'Statistics', 'Feature extraction', 'Machine learning algorithms', 'Machine learning']","['Binary sailfish optimizer', 'feature selection', 'adaptive β-hill climbing', 'hybrid optimization', 'UCI dataset']"
"The increase in the volume of user-generated content on Twitter has resulted in tweet sentiment analysis becoming an essential tool for the extraction of information about Twitter users' emotional state. Consequently, there has been a rapid growth of tweet sentiment analysis in the area of natural language processing. Tweet sentiment analysis is increasingly applied in many areas, such as decision support systems and recommendation systems. Therefore, improving the accuracy of tweet sentiment analysis has become practical and an area of interest for many researchers. Many approaches have tried to improve the performance of tweet sentiment analysis methods by using the feature ensemble method. However, most of the previous methods attempted to model the syntactic information of words without considering the sentiment context of these words. Besides, the positioning of words and the impact of phrases containing fuzzy sentiment have not been mentioned in many studies. This study proposed a new approach based on a feature ensemble model related to tweets containing fuzzy sentiment by taking into account elements such as lexical, word-type, semantic, position, and sentiment polarity of words. The proposed method has been experimented on with real data, and the result proves effective in improving the performance of tweet sentiment analysis in terms of theF1score.","['Sentiment analysis', 'Feature extraction', 'Analytical models', 'Semantics', 'Twitter', 'Syntactics']","['Feature ensemble model', 'fuzzy sentiment', 'tweet embeddings', 'tweet sentiment analysis']"
"Interval-valued Pythagorean fuzzy (IVPF) set is one the successful extension of the existing theories for handling the uncertainties during the decision-making process. Under that environment, various aggregation operators have been developed by the authors to aggregate the different preferences of the decision makers under the different attributes. But these studies have conducted under the assumption that their corresponding pairs are independent and don’t consider the interaction between the pairs of the membership degrees. In this paper, these conditions have been relaxed by considering the interrelationship between the different inputs by using Maclaurin symmetric mean (MSM) operator. Further, based on the input and MSM operator, we proposed two aggregation operators namely, IVPF Maclaurin symmetric mean and IVPF weighted Maclaurin symmetric mean operators and studied their desirable properties. A decision-making method based on these operators has been discussed for solving the decision-making problems under IVPF set environment. Finally, an illustrative example and a comparative analysis have been presented to demonstrate the proposed approach.","['Decision making', 'Uncertainty', 'Fuzzy sets', 'Aggregates', 'STEM']","['Multiple attribute decision making (MADM)', 'MSM operator', 'IVPFS', 'aggregation operators', 'potential evaluation', 'emerging technology commercialization']"
"This paper surveys the current research status of location privacy issues in mobile applications. The survey spans five aspects of study: the definition of location privacy, attacks and adversaries, mechanisms to preserve the privacy of locations, location privacy metrics, and the current status of location-based applications. Through this comprehensive review, all the interrelated aspects of location privacy are integrated into a unified framework. Additionally, the current research progress in each area is reviewed individually, and the links between existing academic research and its practical applications are identified. This in-depth analysis of the current state-of-play in location privacy is designed to provide a solid foundation for future studies in the field.","['Privacy', 'Measurement', 'Servers', 'Real-time systems', 'Systematics', 'Trajectory', 'Global Positioning System']","['Location privacy', 'location-based service', 'mobile applications']"
"The proliferation of embedded systems, wireless technologies, and Internet protocols have enabled the Internet of Things (IoT) to bridge the gap between the virtual and physical world through enabling the monitoring and actuation of the physical world controlled by data processing systems. Wireless technologies, despite their offered convenience, flexibility, low cost, and mobility pose unique challenges such as fading, interference, energy, and security, which must be carefully addressed when using resource-constrained IoT devices. To this end, the efforts of the research community have led to the standardization of several wireless technologies for various types of application domains depending on factors such as reliability, latency, scalability, and energy efficiency. In this paper, we first overview these standard wireless technologies, and we specifically study the MAC and physical layer technologies proposed to address the requirements and challenges of wireless communications. Furthermore, we explain the use of these standards in various application domains, such as smart homes, smart healthcare, industrial automation, and smart cities, and discuss their suitability in satisfying the requirements of these applications. In addition to proposing guidelines to weigh the pros and cons of each standard for an application at hand, we also examine what new strategies can be exploited to overcome existing challenges and support emerging IoT applications.","['Wireless sensor networks', 'Wireless communication', 'Bluetooth', 'Internet of Things', 'Protocols', 'IEEE 802.15 Standard']","['Internet of Things', 'IEEE 802.15.4', 'Bluetooth', 'Physical layer', 'Medium Access Control', 'coexistence', 'mesh networking', 'cyber-physical systems', 'WSN', 'M2M']"
"Cardiovascular disease tops the list among all major causes of deaths worldwide. Though, prognostication and in-time diagnosis can help in reducing the mortality rate as well as increases the survival rate of patients. Unavailability or scarcity of radiologists and doctors in different countries due to several reasons is a significant factor for hindrance in early diagnosis. Among various efforts of developing the decision support systems, computational intelligence is an emerging trend in the field of medical imaging to detect, prognosticate and diagnose the disease. It helps radiologists and doctors to get relief from being over-burdened and minimizes the induced delays for in-time diagnosis of patients. In this work, a machine intelligence framework for heart disease diagnosis MIFH has been proposed. MIFH utilizes the factor analysis of mixed data (FAMD) to extract as well as derive features from the UCI heart disease Cleveland dataset and train the machine learning predictive models. The framework MIFH is validated using the holdout validation scheme. Experimentation results show that MIFH performed well over several baseline methods of recent times in terms of accuracy and comparable in terms of sensitivity and specificity. MIFH returns best possible solution among all input predictive models considering performance criteria and improves the efficacy of the system, hence can assist doctors and radiologists in a better way to diagnose heart patients.","['Heart', 'Diseases', 'Feature extraction', 'Medical diagnostic imaging', 'Machine learning', 'Predictive models']","['Cleveland', 'UCI repository', 'FAMD', 'random forest', 'feature selection', 'cardiovascular']"
"The condition monitoring of railway track line is one of the essential tasks to ensure the safety of the railway transportation system. Railway track line is mainly composed of tracks, fasteners, sleepers, and so on. Given the requirements for rapid and accurate inspection, innovative and intelligent methods for multi-target defect identification of the railway track line using image processing and deep learning methods are proposed in this paper. Firstly, the track and fastener positioning method based on variance projection and wavelet transform is introduced. After that, a bag-of-visual-word (BOVW) model combined with spatial pyramid decomposition is proposed for railway track line multi-target defect detection with a detection accuracy of 96.26%. Secondly, an improved YOLOv3 model named TLMDDNet (Track Line Multi-target Defect Detection Network), integrating scale reduction and feature concatenation, is proposed to enhance detection accuracy and efficiency. Finally, to reduce model complexity and further improve the detection speed, with the help of dense connection structure, a lightweight design strategy for the TLMDDNet model named DC-TLMDDNet (Dense Connection Based TLMDDNet) is proposed, in which the DenseNet is applied to optimize feature extraction layers in the backbone network of TLMDDNet. The effectiveness of the proposed methods is demonstrated by the experimental results.",[],[]
"An enormous amount of digital information is expressed as natural-language (NL) text that is not easily processable by computers. Knowledge Graphs (KG) offer a widely used format for representing information in computer-processable form. Natural Language Processing (NLP) is therefore needed for mining (or lifting) knowledge graphs from NL texts. A central part of the problem is to extract the named entities in the text. The paper presents an overview of recent advances in this area, covering: Named Entity Recognition (NER), Named Entity Disambiguation (NED), and Named Entity Linking (NEL). We comment that many approaches to NED and NEL are based on older approaches to NER and need to leverage the outputs of state-of-the-art NER systems. There is also a need for standard methods to evaluate and compare named-entity extraction approaches. We observe that NEL has recently moved from being stepwise and isolated into an integrated process along two dimensions: the first is that previously sequential steps are now being integrated into end-to-end processes, and the second is that entities that were previously analysed in isolation are now being lifted in each other's context. The current culmination of these trends are the deep-learning approaches that have recently reported promising results.","['Task analysis', 'Natural language processing', 'Semantics', 'Standards', 'Hidden Markov models', 'Iris recognition', 'Data mining']","['Knowledge graphs', 'natural-language processing', 'named-entity extraction', 'named-entity recognition', 'named-entity disambiguation', 'named-entity linking']"
"An interval-valued picture fuzzy set (IVPFS) is one of the generalizations of an interval-valued fuzzy set to handle the uncertainties in the data during analysis. The aim of this paper is to introduce and study new operations of IVPFS, along with its properties, and examples. In addition, we present the notion of the interval-valued picture fuzzy soft set theory and investigated their properties. Several operations on such as subset, equal, complement, inf product, sup product, union, and intersection are defined over the interval-valued picture fuzzy soft set and discussed their basic properties. Furthermore, we construct an algorithm using an interval-valued picture fuzzy soft set to solve the decision-making problems and illustrate its applicability through a numerical example. From the study, we conclude that the proposed approach is viable in order to handle the uncertainties during the decision-making problems.","['Decision making', 'Fuzzy sets', 'Uncertainty', 'Frequency selective surfaces', 'Information science', 'STEM']","['Picture fuzzy set', 'interval-valued picture fuzzy set', 'interval-valued picture fuzzy soft set', 'decision-making', 'soft set']"
"Land cover change detection (LCCD) based on bitemporal remote sensing images has become a popular topic in the field of remote sensing. Despite numerous methods promoted in recent decades, an improvement on the usability and performance of these methods has remained necessary. In this paper, a novel LCCD approach based on the integration of k-means clustering and adaptive majority voting (kmeans_AMV) techniques have been developed. The proposed k-means_AMV method consists of three major techniques. First, to utilize the contextual information in an adaptive manner, an adaptive region around a central pixel is constructed by detecting the spectral similarity between the central pixel and its eight neighboring pixels. Second, when the extension for the adaptive region is terminated, the k-means clustering method is applied to determine the label of each pixel within the adaptive region. Finally, an existing AMV technique is used to refine the label of the central pixel of the adaptive region. When change magnitude image (CMI) is scanned and processed in this manner, the label of each pixel in the CMI can be refined and the binary change detection map can be generated. Three image scenes related to different land cover change events are adapted to test the effectiveness and performance of the proposed k-means_AMV approach. The results show that the proposed k-means_AMV approach demonstrates better detection accuracies and visual performance than that of the several extensively used methods.","['Remote sensing', 'Clustering algorithms', 'Spatial resolution', 'Training', 'Earth', 'Satellite broadcasting']","['Adaptive majority voting', 'k-means clustering', 'land cover change detection', 'remote sensing images']"
"Meta-heuristic algorithms have gained substantial popularity in recent decades and have focused on applications in a wide spectrum of fields. In this paper, a new and powerful physics-based algorithm named nuclear reaction optimization (NRO) is presented. Meanwhile, NRO imitates the nuclear reaction process and consists of two phases, namely, a nuclear fission (NFi) phase and a nuclear fusion (NFu) phase. The Gaussian walk and differential evolution operators between nucleus and neutron are employed for exploitation and appropriate exploration in the (NFi) phase, respectively. Meanwhile, the variants of differential evolution operator are utilized for exploration in the NFu phase, which consists of the ionization and fusion stages. Additionally, the variants of Levy flight are used for random searching to escape from the local optima in each stage of the NFu phase. The exploration and exploitation abilities of NRO can be balanced due to a combination of the two phases. Both constrained and unconstrained benchmark functions are employed for testing the performance of NRO. To make comparisons between NRO and the state-of-the-art algorithms, 23 classic benchmark functions and twenty-night modern benchmark functions are performed. Moreover, three engineering design optimization problems are solved as constrained benchmark functions by using NRO and the compared algorithms. The results illustrate that the proposed nuclear reaction optimization algorithm is a potential and powerful approach for global optimization.","['Optimization', 'Heuristic algorithms', 'Sociology', 'Statistics', 'Classification algorithms', 'Benchmark testing', 'Chemicals']","['Differential evolution operator', 'engineering design optimization', 'global optimization', 'Levy flight strategy', 'nuclear reaction optimization (NRO)', 'physics-based algorithm']"
"Online parameter estimation of permanent magnet synchronous machines is critical for improving their control performance and operational reliability. This paper provides an overview of the recent achievements of online parameter estimation of PMSMs with examples. The critical issues in parameter estimation are firstly analysed, especially the rank-deficient issue and inverter nonlinearities. Then, the state-of-the-art online parameter estimation modelling techniques are reviewed and assessed. Finally, some typical applications and examples are outlined, e.g. estimation of mechanical parameters, improvement of sensored and sensorless control performance, thermal condition monitoring, and fault diagnosis, together with future research trends.","['Estimation', 'Inductance', 'Couplings', 'Rotors', 'Parameter estimation', 'Magnetic flux', 'Saturation magnetization']","['Condition monitoring', 'control performance', 'electrical parameter', 'fault diagnosis', 'mechanical parameter', 'online parameter estimation', 'permanent magnet synchronous machine', 'sensorless control']"
"In this paper, the chaotic bat algorithm (CBA) is applied to solve the optimal reactive power dispatch (ORPD) problem taking into account small-scale, medium-scale and large-scale power systems. ORPD plays a key role in the power system operation and control. The ORPD problem is formulated as a mixed integer nonlinear programming problem, comprising both continuous and discrete control variables. The most outstanding benefit of the bat algorithm (BA) is its good convergence for optimal solutions. The BA, however, together with other metaheuristics, often gets stuck into local optima and in order to cope with this shortcoming, the use of the CBA is proposed in this paper. The CBA results from introducing the chaotic sequences into the standard BA to enhance its global search ability. The CBA is utilized to find the optimal settings of generator bus voltages, tap setting transformers and shunt reactive power sources. Three objective functions such as minimization of active power loss, total voltage deviations and voltage stability index are considered in this study. The effectiveness of the CBA technique is demonstrated for standard IEEE 14-bus, IEEE 39 New England bus, IEEE 57-bus, IEEE 118-bus and IEEE 300-bus test systems. The results yielded by the CBA are compared with other algorithms available in the literature. Simulation results reveal the effectiveness and robustness of the CBA for solving the ORPD problem.","['Power system stability', 'Optimization', 'Indexes', 'Reactive power', 'Stability criteria', 'Search problems', 'Heuristic algorithms']","['Chaotic bat algorithm', 'optimal reactive power dispatch', 'chaotic sequences']"
"Alzheimer's Disease (AD) is a chronic neurodegenerative disease. Early diagnosis will considerably decrease the risk of further deterioration. Unfortunately, current studies mainly focus on classifying the states of disease in its current stage, instead of predicting the possible development of the disease. Long short-term memory (LSTM) is a special kind of recurrent neural network, which might be able to connect previous information to the present task. Noticing that the temporal data for a patient are potentially meaningful for predicting the development of the disease, we propose a predicting model based on LSTM. Therefore an LSTM network, with fully connected layer and activation layers, is built to encode the temporal relation between features and the next stage of Alzheimer's Disease. The Experiments show that our model outperforms most of the existing models.","[""Alzheimer's disease"", 'Magnetic resonance imaging', 'Biological neural networks', 'Logic gates', 'Predictive models', 'Time series analysis']","['Alzheimer’s Disease', 'Prediction', 'LSTM', 'Time Sequence', 'Magnetic Resonance Imaging']"
"A home energy management system (HEMS) can potentially enable demand response (DR) applications for residential customers. This paper presents a detailed pricing-based DR for a smart home with various types of household appliances considering customer satisfaction. A wide variety of household appliances with different characteristics, together with energy storage units (ESUs) and distributed energy resources (DERs) can be flexibly incorporated in the proposed scheme. Besides, with a developed satisfaction model suitable for different types of household appliances, the proposed HEMS can provide multiple flexible solutions with different user satisfaction levels to occupants. In addition, other different DR strategies such as demand-limit-based DR and injection-limit-based DR can be easily adapted to the formulated scheme in this work. The numerical results reported in this paper demonstrate the effectiveness of the proposed scheme. The proposed scheme is generally applicable and valuable for any other kinds of the smart home.","['Home appliances', 'Water heating', 'Smart homes', 'Optimization', 'Load management', 'Smart meters', 'Weather forecasting']","['Demand response (DR)', 'distributed energy resource (DER)', 'energy storage units (ESUs)', 'home energy management system (HEMS)', 'roof-mounted photovoltaic (PV)', 'smart home', 'smart meter', 'smart grid']"
"A huge amount of potentially dangerous COVID-19 misinformation is appearing online. Here we use machine learning to quantify COVID-19 content among online opponents of establishment health guidance, in particular vaccinations (“anti-vax”). We find that the anti-vax community is developing a less focused debate around COVID-19 than its counterpart, the pro-vaccination (“pro-vax”) community. However, the anti-vax community exhibits a broader range of “flavors” of COVID-19 topics, and hence can appeal to a broader cross-section of individuals seeking COVID-19 guidance online, e.g. individuals wary of a mandatory fast-tracked COVID-19 vaccine or those seeking alternative remedies. Hence the anti-vax community looks better positioned to attract fresh support going forward than the pro-vax community. This is concerning since a widespread lack of adoption of a COVID-19 vaccine will mean the world falls short of providing herd immunity, leaving countries open to future COVID-19 resurgences. We provide a mechanistic model that interprets these results and could help in assessing the likely efficacy of intervention strategies. Our approach is scalable and hence tackles the urgent problem facing social media platforms of having to analyze huge volumes of online health misinformation and disinformation.","['Vaccines', 'Machine learning', 'Facebook', 'Coherence', 'Public healthcare', 'Immune system', 'COVID-19']","['COVID-19', 'machine learning', 'topic modeling', 'mechanistic model', 'social computing']"
"The next generation of vehicles will be autonomous, connected, electric, and intelligent with distinct requirements such as high mobility, low latency, real-time applications, seamless connectivity, and security. Blockchain can provide a good solution to the issue of secure message dissemination or secure information sharing in vehicular networks with a weak trust relationship among the nodes. In this paper, we investigate the design of a regional blockchain for VANETs, where the blockchain is shared among nodes in a geographically bounded area. We investigate how to design the regional blockchain while achieving a low 51% attack success probability. We derive a condition that guarantees a low 51% attack success probability in terms of the numbers of good nodes and malicious nodes, the message delivery time, and the puzzle computation time. The condition can provide a useful guideline for selection of several control parameters guaranteeing the stable operation of the blockchain. We run several simulations to show the validity of the condition and investigate the effects of various parameters on the 51% attack success probability. Our analysis and simulation results show that maintaining a low message delivery time for good nodes is very important in protecting the stability of the blockchain system.","['Blockchain', 'Vehicular ad hoc networks', 'Security', 'Peer-to-peer computing', 'Delays', 'Accidents', 'Guidelines']","['Blockchain', 'regional blockchain', 'security', '51% attack', 'immutability attack']"
"This paper proposes a new active-neutral-point clamped (ANPC) seven-level inverter based on switched-capacitor technique. The proposed seven-level inverter employs only nine switches and one floating capacitor. With the input amplitude of V DC , the peak output of the proposed topology can reach 1.5V DC . Its boost ability indicates a wider range of output compared with other APNC converters. Needless for auxiliary control methods, the voltages of capacitors in dc link can naturally maintain at 0.5V DC , and the floating capacitor can get self-balance at V DC . The mechanism of natural balance for capacitors and the operation principle of the proposed topology are described in detail. The merits of the proposed topology on reduced components, lower overall voltage stress, natural balance, and boost ability are also demonstrated through the comparison against the latest similar topologies, showing its suitability for distributed generation, electric vehicle, and other applications. Definitively, the simulation and experimental prototype are implemented to verify the feasibility and performance of the proposed topology. The voltage balance of capacitors has been fully demonstrated through multiple transient experiments.","['Inverters', 'Topology', 'Capacitors', 'Switches', 'Modulation', 'Stress', 'Transistors']","['Multilevel', 'switched-capacitor', 'boost', 'natural balance', 'reduced components']"
"The recent development of big data analytics (BDA) and the Internet of Things (IoT) technologies create a huge opportunity for both disaster management systems and disaster-related authorities (emergency responders, police, public health, and fire departments) to acquire state-of-the-art assistance and improved insights for accurate and timely decision-making. The motivation behind this research is to pave the way for effective utilization of the available opportunities that the BDA and IoT collaboratively offer to predict, understand and monitor disaster situations. Most of the conventional disaster management systems lack the support for multiple new data sources and real-time big data processing tools that can assist decision makers with quick and accurate results. This paper highlights the importance of BDA and IoT for disaster management and investigates recent studies directed towards the same. We classify a thematic taxonomy with several related attributes and inspect the prevalent solutions to propose a conceptual reference model for the deployment of BDA- and IoT-based disaster management environments. The reference model with its proposed integrated parameters can provide guidelines to harvest, transmit, manage, and analyze disaster data from various data sources to deliver updated and valuable information for disaster management. We also enumerate some important use cases from a disaster management perspective. Finally, we highlight the main research challenges that need to be addressed in such an important field of research.","['Disaster management', 'Internet of Things', 'Big Data', 'Taxonomy', 'Decision making', 'Real-time systems', 'Sensors']","['Big data analytics', 'data sources', 'disaster communications', 'disaster management', 'Internet of Things', 'reference model', 'taxonomy']"
"Since the release of the first mobile devices, the usability of on-board applications has been the concern not only of software vendors but hardware manufacturers as well. The academia community later willingly joined the discussion on usability in terms of theory and empirical measurement, having experience and knowledge in desktop settings. At first sight, such a background should guarantee a solid foundation to conduct research on software usability in a new setting. However, a preliminary study on the subject matter revealed methodological disorder in contemporary literature. As a matter of fact, a need emerged to review existing usability definitions, attributes and measures to recognize all associated aspects. In order to fill this void, we conducted a systematic literature review on usability studies indexed by the Scopus database and devoted to mobile applications. The input volume covers 790 documents from 2001 to 2018. The data analysis shows that the ISO 9241-11 usability definition has been adopted in an unchanged form and popularized as the standard by the HCI community. Secondly, in total, 75 attributes were identified and analysed. The most frequent are efficiency (70%), satisfaction (66%) and effectiveness (58%), which directly originate from the above definition. Subsequently, the less frequent are learnability (45%), memorability (23%), cognitive load (19%) and errors (17%). The last two concern simplicity (13%) and ease of use (9%). Thirdly, in the evaluation of usability, controlled observation and surveys are two major research methods applied, while eye-tracking, thinking aloud and interview are hardly used and serve as complementary to collect additional data. Moreover, usability evaluations are often confused with user experience dimensions, covering not only application quality characteristics, but also user beliefs, emotions and preferences. All these results indicate the need for further research on the usability of mobile applications, aiming to establish a consensus in the theory and practice among all interested parties.","['Usability', 'Mobile applications', 'Systematics', 'Bibliographies', 'ISO Standards', 'Smart phones']","['Mobile applications', 'usability', 'attributes', 'measures', 'usability evaluation methods', 'systematic literature review']"
"Accurate wind power prediction provides significant guarantee for power grid dispatching, and wind speed prediction, as the basic link of wind power forecasting, has crucial theoretical research significance and practical application value. In this paper, we present the wind speed prediction of IPSOBP neural network based on Lorenz disturbance. At first, the data is processed by principal component analysis (PCA) to select the key factors affecting wind speed, which can effectively reduce the complexity of model. Then, the improved particle swarm optimization (IPSO) algorithm is used to globally optimize the weights and thresholds of BP neural network, and overcome the problem of local minimum value. The initial prediction results can be obtained by the IPSO-BPNN model. Finally, Lorenz system is introduced to correct the initial prediction value and improve forecasting accuracy. According to the wind farm data of Spain and Chang Ma in China, we take an empirical research to analyze the optimization effect of IPSO algorithm and the promotion effect of Lorenz system on the precision of preliminary forecasting. The results are as follows: 1) IPSO algorithm accelerates the convergence rate of weights and thresholds of BP neural network and 2) Lorenz disturbance system obviously weakens the random volatility of wind speed, effectively modifies its preliminary prediction results, and upgrades its prediction accuracy.","['Wind speed', 'Neural networks', 'Prediction algorithms', 'Wind power generation', 'Forecasting', 'Convergence', 'Principal component analysis']","['BP neural network', 'IPSO', 'Lorenz system', 'PCA', 'short-term wind prediction']"
"Convolutional neural networks (CNNs) have found applications in ship detection from synthetic aperture radar (SAR) images. However, there are some challenges hamper their advance. First, the detected bounding boxes are not very compact. Second, there are quite a few missing detections for small and densely clustered ships. Third, objects with analogical scatterings on land are detected as ships by making mistake. This is due to: 1) the CNN-based SAR ship detectors cannot utilize the spatial information very sufficiently; 2) features learned from CNNs only describe SAR images in space domain while neglecting the information hidden in frequency domain; and 3) information contained in the meta-data file, which may link to other sources, is not taken into account. To overcome these problems, in this paper, a cascade coupled CNN-guided (3C2N-guided) visual attention method for SAR ship detection is proposed. This method considers the newly presented 3C2N model as a qualified ship proposal generator because the images' spatial information is utilized more sufficiently. The 3C2N model, with coupled CNN as the baseline, consists of a sequence of cascade detectors for training. Complementally, a pulse cosine transformation-based visual attention model in frequency domain is operated on the adaptive regions for ship discrimination. This could further refine the proposals' locations and could significantly reduce the missing detections and false alarms. In addition, the digital elevation model data are adopted to remove ship-like targets on land. Experimental evaluations on 25 Sentinel-1 images demonstrate that the proposed method is superior to the previous state-of-the-art methods.",[],[]
"The World Health Organization identifies the overall increasing of noncommunicable diseases as a major issue, such as premature heart diseases, diabetes, and cancer. Unhealthy diets have been identified as the important causing factor of such diseases. In this context, personalized nutrition emerges as a new research field for providing tailored food intake advices to individuals according to their physical, physiological data, and further personal information. Specifically, in the last few years, several types of research have proposed computational models for personalized food recommendation using nutritional knowledge and user data. This paper presents a general framework for daily meal plan recommendations, incorporating as main feature the simultaneous management of nutritional-aware and preference-aware information, in contrast to the previous works which lack this global viewpoint. The proposal incorporates a pre-filtering stage that uses AHPSort as multi-criteria decision analysis tool for filtering out foods which are not appropriate to the current user characteristics. Furthermore, it incorporates an optimization-based stage for generating a daily meal plan whose goal is the recommendation of food highly preferred by the user, not consumed recently, and satisfying his/her daily nutritional requirements. A case study is developed for testing the performance of the recommender system.","['Recommender systems', 'Optimization', 'Proposals', 'Diseases', 'Task analysis', 'Tools', 'Planning']","['Daily meal plan recommendation', 'user preferences', 'nutritional information', 'multi-criteria decision making', 'recommender systems']"
"In recent years, intelligent railway operation and maintenance using cloud technology have received wide consideration for the provision of public transport services. Under the cloud environment, information security is critical to ensure the integrity of data through protection from unauthorized manipulation and the confidentiality through protection against the leakage of sensitive information. This paper proposes a lightweight authenticated encryption scheme with associated data based on a novel discrete chaotic S-box coupled map lattice (SCML), which avoids the dynamic degradation of the digital chaotic system and low efficiency of the chaos-based cryptosystem. Based on the chaotic SCML, an authenticated encryption scheme that protects the confidentiality and integrity in one pass is presented in detail. The security analysis and performance simulations in software and hardware show that the proposed scheme is efficient and provides adequate security through authentication and encryption. Such a scheme could be used for applications in a railway cloud service that requires moderate security and low-cost implementations.","['Lattices', 'Rail transportation', 'Encryption', 'Cloud computing', 'Correlation']","['Chaos', 'cryptography', 'message authentication', 'encryption', 'Internet of Things', 'security', 'clouds', 'hardware']"
"Sustainable electrification planning for remote locations especially in developing countries is very complex in nature while considering different traits such as social, economic, technical, and environmental. To address these issues related to current energy needs depending upon the end user requirements, a coherent, translucent, efficient, and rational energy planning framework has to be identified. This paper presents a comprehensive generalized methodological framework based on the synergies of decision analysis and optimization models for the design of a reliable, robust, and economic microgrid system based on locally available resources for rural communities in developing nations. The framework consists of three different stages. First, decision analysis considering various criterions (technical, social, economic, and environmental) for the selection of suitable energy alternative for designing the microgrid considering multiple scenarios are carried out. Second, the optimal sizing of the various energy resources in different microgrid structures is illustrated. Third, hybrid decision analysis methods are used for selection of the best sustainable microgrid energy system. Finally, the framework presented is then utilized for the design of a sustainable rural microgrid for a remote community located in the Himalayas in India to illustrate its effectiveness. The results obtained show that decision analysis tools provide a real-time solution for rural electrification by binding the synergy between various criteria considering different scenarios. The feasibility analysis using proposed multiyear scalable approach shows its competence not only in determining the suitable size of the microgrid, but also by reducing the net present cost and the cost of electricity significantly.","['Microgrids', 'Decision analysis', 'Planning', 'Tools', 'Economics', 'Biological system modeling', 'Renewable energy sources']","['Microgrid', 'hybrid energy system', 'renewable energy', 'rural electrification', 'multi-criteria decision analysis (MCDA)']"
"It is of great importance in telemedicine to protect authenticity and integrity of medical images. They are mainly addressed by two technologies, which are region of interest (ROI) lossless watermarking and reversible watermarking. However, the former causes biases on diagnosis by distorting region of none interest (RONI) and introduces security risks by segmenting image spatially for watermark embedding. The latter fails to provide reliable recovery function for the tampered areas when protecting image integrity. To address these issues, a novel robust reversible watermarking scheme is proposed in this paper. In our scheme, a reversible watermarking method is designed based on recursive dither modulation (RDM) to avoid biases on diagnosis. In addition, RDM is combined with Slantlet transform and singular value decomposition to provide a reliable solution for protecting image authenticity. Moreover, ROI and RONI are divided for watermark generation to design an effective recovery function under limited embedding capacity. Finally, watermarks are embedded into whole medical images to avoid the risks caused by segmenting image spatially. Experimental results demonstrate that our proposed lossless scheme not only has remarkable imperceptibility and sufficient robustness but also provides reliable authentication, tamper detection, localization, and recovery functions, which outperforms existing schemes for protecting medical images.","['Watermarking', 'Medical diagnostic imaging', 'Hospitals', 'Transforms', 'Robustness']","['Robust reversible watermarking', 'authenticity', 'integrity', 'medical image']"
"Smart campus is an exciting, new, and emerging research area that uses technology and infrastructure to support and improve its processes in campus services, teaching, learning, and research, especially, the explosive growth in knowledge makes the role of cybersecurity of smart campus become increasingly important. Cyber range is an adaptable virtualization platform consisting of computers, networks, and systems on which various real-world cyber threat scenarios and systems can be evaluated to provide a comprehensive, unbiased assessment of the security of information and automated control systems. As an important part of features, cyber range must provide the capability of data collection, aggregation, correlation, and replay for the scenario owner or any “specialized users”to review attacks-defense processes on known targets and future zero-day research. To this end, based on our previous work, the Heetian cyber range, we proposed a method named C2RS meaning “a real-time correlation of host-level events in cyber range service.”C2RS implements out-of-band data capturing for greater attack resistance with virtual machine introspection technique. This approach allows C2RS to isolate the data captured from monitored hosts. C2RS leverages these captured data by incorporating them into the volatility framework to aid in simplifying the analysis of operating system memory structures. Finally, we proposed an object-dependent method to analyze the evidence of illegal activity. We conduct extensive experiments to evaluate the functions and performance of C2RS in a dynamic service. Through the test, we confirm that the proposed method is effective for real-time correlation of host-level events in cyber range service.","['Virtual machining', 'Correlation', 'Security', 'Forensics', 'Training', 'Monitoring', 'Real-time systems']","['Security education', 'cyber range', 'network security', 'correlation', 'smart campus']"
"Soft robotics is quickly emerging in anthropomorphic robotic hand design, with innovative soft robot hands reported to achieve a remarkably large subset of human hand dexterity, despite their substantially lower mechanistic sophistication compared to conventional rigid or underactuated robotic hands. More interestingly, soft robot hands were most successful in reproducing object grasping, rather than in-hand manipulation tasks. Inspired by this notable advance, this paper investigated the soft robotic approach, on the influence of passive compliance to functional dexterity, offering insights to their efficacy and addressing the remaining gaps to fully replicating human hand dexterous motions. A novel soft robotic hand, BCL-26, with 26 independent degrees of freedom was then proposed, replicating the human hand model. The BCL-26 hand achieved full scores in different aspects of functional dexterity measures, on GRASP taxonomy, thumb dexterity, and in-hand manipulation. Completed with proprietary actuation and control, the overall BCL-26 hand system facilitated further investigations from the influence of passive compliance achieving in-hand manipulation/writing, to fully independent control of all finger joints, and to metacarpal extension enabled by the soft robotic approach. The BCL-26 hand, as a new soft-robotic addition to mechanistically exact human hand replicas, had demonstrated the promising potentials of soft robotics, it also enabled investigating the dexterities of robotic and human hand.","['Soft robotics', 'Actuators', 'Thumb', 'Taxonomy', 'Robot sensing systems', 'Grasping']","['Humanoid robotic hand', 'soft robotics', 'robot hand design and control']"
"Cervical cancer is one of the most common and deadliest cancers among women. Despite that, this cancer is entirely treatable if it is detected at a precancerous stage. Pap smear test is the most extensively performed screening method for early detection of cervical cancer. However, this hand-operated screening approach suffers from a high false-positive result because of human errors. To improve the accuracy and manual screening practice, computer-aided diagnosis methods based on deep learning is developed widely to segment and classify the cervical cytology images automatically. In this survey, we provide a comprehensive study of the state of the art approaches based on deep learning for the analysis of cervical cytology images. Firstly, we introduce deep learning and its simplified architectures that have been used in this field. Secondly, we discuss the publicly available cervical cytopathology datasets and evaluation metrics for segmentation and classification tasks. Then, a thorough review of the recent development of deep learning for the segmentation and classification of cervical cytology images is presented. Finally, we investigate the existing methodology along with the most suitable techniques for the analysis of pap smear cells.","['Image segmentation', 'Deep learning', 'Cervical cancer', 'Feature extraction', 'Image analysis', 'Biomedical imaging']","['Cervical cancer', 'cytopathology', 'convolutional neural networks', 'deep learning', 'segmentation', 'classification', 'pap smear']"
"Wireless power transfer (WPT) technology has been widely applied to automobile industries, household electronics and medical devices because of its many advantages. The hybrid battery charging scheme, which combines constant voltage (CV) and constant current (CC), is considered to be quite reasonable in view of the limitations of the conventional CC/CV implementation scheme. In this study, based on the inductance and double capacitances-series (LCC-S) compensation topology, a switching hybrid topology is proposed for CC/CV electric vehicle (EV) battery charging. The topology parameters are designed according to the specified CV and zero phase angle (ZPA). In the CC charging mode, two additional capacitances are added to the topology for CC and ZPA implementation. Based on the proposed weak communication, the CC and CV charging mode can be converted via two AC switches (ACSs). The proposed hybrid system provides a simple structure, easy controllability, and stable output. A 2.5-kW experimental prototype is configured to verify the proposed hybrid charger. The maximum DC efficiencies (at 2.5-kW) of the CC and CV charging modes are 89.28% and 88.33%, respectively.","['Topology', 'Batteries', 'Switches', 'Capacitance', 'Inductive charging', 'Zero voltage switching', 'Frequency modulation']","['Wireless power transfer (WPT)', 'electric vehicle (EV)', 'switching hybrid topology', 'inductance and double capacitances-series (LCC-S)', 'constant current/constant voltage (CC/CV)']"
"With the continuous development of the Chinese economy and the gradual acceleration of urbanization, it has caused tremendous damage to the environment. The bad air environment seriously damages the physical and mental health of the people. The change in smog concentration will be affected by many realistic factors and exhibit nonlinear characteristics. The method proposed in this paper is to use the Internet of Things (IoT) technology to monitor the acquired data, process the data, and predict the next data using a neural network. The existing prediction models have limitations. They don't accurately capture the law between the concentration of haze and the factors affecting reality. It is difficult to accurately predict the nonlinear smog data. One algorithm proposed in this paper is a two-layer model prediction algorithm based on Long Short Term Memory Neural Network and Gated Recurrent Unit (LSTM&GRU). We set a double-layer Recurrent Neural Network to predict the PM2.5 value. This model is an improvement and enhancement of the existing prediction method Long Short Term Memory (LSTM). The experiment integrates data monitored by the IoT node and information released by the national environmental protection department. First, the data of 96 consecutive hours in four cities were selected as the experimental samples. The experimental results are close to the true value. Then, we selected daily smog data from 2014/1/1 to 2018/1/1 as a train and test dataset. It contains smog data for 74 city sites. The first 70% of the data was used for training and the rest for testing. The results of this experiment show that our model can play a better prediction.","['Monitoring', 'Air quality', 'Atmospheric modeling', 'Internet of Things', 'Urban areas', 'Predictive models', 'Neural networks']","['Air pollution', 'Internet of Things', 'forecasting', 'LSTM', 'GRU']"
"Energy router is an intelligent power electronic device that can realize the active management of power flow and provide convenient access to distributed energy resource. This paper presents the structure of an AC-DC hybrid multi-port energy router, which acts as the interface between the power consumer and the distribution network. The corresponding coordinated control strategy is developed to guarantee the regular operation of the energy router and a mode switch strategy with advanced compensation is proposed to achieve seamless transition between grid-connected mode and islanded mode. A novel and practical fuzzy logic controller considering unit-time electricity charge is proposed for the energy router to prolong battery life, to improve economic benefits of power consumers, and to smooth fluctuations of renewable energy generation or load consumption. The simulation and experimental results have validated the coordinated control and energy management strategies and demonstrated that the energy router has satisfactory performance.","['Erbium', 'Energy management', 'Batteries', 'Hybrid power systems', 'Power supplies', 'Microgrids']","['Energy router', 'distribution power system', 'energy storage', 'fuzzy control', 'coordinated control strategy', 'energy management']"
"The purpose of this study is to determine appropriate innovative strategies for the renewable energy investments. For this purpose, a hybrid multi-criteria decision-making (MCDM) model is proposed based on interval type-2 (IT2) fuzzy sets and alpha cut levels. Within this context, hesitant IT2 fuzzy DEMATEL-Based Analytic Network Process (DANP) with alpha cut levels is applied for weighting the customer requirements. Moreover, hesitant IT2 fuzzy technique for order preference by similarity to ideal solution (TOPSIS) with alpha cut levels is used for ranking the TRIZ-based strategies priorities of renewable energy investments based on house of quality technique. These strategies are also ranked with hesitant IT2 fuzzy Vise Kriterijumska Optimizacija I Kompromisno Resenje (VIKOR) approach to make a comparative evaluation. The results illustrate that ease of access and security are among the most prominent factors of customer requirements for renewable energy investments. It is also identified that innovative technical requirement entitled cushion in advance has the best choice for the sustainable renewable energy projects. Furthermore, the results of proposed model using hesitant IT2 fuzzy DANP and hesitant IT2 fuzzy TOPSIS are identical for the different levels of alpha cut. In addition, it is also defined that the results of hesitant IT2 fuzzy TOPSIS and hesitant IT2 fuzzy VIKOR are quite coherent. This is a clear evidence that the proposed model is coherent and could provide comprehensive results for the future studies. It is strongly recommended that a detailed analysis is required to identify the risks in renewable energy investment projects. Hence, necessary actions can be taken appropriately so that it can be possible to prevent problems before they grow.","['Renewable energy sources', 'Investment', 'Fuzzy logic', 'Fuzzy sets', 'Technical requirements', 'Analytical models', 'Companies']","['TRIZ', 'house of quality', 'hesitant IT2 fuzzy DEMATEL', 'hesitant IT2 fuzzy TOPSIS', 'renewable energy', 'strategy development']"
"With the growth of the human population comes the constantly rising demand for agricultural products. Nevertheless, as the world experiences climate change, many crops are often damaged by weather conditions.This study utilizes Intelligent Agriculture IoT equipment to monitor the environmental factors on a farm. The collected data underwent 3D cluster analysis to yield analysis of the environmental factors of that farm. The proposed scheme bears the following features: (1) data normalization is achieved via the combination of moving average and average variance; (2) we applied 3D cluster analysis to analyze the relation between environmental factors and subsequently examine the rules of thumb held by the farmers; (3) the system determines whether a selected crop has been placed in the appropriate cluster; and (4) the system sets a critical value in the cluster based on future environments and provides advice on whether a crop is suitable for the farm. We placed Intelligent Agriculture IoT equipment in the farm for monitoring purposes and ran an actual-scenario analysis using the algorithm in our study; results confirm that our proposed scheme is indeed feasible.","['Agriculture', 'Big Data', 'Sensors', 'Monitoring', 'Environmental factors', 'Decision making', 'Soil measurements', 'Climate change']","['Big data', 'intelligent agriculture', 'internet of things', 'agricultural engineering', 'data mining']"
"Nearest neighbor search is a fundamental problem in various domains, such as computer vision, data mining, and machine learning. With the explosive growth of data on the Internet, many new data structures using spatial partitions and recursive hyperplane decomposition (e.g., k-d trees) are proposed to speed up the nearest neighbor search. However, these data structures are facing big data challenges. To meet these challenges, binary hashing-based approximate nearest neighbor search methods attract substantial attention due to their fast query speed and drastically reduced storage. Since the most notably locality sensitive hashing was proposed, a large number of binary hashing methods have emerged. In this paper, we first illustrate the development of binary hashing research by proposing an overall and clear classification of them. Then we conduct extensive experiments to compare the performance of these methods on five famous and public data sets. Finally, we present our view on this topic.","['Encoding', 'Binary codes', 'Distributed databases', 'Data mining', 'Nearest neighbor searches', 'Hamming distance']","['Approximate nearest neighbor search', 'large-scale database', 'hashing based methods', 'overview']"
"With the widespread of E-commerce, the need of a trusted system to ensure the delivery of traded items is crucial. Current proof of delivery (PoD) systems lacks transparency, traceability, and credibility. These systems are mostly centralized and rely on trusted third parties (TTPs) to complete the delivery between sellers and buyers. TTPs can be costly, a single point of failure, and subject to hacking, privacy evasion, and compromise. The blockchain is an immutable, trusted, and decentralized ledger with logs and events that can be used for transparency, traceability, and tracking. In this paper, we present a solution and a general framework using the popular permissionless Ethereum blockchain to create a trusted, decentralized PoD system that ensures accountability, auditability, and integrity. The solution uses Ethereum smart contracts to prove the delivery of a shipped item between a seller and a buyer irrespective of the number of intermediate transporters needed. In our proposed solution, all participating entities are incentivized to act honestly by using a double deposit collateral. Automated payment in ether is an integral part of a solution to ensure that every entity gets its intended share of ether upon successful delivery. An arbitration mechanism is also incorporated if a dispute arises during the shipping process. In this paper, we show how we implemented, verified, and tested the proper functionality of our PoD solution. We also provide security analysis and give estimates of the cost consumption in ether gas. We made the full code of the Ethereum smart contracts publicly available at Github.","['Contracts', 'Authentication', 'Computer crime', 'Privacy']","['Blockchain', 'Ethereum', 'smart contracts', 'cyber security', 'security analysis', 'decentralized management']"
"Inkjet printing technology uses the low-cost direct deposition manufacturing technique for printing and is applicable in various fields including optics, ceramics, three-dimensional printing in biomedicine, and conductive circuitry. This study reviews the classifications and applications of inkjet printing technologies, with a focus on recent publications. The different design approaches, applications, and research progress of several inkjet printing techniques are reviewed. Among them, the piezoelectric inkjet printing technology is the main focus owing to its reliability and handling of a diverse range of inks. A piezo-driven inkjet printhead is activated by applying a voltage waveform to a piezoelectric membrane. The waveform ensures the formation of the designed droplet and a stable jet. A survey of various driving-voltage waveforms is conducted, which can serve as a reference to the research community that uses piezo-driven inkjet printheads. The challenges of printing quality, stability, and speed and their solutions as published in recent studies are reviewed. Technologies for producing high-viscosity inkjets are explored, and the applications of inkjet printing technology in textile, displays, and wearable devices are discussed.","['Printing', 'Ink jet printing', 'Voltage', 'Satellites', 'Oscillators', 'Substrates', 'Tuning']","['Inkjet printing technology', 'printhead', 'piezoelectric inkjet printing', 'satellite droplet', 'voltage waveform']"
"The cognitive radio-based sensor network (CRSN) is envisioned as a strong driver in the development of modern power system smart grids (SGs). This can address the spectrum limitation in the sensor nodes due to interference cause by other wireless devices operating on the same unlicensed frequency in the Industrial, Scientific and Medical band. These sensor nodes are used for monitoring and control purposes in various components of a SG, ranging from generation, transmission, and distribution, and down to the consumer, including monitoring of utility network assets. A reliable SG communication network architecture is required for transferring information which needed by the SG applications, alongside the monitoring and control by CRSN. Hence, this paper investigates and explores the CRSN conceptual framework, and SG communication architecture with its applications; vis-à-vis the communication access technologies, including implementation design with quality of service support. Consequently, this paper highlights various research gaps, such as implementation design model, utilization of LPWAN for CRSN based SG deployment, and so on. This includes discussion on the future direction for various aspects of the CRSN in SG. To address these research gaps, we introduced a smart unified communication solution to improve the efficiency of the SG and mitigate various associated challenges.","['Cognitive radio', 'Wireless sensor networks', 'Communication networks', 'Quality of service', 'Smart grids', 'Monitoring']","['AMI', 'CRSN', 'distributed automation', 'LPWAN', 'protocols', 'QoS', 'reliability', 'smart grid', 'WAMR']"
"With the roll-out of electric vehicles (EVs), the automobile industry is transitioning away from conventional gasoline-fueled vehicles. As a result, the EV charging demand is continuously growing and to meet this growing demand, various types of electric vehicle charging stations (EVCSs) are being deployed for commercial and residential use. This nexus of EVs, EVCSs, and power grids creates complex cyber-physical interdependencies that can be maliciously exploited to damage each of these components. This paper describes and analyzes cyber vulnerabilities that arise at this nexus and points to the current and emerging gaps in the security of the EV charging ecosystem. These vulnerabilities must be addressed as the number of EVs continue to grow worldwide and their impact on the power grid becomes more viable. The purpose of this paper is to list and characterize all backdoors that can be exploited to seriously harm either EV and EVCS equipments, or power grid, or both. The presented issues and challenges intend to ignite research efforts on cybersecurity of smart EV charging and enhancing power grid resiliency against such demand-side cyberattacks in general.","['Electric vehicle charging', 'Power grids', 'Computer security', 'Security', 'Computer crime', 'Protocols', 'HVAC']","['Cybersecurity', 'electric vehicles', 'electric vehicle charging stations', 'smart grids']"
"Urban areas have been focused recently on the remote sensing applications since their function closely relates to the distribution of built-up areas, where reflectivity or scattering characteristics are the same or similar. Traditional pixel-based methods cannot discriminate the types of urban built-up areas very well. This paper investigates a deep learning-based classification method for remote sensing images, particularly for high spatial resolution remote sensing (HSRRS) images with various changes and multi-scene classes. Specifically, to help develop the corresponding classification methods in urban built-up areas, we consider four deep neural networks (DNNs): 1) convolutional neural network (CNN); 2) capsule networks (CapsNet); 3) same model with a different training rounding based on CNN (SMDTR-CNN); and 4) same model with different training rounding based on CapsNet (SMDTR-CapsNet). The performances of the proposed methods are evaluated in terms of overall accuracy, kappa coefficient, precision, and confusion matrix. The results revealed that SMDTR-CNN obtained the best overall accuracy (95.0%) and kappa coefficient (0.944) while also improving the precision of parking lot and resident samples by 1% and 4%, respectively.","['Remote sensing', 'Deep learning', 'Classification algorithms', 'Image analysis', 'Feature extraction', 'Kernel', 'Urban areas']","['Deep learning', 'convolution neural network', 'urban built-up area', 'capsule network', 'model ensemble', 'high resolution remote sensing classification']"
"Orthogonal frequency division multiplexing (OFDM) provides a promising modulation technique for underwater acoustic (UWA) communication systems. It is indispensable to obtain channel state information for channel estimation to handle the various channel distortions and interferences. However, the conventional channel estimation methods such as least square (LS), minimum mean square error (MMSE) and back propagation neural network (BPNN) cannot be directly applied to UWA-OFDM systems, since complicated multipath channels may cause a serious decline in performance estimation. To address the issue, two types of channel estimators based on deep neural networks (DNNs) are proposed with a novel training strategy in this paper. The proposed DNN models are trained with the received pilot symbols and the correct channel impulse responses in the training process, and then the estimated channel impulse responses are offered by the proposed DNN models in the working process. The experimental results demonstrate that the proposed methods outperform LS, BPNN algorithms and are comparable to the MMSE algorithm in respect to bit error rate and normalized mean square error. Meanwhile, there is no requirement of prior statistics information about channel autocorrelation matrix and noise variance for our proposals to estimate channels in UWA-OFDM systems, which is superior to the MMSE algorithm. Our proposed DNN models achieve better performance using 16QAM than 32QAM, 64QAM, furthermore, the specified DNN architectures help improve real-time performance by saving runtime and storage resources for online UWA communications.","['Channel estimation', 'OFDM', 'Underwater acoustics', 'Biological neural networks', 'Modulation', 'Multipath channels']","['Deep neural networks', 'OFDM systems', 'channel estimation', 'underwater acoustic communication']"
"Digital game-based learning (DGBL) has been perceived as an engaging teaching approach to foster students' learning and motivation. There are different opinions about the potential benefits of gaming on students' academic achievements, motivation, and skills in science courses due to the lack of empirical evidence and mixed results. To address this issue, this paper provides a review of relevant literature from 2006 to 2017 to examine the effects of using educational computer games in teaching science at the elementary education level. This paper employed a multidimensional framework to classify learning outcomes from studies of DGBL applications in the area of elementary science education. The findings of this review show a promising potential of DGBL, particularly in the area of content understanding. However, the findings of the review also suggest that there is a need to provide additional research in order to gain a more comprehensive picture of the educational effectiveness of DGBL. Hence, researchers are advised to conduct more randomized controlled trials (RCTs), various learning modes (e.g., collaborative and individual), and comparisons of DGBL to traditional methods of teaching. Furthermore, the researchers are highly encouraged to examine the effectiveness of DGBL applications in other areas, such as problem-solving and critical thinking. The findings of this review can benefit educational computer game designers, educators, and practitioners in the area of science education, particularly at the elementary level.","['Games', 'Education', 'Collaboration', 'Databases', 'Three-dimensional displays', 'Two dimensional displays', 'Systematics']","['Digital game-based learning', 'science education', 'serious games', 'systematic review']"
"Edge computing has recently emerged as an extension to cloud computing for quality of service (QoS) provisioning particularly delay guarantee for delay-sensitive applications. By offloading the computationally intensive workloads to edge servers, the quality of computation experience, e.g., network transmission delay and transmission energy consumption, could be improved greatly. However, the computation resource of an edge server is so scarce that it cannot respond quickly to the bursting computation requirements. Accordingly, queuing delay is un-negligible in a computationally intensive environment, e.g., a computing environment consists of the Internet of Things (IoT) applications. In addition, the computation energy consumption in edge servers may be higher than that in clouds when the workload is heavy. To provide QoS for end users while achieving green computing for computing systems, the cooperation between edge servers and the cloud is significantly important. In this paper, the energy-efficient and delay-guaranteed workload allocation problem in an IoT-edge-cloud computing system are investigated. We formulate a delay-based workload allocation problem which suggests the optimal workload allocations among local edge server, neighbor edge servers, and cloud toward the minimal energy consumption as well as the delay guarantee. The problem is then tackled using a delay-base workload allocation (DBWA) algorithm based on Lyapunov drift-plus-penalty theory. The theoretical analysis and simulation results have been conducted to demonstrate the efficiency of the proposal for energy efficiency and delay guarantee in an IoT-edge-cloud system.","['Delays', 'Cloud computing', 'Servers', 'Resource management', 'Energy consumption', 'Edge computing', 'Internet of Things']","['Edge computing', 'cloud computing', 'workload allocation', 'energy efficiency', 'delay guarantee']"
"In this paper, a channel measurement campaign is introduced, which utilizes direction-scan-sounding to capture the spatial characteristics of 28-GHz wave propagation channels with 500-MHz sounding bandwidth in office environments. Both line-of-sight and non-line-of-sight scenarios were considered. Measurements were performed by fixing a transmit pyramidal horn antenna, and rotating another one in the receiver site at 10° steps in azimuth. The antenna outputs are viewed as array signals, and a space-alternating generalized expectation-maximization (SAGE) algorithm is applied to estimate delay and angular parameters of multipath components. Benefiting from high resolution achieved by using the SAGE and deembedding of antenna radiation pattern and system responses, more multipath clusters with less spreads in delay and azimuth are found per channel compared with existing works on 28-GHz propagation. The statistics of channel parameters extracted here constitute a preliminary stochastic multipath-cluster spatial channel model.","['Antenna measurements', 'Millimeter wave propagation', 'Receiving antennas', 'Horn antennas', 'Directive antennas', 'Antenna radiation patterns', 'SAGE', 'Cluster approximation']","['Direction-scan-sounding', 'millimeter wave propagation', 'channel measurement', 'horn antenna', 'SAGE', 'multipath cluster']"
"The aim of an automatic video-based facial expression recognition system is to detect and classify human facial expressions from image sequence. An integrated automatic system often involves two components: 1) peak expression frame detection and 2) expression feature extraction. In comparison with the image-based expression recognition system, the video-based recognition system often performs online detection, which prefers low-dimensional feature representation for cost-effectiveness. Moreover, effective feature extraction is needed for classification. Many recent recognition systems often incorporate rich additional subjective information and thus become less efficient for real-time application. In our facial expression recognition system, first, we propose the double local binary pattern (DLBP) to detect the peak expression frame from the video. The proposed DLBP method has a much lower-dimensional size and can successfully reduce detection time. Besides, to handle the illumination variations in LBP, logarithm-laplace (LL) domain is further proposed to get a more robust facial feature for detection. Finally, the Taylor expansion theorem is employed in our system for the first time to extract facial expression feature. We propose the Taylor feature pattern (TFP) based on the LBP and Taylor expansion to obtain an effective facial feature from the Taylor feature map. Experimental results on the JAFFE and Cohn-Kanade data sets show that the proposed TFP method outperforms some state-of-the-art LBP-based feature extraction methods for facial expression feature extraction and can be suited for real-time applications.","['Feature extraction', 'Face recognition', 'Facial features', 'Image recognition', 'Face', 'Lighting', 'Taylor series']","['Pattern recognition', 'facial expression recognition', 'video processing', 'image processing']"
"With the advancements in machine and deep learning algorithms, the envision of various critical real-life applications in computer vision becomes possible. One of the applications is facial sentiment analysis. Deep learning has made facial expression recognition the most trending research fields in computer vision area. Recently, deep learning-based FER models have suffered from various technological issues like under-fitting or over-fitting. It is due to either insufficient training and expression data. Motivated from the above facts, this paper presents a systematic and comprehensive survey on current state-of-art Artificial Intelligence techniques (datasets and algorithms) that provide a solution to the aforementioned issues. It also presents a taxonomy of existing facial sentiment analysis strategies in brief. Then, this paper reviews the existing novel machine and deep learning networks proposed by researchers that are specifically designed for facial expression recognition based on static images and present their merits and demerits and summarized their approach. Finally, this paper also presents the open issues and research challenges for the design of a robust facial expression recognition system.","['Feature extraction', 'Sentiment analysis', 'Taxonomy', 'Machine learning', 'Face recognition', 'Face']","['Facial sentiment analysis', 'machine learning', 'deep learning', 'convolutional neural network', 'deep belief network', 'artificial intelligence']"
"This paper addresses a local minima problem for multiple unmanned aerial vehicles (UAVs) in the process of collision avoidance by using the artificial potential field method, thereby enabling UAVs to avoid the obstacle effectively in 3-D space. The main contribution is to propose a collision avoidance control algorithm based on the virtual structure and the “leader-follower”control strategy in 3-D space that can avoid the obstacle effectively and then track the motion target. The three UAVs constitute the regular triangular formation as the control object, the virtual leader flight trajectory as the expected path, the obstacles as the simplified cylinders, and the artificial potential fields around them as approximately spherical surfaces. The attractive force of the artificial potential field can guide the virtual leader to track the target. At the same time, the follower tracks the leader to maintain the formation flight. The effect of the repulsive force can avoid the collision between the UAVs and arrange the followers such that they are evenly distributed on the spherical surface. Moreover, the follower's specific order and position are not required. The collision path of the UAV formation depends on the artificial potential field with the two composite vectors, and every UAV may choose the optimal path to avoid the obstacle and reconfigure the regular triangular formation flight after passing the obstacle. The effectiveness of the proposed collision avoidance control algorithm is fully proved by simulation tests. Meanwhile, we also provide a new concept for multi-UAV formation avoidance of an obstacle.","['Collision avoidance', 'Unmanned aerial vehicles', 'Force', 'Target tracking', 'Mathematical model']","['Local minima', 'information architecture', 'virtual leader', 'optimal path', 'avoidance obstacle']"
"Harmonic emissions have been changed in distribution networks, with respect to frequency range and magnitude, due to the penetration of modern power electronics systems. Two new frequency ranges 2-9 and 9-150 kHz have been identified as new disturbing frequency ranges affecting distribution networks. This paper presents the effects of grid-connected three-phase systems with different front-end topologies: conventional, small dc-link capacitor, and electronic inductor. A power converter with a small dc-link capacitor can create a resonant frequency with the line impedance below and above 1 kHz depending on the grid configurations. The resonant effects depend on many factors, such as load power levels, filter types, and the number of parallel drives. These issues can affect the grid current harmonics and power quality of the distribution networks. Analyses and simulations have been carried out for three different topologies and the results have been verified by experimental test at system level. Current harmonic emissions have been considered for 0-2, 2-9, and 9-150 kHz frequency ranges.","['Harmonic analysis', 'Power system harmonics', 'Power electronics', 'Motor drives', 'Capacitors', 'Resonant frequency', 'Inductors']","['Harmonic mitigation techniques', 'power quality', 'DC-link capacitor', 'distribution networks', 'resonant frequency', '2–9 kHz']"
"In this paper, a compact substrate-integrated waveguide (SIW) cavity-backed slot antenna array with high gain, broadband, and dual-polarization performances is proposed for 60-GHz applications. An enhanced 17.1% impedance bandwidth was achieved by cutting semi-circle edges on the conventional slot radiator. A simplified SIW feed network is aperture-coupled vertically and constructed on a double-layered structure to implement the dual-polarization operation. By adopting innovative techniques on both radiating element and double-layered SIW feed networks, a high-gain, broadband, and dual-polarized 8 × 8 antenna array was designed on three-layered printed circuit board that allows for mass production. This configuration also resolves the trade-off between the bandwidth and gain of the existing 60-GHz dual-polarized antenna array. Its feasibility is proved by obtaining a measured gain in the range of 19.7-22.3 dB and an enhanced impedance bandwidth of 17.1% over 55.7-66.1 GHz for both horizontal and vertical polarizations. With advantages of high-gain, broadband, and dual-polarization performances in a low-cost low-profile structure, the proposed antenna array is a promising candidate for millimeter-wave wireless systems.","['Antenna arrays', 'Broadband antennas', 'Bandwidth', 'Cavity resonators', 'Slot antennas', 'Antenna feeds']","['High-gain', 'broadband', 'dual-polarization', 'slot antenna array', 'substrate-integrated-waveguide (SIW)', '60 GHz']"
"Highly accurate indoor localization based on significantly low complex infrastructure has recently gained great interest for a variety of innovative location-based applications. In this regards, the chipless radio frequency identification (RFID) system is presented to be the low-cost solution, while time-based ranging using the ultrawide-band spectrum is promising to offer precise ranging capability. However, the current wide-band systems suffer from the spectrum and power limitations, which restrict the function of chipless RFID-based localization systems. Therefore, we propose terahertz (THz)-based chipless RFID localization system that enables a smart object localizing itself using the infrastructure composed from reference chipless tags. In more details, THz band offers huge bandwidth providing superior-resolution localization and large coding capacity. Moreover, we utilize the combination between dielectric resonator (DR) and lens to be designed as a frequency-coded chipless tag, where this combination increases the radar cross section of the chipless tags and, hence, extends their coverage zone. This cost-efficient design of the tag enables the dense deployment of low-cost infrastructure acting as reference anchors. Furthermore, we investigate the link budget of the proposed system in order to characterize the tag and distance-dependent spectral windows that are feasible for RFID-based localization. Afterward, the time-domain backscattered signal from a DR-Lens tag is analyzed in order to perform ranging and to calculate the relative distances between the DR-Lens tags and the reader leading to determining the reader position. Measurements are performed to prove the concept of the DR-Lens tag, while the numerical simulation is conducted to evaluate the proposed localization system. Simulation results show that the proposed system can reach superior accuracy of millimeter-levels.","['Radiofrequency identification', 'Distance measurement', 'Bandwidth', 'Backscatter', 'Lenses', 'Resonant frequency', 'Indoor environments']","['Localization', 'RFID', 'large-scale MIMO', 'chipless RFID', 'dielectric resonator (DR)', 'lens', 'RToF', 'estimation accuracy']"
"More electric aircraft (MEA) architectures consist of several subsystems, which must all comply with the settled safety requirements of aerospace applications. Thus, achieving reliability and fault-tolerance represents the main cornerstone when classifying different solutions. Hybrid electric aircraft (HEA) extends the MEA concept by electrifying the propulsive power as well as the auxiliary power, and thereby pushing the limits of electrification. This paper gives an overview of the high-power electrical machine families and their associated power electronic converter (PEC) interfaces that are currently competing for aircraft power conversion systems. Various functionalities and starter-generator (S/G) solutions are also covered. In order to highlight the latest advancements, the efficiency of the world's most powerful aerospace generator (Mark 1) developed within the E-Fan X HEA project is graphically represented and assessed against other rivaling solutions. Motivated by the strict requirements on efficiency, power density, trustworthiness, as well as starting functionalities, supplementary considerations on the system-level design are paramount. In order to highlight the MEA goals and take advantage of all potential benefits, all subsystems must be treated as a whole. It is then shown that the combination of PECs, aircraft grid and electrical machines can be better adapted to benefit the overall system. This survey outlines the influence of these concerns and offers a view of the future technology outlook, as well as covering the present challenges and opportunities.","['Aircraft', 'Aerospace electronics', 'Topology', 'Generators', 'Density measurement', 'Power system measurements']","['Aerospace generators', 'more-electric aircraft (MEA)', 'hybrid-electric aircraft (HEA)', 'power electronic interfaces', 'matrix converters', 'three-level converters', 'wound-rotor synchronous machines', 'induction machines', 'permanent magnet machines', 'reluctance machines']"
"Human action recognition is one of the fundamental challenges in robotics systems. In this paper, we propose one lightweight action recognition architecture based on deep neural networks just using RGB data. The proposed architecture consists of convolution neural network (CNN), long short-term memory (LSTM) units, and temporal-wise attention model. First, the CNN is used to extract spatial features to distinguish objects from the background with both local and semantic characteristics. Second, two kinds of LSTM networks are performed on the spatial feature maps of different CNN layers (pooling layer and fully-connected layer) to extract temporal motion features. Then, one temporal-wise attention model is designed after the LSTM to learn which parts in which frames are more important. Lastly, a joint optimization module is designed to explore intrinsic relations between two kinds of LSTM features. Experimental results demonstrate the efficiency of the proposed method.","['Feature extraction', 'Convolution', 'Neural networks', 'Optimization', 'Computer architecture', 'Robots', 'Semantics']","['Artificial intelligent', 'human action recognition', 'attention model', 'deep neural networks', 'robotic system']"
"As a mission-critical sensor, SAR has been applied in environmental monitoring and battlefield surveillance; moreover, SAR target recognition is one of the most important applications of SAR technology. However, in practical applications, the number of samples available for training is relatively small, so the SAR target recognition can be regarded as a small sample recognition problem. One of the main directions to solve the small sample recognition problem is to realize the data augmentation. Therefore, a SAR image data augmentation method via Generative Adversarial Nets (GAN) is proposed in this paper. The method uses Wasserstein GAN with a gradient penalty (WGAN-GP) to generate new samples based on existing SAR data, which can augment the sample number in training dataset. Meanwhile, the sample selection filters are designed to extract the generated samples with high quality and specific azimuth, which can avoid the randomness of the data augmentation, and improve the quality of the newly generated training samples. The experiments based on MSTAR data show that, for three-class recognition problem, when the training sample is only 108, the proposed method can improve the recognition rate from 79% to 91.6%; and for ten-class recognition problem, when the training sample is only 360, the proposed method can improve the recognition rate from 57.48% to 79.59%. Compared with the traditional data linear generation method, the proposed method shows significant improvement on the quantity and quality of the training samples, and can effectively solve the problem of the small sample recognition.","['Training', 'Synthetic aperture radar', 'Target recognition', 'Radar polarimetry', 'Gallium nitride', 'Azimuth', 'Generative adversarial networks']","['Synthetic aperture radar', 'target recognition', 'small sample recognition', 'data augmentation', 'Generative Adversarial Nets']"
"This paper aimed to alleviate the disparity in the literature regarding social media use for collaboration and communication and its influence on the performance of students at higher education. A questionnaire survey on constructivism theory, technology acceptance model, and communication theory were utilized as the key method for collecting data and was circulated among a total of 863 university students. The obtained outcomes of students’ behavioral intention to utilize social media to collaborate learning and online communication indicates a positive effect on their academic works in higher education institutes, while male students were not completely satisfied with interaction with peers for collaboration learning. The study indicates that collaboration learning, as well as online communication over social media enhances, the students learning activities and enable to sharing knowledge, information, and discussions, and hence, we recommend students to utilize social media for education purpose and should have encouraged them through lecturers at higher level education institutions.","['Collaboration', 'Education', 'Facebook', 'Tools', 'Context modeling']","['Constructivism theory', 'social media', 'communication theory', 'technology acceptance model (TAM)', 'students’ academic performance']"
"Among various physiological signal acquisition methods for the study of the human brain, EEG (Electroencephalography) is more effective. EEG provides a convenient, non-intrusive, and accurate way of capturing brain signals in multiple channels at fine temporal resolution. We propose an ensemble learning algorithm for automatically computing the most discriminative subset of EEG channels for internal emotion recognition. Our method describes an EEG channel using kernel-based representations computed from the training EEG recordings. For ensemble learning, we formulate a graph embedding linear discriminant objective function using the kernel representations. The objective function is efficiently solved via sparse non-negative principal component analysis and the final classifier is learned using the sparse projection coefficients. Our algorithm is useful in reducing the amount of data while improving computational efficiency and classification accuracy at the same time. The experiments on publicly available EEG dataset demonstrate the superiority of the proposed algorithm over the compared methods.","['Electroencephalography', 'Emotion recognition', 'Kernel', 'Feature extraction', 'Support vector machines', 'Training', 'Linear programming']","['Multiple channel EEG', 'emotion recognition', 'linear discriminant analysis', 'sparse PCA']"
"Public fog nodes extend cloud services for the Internet of Things (IoT) clients and smart devices to provide additional computation capabilities, storage space, and reduce latency and response time. The openness and pervasiveness of public fog nodes leads to the requirement of using trust models to ensure reliability, security, privacy, and meet the service-level agreements (SLAs). Conventional trust models for public fog nodes are centrally configured, deployed, and maintained considering security, privacy, and SLA requirements. However, these trust models enforce centralized governance policies across the system which leads towards the single-point-of-failure and single-point-of-compromise over IoT devices' and users' personal data. This paper proposes a decentralized trust model in order to maintain the reputation of publicly available fog nodes. The reputation is maintained considering users' opinions about their past interactions with the public fog nodes. The proposed trust model is designed using public Ethereum blockchain and smart contract technologies in order to enable decentralized trustworthy service provisioning between IoT devices and public fog nodes. The proposed approach is tested and evaluated in terms of security, performance, and cost. The results show that using blockchain for decentralized reputation management could become more advantageous when compared to the existing centralized trust models.","['Edge computing', 'Contracts', 'Computational modeling', 'Servers', 'Bitcoin']","['Blockchain', 'fog computing', 'IoT', 'reputation', 'trust']"
"Unmanned surface vehicle (USV) has witnessed a rapid growth in the recent decade and has been applied in various practical applications in both military and civilian domains. USVs can either be deployed as a single unit or multiple vehicles in a fleet to conduct ocean missions. Central to the control of USV and USV formations, path planning is the key technology that ensures the navigation safety by generating collision free trajectories. Compared with conventional path planning algorithms, the deep reinforcement learning (RL) based planning algorithms provides a new resolution by integrating a high-level artificial intelligence. This work investigates the application of deep reinforcement learning algorithms for USV and USV formation path planning with specific focus on a reliable obstacle avoidance in constrained maritime environments. For single USV planning, with the primary aim being to calculate a shortest collision avoiding path, the designed RL path planning algorithm is able to solve other complex issues such as the compliance with vehicle motion constraints. The USV formation maintenance algorithm is capable of calculating suitable paths for the formation and retain the formation shape robustly or vary shapes where necessary, which is promising to assist with the navigation in environments with cluttered obstacles. The developed three sets of algorithms are validated and tested in computer-based simulations and practical maritime environments extracted from real harbour areas in the UK.","['Reinforcement learning', 'Trajectory', 'Training', 'Navigation', 'Heuristic algorithms', 'Planning']","['Deep reinforcement learning', 'motion planning', 'multi-agent systems', 'unmanned surface vehicles (USVs)', 'USV formations']"
"In this paper, we model prosumers’ energy trading behavior, with the operation of an energy storage system, in a proposed event-driven local energy market. Through modeling local energy trading strategies of a prosumer in the proposed holistic market model, the prosumer’s decision-making process will be built as a Markov decision process with many continuous variables. Then, this decision-making process of local market participation will be solved by deep reinforcement learning technology with experience replay mechanism. Specifically, a deep Q-learning for local energy trading algorithm is modified from deep Q-network to facilitate such a decision-making within an intelligent energy system and promote prosumers’ willingness to participate in the localized energy ecosystem.","['Machine learning', 'Energy storage', 'Electricity supply industry', 'Companies', 'Decision making', 'Ecosystems', 'Learning (artificial intelligence)']","['Prosumer', 'energy trading', 'Markov decision process', 'deep reinforcement learning']"
"The identification of maize leaf diseases will meet great challenges because of the difficulties in extracting lesion features from the constant-changing environment, uneven illumination reflection of the incident light source and many other factors. In this paper, a novel maize leaf disease recognition method is proposed. In this method, we first designed a maize leaf feature enhancement framework with the capability of enhancing the features of maize under the complex environment. Then a novel neural network is designed based on backbone Alexnet architecture, named DMS-Robust Alexnet. In the DMS-Robust Alexnet, dilated convolution and multi-scale convolution are combined to improve the capability of feature extraction. Batch normalization is performed to prevent network over-fitting while enhancing the robustness of the model. PRelu activation function and Adabound optimizer are employed to improve both convergence and accuracy. In experiments, it is validated from different perspectives that the maize leaf disease feature enhancement algorithm is conducive to improving the capability of the DMS-Robust Alexnet identification. Our method demonstrates strong robustness for maize disease images collected in the natural environment, providing a reference for the intelligent diagnosis of other plant leaf diseases.","['Diseases', 'Feature extraction', 'Agriculture', 'Image recognition', 'Lesions', 'Neural networks', 'Image enhancement']","['Image enhancement', 'dilated convolution', 'multi-scale convolution', 'maize leaf disease', 'convolutional neural network']"
"Speech emotion recognition is a challenging but important task in human computer interaction (HCI). As technology and understanding of emotion are progressing, it is necessary to design robust and reliable emotion recognition systems that are suitable for real-world applications both to enhance analytical abilities supporting human decision making and to design human-machine interfaces (HMI) that assist efficient communication. This paper presents a multimodal approach for speech emotion recognition based on Multi-Level Multi-Head Fusion Attention mechanism and recurrent neural network (RNN). The proposed structure has inputs of two modalities: audio and text. For audio features, we determine the mel-frequency cepstrum (MFCC) from raw signals using the OpenSMILE toolbox. Further, we use pre-trained model of bidirectional encoder representations from transformers (BERT) for embedding text information. These features are fed parallelly into the self-attention mechanism base RNNs to exploit the context for each timestamp, then we fuse all representatives using multi-head attention technique to predict emotional states. Our experimental results on the three databases: Interactive Emotional Motion Capture (IEMOCAP), Multimodal EmotionLines Dataset (MELD), and CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), reveal that the combination of the two modalities achieves better performance than using single models. Quantitative and qualitative evaluations on all introduced datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.","['Feature extraction', 'Emotion recognition', 'Speech recognition', 'Mel frequency cepstral coefficient', 'Bit error rate', 'Recurrent neural networks', 'Hidden Markov models']","['Speech emotion recognition', 'multi-level multi-head fusion attention', 'RNN', 'audio features', 'textual features']"
"Smart health is one of the most popular and important components of smart cities. It is a relatively new context-aware healthcare paradigm influenced by several fields of expertise, such as medical informatics, communications and electronics, bioengineering, ethics, to name a few. Smart health is used to improve healthcare by providing many services such as patient monitoring, early diagnosis of disease and so on. The artificial neural network (ANN), support vector machine (SVM) and deep learning models, especially the convolutional neural network (CNN), are the most commonly used machine learning approaches where they proved to be performance in most cases. Voice disorders are rapidly spreading especially with the development of medical diagnostic systems, although they are often underestimated. Smart health systems can be an easy and fast support to voice pathology detection. The identification of an algorithm that discriminates between pathological and healthy voices with more accuracy is needed to obtain a smart and precise mobile health system. The main contribution of this paper consists of proposing a multiclass-pathologic voice classification using a novel multileveled textural feature extraction with iterative feature selector. Our approach is a simple and efficient voice-based algorithm in which a multi-center and multi threshold based ternary pattern is used (MCMTTP). A more compact multileveled features are then obtained by sample-based discretization techniques and Neighborhood Component Analysis (NCA) is applied to select features iteratively. These features are finally integrated with MCMTTP to achieve an accurate voice-based features detection. Experimental results of six classifiers with three diagnostic diseases (frontal resection, cordectomy and spastic dysphonia) show that the fused features are more suitable for describing voice-based disease detection.","['Feature extraction', 'Diseases', 'Medical diagnostic imaging', 'Machine learning', 'Histograms', 'Biomedical engineering', 'Smart healthcare']","['MCMTTP', 'discrete wavelet transform', 'voice disease detection', 'smart health', 'machine learning']"
"This paper investigates the adaptive finite-time tracking control problem for a class of switched nonlinear systems with unmodeled dynamics. In practical applications, switched systems usually possess unfavourable factors, such as unmeasured states and unmodeled dynamics both of which are taken into account in this paper. A dynamic signal defined with a special property is introduced in this paper to improve control performance while garanteeing stability of the controlled system. By designing an observer, a finite-time adaptive output-feedback tracking controller is constructed via the backstepping technique. Then, the finite-time stability problem of the considered systems is studied. It is shown that all the signals in the closed-loop system are semi-globally uniformly finite-time bounded (SGFUB), and the observer errors and tracking errors can be regulated to a small neighborhood of the origin by choosing appropriate parameters. It is noted that, the design process is less complex than some existing results on tackling control problems of nonlinear systems with unmodeled dynamics. In the example, the simulation result testifies the effectiveness of the proposed method.","['Nonlinear systems', 'Stability criteria', 'Switches', 'Adaptive systems', 'Switched systems']","['Switched systems', 'adaptive control', 'observer', 'finite-time control', 'unmodeled dynamics']"
"In this paper, we investigate a wireless-powered dual-hop relaying multiple-input multiple-output system, which consists of a multi-antenna source (S) node, a multi-antenna destination (D) node, andN(N>1)single-antenna wireless-powered relaying nodes. At each relay, a power splitting receiver is applied to process the received signal for information decoding and energy harvesting simultaneously, and a decode-and-forward scheme is adopted to forward the processed information. Furthermore, the energy harvester at each relay is assumed to be non-linear with a saturation threshold to limit the power level of the energy. Assuming imperfect channel state information is available both at S and D, outage performance is investigated when S adopts transmit antenna selection in the presence of feedback delay and D performs maximal ratio combining technique to deal with the multiple copies of signals with channel estimation errors. Taking into account aKth best relay selection criterion, which results in theKth best performance in terms of outage probability for the source-relay-destination link, an analytical expression for OP is derived. Monte Carlo simulation results are presented to verify the accuracy of the derived analytical model.","['MIMO', 'Channel state information', 'Energy harvesting', 'Power outages', 'Non linear programming', 'Wireless communication', 'Relays', 'Wireless sensor networks', 'Receivers', 'Multi-antennas', 'Monte Carlo methods']","['Channel state information', 'energy harvesting', 'multiple-input multiple-output', 'non-linear', 'outage probability', 'wireless-powered relaying']"
"The IEEE 802.1 time sensitive networking working group has recently standardized the time aware shaper (TAS). The TAS provides deterministic latency guarantees but requires tight time synchronization in all network switches. This paper thoroughly evaluates the mean and maximum packet delays and packet losses of the TAS for a typical industrial control ring network for random (sporadic) and for periodic traffic. We propose and evaluate adaptive bandwidth sharing and adaptive slotted window mechanisms to make TAS adaptive to traffic fluctuations. This paper further evaluates the asynchronous traffic shaper (ATS), which has been proposed to provide low latency network service without the need for time synchronization in network nodes. Our evaluations indicate that TAS with proper configurations, e.g., accurate and precise gating schedules, generally achieves the specified latency bounds for both sporadic and periodic traffic. In contrast, ATS performs relatively well for sporadic traffic; but struggles for moderate to high loads of periodic traffic.","['Ethernet', 'Standards', 'Delays', 'Synchronization', 'Schedules', 'Job shop scheduling', 'Automotive engineering']","['Asynchronous traffic shaper (ATS)', 'packet delay', 'throughput', 'time-sensitive networking (TSN)', 'time aware shaper (TAS)', 'ultra-low latency']"
"Solar energy is the key to clean energy, which can generate large amounts of electricity for the future smart grid. Unfortunately, the randomness and intermittency of solar energy resources bring difficulties to the stable operation and management of the power systems. To reduce the negative impact of photovoltaic (PV) plants accessing on the power systems, it is great significant to predict PV power accurately. In light of this, we propose a hybrid deep learning approach based on convolutional neural network (CNN) and long-short term memory recurrent neural network (LSTM) for the PV output power forecasting. The CNN model is leveraged to discover the nonlinear features and invariant structures exhibited in the previous output power data, thereby facilitating the prediction of PV power. The LSTM is used to model the temporal changes in the latest PV data, and predict the PV power of next time step. Then, the prediction results in the two models are comprehensively considered to obtain the expected output power. The proposed approach is extensively evaluated on real PV data in Limberg, Belgium, and numerical results demonstrate that the proposed approach can provide good prediction performance in PV systems.","['Forecasting', 'Predictive models', 'Meteorology', 'Photovoltaic systems', 'Hybrid power systems']","['Solar energy', 'deep learning', 'photovoltaic (PV) power forecasting', 'power systems']"
"Rapid spread of Coronavirus disease COVID-19 leads to severe pneumonia and it is estimated to create a high impact on the healthcare system. An urgent need for early diagnosis is required for precise treatment, which in turn reduces the pressure in the health care system. Some of the standard image diagnosis available is Computed Tomography (CT) scan and Chest X-Ray (CXR). Even though a CT scan is considered a gold standard in diagnosis, CXR is most widely used due to widespread, faster, and cheaper. This study aims to provide a solution for identifying pneumonia due to COVID-19 and healthy lungs (normal person) using CXR images. One of the remarkable methods used for extracting a high dimensional feature from medical images is the Deep learning method. In this research, the state-of-the-art techniques used is Genetic Deep Learning Convolutional Neural Network (GDCNN). It is trained from the scratch for extracting features for classifying them between COVID-19 and normal images. A dataset consisting of more than 5000 CXR image samples is used for classifying pneumonia, normal and other pneumonia diseases. Training a GDCNN from scratch proves that, the proposed method performs better compared to other transfer learning techniques. Classification accuracy of 98.84%, the precision of 93%, the sensitivity of 100%, and specificity of 97.0% in COVID-19 prediction is achieved. Top classification accuracy obtained in this research reveals the best nominal rate in the identification of COVID-19 disease prediction in an unbalanced environment. The novel model proposed for classification proves to be better than the existing models such as ReseNet18, ReseNet50, Squeezenet, DenseNet-121, and Visual Geometry Group (VGG16).","['Diseases', 'Lung', 'Mathematical model', 'Computed tomography', 'Feature extraction', 'Computer architecture', 'Optimization']","['Genetic Deep Learning Convolutional Neural Network (GDCNN)', 'Computed Tomography (CT)', 'Chest X-Ray (CXR)', 'Artificial Intelligence (AI)']"
"The use of millimeter-wave (mmWave) bandwidth is one key enabler to achieve the high data rates in the fifth-generation (5G) cellular systems. However, mmWave signals suffer from significant path loss due to high directivity and sensitivity to blockages, limiting its adoption within small-scale deployments. To enhance the coverage of mmWave communication in 5G and beyond, it is promising to deploy a large number of reconfigurable intelligent surfaces (RISs) that passively reflect mmWave signals towards desired directions. With this motivation, in this work, we study the coverage of an RIS-assisted large-scale mmWave cellular network using stochastic geometry, and derive the peak reflection power expression of an RIS and the downlink signal-to-interference ratio (SIR) coverage expression in closed forms. These analytic results clarify the effectiveness of deploying RISs in the mmWave SIR coverage enhancement, while unveiling the major role of the density ratio between active base stations (BSs) and passive RISs. Furthermore, the results show that deploying passive reflectors are as effective as equipping BSs with more active antennas in the mmWave coverage enhancement. Simulation results confirm the tightness of the closed-form expressions, corroborating our major findings based on the derived expressions.","['Cellular networks', 'Antenna arrays', 'Millimeter wave communication', 'Geometry', 'Stochastic processes', 'MIMO communication', 'Array signal processing']","['Millimeter-wave (mmWave)', 'reconfigurable intelligent surface (RIS)', 'coverage', 'signal-to-interference ratio (SIR)', 'stochastic geometry']"
"Sensors are devices that quantify the physical aspects of the world around us. This ability is important to gain knowledge about human activities. Human Activity recognition plays an import role in people's everyday life. In order to solve many human-centered problems, such as health care, and individual assistance, the need to infer various simple to complex human activities is prominent. Therefore, having a well defined categorization of sensing technology is essential for the systematic design of human activity recognition systems. By extending the sensor categorization proposed by White, we survey the most prominent research works that utilize different sensing technologies for human activity recognition tasks. To the best of our knowledge, there is no thorough sensor-driven survey that considers all sensor categories in the domain of human activity recognition with respect to the sampled physical properties, including a detailed comparison across sensor categories. Thus, our contribution is to close this gap by providing an insight into the state-of-the-art developments. We identify the limitations with respect to the hardware and software characteristics of each sensor category and draw comparisons based on benchmark features retrieved from the research works introduced in this survey. Finally, we conclude with general remarks and provide future research directions for human activity recognition within the presented sensor categorization.","['Mechanical sensors', 'Activity recognition', 'Sensor phenomena and characterization', 'Intelligent sensors', 'Acoustics', 'Acoustic sensors']","['Sensor categorization', 'human activity recognition', 'public databases for human activity recognition', 'physical sensors', 'sensor benchmark']"
"Sentiment analysis on Chinese microblogs has received extensive attention recently. Most previous studies focus on identifying sentiment orientation by encoding as many word properties as possible while they fail to consider contextual features (e.g., the long-range dependencies of words), which are, however, essentially important in the sentiment analysis. In this paper, we propose a Chinese sentiment analysis method by incorporating a word2vec model and a stacked bidirectional long short-term memory (Stacked Bi-LSTM) model. We first employ the word2vec model to capture semantic features of words and transfer words into high-dimensional word vectors. We evaluate the performance of two typical word2vec models: continuous bag-of-words (CBOW) and skip-gram. We then use the Stacked Bi-LSTM model to conduct the feature extraction of sequential word vectors. We next apply a binary softmax classifier to predict the sentiment orientation by using semantic and contextual features. Moreover, we also conduct extensive experiments on the real dataset collected from Weibo (i.e., one of the most popular Chinese microblogs). The experimental results show that our proposed approach achieves better performance than other machine-learning models.","['Sentiment analysis', 'Feature extraction', 'Analytical models', 'Semantics', 'Machine learning', 'Task analysis', 'Dictionaries']","['Long short-term memory (LSTM)', 'stacked bi-directional LSTM', 'sentiment analysis', 'continuous bag-of-words', 'Chinese microblog', 'contextual features']"
"The increasing demand of routing in the field of communication is the most important subject in ad hoc networks now a days. Flying Ad Hoc Network (FANET) is one of the emerging areas that evolved from Mobile Ad Hoc Networks. Selecting the best optimal path in any network is a real challenge for a routing protocol. Because the network performance like throughput, Quality of Service (QoS), user experience, response time and other key parameters depend upon the efficiency of the algorithm running inside the routing protocol. The complexity and diversity of the problem is augmented due to dynamic spatial and temporal mobility of FANET nodes. Due to these challenges the performance and efficiency of the routing protocol becomes very critical. This paper presents a novel routing protocol for FANET using modified AntHocNet. Ant colony optimization technique or metaheuristics in general has shown better dependability and performance as compared to other legacy best path selection techniques. Energy stabilizing parameter introduced in this study improves energy efficiency and overall network performance. Simulation results show that the proposed protocol is better than generic Ant Colony Optimization (ACO) and other traditional routing protocols utilized in FANET.","['Routing protocols', 'Routing', 'Mobile ad hoc networks', 'Ant colony optimization', 'Quality of service', 'Topology']","['FANET', 'routing', 'nature inspired algorithms', 'ACO']"
"Permanent magnet synchronous motors (PMSMs) are widely used in the field of industrial servo control, especially in high-precision applications. Owing to the periodic torque ripple caused by the cogging torque, flux harmonics, and current offsets, the speed output of the system has a periodic ripple, which affects the control accuracy of the servo system. The conventional proportional–integral controllers cannot reject torque ripple and are highly dependent on motor parameters. This limits the control performance when a PMSM is used as a high-precision servo system. Thus, this paper proposes a combination of model predictive control (MPC) and iterative learning control (ILC) to not only speed up the response time of the system but also effectively reduce the speed ripples. MPC updates the predictive model in real time through feedback and evaluates the system output and control rate according to the cost function. It obtains an optimal control sequence for the next moment and has good parameter robustness and fast response. ILC records the speed of ripple signals over an entire cycle and then uses those signals to compensate for the control signal in the next cycle. It is capable of reducing the periodic speed ripples. The experimental verification of the schemes was conducted on a digital signal processor–field programmable gate-array-based platform. The experimental results obtained confirm the effectiveness of the proposed MPC–ILC scheme.","['Torque', 'Torque measurement', 'Permanent magnet motors', 'Stators', 'Forging', 'Harmonic analysis', 'Synchronous motors']","['Iterative learning control', 'model predictive control', 'PMSM control', 'speed ripple']"
"Sliding Mode Control and Adaptive Control are widely studied in the area of Rotor UAV in recent years. Although the performance of Rotor UAV with these controllers show high command tracking ability and good robustness, they are limited by model accuracy so that they cannot take place PID. In this paper, a novel method named State damping control is proposed to be a candidate for the traditional PID method. Our proposed State Damping Control is inspired by the format of air resistance. The method is based on the general idea that resistance will make a system easy to stabilize. State damping control is independent of model accuracy and just uses three parameters to control attitude, so it is easy to realize. Krasovskii Theorem is used to give the evidence that State damping control is asymptotic stable in our considered state space. Finally, simulations are implemented in C++ on VS2017, it demonstrates that State damping control is easy to be tuned and robust to wind attack and inertial parameters. Compared with PID, our proposed method is robust to wind disturbances obviously.","['Mathematical model', 'Robustness', 'Damping', 'Backstepping', 'Aerodynamics', 'Navigation', 'Adaptation models']","['State damping control', 'robust control', 'nonlinear systems', 'computational methods']"
"Wireless network virtualization (WNV) has drawn attention from the researchers ranging from academia to industry as one of the significant technologies in the cellular network communication. It is considered as a pioneer to achieve effective resource utilization with decreased operating expenses and capital expenses by decoupling the networks functionalities of coexisting virtual networks. It facilitates fast deployment of new services and novel technologies. WNV paradigm is in the early stages, and there is a large room for the research community to develop new architectures, systems, and applications. The availability of software-defined networking (SDN) and cloud/centralized radio access network (C-RAN) steers up the hope for the WNV realization. This paper surveys WNV along with the recent developments in SDN and C-RAN technologies. Based on these technologies and WNV concepts, we identify the requirements and opportunities of future cellular networks. We then propose a general architectural framework for the WNV based on SDN. In-depth discussion of challenges and research issues as well as promising approaches for future networks communication improvements are also proposed. Finally, we give several promising candidates of future network services for residential customers and business customers.","['Virtualization', 'Wireless networks', 'Hardware', 'Resource management', 'Mobile communication', 'Indium phosphide']","['5G Networks', 'C-RAN', 'infrastructure provider', 'SDN', 'virtual networks', 'wireless network virtualization']"
"Audio-visual recognition (AVR) has been considered as a solution for speech recognition tasks when the audio is corrupted, as well as a visual recognition method used for speaker verification in multispeaker scenarios. The approach of AVR systems is to leverage the extracted information from one modality to improve the recognition ability of the other modality by complementing the missing information. The essential problem is to find the correspondence between the audio and visual streams, which is the goal of this paper. We propose the use of a coupled 3D convolutional neural network (3D CNN) architecture that can map both modalities into a representation space to evaluate the correspondence of audio-visual streams using the learned multimodal features. The proposed architecture will incorporate both spatial and temporal information jointly to effectively find the correlation between temporal information for different modalities. By using a relatively small network architecture and much smaller data set for training, our proposed method surpasses the performance of the existing similar methods for audio-visual matching, which use 3D CNNs for feature representation. We also demonstrate that an effective pair selection method can significantly increase the performance. The proposed method achieves relative improvements over 20% on the equal error rate and over 7% on the average precision in comparison to the state-of-the-art method.","['Feature extraction', 'Speech', 'Speech recognition', 'Visualization', 'Lips', 'Three-dimensional displays', 'Data mining']","['Convolutional networks', '3D architecture', 'deep learning', 'audio-visual recognition']"
"Corona pandemic has affected the whole world, and it is a highly researched area in biological sciences. As the current pandemic has affected countries socially and economically, the purpose of this bibliometric analysis is to provide a holistic review of the corona pandemic in the field of social sciences. This study aims to highlight significant, influential aspects, research streams, and themes. We have reviewed 395 journal articles related to coronavirus in the field of social sciences from 2003 to 2020. We have deployed ‘biblioshiny’ a web-interface of the ‘bibliometrix 3.0’ package of R-studio to conduct bibliometric analysis and visualization. In the field of social sciences, we have reported influential aspects of coronavirus literature. We have found that the ‘Morbidity and Mortality Weekly Report’ is the top journal. The core article of coronavirus literature is ‘Guidelines for preventing health-care-associated pneumonia’. The most commonly used word, in titles, abstracts, author’s keywords, and keywords plus, is ‘SARS’. Top affiliation is ‘The University of Hong Kong’. Hong Kong is a leading country based on citations, and the USA is on top based on total publications. We have used a conceptual framework to identify potential research streams and themes in coronavirus literature. Four research streams are found by deploying a co-occurrence network. These research streams are ‘Social and economic effects of epidemic disease’, ‘Infectious disease calamities and control‘, ‘Outbreak of COVID 19,’ and ‘Infectious diseases and the role of international organizations’. Finally, a thematic map is used to provide a holistic understanding by dividing significant themes into basic or transversal, emerging or declining, motor, highly developed, but isolated themes. These themes and subthemes have proposed future directions and critical areas of research.","['COVID-19', 'Bibliometrics', 'Social sciences', 'Corona', 'Pandemics', 'Infectious diseases', 'Production']","['Bibliometric analysis', 'biblioshiny', 'conceptual structure', 'COVID survey', 'coronavirus', 'COVID-19', 'pandemic', 'r-studio', 'SARS', 'social sciences']"
"The optical fiber acoustic sensing system is suitable for long-distance monitoring of the acoustic signals generated by the external disturbances. According to the continuity of sensing units, quasi-distributed and distributed optical fiber acoustic sensing technologies are differentiated to meet different application requirements. On the one hand, the recent progress of Fabry-Perot interferometer (FPI) focusing on the diaphragm material, and the research hotspots in the field of the continuous Fiber Bragg grating (FBG) array are firstly reviewed. On the other hand, Mach-Zehnder interferometry (MZI), Michelson interferometry (MI), and Sagnac interferometry (SI) have rapidly developed in the aspect of the demodulation algorithm optimization with the purpose of the sensing performance improvement. Moreover, the current primary research works of the phase-sensitive optical time-domain reflectometer (φ-OTDR) are the signal-to-noise ratio improvement and the mixed optical structure design. Finally, this paper presents an overview of the recent advances of optical fiber acoustic sensing system in the application domains of military defense, structural health monitoring, petroleum exploration, and development.","['Optical interferometry', 'Optical fiber sensors', 'Optical fibers', 'Acoustics']","['Acoustic detection', 'distributed acoustic sensing', 'optical fiber sensing', 'φ-OTDR', 'structural health monitoring']"
"Synthetic aperture radar (SAR) ship detection based on deep learning has been widely applied in recent years. However, two main obstacles are hindering SAR ship detection. First, the identification of ships in a port is seriously disrupted by the presence of onshore buildings. It is difficult for the existing detection algorithms to effectively distinguish the targets from such a complex background. Additionally, it appears more complicated to accurately locate densely arranged ships. Second, the ships in SAR images exist at a variety of scales due to multiresolution imaging modes and the variety of ship shapes; these pose a much greater challenge to ship detection. To solve the above problems, this paper proposes an object detection network combined with an attention mechanism to accurately locate targets in complex scenarios. To address the diverse scales of ship targets, we construct a loss function that incorporates the generalized intersection over union (GIoU) loss to reduce the scale sensitivity of the network. For the final processing of the results, soft nonmaximum suppression (Soft-NMS) is also introduced into the model to reduce the number of missed detections for ship targets in the presence of severe overlap. The experimental results reveal that the proposed model exhibits excellent performance on the extended SAR ship detection dataset (SSDD) while achieving real-time detection.","['Marine vehicles', 'Feature extraction', 'Radar polarimetry', 'Detection algorithms', 'Synthetic aperture radar', 'Object detection', 'Neural networks']","['Ship detection', 'synthetic aperture radar (SAR)', 'deep neural network', 'attention mechanism']"
"The recent advance in neural network architecture and training algorithms has shown the effectiveness of representation learning. The neural-network-based models generate better representation than the traditional ones. They have the ability to automatically learn the distributed representation for sentences and documents. To this end, we proposed a novel model that addresses several issues that are not adequately modeled by the previously proposed models, such as the memory problem and incorporating the knowledge of document structure. Our model uses a hierarchical structured self-attention mechanism to create the sentence and document embeddings. This architecture mirrors the hierarchical structure of the document and in turn enables us to obtain better feature representation. The attention mechanism provides extra source of information to guide the summary extraction. The new model treated the summarization task as a classification problem in which the model computes the respective probabilities of sentence-summary membership. The model predictions are broken up by several features such as information content, salience, novelty, and positional representation. The proposed model was evaluated on two well-known datasets, the CNN/Daily Mail and DUC 2002. The experimental results show that our model outperforms the current extractive state of the art by a considerable margin.","['Computational modeling', 'Computer architecture', 'Task analysis', 'Data mining', 'Recurrent neural networks', 'Feature extraction', 'Semantics']","['Long short-term memory', 'hierarchical structured self-attention', 'document summarization', 'abstract features', 'sentence embedding', 'document embedding']"
"Cognitive prediction in the complicated and active environments is of great importance role in artificial learning. Classification accuracy of sound events has a robust relation with the feature extraction. In this paper, deep features are used in the environmental sound classification (ESC) problem. The deep features are extracted by using the fully connected layers of a newly developed Convolutional Neural Networks (CNN) model, which is trained in the end-to-end fashion with the spectrogram images. The feature vector is constituted with concatenating of the fully connected layers of the proposed CNN model. For testing the performance of the proposed method, the feature set is conveyed as input to the random subspaces K Nearest Neighbor (KNN) ensembles classifier. The experimental studies, which are carried out on the DCASE-2017 ASC and the UrbanSound8K datasets, show that the proposed CNN model achieves classification accuracies 96.23% and 86.70%, respectively.","['Feature extraction', 'Hidden Markov models', 'Spectrogram', 'Support vector machines', 'Training', 'Convolution', 'Time-frequency analysis']","['Environmental sound classification', 'spectrogram images', 'CNN model', 'deep features']"
"An inherently non-negative latent factor model is proposed to extract non-negative latent factors from non-negative big sparse matrices efficiently and effectively. A single-element-dependent sigmoid function connects output latent factors with decision variables, such that non-negativity constraints on the output latent factors are always fulfilled and thus successfully separated from the training process with respect to the decision variables. Consequently, the proposed model can be easily and fast built with excellent prediction accuracy. Experimental results on an industrial size sparse matrix are given to verify its outstanding performance and suitability for industrial applications.","['Sparse matrices', 'Predictive models', 'Decision making', 'Training', 'Latent forces']","['Latent Factors', 'Non-negativity', 'Inherently Non-negative', 'Non-negative Big Sparse Matrices', 'Big Data']"
"Traction inverter has been the subject of many studies due to its essential role in the proper performance of the drive system. With the recent trend in increasing the input voltage in battery-powered electric vehicles, multilevel inverters have been proposed in the literature as a promising substitute for conventional two-level traction inverters. A critical aspect of utilizing multilevel structures is employing proper control and modulation techniques. The control system structure must be capable of handling a number of key issues, like capacitor voltage balancing and equal power loss sharing, which arise in multilevel topologies. This paper presents a review of the present-day traction drive systems in the industry, control and modulation techniques for multilevel structures in the inverters, as well as the principal challenges that need to be addressed in the control stage of the multilevel traction inverter. A comparison has been made between different methods based on the most important criteria and requirements of the traction drive system. Finally, future trends in this application are presented and some suggestions have been made for the next generation of traction drives.","['Inverters', 'Batteries', 'Semiconductor device modeling', 'Topology', 'Market research', 'Insulated gate bipolar transistors', 'Control systems']","['Direct torque control', 'electric vehicles', 'model-predictive control', 'modulation and control schemes', 'multilevel inverters', 'traction motor drives', 'transportation electrification']"
"The Internet of Things (IoT) is shaping the current and next generation of the Internet. The vision of IoT is to embed communication capabilities with a highly distributed, ubiquitous and dense heterogeneous devices network. This vision includes the adaptation of secure mobile networks, anytime, anywhere, by anyone or anything with new intelligent applications and services. Many efforts have been made to review the literature related to the IoT for the benefit of IoT development. However, many issues need to be addressed to overtake the full potential of the IoT. Therefore, this paper aims to classify and standardize IoT research areas by considering review papers that were published between 2010 and 2019. This paper analyzes a total of 95 related reviews, which were manually selected from databases based on 6 chosen areas. This paper presents the trends and classification of IoT reviews based on 6 research areas, namely, application, architecture, communication, challenges, technology, and security. IoT communication research has been dominating the trends with 21% of total reviews and more than 100% research growth in the last 10 years. Hence, this paper can provide useful insights into specific emerging areas of IoT to assist future research.","['Internet of Things', 'Market research', 'Security', 'Protocols', 'Machine-to-machine communications']","['IoT applications', 'IoT architectures', 'IoT challenges', 'IoT communication', 'IoT security', 'IoT technology']"
"Big data (BD) analytics is one of the critical components in the digitalization of the oil and gas (O&G) industry. Its focus is managing and processing a high volume of data to improve operational efficiency, enhance decision making and mitigate risks in the workplace. Enhanced processing of seismic data also provides the industry with a better understanding of BD applications. However, the industry still exercises caution in adopting new technologies. The slow pace of technology adoption can be attributed to various causes, from the obstacles to the integration with existing systems, to cybersecurity for defending the BD system against cyber attacks. In some applications using wearable devices, physiological and location-tracking data also causes concerns related to workplace privacy implications. These shortcomings give rise to uncertainties about the practical benefits and effectiveness of applying BD in O&G activities. The objective of this paper is to perform a systematic review of BD analytics within the context of the O&G industry. This paper attempts to evaluate technical and nontechnical factors affecting the adoption of BD technologies. The study includes BD development platforms, network architecture, data privacy implications, cybersecurity, and the opportunities and challenges of adopting BD technologies in the O&G industry.","['Industries', 'Big Data', 'Oils', 'Tools', 'Data privacy', 'Production', 'Reservoirs']","['Big data analytics', 'O&G digitalization', 'Industry 4.0', 'data privacy and security']"
"Wireless Body Area Network is an emerging technology that is used primarily in the area of healthcare applications. It is a low-cost network having the capability of transportability and adaptability. It can be used in location independent and long-term remote monitoring of people without disturbing their daily activities. In a typical WBAN system, sensing devices are either implanted or etched into the human body that continuously monitors his physiological parameters or vital signs. In such a network, trusts among the stakeholders (healthcare providers, users, and medical staff, etc.) are found of high importance and regarded as the critical success factor for the reliability of information exchange among them. In remote patient monitoring, the implementation of trust and privacy preservation is crucial, as vital parameters are being communicated to remote locations. Nonetheless, its widespread use, WBAN, has severe trust and privacy risks, limiting its adaptation in healthcare applications. To address trust and privacy-related issues, reliable communication solutions are widely used in WBANs. Given the motivation, in this paper, we have proposed a trust-based communication scheme to ensure the reliability and privacy of WBAN. To ensure reliability, a cooperative communication approach is used, while for privacy preservation, a cryptography mechanism is used. The performance of the proposed scheme is evaluated using MATLAB simulator. The output results demonstrated that the proposed scheme increases service delivery ratio, reliability, and trust with reduced average delay. Furthermore, a fuzzy-logic method used for ranking benchmark schemes, that has been concluded that the proposed scheme has on top using comparative performance ranking.","['Wireless communication', 'Body area networks', 'Reliability', 'Patient monitoring', 'Medical services', 'Wireless sensor networks', 'Trust management']","['Wireless body area networks', 'body-to-body-networks', 'energy-efficiency', 'trust-based communication', 'reliability', 'fuzzy logic']"
"E-Learning has become more and more popular in recent years with the advance of new technologies. Using their mobile devices, people can expand their knowledge anytime and anywhere. E-Learning also makes it possible for people to manage their learning progression freely and follow their own learning style. However, studies show that E-Learning can cause the user to experience feelings of isolation and detachment due to the lack of human-like interactions in most E-Learning platforms. These feelings could reduce the user's motivation to learn. In this paper, we explore and evaluate how well current chatbot technologies assist users' learning on E-Learning platforms and how these technologies could possibly reduce problems such as feelings of isolation and detachment. For evaluation, we specifically designed a chatbot to be an E-Learning assistant. The NLP core of our chatbot is based on two different models: a retrieval-based model and a QANet model. We designed this two-model hybrid chatbot to be used alongside an E-Learning platform. The core response context of our chatbot is not only designed with course materials in mind but also everyday conversation and chitchat, which make it feel more like a human companion. Experiment and questionnaire evaluation results show that chatbots could be helpful in learning and could potentially reduce E-Learning users' feelings of isolation and detachment. Our chatbot also performed better than the teacher counselling service in the E-Learning platform on which the chatbot is based.","['Electronic learning', 'Chatbot', 'Google', 'Urban areas', 'Market research']","['E-Learning', 'chatbot', 'isolation', 'detachment', 'retrieval-based model', 'QANet']"
"In this study, artificial intelligence and image recognition technologies are combined with environmental sensors and the Internet of Things (IoT) for pest identification. Real-time agricultural meteorology and pest identification systems on mobile applications are evaluated based on intelligent pest identification and environmental IoT data. We combined the current mature AIoT technology and deep learning and applied it to smart agriculture. We used deep learning YOLOv3 for image recognition to obtain the location of Tessaratoma papillosa and analyze the environmental information from weather stations through Long Short-Term Memory (LSTM) to predict the occurrence of pests. The experimental results showed that the pest identification accuracy reached 90%. Precise positioning can effectively reduce the amount of pesticides used and reduce pesticide damage to the soil. The current research provides the location of the pest and the extent of the pests to farmers can accurately use pesticide application at a precise time and place and thus reduce the agricultural workforce required for timely pest control, thus achieving the goal of smart agriculture. The proposed system notifies farmers of the presence of different pests before they start multiplying in large numbers. It improves overall agricultural economic value by providing appropriate pest control methods that decrease crop losses and reduce the environmental damage caused by the excessive usage of pesticides.","['Agriculture', 'Machine learning', 'Image recognition', 'Feature extraction', 'Training', 'Detectors']","['Deep learning', 'YOLOv3', 'pests and diseases', 'smart agriculture', 'unmanned aerial vehicle (UAV)', 'artificial intelligence (AI)', 'Internet of Things (IoT)', 'the artificial Intelligence of Things (AIoT)']"
"The aim of this study is to generate appropriate strategies to improve renewable energy investments. Within this framework, a novel model has also been proposed which includes three different stages. Firstly, incomplete preferences of the relation matrixes are calculated. For this purpose, 4 different decision makers evaluate the balanced scorecard-based criteria. In this stage, missing values are estimated by incomplete preferences to complete the relation matrixes. Additionally, the second stage includes the computing the fuzzy preferences by considering the consensus-based group decision-making (CGDM). The final stage is related to the calculation of the weights of the criteria by considering Pythagorean fuzzy decision-making trial and evaluation laboratory (DEMATEL) methodology. Hence, the main motivation of this study is to identify innovative strategies for the renewable energy investments with a novel multi-criteria decision-making (MCDM) model based on incomplete preferences, CGDM and Pythagorean fuzzy sets. The findings indicate that learning and growth is the most important balanced scorecard-based perspective to improve the performance of renewable energy investments. Additionally, the perspective of internal process is identified as another significant factor for this situation. The biggest problem in renewable energy projects is their high initial costs. Hence, technological developments reduce the production costs of renewable energy sources. Additionally, it is also possible to increase the amount of electricity from renewable energy sources owing to the innovative technologies. Thus, renewable energy investors should follow up-to-date technological developments so that it will be possible to reduce the cost of renewable energy investments.","['Investment', 'Renewable energy sources', 'Decision making', 'Fuzzy sets', 'Bibliographies', 'Companies']","['Renewable energy investments', 'incomplete preferences', 'consensus group decision making', 'Pythagorean fuzzy sets', 'balanced scorecard', 'DEMATEL']"
"Ultra-high frequency radio frequency identification (UHF RFID) localization technique has been considered increasingly promising in indoor positioning systems. However, conventional localization algorithms are vulnerable in multipath and non-line of sight (NLOS) environments. To solve this problem, this paper presents an indoor localization method based on angle of arrival and phase difference of arrival (PDOA) using virtual stations for passive UHF RFID. We use the array antenna to distinguish multipath signals and choose the two strongest paths according to the received signal strength to perform localization. The angles of the two paths are obtained through the phase difference of the received signals at different array elements, and the distances of the two paths are estimated through PDOA measurement. After obtaining the angles and distances, we establish virtual stations to convert NLOS paths into LOS paths. The possible positions of the tag are calculated through virtual stations, angle, and distance information, which are derived from the two signal paths. Then, the weighted least squares combined with residual weighted algorithm are proposed to calculate real position of the tag. Simulation results demonstrate that our method achieves decimeter level accuracy and has higher precision than traditional algorithms.","['Antenna arrays', 'Estimation', 'Passive RFID tags', 'Multiple signal classification', 'Channel models', 'Mathematical model']","['AOA', 'PDOA', 'multipath', 'NLOS', 'UHF RFID', 'virtual stations']"
"As an algorithm with excellent performance, convolutional neural network has been widely used in the field of image processing and achieved good results by relying on its own local receptive fields, weight sharing, pooling, and sparse connections. In order to improve the convergence speed and recognition accuracy of the convolutional neural network algorithm, this paper proposes a new convolutional neural network algorithm. First, a recurrent neural network is introduced into the convolutional neural network, and the deep features of the image are learned in parallel using the convolutional neural network and the recurrent neural network. Secondly, according to the idea of ResNet's skip convolution layer, a new residual module ShortCut3-ResNet is constructed. Then, a dual optimization model is established to realize the integrated optimization of the convolution and full connection process. Finally, the effects of various parameters of the convolutional neural network on the network performance are analyzed through simulation experiments, and the optimal network parameters of the convolutional neural network are finally set. Experimental results show that the convolutional neural network algorithm proposed in this paper can learn the diverse features of the image, and improve the accuracy of feature extraction and image recognition ability of the convolutional neural network.","['Convolutional neural networks', 'Feature extraction', 'Image recognition', 'Convolution', 'Neurons', 'Recurrent neural networks', 'Optimization']","['Convolutional neural network', 'artificial intelligence', 'image recognition']"
"Big data analytics (BDA) is a systematic approach for analyzing and identifying different patterns, relations, and trends within a large volume of data. In this paper, we apply BDA to criminal data where exploratory data analysis is conducted for visualization and trends prediction. Several the state-of-the-art data mining and deep learning techniques are used. Following statistical analysis and visualization, some interesting facts and patterns are discovered from criminal data in San Francisco, Chicago, and Philadelphia. The predictive results show that the Prophet model and Keras stateful LSTM perform better than neural network models, where the optimal size of the training data is found to be three years. These promising outcomes will benefit for police departments and law enforcement organizations to better understand crime issues and provide insights that will enable them to track activities, predict the likelihood of incidents, effectively deploy resources and optimize the decision making process.","['Data mining', 'Data visualization', 'Market research', 'Big Data', 'Predictive models', 'Urban areas', 'Deep learning']","['Big data analytics (BDA)', 'data mining', 'data visualization', 'neural network', 'time series forecasting']"
"With the evaluation and simulation of long-term evolution/4G cellular network and hot discussion about new technologies or network architecture for 5G, the appearance of simulation and evaluation guidelines for 5G is in urgent need. This paper analyzes the challenges of building a simulation platform for 5G considering the emerging new technologies and network architectures. Based on the overview of evaluation methodologies issued for 4G candidates, challenges in 5G evaluation are formulated. Additionally, a cloud-based two-level framework of system-level simulator is proposed to validate the candidate technologies and fulfill the promising technology performance identified for 5G.","['Wireless communication', '5G mobile communication', 'Performance evaluation', 'Long Term Evolution', 'Cellular networks', 'System level design and analysis']","['5G', 'system-level simulations', 'performance evaluation', 'two-level simulator']"
"This paper proposes a hybrid approach combining Wigner-Ville distribution (WVD) with convolutional neural network (CNN) for power quality disturbance (PQD) classification. Firstly, a WVD technique is developed to transfer a 1D voltage disturbance signal into a 2D image file, followed by a CNN model developed for the image classification. Then, the feature maps are extracted automatically from the image file and different patterns are extracted from variables on CNN. A set of synthetic signals, as well as real-world measurement data, are used to test the proposed method. The high classification accuracy of test results is achieved to confirm the effectiveness of the proposed method. Furthermore, the model is simplified and optimized by visualizing the output of convolutional layers. On this basis, one visualizing technique called the class activation map (CAM) is used to identify the location and shape of “hotspots (PQDs)”. The effect of incorrect classification of the model is analyzed with the CAM. Therefore, the proposed method is proved to have the capability of providing necessary and accurate information for PQDs, which will then be used to determine the subsequent PQ remedy actions accordingly.","['Feature extraction', 'Convolution', 'Time-frequency analysis', 'Power quality', 'Kernel', 'Deep learning', 'Convolutional neural networks']","['Classification', 'convolutional neural network (CNN)', 'deep learning', 'power quality disturbances', 'power systems', 'Wigner-Ville distribution (WVD)']"
"Novel air traffic management (ATM) strategies are proposed through the Next Generation Air Transportation and Single European Sky for ATM Research projects to improve the capacity of the airspace and to meet the demands of the future air traffic. The implementation of the proposed solutions leads to increasing use of wireless data for aeronautical communications. Another emerging trend is the unmanned aerial vehicles. The unmanned aerial systems (UASs) need reliable wireless data link and dedicated spectrum allocation for its operation. On-board broadband connectivity also needs dedicated spectrum to satisfy the quality of service requirements of the users. With the growing demand, the aeronautical spectrum is expected to be congested. However, the studies revealed that the aeronautical spectrum is underutilized due to the static spectrum allocation strategy. The aeronautical communication systems, such as air-air and air-ground communication systems, inflight infotainment systems, wireless avionics intra-communications, and UAS, can benefit significantly from the introduction of cognitive radio-based transmission schemes. This paper summarizes the current trends in aeronautical spectrum management followed by the major applications and contributions of cognitive radio in solving the spectrum scarcity crisis in the aeronautical domain. Also, to cope with the evolving technological advancement, researchers have prioritized the issues in the case of cognitive radio that needs to be addressed depending on the domain of operation. The proposed cognitive aeronautical communication systems should also be compliant with the Aeronautical Radio Incorporated and Aerospace Recommended Practice standards. An overview of these standards and the challenges that need immediate attention to make the solution feasible for a large-scale operation, along with the future avenues of research is also furnished.","['Cognitive radio', 'Market research', 'Resource management', 'Quality of service', 'Air traffic control', 'Aeronautical communication']","['Aeronautical communications', 'cognitive radio', 'interweave mode', 'overlay mode', 'underlay mode']"
"Until now, an effective defense method against Distributed Denial of Service (DDoS) attacks is yet to be offered by security systems. Incidents of serious damage due to DDoS attacks have been increasing, thereby leading to an urgent need for new attack identification, mitigation, and prevention mechanisms. To prevent DDoS attacks, the basic features of the attacks need to be dynamically analyzed because their patterns, ports, and protocols or operation mechanisms are rapidly changed and manipulated. Most of the proposed DDoS defense methods have different types of drawbacks and limitations. Some of these methods have signature-based defense mechanisms that fail to identify new attacks and others have anomaly-based defense mechanisms that are limited to specific types of DDoS attacks and yet to be applied in open environments. Subsequently, extensive research on applying artificial intelligence and statistical techniques in the defense methods has been conducted in order to identify, mitigate, and prevent these attacks. However, the most appropriate and effective defense features, mechanisms, techniques, and methods for handling such attacks remain to be an open question. This review paper focuses on the most common defense methods against DDoS attacks that adopt artificial intelligence and statistical approaches. Additionally, the review classifies and illustrates the attack types, the testing properties, the evaluation methods and the testing datasets that are utilized in the methodology of the proposed defense methods. Finally, this review provides a guideline and possible points of encampments for developing improved solution models of defense methods against DDoS attacks.","['Computer crime', 'Botnet', 'Artificial intelligence', 'Servers', 'Tools']","['DDoS attack', 'DDoS defense', 'artificial intelligence technique', 'statistical technique']"
"The problem of adaptive traffic signal control in the multi-intersection system has attracted the attention of researchers. Among the existing methods, reinforcement learning has shown to be effective. However, the complex intersection features, heterogeneous intersection structures, and dynamic coordination for multiple intersections pose challenges for reinforcement learning-based algorithms. This paper proposes a cooperative deep Q-network with Q-value transfer (QT-CDQN) for adaptive multi-intersection signal control. In QT-CDQN, a multi-intersection traffic network in a region is modeled as a multi-agent reinforcement learning system. Each agent searches the optimal strategy to control an intersection by a deep Q-network that takes the discrete state encoding of traffic information as the network inputs. To work cooperatively, the agent considers the influence of the latest actions of its adjacencies in the process of policy learning. Especially, the optimal Q-values of the neighbor agents at the latest time step are transferred to the loss function of the Q-network. Moreover, the strategy of the target network and the mechanism of experience replay are used to improve the stability of the algorithm. The advantages of QT-CDQN lie not only in the effectiveness and scalability for the multi-intersection system but also in the versatility to deal with the heterogeneous intersection structures. The experimental studies under different road structures show that the QT-CDQN is competitive in terms of average queue length, average speed, and average waiting time when compared with the state-of-the-art algorithms. Furthermore, the experiments of recurring congestion and occasional congestion validate the adaptability of the QT-CDQN to dynamic traffic environments.","['Reinforcement learning', 'Feature extraction', 'Roads', 'Aerospace electronics', 'Heuristic algorithms', 'Adaptation models', 'Fuzzy logic']","['Deep reinforcement learning', 'multi-intersection signal control', 'Q-learning', 'Q-value transfer', 'cooperative']"
"The advances in smart grids are enabling huge amount of data to be aggregated and analyzed for various smart grid applications. However, the traditional smart grid data management systems cannot scale and provide sufficient storage and processing capabilities. To address these challenges, this paper presents a smart grid big data eco-system based on the state-of-the-art Lambda architecture that is capable of performing parallel batch and real-time operations on distributed data. Furthermore, the presented eco-system utilizes a Hadoop Big Data Lake to store various types of smart grid data including smart meter, images, and video data. An implementation of the smart grid big data eco-system on a cloud computing platform is presented. To test the capability of the presented eco-system, real-time visualization and data mining applications were performed on the real smart grid data. The results of those applications on top of the eco-system suggest that it is capable of performing numerous smart grid big data analytics.","['Smart grids', 'Big Data', 'Computer architecture', 'Real-time systems', 'Data mining', 'Distributed databases', 'Task analysis']","['Smart grids', 'smart meter', 'big data', 'cloud', 'data mining', 'clustering', 'visualization']"
"Human Activity Recognition (HAR) has been attracting significant research attention because of the increasing availability of environmental and wearable sensors for collecting HAR data. In recent years, deep learning approaches have demonstrated a great success due to their ability to model complex systems. However, these models are often evaluated on the same subjects as those used to train the model; thus, the provided accuracy estimates do not pertain to new subjects. Occasionally, one or a few subjects are selected for the evaluation, but such estimates highly depend on the subjects selected for the evaluation. Consequently, this paper examines how well different machine learning architectures make generalizations based on a new subject(s) by using Leave-One-Subject-Out Cross-Validation (LOSOCV). Changing the subject used for the evaluation in each fold of the cross-validation, LOSOCV provides subject-independent estimate of the performance for new subjects. Six feed forward and convolutional neural network (CNN) architectures as well as four pre-processing scenarios have been considered. Results show that CNN architecture with two convolutions and one-dimensional filter accompanied by a sliding window and vector magnitude, generalizes better than other architectures. For the same CNN, the accuracy improves from 85.1% when evaluated with LOSOCV to 99.85% when evaluated with the traditional 10-fold cross-validation, demonstrating the importance of using LOSOCV for the evaluation.",[],[]
"In recent years, many studies have investigated the potential of demand response management (DRM) schemes to manage energy for residential buildings in a smart grid. However, most of the existing studies mainly focus on the theoretical design of DRM schemes and do not verify the proposed schemes through implementation. Smart grid research is highly interdisciplinary. As such, the establishment of testbeds to conduct DRM requires various skill sets that might not always be possible to arrange. However, the implementation of a DRM scheme is critical not only to verify the correctness of the design in a practical environment but also to address many important assumptions that are necessary for the actual deployment of the scheme. Thus, the theoretical aspect of DRM solutions should be discussed and verified in a practical environment to ensure that the scheme is suitable for deployment. In this paper, we propose a DRM scheme and construct a residential smart grid testbed to implement the proposed scheme. In the proposed DRM scheme, we suggest two different types of customer engagement plans, namely, green savvy plan and green aware plan, and design algorithms based on two user inconvenience indices to evaluate DRM for peak load reduction. The testbed verifies the effectiveness and efficiency of the proposed DRM scheme.","['Smart grids', 'Home appliances', 'Logic gates', 'Load modeling', 'Load management', 'Green products']","['Smart grid', 'user inconvenience', 'peak load reduction', 'customer engagement plan', 'demand response', 'energy management service (EMS)', 'implementation']"
"CT screening has been proven to be effective for diagnosing lung cancer at its early manifestation in the form of pulmonary nodules, thus decreasing the mortality. However, the exponential increase of image data makes their accurate assessment a very challenging task given that the number of radiologists is limited and they have been overworked. Recently, numerous methods, especially ones based on deep learning with convolutional neural network (CNN), have been developed to automatically detect and classify pulmonary nodules in medical images. In this paper, we present a comprehensive analysis of these methods and their performances. First, we briefly introduce the fundamental knowledge of CNN as well as the reasons for their suitability to medical images analysis. Then, a brief description of various medical images datasets, as well as the environmental setup essential for facilitating lung nodule investigations with CNNs, is presented. Furthermore, comprehensive overviews of recent progress in pulmonary nodule analysis using CNNs are provided. Finally, existing challenges and promising directions for further improving the application of CNN to medical images analysis and pulmonary nodule assessment, in particular, are discussed. It is shown that CNNs have transformed greatly the early diagnosis and management of lung cancer. We believe that this review will provide all the medical research communities with the necessary knowledge to master the concept of CNN so as to utilize it for improving the overall human healthcare system.","['Cancer', 'Lung', 'Computed tomography', 'Medical diagnostic imaging', 'Deep learning', 'Convolutional neural networks']","['Lung cancer', 'deep learning', 'convolutional neural networks', 'computed tomography (CT) images', 'pulmonary nodules', 'image classification']"
"This paper studies the optimal charging scheduling for electric vehicles (EVs) in a workplace parking lot, powered by both the photovoltaic power system and the power grid. Due to the uncertainty and fluctuation of solar energy and the time-varying EV charging requirements, it is challenging to guarantee the economic operation of the parking lot charging station. To address this issue, we formulate the EV charging scheduling in the parking lot as a benefit maximization problem. First, by analyzing the relationship among the EV charging requirements, the charging load, and the harvested solar energy, we derive several necessary conditions for obtaining an optimal decision, such that the primal optimization problem can be simplified. Then, we design a dynamic charging scheduling scheme (DCSS) to manage the EV charging processes, in which the model predictive control method is employed to deal with the real-time information of EV charging requirements and the solar energy. Simulation results demonstrate the effectiveness and efficiency of the designed DCSS.","['Electric vehicle charging', 'Solar energy', 'Power grids', 'Dynamic scheduling', 'Renewable energy sources', 'Power system dynamics']","['Electric vehicle', 'charging scheduling', 'photovoltaic power', 'model predictive control']"
"Personal and business users prefer to use e-mail as one of the crucial sources of communication. The usage and importance of e-mails continuously grow despite the prevalence of alternative means, such as electronic messages, mobile applications, and social networks. As the volume of business-critical e-mails continues to grow, the need to automate the management of e-mails increases for several reasons, such as spam e-mail classification, phishing e-mail classification, and multi-folder categorization, among others. This paper comprehensively reviews articles on e-mail classification published in 2006-2016 by exploiting the methodological decision analysis in five aspects, namely, e-mail classification application areas, data sets used in each application area, feature space utilized in each application area, e-mail classification techniques, and the use of performance measures. A total of 98 articles (56 articles from Web of Science core collection databases and 42 articles from Scopus database) are selected. To achieve the objective of the study, a comprehensive review and analysis is conducted to explore the various areas where e-mail classification was applied. Moreover, various public data sets, features sets, classification techniques, and performance measures are examined and used in each identified application area. This review identifies five application areas of e-mail classification. The most widely used data sets, features sets, classification techniques, and performance measures are found in the identified application areas. The extensive use of these popular data sets, features sets, classification techniques, and performance measures is discussed and justified. The research directions, research challenges, and open issues in the field of e-mail classification are also presented for future researchers.","['Electronic mail', 'Feature extraction', 'Area measurement', 'Databases', 'Computer science', 'Information filters']","['Email classification', 'spam detection', 'phishing detection', 'multi-folder categorization', 'machine learning techniques']"
"Time series prediction with neural networks has been the focus of much research in the past few decades. Given the recent deep learning revolution, there has been much attention in using deep learning models for time series prediction, and hence it is important to evaluate their strengths and weaknesses. In this paper, we present an evaluation study that compares the performance of deep learning models for multi-step ahead time series prediction. The deep learning methods comprise simple recurrent neural networks, long short-term memory (LSTM) networks, bidirectional LSTM networks, encoder-decoder LSTM networks, and convolutional neural networks. We provide a further comparison with simple neural networks that use stochastic gradient descent and adaptive moment estimation (Adam) for training. We focus on univariate time series for multi-step-ahead prediction from benchmark time-series datasets and provide a further comparison of the results with related methods from the literature. The results show that the bidirectional and encoder-decoder LSTM network provides the best performance in accuracy for the given time series problems.","['Time series analysis', 'Predictive models', 'Forecasting', 'Deep learning', 'Neural networks', 'Biological system modeling', 'Biological neural networks']","['Recurrent neural networks', 'LSTM networks', 'convolutional neural networks', 'deep learning', 'time series prediction']"
"Human mobility prediction is of great importance in a wide range of modern applications in different fields such as personalized recommendation systems, the fifth-generation (5G) mobile communication systems, and so on. Generally, the prediction goal varies from different application scenarios. For the applications of 5G network including resource allocation and mobility management, it is essential to predict the positions of mobile users in the near future from dozens of seconds to a few minutes so as to make preparation in advance, which is actually a trajectory prediction problem. In this paper, with the particular focus on multi-user multi-step trajectory prediction, we first design a basic deep learning-based prediction framework, where the long short-term memory (LSTM) network is directly applied as the most critical component to learn user-specific mobility pattern from the user's historical trajectories and predict his/her movement trends in the future. Motivated by the related findings after testifying and analyzing this basic framework on a model-based dataset, we extend it to a region-oriented prediction scheme and propose a multi-user multi-step trajectory prediction framework by further incorporating the sequence-to-sequence (Seq2Seq) learning. The experimental results on a realistic dataset demonstrate that the proposed framework has significant improvements on generalization ability and reduces error-accumulation effect for multi-step prediction.","['Trajectory', 'Hidden Markov models', 'Predictive models', '5G mobile communication', 'Logic gates', 'Machine learning', 'Market research']","['Trajectory prediction', 'multi-step prediction', 'long short-term memory', 'sequence-to-sequence', 'machine learning']"
"As the mobile operators strive to accommodate the increasing load and capacity requirements, direct communication among users' devices, namely, device-to-device (D2D) communication, emerges as an advantageous solution for cellular traffic offloading. However, the formation and the operation of D2D networks are challenging, as D2D peers must satisfy various network-related constraints. Although existing approaches address the D2D communication technical challenges, they usually neglect the fact that devices are used by humans possibly reluctant to communicate with unknown users, introducing an additional constraint. Following the proliferation of social networks and cutting edge mobile devices, social ties among users can promote D2D cooperation. In D2D cooperative communication, multiple devices in close proximity attempt to access the wireless medium. Their interactions at medium access level are affected by the users' social features, as socially connected users are more likely to engage in D2D cooperation. Moreover, the energy consumption of power-constrained mobile devices affects the effectiveness of D2D cooperative communication, stressing the need for incorporating energy awareness in D2D networking. In this paper, we outline the challenges that appear in D2D cooperative networking and medium access control (MAC) design under the influence of social characteristics and the energy consumption concerns that arise in modern D2D networking scenarios. Considering the users' social ties, we present an energy efficient social-aware cooperative D2D MAC protocol as a paradigm of social information inclusion in the green D2D MAC design. Last, we discuss the practical issues of the adoption of social awareness in green D2D cooperation, which may affect the D2D performance in realistic scenarios. Our simulation results demonstrate the effectiveness of exploiting the existence of users' social connections in D2D cooperation, highlighting the need for green social-aware D2D cooperative schemes.","['Smart devices', 'Resource management', 'Social network services', 'Green products', 'Cooperative communication', 'Energy efficiency', 'Media Access Protocol', 'Energy consumption', 'Mobile communication']","['Cooperation', 'D2D', 'energy efficiency', 'resource management', 'social awareness']"
"Recently, the demand for portable electronics and embedded systems has increased. These devices need low-power circuit designs because they depend on batteries as an energy resource. Moreover, multi-valued logic (MVL) circuits provide notable improvements over binary circuits in terms of interconnect complexity, chip area, propagation delay, and energy consumption. Therefore, this paper proposes new ternary circuits aiming to lower the power delay product (PDP) to save battery consumption. The proposed designs include new ternary gates [standard ternary inverter (STI) and ternary NAND (TNAND)] and combinational circuits [ternary decoder (TDecoder), ternary half-adder (THA), and ternary multiplier (TMUL)] using carbon nano-tube field-effect transistors (CNFETs). This paper employs the best trade-off between reducing the number of used transistors, utilizing energy-efficient transistor arrangement such as transmission gate, and applying the dual supply voltages (V dd and V dd /2). The five proposed designs are compared with the latest 15 ternary circuits using the HSPICE simulator for different supply voltages, different temperatures, and different frequencies; 180 simulations are performed to prove the efficiency of the proposed designs. The results show the advantage of the proposed designs in reduction over 43% in terms of transistors' count for the ternary decoder and over 88%, 99%, 98%, 86%, and 78% in energy consumption (PDP) for the STI, TNAND, TDecoder, THA, and TMUL, respectively.","['Logic gates', 'CNTFETs', 'Multivalued logic', 'Inverters', 'Decoding', 'Carbon']","['Carbon nano-tube field effect transistors (CNFET)', 'ternary combinational circuits', 'ternary logic gates', 'multi-valued logic (MVL)', 'power delay product']"
"Insulator fault in the transmission lines is the main factor of power transmission accident. The images captured from the aerial inspection can be utilized to detect the fault of insulators for further maintenance. For automatic transmission lines inspection system, the insulator fault detection is an interesting and challenging task due to the complex background and diversified insulators. In this paper, we propose a novel insulator fault detection method based on multi-level perception for aerial images. The multi-level perception is implemented by an ensemble architecture which combines three single-level perceptions. These single-level perceptions include the low level, middle level, and high level that are named by the attention to the insulator fault. They detect the insulator fault in the entire image, multi-insulator image, and single-insulator image, respectively. To address the filtering problem in the combination of three single-level perceptions, an ensemble method is proposed for generating the final results. For training the detection models employed in the multi-level perception, a powerful deep meta-architecture so-called single shot multibox detector (SSD) is utilized. The well-trained SSD models can automatically extract high quality features from aerial images instead of manually extracting features. By using the multi-level perception, the advantages of global and local information can achieve a favorable balance. Moreover, limited inspection images are fully utilized by the proposed method. Fault detection recall and precision of the proposed method are 93.69% and 91.23% testing in the practical inspection data, and insulator fault under various conditions can be correctly detected in the aerial images. The experimental results show that the proposed method can enhance the accuracy and robustness significantly.","['Insulators', 'Inspection', 'Fault detection', 'Power transmission lines', 'Training', 'Feature extraction', 'Electrical fault detection']","['Transmission lines inspection', 'insulator fault detection', 'ensemble learning', 'multi-level perception', 'deep learning']"
"Rainfall prediction targets the determination of rainfall conditions over a specific location. It is considered vital for the agricultural industry and other industries. In this paper, we propose a new forecasting method that uses a deep convolutional neural network (CNN) to predict monthly rainfall for a selected location in eastern Australia. To our knowledge, this is the first time applying a deep CNN in predicting monthly rainfall. The proposed approach was compared against the Australian Community Climate and Earth-System Simulator-Seasonal Prediction System (ACCESS), which is a forecasting model released by the Bureau of Meteorology. In addition, the CNN was compared against a conventional multi-layered perceptron (MLP). The better mean absolute error, root mean square error (RMSE), Pearson correlation (r), and Nash Suttcliff coefficient of efficiency values were obtained with the proposed CNN. A difference of 37.006 mm was obtained in terms of RMSE compared with ACCESS and 15.941 compared with conventional MLP. Further investigation revealed that the CNN was generally performing better in months with higher annual averages, while ACCESS was performing better in months with low annual averages. The generated output is promising and can be widely extended in this type of applications.","['Predictive models', 'Convolutional neural networks', 'Weather forecasting', 'Forecasting', 'Australia']","['Convolutional neural networks', 'rainfall prediction', 'weather forecasting models']"
"Convolutional neural network (CNN) has achieved remarkable success in the field of fundus images due to its powerful feature learning ability. Computer-aided diagnosis can obtain information with reference value for doctors in clinical diagnosis or screening through proper processing and analysis of fundus images. However, most of the previous studies have focused on the detection of a certain fundus disease, and the simultaneous diagnosis of multiple fundus diseases still faces great challenges. We propose a multi-label classification ensemble model of fundus images based on CNN to directly detect one or more fundus diseases in the retinal fundus images. Every single model consists of two parts. The first part is a feature extraction network based on EfficientNet, and the second part is a custom classification neural network for multi-label classification problems. Finally, the output probabilities of different models are fused as the final recognition result. And it was trained and tested on the data set provided by ODIR 2019 (Peking University International Competition on Ocular Disease Intelligent Recognition). The experimental results show that our model can be trained on fewer data sets and get good results.","['Diseases', 'Feature extraction', 'Neural networks', 'Deep learning', 'Data models', 'Training', 'Diabetes']","['CNN', 'deep learning', 'ensemble learning', 'fundus images', 'multi label classification', 'transfer learning']"
"Nano-communication-based devices have the potential to play a vital role in future healthcare technologies by improving the quality of human life. Its application in medical diagnostics and treatment has a great potential, because of its ability to access small and delicate body sites noninvasively, where conventional medical devices fall short. In this paper, the state of the art in this field is presented to provide a comprehensive understanding of current models, considering various communication paradigms, antenna design issues, radio channel models based on numerical and experimental analysis and network, and system models for such networks. Finally, open research areas are identified for the future directions within the field.","['Nanobioscience', 'Nanoscale devices', 'Biological system modeling', 'Monitoring', 'Electromagnetics', 'Biomedical monitoring', 'Medical services']","['Nano communication', 'terahertz', 'body area network', 'channel modeling', 'network modeling']"
"In previous investigations, the nonlinear hypothesis use the linear bounded maps. Nonlinear hypothesis are described as the combination of the first order terms, and after of the mentioned combination, one bounded map is applied to alter the result. This document proposes two nonlinear hypothesis which use different structures instead of using the linear bounded maps. They are termed as novel nonlinear hypothesis and second order nonlinear hypothesis and their goal is to improve the second order processes modeling. The proposed nonlinear hypothesis are described as the combination of the first order and second order terms. Since the delta parallel robot is a second order process, it is an excellent platform to prove the effectiveness of the two proposed hypothesis.","['Parallel robots', 'Process modeling', 'Data models', 'Input variables', 'Neural networks', 'Cost function']","['Novel nonlinear hypothesis', 'second order nonlinear hypothesis', 'nonlinear hypothesis', 'delta parallel robot']"
"Sybil security threat in vehicular ad hoc networks (VANETs) has attracted much attention in recent times. The attacker introduces malicious nodes with multiple identities. As the roadside unit fails to synchronize its clock with legitimate vehicles, unintended vehicles are identified, and therefore erroneous messages will be sent to them. This paper proposes a novel biologically inspired spider-monkey time synchronization technique for large-scale VANETs to boost packet delivery time synchronization at minimized energy consumption. The proposed technique is based on the metaheuristic stimulated framework approach by the natural spider-monkey behavior. An artificial spider-monkey technique is used to examine the Sybil attacking strategies on VANETs to predict the number of vehicular collisions in a densely deployed challenge zone. Furthermore, this paper proposes the pseudocode algorithm randomly distributed for energy-efficient time synchronization in two-way packet delivery scenarios to evaluate the clock offset and the propagation delay in transmitting the packet beacon message to destination vehicles correctly. The performances of the proposed technique are compared with existing protocols. It performs better over long transmission distances for the detection of Sybil in dynamic VANETs’ system in terms of measurement precision, intrusion detection rate, and energy efficiency.","['Synchronization', 'Protocols', 'Security', 'Vehicular ad hoc networks', 'Time division multiple access', 'Biology', 'Routing']","['Spider monkey time synchronization (SMTS)', 'Sybil attacks', 'probability of detection', 'VANETs']"
"In this paper, we propose an adaptive multiple-input-multiple-output (MIMO) free-space optical (FSO) links using an orbital-angular-momentum (OAM)-multiplexed based on the spatial-mode multiplexing (SMM) through the turbulent channel. We propose to use the SMM and spatial-mode diversity (SMD) combined with an adaptive MIMO technique to mitigate the atmospheric turbulence effects. In this paper, our objective is to design the adaptive MIMO-FSO links based on OAM-MIMO/SMM multiplexed and analyze its performance in the atmospheric turbulence conditions. The simulation results show four OAM modes-based MIMO/SMM and resulting in four OAM-multiplexed channels. Each OAM mode carries a 100-Gbit/s quadrature phase-shift keying signal (aggregate 400 Gbit/s) on a single wavelength channel (λ ~ 1550 nm) and is transmitted for a 2-km link. The calculated received power and inter-channel crosstalk of an OAM-MIMO/SMM signal fluctuate by 4.5 -6 dB, respectively. The power penalties can be reduced by 1-4 dB for all channels after OAM-MIMO/SMM equalization at a bit-error rate (BER) of 10 -9 . The calculating results show that the system using an OAM-based MIMO/SMM and SMD multiplexing achieves superior BER performance using an adaptive MIMO/SMM equalization. The Numerical results show favorable transmission performance of OAM based on MIMO/SMM and the SMD multiplexing compared to the conventional-MIMO (CMIMO) of FSO transmission link. The Simulation models verified the superior BER performance of OAM-SMD-based MIMO/SMM. The SMM/MIMO-SMD technique performed better in the channel capacity and signal-to-noise ratios over other commonly used CMIMO algorithms. To sufficiently discuss the OAM-MIMO/SMM behavior-based SMD multiplexing, the performance of the novel SMM/MIMO-SMD technique is analyzed using simulations based on the Matlab/simulink program in order to verify the accuracy of the models and simulation results. This paper could be useful for the practical implementation of the SMM and the SMD using an adaptive MIMO equalization in the FSO systems.","['Multiplexing', 'MIMO communication', 'Adaptation models', 'Lenses', 'Orbits', 'Adaptive equalizers', 'Receivers']","['Free-space optical communications', 'adaptive MIMO equalization', 'orbital-angular-momentum-multiplexed', 'spatial-mode multiplexing (SMM)', 'power penalty (PP)', 'spatial-mode diversity (SMD)']"
"The smart cities vision is inexorably turning into a reality. Among the different approaches used to realize more intelligent and sustainable environments, a common denominator is the role that information and communication technologies will play. Moreover, if there is one of these technologies that emerges among the rest, it is the Internet-of-Things (IoT). The ability to ubiquitously embed sensing and actuating capabilities that this paradigm enables is at the forefront of the technologies driving the urban environments transformation. However, there are very little practical experiences of the IoT infrastructure deployment at a large scale. This paper presents practical solutions to the main challenges faced during the deployment and management of a city-scale IoT infrastructure, which encompasses thousands of sensors and other information sources. The experience we have gained during the deployment and operation of the IoT-based smart city infrastructure carried out at Santander (Spain) has led to a number of practical lessons that are summarized in this paper. Moreover, the challenges and problems examples, excerpted from our own real-life experience, are described as motivators for the adopted solutions.","['Wireless sensor networks', 'Smart cities', 'Sensors', 'Monitoring', 'Mobile communication', 'Planning']","['Data quality', 'deployment', 'Internet-of-Things', 'smart city']"
"Medical images play a very important role in making the right diagnosis for the doctor and in the patient's treatment process. Using intelligent algorithms makes it possible to quickly distinguish the lesions of medical images, and it is especially important to extract features from images. Many studies have integrated various algorithms into medical images. For medical image feature extraction, a large amount of data is analyzed to obtain processing results, helping doctors to make more accurate case diagnosis. In view of this, this paper takes tumor images as the research object, and first performs local binary pattern feature extraction of the tumor image by rotation invariance. As the image shifts and the rotation changes, the image is stationary relative to the coordinate system. The method can accurately describe the texture features of the shallow layer of the tumor image, thereby enhancing the robustness of the image region description. Focusing on image feature extraction based on convolutional neural network (CNN), the basic framework of CNN is built. In order to break the limitations of machine vision and human vision, the research is extended to multi-channel input CNN for image feature extraction. Two convolution models of Xception and Dense Net are built to improve the accuracy of the CNN algorithm. It can be seen from the experimental results that the CNN algorithm shows high accuracy in tumor image feature extraction. In this paper, the CNN algorithm is compared with several classical algorithms in the local binary mode. The CNN algorithm has more accurate feature extraction ability for tumor CT images on a larger data basis. Furthermore, the advantages of CNN algorithms in this field are demonstrated.","['Feature extraction', 'Convolutional neural networks', 'Tumors', 'Convolution', 'Medical diagnostic imaging', 'Image segmentation']","['Convolutional neural network', 'image feature extraction', 'local binary mode']"
"Energy-efficient computation is important in mobile edge computing (MEC) systems. However, the computation efficiency problem in the unmanned aerial vehicle (UAV)-enabled MEC systems has been rarely researched. In this paper, a UAV-enabled MEC system under partial computation offloading mode is investigated. The computation efficiency is maximized by jointly optimizing the offloading times, the central processing unit frequencies, the transmit powers of the user and the trajectory of the UAV. For the non-convex computation efficiency problem, a two-stage iterative algorithm is proposed. Moreover, we derive the closed-form expressions for the local computation frequency and the transmit power of the user, which facilitates our algorithm implementation. Simulation results demonstrate that the computation efficiency of our proposed joint optimization scheme is better than those of other benchmark schemes.","['Resource management', 'Task analysis', 'Trajectory', 'Servers', 'Edge computing', 'Time-frequency analysis', 'Mobile handsets']","['Mobile edge computing', 'resource allocation', 'unmanned aerial vehicle communications', 'computation efficiency']"
"Wind speed fluctuations and load demand variations represent the big challenges against wind energy conversion systems (WECS). Besides, the inefficient measuring devices and the environmental impacts (e.g. temperature, humidity, and noise signals) affect the system equipment, leading to increased system uncertainty issues. In addition, the time delay due to the communication channels can make a gap between the transmitted control signal and the WECS that causes instability for the WECS operation. To tackle these issues, this paper proposes an adaptive neuro-fuzzy inference system (ANFIS) as an effective control technique for blade pitch control of the WECS instead of the conventional controllers. However, the ANFIS requires a suitable dataset for training and testing to adjust its membership functions in order to provide effective performance. In this regard, this paper also suggests an effective strategy to prepare a sufficient dataset for training and testing of the ANFIS controller. Specifically, a new optimization algorithm named the mayfly optimization algorithm (MOA) is developed to find the optimal parameters of the proportional integral derivative (PID) controller to find the optimal dataset for training and testing of the ANFIS controller. To demonstrate the advantages of the proposed technique, it is compared with different three algorithms in the literature. Another contribution is that a new time-domain named figure of demerit is established to confirm the minimization of settling time and the maximum overshoot in a simultaneous manner. A lot of test scenarios are performed to confirm the effectiveness and robustness of the proposed ANFIS based technique. The robustness of the proposed method is verified based on the frequency domain conditions that are driven from Hermite-Biehler theorem. The results emphases that the proposed controller provides superior performance against the wind speed fluctuations, load demand variations, system parameters uncertainties, and the time delay of the communication channels.","['Blades', 'Wind speed', 'Fluctuations', 'Wind turbines', 'Training', 'Testing', 'Generators']","['Wind energy', 'artificial intelligence', 'optimization algorithm', 'ANFIS controller', 'fluctuations']"
"In intelligent transportation systems, a vehicular ad hoc network (VANET) has a significant impact in enhancing road safety, traffic management efficiency, and in-vehicle infotainment features. Routing in a VANET is hampered by frequent link disconnection for non-line-of-sight communication due to roadside obstacles, high mobility, and frequent topological changes. With the help of three-dimensional movement capability, an unmanned aerial vehicle (UAV) can drastically improve the routing experience of a VANET, by increasing the line-of-sight probability, better connectivity, and efficient store-carry-forward mechanism. As a result, various routing protocols with different objectives have been reported for UAV-aided VANETs. Several surveys have been conducted based on different routing protocols for VANETs so far. However, to the best of the authors' knowledge, no survey exists till now that dedicatedly covers routing protocols for UAV-aided VANETs. This survey paper presents a comprehensive review on state-of-the-art routing protocols for UAV-aided VANETs. The protocols are categorized into seven groups in terms of their working mechanism and design principles. The shortcomings of the protocols are identified individually by critically analyzing them with regard to their advantages, disadvantages, application areas, and future improvements. The routing protocols are qualitatively compared with each other in tabular format as well on the basis of various design aspects and system parameters. In particular, not only performance and special features but also optimization criteria and techniques are extensively discussed in addition to the tabular comparison. Furthermore, open research issues and challenges are summarized and discussed.","['Routing protocols', 'Vehicular ad hoc networks', 'Routing', 'Unmanned aerial vehicles', 'Roads', 'Optimization']","['Unmanned aerial vehicle', 'vehicular ad hoc network', 'mobile ad hoc network', 'routing protocol', 'drone', 'roadside unit', 'multihop routing']"
"Blockchain technology is a private, secure, trustworthy, and transparent information exchange performed in a decentralised manner. In this case, the coordination and validation efforts are simplified as the records are designed to update regularly and there is no difference in the two databases. This review focuses on how the blockchain addresses scalability challenges and provides solutions in the healthcare field through the implementation of blockchain technology. Accordingly, 16 solutions fell under two main areas, namely storage optimization and redesign of blockchain. However, limitations persist, including block size, high volume of data, transactions, number of nodes, and protocol challenges. This review consists of six stages, namely identification of research question, procedures of research, screening of relevant articles, keywording based on the abstract, data extraction, and mapping process. Through Atlas.ti software, the selected keywords were used to analyse through the relevant articles. As a result, 48 codes and 403 quotations were compiled. Manual coding was performed to categorise the quotations. The codes were then mapped onto the network as a mapping process. Notably, 16 solutions fell under two main areas, namely storage optimization and redesign of blockchain. Basically, there are 3 solutions compiled for storage optimization and 13 solutions for the redesign of the blockchain, namely blockchain modelling, read mechanism, write mechanism, and bi-directional network.","['Blockchain', 'Medical services', 'Scalability', 'Systematics', 'Peer-to-peer computing', 'Databases', 'Data mining']","['Blockchain', 'healthcare', 'scalability', 'systematic review']"
"Nowadays, with rapid advancements of vehicular telematics and communication techniques, proliferation of vehicular ad hoc networks (VANETs) have been witnessed, which facilitates the construction of promising intelligent transportation system (ITS). Due to inherent wireless communicating features in open environment, secure transmission among numerous VANET entities remains crucial issues. Currently, lots of research efforts have been made, while most of which tend to allocate the universal group key to the verified devices for both vehicle-to-vehicle (V2V) and vehicle-to-RSU (V2R) communications. However, in heterogeneous VANET environment with large numbers of devices in same vehicular group, complicated and variable topologies lead to continuous key updating in every moment, causing interference to regular V2R data exchange, which is not reliable and efficient for resource-constrained VANET environment. Moreover, group membership recording and detecting mechanisms are necessary for real time vehicle revocation and participation, which has not been further studied so far. In this paper, we address the above issues by proposing a secure authentication and key management scheme. In our design, novel VANET system model with edge computing infrastructure is adopted so as to offer adequate computing and storing capacity compared to traditional VANET structure. Note that our certificateless authentication scheme applies the independent session key for each vehicle for interference avoidance. Furthermore, consortium blockchain is employed for V2V group key construction. Real time group membership arrangement with efficient group key updating is accordingly provided. Formal security proofs are presented, demonstrating that the proposed scheme can achieve desired security properties. Performance analysis is conducted as well, proving that the proposed scheme is efficient compared with the state-of-the-arts.","['Vehicular ad hoc networks', 'Authentication', 'Blockchain', 'Vehicle dynamics', 'Real-time systems', 'Servers']","['Vehicular ad hoc networks (VANETs)', 'certificateless authentication', 'dynamic group key management', 'consortium blockchain']"
"Recent progress of self-supervised visual representation learning has achieved remarkable success on many challenging computer vision benchmarks. However, whether these techniques can be used for domain adaptation has not been explored. In this work, we propose a generic method for self-supervised domain adaptation, using object recognition and semantic segmentation of urban scenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image rotation prediction), we assess different learning strategies to improve domain adaptation effectiveness by self-supervision. Additionally, we propose two complementary strategies to further boost the domain adaptation accuracy on semantic segmentation within our method, consisting of prediction layer alignment and batch normalization calibration. The experimental results show adaptation levels comparable to most studied domain adaptation methods, thus, bringing self-supervision as a new alternative for reaching domain adaptation. The code is available at this link. https://github.com/Jiaolong/self-supervised-da.","['Task analysis', 'Semantics', 'Training', 'Image segmentation', 'Visualization', 'Data models', 'Object recognition']","['Domain adaptation', 'semantic segmentation', 'object recognition']"
"Electronic health records (EHRs) replaced the old paper-based systems to make patient data more accurate, reliable, and more accessible. Yet, the EHRs system requires high transmission cost, energy, and waste of time for both doctors and patients. Furthermore, EHRs security presents a serious issue threatening the patient's privacy. Most of the third-party hosting systems have some issues related to the users' privacy and data security. Hence, it is necessary to restrict the access control policies and develop efficient mechanisms for cloud-based EHRs data. In this paper, a sensitive and energetic access control (SE-AC) mechanism is proposed for managing the cloud-hosted EHRs and providing a fine-grained access control even in critical situations. The proposed mechanism ensures the confidentiality of the patient's data, where only authorized individuals to have permission to be able to edit or review certain of the patient's data. Each EHR data is encrypted by the managing authority before submitting to the cloud storage. The requesting user can get dynamically changing permissions based on authentication and context attributes. In addition, seven major aspects have been quantified to assess the operation of any access control that could be deployed in the Internet-of-Thing (IoT). The security analysis indicates that the SE-AC mechanism is secure and will prevent any unauthorized access. The results show exceptional compatibility and performance with different setups and configuration.","['Cloud computing', 'Access control', 'Internet of Things', 'Encryption', 'Data privacy', 'Privacy']","['Access control', 'cloud computing', 'electronic health records', 'Internet-of-Things', 'data security']"
"This paper proposes a fusion model based on the autoregressive moving average (ARMA) model and Elman neural network (NN) to achieve accurate prediction for the state of health (SOH) of lithium-ion batteries. First, the voltage and capacity degradation variation of the battery are acquired through the battery lifecycle data, and the health factor related to the battery aging is selected according to the variation of the voltage profile. Second, the empirical mode decomposition (EMD) is employed to process the capacity degradation data and eliminate the phenomenon of tiny capacity recovery, and multiple data sequences, as well as the related residue, are extracted, then the grey relational analysis (GRA) between sub-sequences and health factor are discussed. Furthermore, the ARMA model and Elman NN model are respectively built by training the subsequent time series data and residue data. Finally, all the individual predictions are combined to generate the estimated SOH sequences. The experimental validation is performed to manifest that the addressed fusion method performs the SOH prediction with satisfactory accuracy, compared with the single ARMA method and Elman NN model.","['Batteries', 'Degradation', 'Estimation', 'Integrated circuit modeling', 'Autoregressive processes', 'Predictive models', 'Aging']","['Autoregressive moving average (ARMA)', 'Elman neural network (NN)', 'grey relational analysis (GRA)', 'empirical mode decomposition (EMD)', 'state of health (SOH)']"
"The most important motivation for streamflow forecasts is flood prediction and longtime continuous prediction in hydrological research. As for many traditional statistical models, forecasting flood peak discharge is nearly impossible. They can only get acceptable results in normal year. On the other hand, the numerical methods including physics mechanisms and rainfall-atmospherics could provide a better performance when floods coming, but the minima prediction period of them is about one month ahead, which is too short to be used in hydrological application. In this study, a deep neural network was employed to predict the streamflow of the Hankou Hydrological Station on the Yangtze River. This method combined the Empirical Mode Decomposition (EMD) algorithm and Encoder Decoder Long Short-Term Memory (En-De-LSTM) architecture. Owing to the hydrological series prediction problem usually contains several different frequency components, which will affect the precision of the longtime prediction. The EMD technique could read and decomposes the original data into several different frequency components. It will help the model to make longtime predictions more efficiently. The LSTM based En-De-LSTM neural network could make the forecasting closer to the observed in peak flow value through reading, training, remembering the valuable information and forgetting the useless data. Monthly streamflow data (from January 1952 to December 2008) from Hankou Hydrological Station on the Yangtze River was selected to train the model, and predictions were made in two years with catastrophic flood events and ten years rolling forecast. Furthermore, the Root Mean Square Error (RMSE), Coefficient of Determination (R 2 ), Willmott’s Index of agreement (WI) and the Legates-McCabe’s Index (LMI) were used to evaluate the goodness-of-fit and performance of this model. The results showed the reliability of this method in catastrophic flood years and longtime continuous rolling forecasting.","['Predictive models', 'Rivers', 'Machine learning', 'Numerical models', 'Time series analysis', 'Floods', 'Adaptation models']","['Yangtze River', 'hydrological time series forecasting', 'streamflow prediction', 'empirical mode decomposition', 'deep learning']"
"Extensive studies have been conducted on the Dijkstra algorithm owing to its bright prospect. However, few of them have studied the surface path planning of mobile robots. Currently, some application fields (e.g., wild ground, planet ground, and game scene) need to solve the optimal surface path. This paper proposes an extended Dijkstra algorithm. We utilize the Delaunay triangulation to model the surface environment. Based on keeping the triangle side length unchanged, the triangle mesh on the surface is equivalently converted into a triangle on the two-dimensional plane. Through this transformation, we set up the two-dimensional developable passable channel of the surface and solve the optimal route on this channel. Traversing all the two-dimensional developable and passable paths of the surface, we can get the shortest route among all the optimal paths. Then the inverse transformation from the two-dimensional plane coordinates to the corresponding surface coordinates obtains the surface optimal path. The simulation results show that, compared with the traditional Dijkstra algorithm, this method improves the accuracy of the surface optimization path in single-robot single-target and multi-robot multi-target path planning tasks.","['Path planning', 'Euclidean distance', 'Planning', 'Transportation', 'Task analysis', 'Mobile robots', 'Routing']","['Dijkstra algorithm', 'path planning', 'surface', 'Delaunay triangulation', 'mobile robots', 'optimization methods']"
"Internet of Things (IoT) and Mobile Edge Computing (MEC) technology acts as a significant part of daily lives to facilitate control and monitoring of objects to revolutionize the ways that human interacts with physical world. IoT system includes large volume of data with network connectivity, power, and storage resources to transform data into meaningful information. Blockchain has decentralized nature to provide useful mechanism for addressing IoT challenges. Blockchain is distributed ledger with fundamental attributes, namely recorded, transparent, and decentralized. Blockchain formed participants in distributed ledger to record the transactions and communicate with other through trustless method. Security is considered as the most valuable features of Blockchain. IoT and Blockchain are emerging ideas for creating the applications to share the intrinsic features. Several existing works has been developed for the integration of blockchain with IoT. But, Blockchain protocols in the state-of-the-art works with IoT failed to consider the computational loads, delays, and bandwidth overhead which lead to new set of problems. The review estimates main challenges in integration of Blockchain and IoT technologies to attain high-level solutions by addressing the shortcomings and limitations of IoT and Blockchain technologies.","['Privacy', 'Computer architecture', 'Internet of Things', 'Reliability', 'Data integrity']","['The Internet of Things', 'security', 'blockchain', 'transactions', 'transparent', 'decentralized', 'bandwidth overhead']"
"The problem of malicious activities in online social networks, such as Sybil attacks and malevolent use of fake identities, can severely affect the social activities in which users engage while online. For example, this problem can affect content publishing, creation of friendships, messaging, profile browsing, and commenting. Moreover, fake identities are often created to disseminate spam, use the private information of other users, commit fraud, and so on. A malicious person can generate numerous fake accounts for these purposes to reach a large number of trustworthy users. Thus, these types of malicious accounts must be detected and deactivated as quickly as possible. However, this objective is challenging, because a fake account can exhibit trustworthy behaviors and have a type of name that will prevent it from being detected by the security system. In this paper, we provide a comprehensive survey of literature from 2006 to 2016 on Sybil attacks in online social networks and use of social networks as a tool to analyze and prevent these attack types. We first review existing Sybil attack definitions, including those in the context of online social networks. We then discuss a new taxonomy of Sybil attack defense schemes and methodologies. Finally, we compare the literature and identify areas for further research in Sybil attacks in online social networks.","['Twitter', 'Facebook', 'YouTube', 'Google', 'Recommender systems', 'Context modeling', 'Social network services', 'Online services']","['Online social networks', 'Sybil attack and defense', 'Twitter', 'Sybil impact']"
"On-line monitoring and diagnosis of transformers have been investigated and discussed significantly in the last few decades. Vibration method is considered as one of the non-destructive and economical methods to explore transformer operating condition and evaluate transformer mechanical integrity and performance. However, transformer vibration and its evaluation criteria in transformer faulty condition are quite challenging and are not yet agreed upon. At the same time, with the advent of IoT facilities and services, it is expected that classical diagnosis techniques will be replaced with more powerful data-driven prognosis methods that can be used efficiently and effectively in smart monitoring. In this paper, we first discuss in detail an analytical approach to the transformer vibration modeling. Nevertheless, precise interpretation of transformer vibration signal through analytical models becomes unrealistic as higher harmonics are mixed with fundamental harmonics in vibration spectra. Therefore, as the next step, we aim to support the Industry 4.0 concept by utilizing the state-of-the-art machine learning and signal processing techniques to develop prognosis models of transformer operating condition based on vibration signals. Transformer turn-to-turn insulation deterioration and short circuit analysis as one the most important concerns in transformer operation is practically emulated and examined. Along with transformer short-circuit study, transformer over and under excitations are also studied and evaluated. Our constructed predictive models are able to detect transformer short-circuit fault in early stages using vibration signals before transformer catastrophic failure. Real-time information is transferred to the cloud system and results become accessible over any portable device.","['Vibrations', 'Oil insulation', 'Power transformer insulation', 'Predictive models', 'Transformer cores', 'Magnetostriction']","['IoT in power system', 'online transformer assessment', 'prognosis', 'vibration analysis', 'signal modeling', 'prediction', 'regression']"
"In recent years, artificial intelligence has played an increasingly important role in the field of automated control of drones. After AlphaGo used Intensive Learning to defeat the World Go Championship, intensive learning gained widespread attention. However, most of the existing reinforcement learning is applied in games with only two or three moving directions. This paper proves that deep reinforcement learning can be successfully applied to an ancient puzzle game Nokia Snake after further processing. A game with four directions of movement. Through deep intensive learning and training, the Snake (or self-learning Snake) learns to find the target path autonomously, and the average score on the Snake Game exceeds the average score on human level. This kind of Snake algorithm that can find the target path autonomously has broad prospects in the industrial field, such as: UAV oil and gas field inspection, Use drones to search for and rescue injured people after a complex disaster. As we all know, post-disaster relief requires careful staffing and material dispatch. There are many factors that need to be considered in the artificial planning of disaster relief. Therefore, we want to design a drone that can search and rescue personnel and dispatch materials. Current drones are quite mature in terms of automation control, but current drones require manual control. Therefore, the Snake algorithm proposed here to be able to find the target path autonomously is an attempt and key technology in the design of autonomous search and rescue personnel and material dispatching drones.","['Reinforcement learning', 'Drones', 'Games', 'Training', 'Task analysis', 'Deep learning', 'Genetic algorithms']","['Deep reinforcement learning', 'Markov decision', 'Monte Carlo', 'Q-learning']"
"One of the most important tasks in the advanced transportation systems is road extraction. Extracting road region from high-resolution remote sensing imagery is challenging due to complicated background such as buildings, trees shadows, pedestrians and vehicles and rural road networks that have heterogeneous forms with low interclass and high intraclass differences. Recently, deep learning-based techniques have presented a notable enhancement in the image segmentation results, however, most of them still cannot preserve boundary information and obtain high-resolution road segmentation map when processing the remote sensing imagery. In the present study, we introduce a new deep learning-based convolutional network called VNet model to produce a high-resolution road segmentation map. Moreover, a new dual loss function called cross-entropy-dice-loss (CEDL) is defined that synthesize cross-entropy (CE) and dice loss (DL) and consider both local information (CE) and global information (DL) to decrease the class imbalance influence and improve the road extraction results. The proposed VNet+CEDL model is implemented on two various road datasets called Massachusetts and Ottawa datasets. The suggested VNet+CEDL approach achieved an average F1 accuracy of 90.64% for Massachusetts dataset and 92.41% for Ottawa dataset. When compared to other state-of-the-art deep learning-based frameworks like FCN, Segnet and Unet, the proposed approach could improve the results to 1.09%, 2.45% and 0.39%, for Massachusetts dataset and 7.21%, 1.86% and 2.68%, for Ottawa dataset. Also, we compared the proposed method with the state-of-the-art road extraction techniques, and the results proved that the proposed technique outperformed other deep learning-based techniques in road extraction.","['Roads', 'Remote sensing', 'Image segmentation', 'Feature extraction', 'Data mining', 'Training', 'Convolutional neural networks']","['CEDL', 'road extraction', 'remote sensing', 'VNet network']"
"Unpredictable stock market factors make it difficult to predict stock index futures. Although efforts to develop an effective prediction method have a long history, recent developments in artificial intelligence and the use of artificial neural networks have increased our success in nonlinear approximation. When we study financial markets, we can now extract features from a big data environment without prior predictive information. We here propose to further improve this predictive performance using a combination of a deep-learning-based stock index futures prediction model, an autoencoder, and a restricted Boltzmann machine. We use high-frequency data to examine the predictive performance of deep learning, and we compare three traditional artificial neural networks: 1) the back propagation neural network; 2) the extreme learning machine; and 3) the radial basis function neural network. We use all of the 1-min high-frequency transaction data of the CSI 300 futures contract (IF1704) in our empirical analysis, and we test three groups of different volume samples to validate our observations. We find that the deep learning method of predicting stock index futures outperforms the back propagation, the extreme learning machine, and the radial basis function neural network in its fitting degree and directional predictive accuracy. We also find that increasing the amount of data increases predictive performance. This indicates that deep learning captures the nonlinear features of transaction data and can serve as a powerful stock index futures prediction tool for financial market investors.","['Machine learning', 'Feature extraction', 'Neural networks', 'Stock markets', 'Neurons', 'Prediction algorithms', 'Indexes']","['Prediction methods', 'artificial neural networks', 'stock markets', 'deep learning']"
"This paper presents a miniaturized circularly polarized multiple-input multiple-output (MIMO) antenna for wearable biotelemetric devices. The proposed MIMO antenna consists of four elements, which are placed orthogonally to the adjacent elements. The proposed antenna has a wideband response [10-dB bandwidth of 2210 MHz (fractional bandwidth (FBW) = 92.08%) in free space and 10-dB bandwidth of 2200 MHz (FBW = 91.66%) when worn on human-body], this frequency range covers the important and unlicensed industrial, scientific and medical (ISM) band (2.40-2.48 GHz). The antenna exhibits a wideband 3-dB circularly polarized bandwidth of 1300 MHz (FBW=54.16%) and 1040 MHz (FBW=43.33%) in free space and when worn on the body, respectively. The optimized antenna in free space (on-body) has an envelop correlation coefficient (ECC) less than 0.21 (0.23), a diversity gain (DG) greater than 9.77 dB (9.71 dB), a multiplexing efficiency (ME) greater than -0.85 dB (-0.63 dB), and a channel capacity loss (CCL) less than 0.13 bps/Hz (0.13 bps/Hz). The stable radiation, high gain, high efficiency, and good MIMO properties in free space and on human-body make the proposed antenna a suitable choice for use in high data wearable biotelemetric devices.","['MIMO communication', 'Antenna measurements', 'Broadband antennas', 'Integrated circuit modeling', 'Wideband']","['Circularly polarized antenna', 'MIMO antenna', 'wearable antenna', 'wearable biotelemetric devices', 'wireless body-area networks (WBAN)']"
"This paper proposes a backscatter-assisted wireless powered communication network that includes a hybrid access point and multiple users. In conventional wireless powered communication networks with only harvest-then-transmit (HTT) mode, urgent data transmission is not possible since users need to first harvest sufficient energy before transmitting information. Backscatter communication depends on instantaneous excitation energy such that the dedicated time for harvesting energy first is not required. To improve the system performance, both HTT and backscatter modes are employed at the users in the proposed model. An optimization problem is formulated to maximize the sum-throughput by finding the optimal transmission policy, including the optimal users' working mode permutation and time allocation. Simulation results demonstrate the superiority of the proposed model.","['Backscatter', 'Wireless sensor networks', 'Wireless communication', 'Communication networks', 'Optimization', 'Resource management', 'Throughput']","['Wireless powered communication network', 'harvest-then-transmit mode', 'backscatter communication', 'resource allocation']"
"Medical datasets are usually imbalanced, where negative cases severely outnumber positive cases. Therefore, it is essential to deal with this data skew problem when training machine learning algorithms. This study uses two representative lung cancer datasets, PLCO and NLST, with imbalance ratios (the proportion of samples in the majority class to those in the minority class) of 24.7 and 25.0, respectively, to predict lung cancer incidence. This research uses the performance of 23 class imbalance methods (resampling and hybrid systems) with three classical classifiers (logistic regression, random forest, and LinearSVC) to identify the best imbalance techniques suitable for medical datasets. Resampling includes ten under-sampling methods (RUS, etc.), seven over-sampling methods (SMOTE, etc.), and two integrated sampling methods (SMOTEENN, SMOTE-Tomek). Hybrid systems include (Balanced Bagging, etc.). The results show that class imbalance learning can improve the classification ability of the model. Compared with other imbalanced techniques, under-sampling techniques have the highest standard deviation (SD), and over-sampling techniques have the lowest SD. Over-sampling is a stable method, and the AUC in the model is generally higher than in other ways. Using ROS, the random forest performs the best predictive ability and is more suitable for the lung cancer datasets used in this study. The code is available at https://mkhushi.github.io/.","['Training', 'Lung cancer', 'Lung', 'Support vector machines', 'Classification algorithms', 'Standards', 'Bagging']","['Class imbalance', 'data resampling', 'healthcare', 'lung cancer', 'machine learning']"
"Iris recognition is one of the most representative identification technologies in biometric recognition, which is widely used in various fields. Recently, many deep learning methods have been used in biometric recognition, owing to their advantages such as automatic learning, high accuracy, and strong generalization ability. The deep convolutional neural network (CNN) is the mainstream method of image processing widely used in many domains, but it has poor anti-noise capacity in image classification and is easily affected by slight disturbances. CNN also needs a large number of samples for training. The recent capsule network not only has high recognition accuracy in classification tasks but can also learn part-whole relationships, increasing the robustness of the model. Furthermore, it can be trained using a small number of samples. In this paper, we propose a deep learning method based on the capsule network architecture in iris recognition. The structure detail of the network is adjusted, and we provide a modified routing algorithm based on the dynamic routing between two capsule layers to make this technique adapt to iris recognition. Migration learning makes the deep learning method available even when the number of samples is limited. Therefore, three state-of-the-art pretrained models, VGG16, InceptionV3, and ResNet50, are introduced. We divide the three networks into a series of subnetwork structures according to the number of their major constituent blocks. They are used as the convolutional part to extract primary features, instead of a single convolutional layer in the capsule network. Our experiments are conducted on three iris datasets, JluIrisV3.1, JluIrisV4, and CASIA-V4 Lamp, to analyze the performance of different network structures. We also test the proposed networks in simulated strong and weak light environments, showing that the networks with capsule architecture are more stable than those without.","['Iris recognition', 'Deep learning', 'Feature extraction', 'Heuristic algorithms', 'Convolution', 'Routing', 'Training']","['Iris recognition', 'deep learning', 'capsule network', 'transfer learning']"
"Vehicular ad hoc network (VANET) is a technology that enables smart vehicles to communicate with each other and form a mobile network. VANET facilitates users with improved traffic efficiency and safety. Authenticated communication becomes one of the prime requirements of VANET. However, authentication may reveal a user's personal information such as identity or location, and therefore, the privacy of an honest user must be protected. This paper proposes an efficient and practical pseudonymous authentication protocol with conditional privacy preservation. Our protocol proposes a hierarchy of pseudonyms based on the time period of their usage. We propose the idea of primary pseudonyms with relatively longer time periods that are used to communicate with semi-trusted authorities and secondary pseudonyms with a smaller life time that are used to communicate with other vehicles. Most of the current pseudonym-based approaches are based on certificate revocation list (CRL) that causes significant communication and storage overhead or group-based approaches that are computationally expensive and suffer from group-management issues. These schemes also suffer from trust issues related to certification authority. Our protocol only expects an honest-but-curious behavior from otherwise fully trusted authorities. Our proposed protocol protects a user's privacy until the user honestly follows the protocol. In case of a malicious activity, the true identity of the user is revealed to the appropriate authorities. Our protocol does not require maintaining a CRL and the inherent mechanism assures the receiver that the message and corresponding pseudonym are safe and authentic. We thoroughly examined our protocol to show its resilience against various attacks and provide computational as well as communicational overhead analysis to show its efficiency and robustness. Furthermore, we simulated our protocol in order to analyze the network performance and the results show the feasibility of our proposed protocol in terms of end-to-end delay and packet delivery ratio.","['Ad hoc networks', 'Intelligent vehicles', 'Vehicular ad hoc networks', 'Smart vehicles', 'Privacy', 'Authentication', 'Mobile computing']","['Vehicular adhoc network', 'authentication', 'privacy', 'pseudonyms']"
"In this paper, we develop and put into practice an automatic optical inspection (AOI) system based on machine vision to check the holes on a printed circuit board (PCB). We incorporate the hardware and software. For the hardware part, we combine a PC, the three-axis positioning system, a lighting device, and charge-coupled device cameras. For the software part, we utilize image registration, image segmentation, drill numbering, drill contrast, and defect displays to achieve this system. Results indicated that an accuracy of 5 μm could be achieved in errors of the PCB holes allowing comparisons to be made. This is significant in inspecting the missing, the multi-hole, and the incorrect location of the holes. However, previous work only focuses on one or other feature of the holes. Our research is able to assess multiple features: missing holes, incorrectly located holes, and excessive holes. Equally, our results could be displayed as a bar chart and target plot. This has not been achieved before. These displays help users to analyze the causes of errors and immediately correct the problems. In addition, this AOI system is valuable for checking a large number of holes and finding out the defective ones on a PCB. Meanwhile, we apply a 0.1-mm image resolution, which is better than others used in industry. We set a detecting standard based on 2-mm diameter of circles to diagnose the quality of the holes within 10 s.","['Inspection', 'Drilling machines', 'Machine vision', 'Electronic components', 'Automatic optical inspection', 'Laser modes', 'Charged coupled devices']","['Automatic optical inspection (AOI) system', 'drill inspection', 'drilling technique', 'printed circuits board (PCB)', 'machine vision']"
"Continuous glucose monitoring systems (CGMSs) allow measuring the blood glycaemic value of a diabetic patient at a high sampling rate, producing a considerable amount of data. These data can be effectively used by machine learning techniques to infer future values of the glycaemic concentration, allowing the early prevention of dangerous hyperglycaemic or hypoglycaemic states and better optimization of the diabetic treatment. Most of the approaches in the literature learn a prediction model from the past samples of the same patient, which needs extensive calibrations and limits the usability of the system. In this paper, we investigate the prediction models trained on glucose signals of a large and heterogeneous cohort of patients and then applied to infer future glucose-level values on a completely new patient. To achieve this purpose, we designed and compared two different types of solutions that were proved successful in many time-series prediction problems based respectively, on non-linear autoregressive (NAR) neural network and on long short-term memory (LSTM) networks. These solutions were experimentally compared with three literature approaches, respectively, based on feed-forward neural networks (FNNs), autoregressive (AR) models, and recurrent neural networks (RNN). While the NAR obtained good prediction accuracy only for short-term predictions (i.e., with prediction horizon within 30 min), the LSTM obtained extremely good performance both for short- and long-term glucose-level inference (60 min and more), overcoming all the other methods in terms of correlation between the measured and the predicted glucose signal and in terms of clinical outcome.","['Sugar', 'Diabetes', 'Insulin', 'Predictive models', 'Blood', 'Neural networks', 'Data models']","['Continuous glucose monitoring', 'diabetes', 'non-linear autoregressive neural network', 'long short-term memory (LSTM) network', 'time-series analysis', 'machine learning']"
"A novel dual-broadband dual-polarized base station antenna array with compact structure and low profile is proposed in this paper for the existing mobile communication system operating over 0.79-0.96 GHz (European Digital Dividend/CDMA/GSM) and 1.71-2.17 GHz (DCS/PCS/UMTS). The antenna array is mainly composed of five lower-band elements, ten upper-band elements, some U-shaped metal baffles, and a metal reflector with specific shape. In order to reduce the overall size of the antenna array, lower-band element is designed as octagon aperture shape that upper-band elements can be embedded in it. Two kinds of radiation elements (five for each kind of element) are applied in the antenna array as upper-band elements to achieve better radiation performance. The proposed antenna array achieves electrical downtilt (0°-14° and 0°-10° at lower frequency band and upper frequency band, respectively) by adjusting input amplitude and phase of each array element. Measured results demonstrate that the antenna array has good broadside radiation characteristics, including low voltage standing wave ratio (VSWR <; 1.5), high port-to-port isolation (>28 dB), low backlobe level (>25 dB), high cross-polarization discrimination (>20 dB), and stable radiation pattern with horizontal half-power beamwidth (HPBW) 65° ± 5° at both frequency bands and all electrical downtilt angles. The peak gains of 15.1 and 17.3 dBi are obtained at lower and upper bands respectively. Owing to these advantages, the antenna array is suitable for existing 2G/3G applications in modern mobile communication systems.","['Antenna arrays', 'Metals', 'Base stations', 'Dipole antennas', 'Antenna radiation patterns', 'Broadband antennas']","['Base station antenna array', 'dual-broadband', 'dual-polarized', 'electrical downtilt']"
"Ciphertext-policy attribute-based encryption (CP-ABE) is a promising cryptographic technique that integrates data encryption with access control for ensuring data security in IoT systems. However, the efficiency problem of CP-ABE is still a bottleneck limiting its development and application. A widespread consensus is that the computation overhead of bilinear pairing is excessive in the practical application of ABE, especially for the devices or the processors with limited computational resources and power supply. In this paper, we proposed a novel pairing-free data access control scheme based on CP-ABE using elliptic curve cryptography, abbreviated PF-CP-ABE. We replace complicated bilinear pairing with simple scalar multiplication on elliptic curves, thereby reducing the overall computation overhead. And we designed a new way of key distribution that it can directly revoke a user or an attribute without updating other users’ keys during the attribute revocation phase. Besides, our scheme use linear secret sharing scheme access structure to enhance the expressiveness of the access policy. The security and performance analysis show that our scheme significantly improved the overall efficiency as well as ensured the security.","['Encryption', 'Access control', 'Logic gates', 'Elliptic curve cryptography', 'Elliptic curves']","['Access control', 'internet of things', 'CP-ABE', 'elliptic curve', 'pairing-free']"
"Violent video constitutes a threat to public security, and effective detection algorithms are in urgent need. In order to improve the detection accuracy of 3D convolutional neural networks (3D ConvNet), a novel violent video detection scheme based on the modified 3D ConvNet is proposed. In this paper, the preprocessing method of data is improved, and a new sampling method by using the key frame as dividing nodes is designed. Then, a random sampling method is adapted to produce the input frame sequence. With experimental evaluations on the crowd violence dataset, the results demonstrate the effectiveness of the proposed new sampling method. For three public violent detection datasets: hockey fight, movies, and crowd violence, individualized strategies are implemented to suit the varied clip length. For the short clips, the 3D ConvNet is constructed by using the uniform sampling method. For the longer clips, the new frame sampling strategy is adopted. The proposed scheme obtains competitive results: 99.62% on hockey fight, 99.97% on movies, and 94.3% on crowd violence. The experimental results show that our method is simple and effective.","['Three-dimensional displays', 'Feature extraction', 'Sampling methods', 'Convolution', 'Motion pictures', 'Deep learning', 'Visualization']","['Violent video detection', '3D ConvNet', 'key frame extraction']"
"Fine-grained image classification methods often suffer from the challenge that the subordinate categories within an entry-level category can only be distinguished by subtle differences. Crop disease classification is affected by various visual interferences, including uneven illumination, dew, and equipment jitter. It demands an effective algorithm to accurately discriminate one category from the others. Thus, the representational ability of algorithm needs to be strengthened to learn a robust domain-specific discrimination through an effective way. To address this challenge, a unified convolutional neural network (CNN) denoting the matrix-based convolutional neural network (M-bCNN) was proposed. Its hallmark is the convolutional kernel matrix, whose convolutional layers are arranged parallelly in the form of a matrix, and integrated with DropConnect, exponential linear unit, local response normalization, and so on to defeat over-fitting and vanishing gradient. With a tolerable addition of parameters, it can effectively increase the data streams, neurons, and link channels of the model compared with the commonly used plain networks. Therefore, it will create more non-linear mappings and will enhance the representational ability with a tolerable growth of parameters. The images of winter wheat leaf diseases were utilized as experimental samples for their strong similarities among sub-categories. A total of 16652 images containing eight categories were collected from Shandong Province, China, and were augmented into 83260 images. The M-bCNN delivered significant improvements and achieved an average validation accuracy of 96.5% and a testing accuracy of 90.1%; this outperformed AlexNet and VGG-16. The M-bCNN demonstrated accuracy gains with a convolutional kernel matrix in fine-grained image classification.","['Diseases', 'Image classification', 'Feature extraction', 'Convolutional neural networks', 'Agriculture', 'Visualization', 'Classification algorithms']","['Convolutional neural network', 'fine-grained image classification', 'deep learning', 'convolutional kernel matrix', 'wheat leaf diseases']"
"Automated facial expression recognition can greatly improve the human-machine interface. The machine can provide better and more personalized services when it knows the human's emotion. This kind of improvement is an important progress in this artificial intelligence era. Many deep learning approaches have been applied in recent years due to their outstanding recognition accuracy after training with large amounts of data. The performance is limited, however, by the specific environmental conditions and variations in different persons involved. Hence, this paper addresses the issue of how to customize the generic model without label information from the testing samples. Weighted Center Regression Adaptive Feature Mapping (W-CR-AFM) is mainly proposed to transform the feature distribution of testing samples into that of trained samples. By means of minimizing the error between each feature of testing sample and the center of the most relevant category, W-CR-AFM can bring the features of testing samples around the decision boundary to the centers of expression categories; therefore, their predicted labels can be corrected. When the model which is tuned by W-CR-AFM is tested on extended Cohn-Kanade (CK+), Radboud Faces database, and Amsterdam dynamic facial expression set, our approach can improve the recognition accuracy by about 3.01%, 0.49%, and 5.33%, respectively. Compared to the competing deep learning architectures with the same training data, our approach shows the better performance.","['Testing', 'Databases', 'Feature extraction', 'Training', 'Face recognition', 'Training data', 'Machine learning']","['Cross domain adaption', 'facial expression recognition', 'computer vision', 'pattern recognition', 'image processing']"
"With the prosperity of wireless networks, vehicular networks (VNs) have been extensively studied in recent years. It is deployed to ensure road safety, enhance the driving experience, and reduce traffic congestion. However, VNs are vulnerable to various attacks, especially Distributed Denial of Service (DDoS) that attackers control a large number of compromise nodes inside the networks to occupy the network resources of legitimate users and impact the communication among vehicles and between vehicles and infrastructure. In this paper, we design a platform to efficiently detect and rapidly respond to the DDoS attack in VNs based on software-defined networking (SDN). The proposed platform not only contains the trigger mechanism based on the message of OpenFlow protocol (i.e., PACKET_IN message) for a response not timely but also involves a flow feature extraction strategy based on the multi-dimensional information. Moreover, we construct an effective global network flow table feature values based on OpenFlow flow table feature and the entropy feature of flow table entry. We determine all flow table entry by the trained SVM. By analyzing the simulation results, we verify that the detection scheme effectively reduces the time for starting attack detection and classification recognition and has a lower false alarm rate.","['Computer crime', 'Feature extraction', 'Support vector machines', 'Software defined networking', 'Kernel', 'Protocols', 'Entropy']","['Vehicular and wireless tehnoloiesia', 'software defined networking', 'DDoS', 'detection algorithms', 'support vector machines']"
"The encrypted image retrieval in cloud computing is a key technology to realize the massive images of storage and management and images safety. In this paper, a novel feature extraction method for encrypted image retrieval is proposed. First, the improved Harris algorithm is used to extract the image features. Next, the Speeded-Up Robust Features algorithm and the Bag of Words model are applied to generate the feature vectors of each image. Then, Local Sensitive Hash algorithm is applied to construct the searchable index for the feature vectors. The chaotic encryption scheme is utilized to protect images and indexes security. Finally, secure similarity search is executed on the cloud server. The experimental results show that compared with the existing encryption retrieval schemes, the proposed retrieval scheme not only reduces the time consumption but also improves the image retrieval accuracy.","['Feature extraction', 'Image retrieval', 'Indexes', 'Encryption', 'Cloud computing', 'Optimization']","['Cloud computing', 'image retrieval', 'Harris corner detection', 'local sensitive hash']"
"Unlike single geospatial objects extraction from high-resolution remote sensing images, the task of road extraction faces more challenges, including its narrowness, sparsity, diversity, multiscale characteristics, and class imbalance. Focusing on these challenges, this paper proposes an end-to-end framework called the multiple feature pyramid network (MFPN). In MFPN, we design an effective feature pyramid and a tailored pyramid pooling module, taking advantage of multilevel semantic features of high-resolution remote sensing images. In the optimization stage, a weighted balance loss function is presented to solve the class imbalance problem caused by the sparseness of roads. The proposed novel loss function is more sensitive to the misclassified and the sparse real labeled pixels and helps to focus on the spare set of hard pixels in the training stage. Compared with the cross-entropy loss function, the weighted balance loss can reduce training time dramatically for the same precision. Experiments on two challenging datasets of high-resolution remote sensing images which illustrate the performance of the proposed algorithm have achieved significant improvements, especially for narrow rural roads.","['Roads', 'Feature extraction', 'Remote sensing', 'Convolution', 'Robustness', 'Computer architecture', 'Task analysis']","['Multiple feature pyramid network (MFPN)', 'feature pyramid', 'pyramid pooling', 'weighted balance loss']"
"We propose an Iterative Mean Filter (IMF) to eliminate the salt-and-pepper noise. IMF uses the mean of gray values of noise-free pixels in a fixed-size window. Unlike other nonlinear filters, IMF does not enlarge the window size. A large size reduces the accuracy of noise removal. Therefore, IMF only uses a window with a size of3×3. This feature is helpful for IMF to be able to more precisely evaluate a new gray value for the center pixel. To process high-density noise effectively, we propose an iterative procedure for IMF. In the experiments, we operationalize Peak Signal-to-Noise Ratio (PSNR), Visual Information Fidelity, Image Enhancement Factor, Structural Similarity (SSIM), and Multiscale Structure Similarity to assess image quality. Furthermore, we compare denoising results of IMF with ones of the other state-of-the-art methods. A comprehensive comparison of execution time is also provided. The qualitative results by PSNR and SSIM showed that IMF outperforms the other methods such as Based-on Pixel Density Filter (BPDF), Decision-Based Algorithm (DBA), Modified Decision-Based Untrimmed Median Filter (MDBUTMF), Noise Adaptive Fuzzy Switching Median Filter (NAFSMF), Adaptive Weighted Mean Filter (AWMF), Different Applied Median Filter (DAMF), Adaptive Type-2 Fuzzy Filter (FDS): for the IMAGESTEST dataset - BPDF (25.36/0.756), DBA (28.72/0.8426), MDBUTMF (25.93/0.8426), NAFSMF (29.32/0.8735), AWMF (32.25/0.9177), DAMF (31.65/0.9154), FDS (27.98/0.8338), and IMF (33.67/0.9252); and for the BSDS dataset - BPDF (24.95/0.7469), DBA (26.84/0.8061), MDBUTMF (26.25/0.7732), NAFSMF (27.26/0.8191), AWMF (28.89/0.8672), DAMF (29.11/0.8667), FDS (26.85/0.8095), and IMF (30.04/0.8753).","['Microsoft Windows', 'Noise measurement', 'Filtering algorithms', 'Manganese', 'Noise reduction', 'Filtering theory', 'Adaptive filters']","['Salt-and-pepper noise', 'image denoising', 'noise removal', 'image restoration', 'image processing', 'nonlinear filter']"
"Low power wide area network (LPWAN) technologies are increasingly catching the attention of the Internet-of-Things market and have brought the need for reliable knowledge about the performance of such networks. This paper is concerned with the performance and scalability of LoRa networks, a leading LPWAN technology. Several recently published articles have analyzed the ability of LoRa networks to scale, i.e., their ability to support increased traffic and number of nodes. This paper proposes to employ message replication and gateways with multiple receive antennas to achieve, respectively, time and spatial diversity. The paper presents the proposed schemes and evaluates them through theoretical analysis and computer simulations. Results show that LoRa networks are highly sensitive to the increase in user and traffic density, but both message replication and multiple antennas can enhance performance. Message replication has an optimum number of message copies for each network configuration, and its utilization is more beneficial in low-density networks, while the use of multiple receive antennas at the gateway is always beneficial.","['Logic gates', 'Receiving antennas', 'Spatial diversity', 'Analytical models', 'Optimization', 'Fading channels', 'Energy consumption']","['Internet-of-Things', 'long-range low-power communications', 'LoRa', 'communication diversity']"
"In cloud architectures, the microservice model divides an application into a set of loosely coupled and collaborative fine-grained services. As a lightweight virtualization technology, the container supports the encapsulation and deployment of microservice applications. Despite a large number of solutions and implementations, there remain open issues that have not been completely addressed in the deployment and management of the microservice containers. An effective method for container resource scheduling not only satisfies the service requirements of users but also reduces the running overhead and ensures the performance of the cluster. In this paper, a multi-objective optimization model for the container-based microservice scheduling is established, and an ant colony algorithm is proposed to solve the scheduling problem. Our algorithm considers not only the utilization of computing and storage resources of the physical nodes but also the number of microservice requests and the failure rate of the physical nodes. Our algorithm uses the quality evaluation function of the feasible solutions to ensure the validity of pheromone updating and combines multi-objective heuristic information to improve the selection probability of the optimal path. By comparing with other related algorithms, the experimental results show that the proposed optimization algorithm achieves better results in the optimization of cluster service reliability, cluster load balancing, and network transmission overhead.","['Containers', 'Clustering algorithms', 'Optimization', 'Processor scheduling', 'Resource management', 'Scheduling', 'Cloud computing']","['Ant colony algorithm', 'cloud computing', 'container scheduling', 'microservices', 'multi-objective optimization']"
"The recent advancements in Internet of Things (IoT), cloud computing, and Artificial Intelligence (AI) transformed the conventional healthcare system into smart healthcare. By incorporating key technologies such as IoT and AI, medical services can be improved. The convergence of IoT and AI offers different opportunities in healthcare sector. In this view, the current research article presents a new AI and IoT convergence-based disease diagnosis model for smart healthcare system. The major goal of this article is to design a disease diagnosis model for heart disease and diabetes using AI and IoT convergence techniques. The presented model encompasses different stages namely, data acquisition, preprocessing, classification, and parameter tuning. IoT devices such as wearables and sensors permit seamless data collection while AI techniques utilize the data in disease diagnosis. The proposed method uses Crow Search Optimization algorithm-based Cascaded Long Short Term Memory (CSO-CLSTM) model for disease diagnosis. In order to achieve better classification of the medical data, CSO is applied to tune both `weights' and `bias' parameters of CLSTM model. Besides, isolation Forest (iForest) technique is employed in this research work to remove the outliers. The application of CSO helps in considerable improvement in the diagnostic outcomes of CLSTM model. The performance of CSO-LSTM model was validated using healthcare data. During the experimentation, the presented CSO-LSTM model accomplished the maximum accuracies of 96.16% and 97.26% in diagnosing heart disease and diabetes respectively. Therefore, the proposed CSO-LSTM model can be employed as an appropriate disease diagnosis tool for smart healthcare systems.","['Medical services', 'Artificial intelligence', 'Brain modeling', 'Computational modeling', 'Sensors', 'Medical diagnosis', 'Diseases']","['Internet of Things', 'convergence', 'cloud computing', 'artificial intelligence', 'smart healthcare', 'disease diagnosis']"
"Flying ad hoc networks (FANETs) have dynamic topology because of the mobile unmanned aerial vehicles (UAVs). The limited battery resource and mobility of UAVs cause unstable routing in the FANET. In this paper, we try to minimize this issue with the help of an efficient clustering scheme. We propose a bio-inspired clustering scheme for FANETs (BICSF), which uses the hybrid mechanism of glowworm swarm optimization (GSO) and krill herd (KH). The proposed scheme uses energy aware cluster formation and cluster head election on the basis of the GSO algorithm. Furthermore, we propose an efficient cluster management algorithm using the behavioral study of KH. We also use genetic operators such as mutation and crossover for the optimal position of the UAV. For route selection, we propose a path detection function based on the weighted residual energy, number of neighbors, and distance between the UAVs for efficient communication. The performance of BICSF is evaluated in terms of cluster building time, energy consumption, cluster lifetime, and the probability of delivery success with grey wolf optimization and ant colony optimization-based clustering algorithms.","['Clustering algorithms', 'Topology', 'Ad hoc networks', 'Network topology', 'Routing', 'Maintenance engineering', 'Energy consumption']","['FANET', 'bio-inspired', 'self-organization', 'clustering', 'energy optimization', 'routing']"
"A circularly polarized patch antenna for future fifth-generation mobile phones is presented in this paper. Miniaturization and beamwidth enhancement of a patch antenna are the two main areas to be discussed. By folding the edge of the radiating patch with loading slots, the size of the patch antenna is 44.8% smaller than a conventional half wavelength patch, which allows it to be accommodated inside handsets easily. Wide beamwidth is obtained by surrounding the patch with a dielectric substrate and supporting the antenna by a metallic block. A measured half power beamwidth of 124° is achieved. The impedance bandwidth of the antenna is over 10%, and the 3-dB axial ratio bandwidth is 3.05%. The proposed antenna covers a wide elevation angle and complete azimuth range. A parametric study of the effect of the metallic block and the surrounding dielectric substrate on the gain at a low elevation angle and the axial ratio of the proposed antenna are presented.","['Patch antennas', 'Polarization', '5G mobile communication', 'Mobile communication', 'Dielectric substrates', 'Bandwidth', 'Mobile handsets']","['Antenna radiation patterns', 'microstrip patch antennas', 'satellite antennas']"
"As an important part of power system, power transformer plays an irreplaceable role in the process of power transmission. Diagnosis of transformer's failure is of significance to maintain its safe and stable operation. Frequency response analysis (FRA) has been widely accepted as an effective tool for winding deformation fault diagnosis, which is one of the common failures for power transformers. However, there is no standard and reliable code for FRA interpretation as so far. In this paper, support vector machine (SVM) is combined with FRA to diagnose transformer faults. Furthermore, advanced optimization algorithms are also applied to improve the performance of models. A series of winding fault emulating experiments were carried out on an actual model transformer, the key features are extracted from measured FRA data, and the diagnostic model is trained and obtained, to arrive at an outcome for classifying the fault types and degrees of winding deformation faults with satisfactory accuracy. The diagnostic results indicate that this method has potential to be an intelligent, standardized, accurate and powerful tool.","['Circuit faults', 'Windings', 'Support vector machines', 'Power transformers', 'Frequency response', 'Fault diagnosis', 'Strain']","['Transformer', 'winding faults', 'FRA', 'SVM']"
"A four-element compact wide-band optically transparent MIMO antenna with a full ground plane is proposed. The four elements transparent MIMO system has a compact size of 24 × 20 mm 2 with the undivided ground plane as most of the real-time systems demand a common reference. The complete antenna system achieves around 85% transparency due to a combination of AgHT-8 and Plexiglas which forms the transparent conductive patch/ground and substrate, respectively. The antenna geometry leads dual-band operation ranging from 24.10 - 27.18 GHz (Impedance bandwidth = 12%) and 33 - 44.13 GHz (Impedance bandwidth =28.86$ %) targeting the mm-wave 5G applications. The 4-element antenna system achieves isolation between inter-elements >16 dB and maximum gain value of greater than 3 dBi with more than 75% efficiency. The proposed transparent MIMO antenna is evaluated in terms of diversity gain (DG), envelope correlation coefficient (ECC), total active reflection coefficient (TARC), and mean effective gain (MEG) where decent MIMO performance with isolation more than >16 dB between the adjacent and other elements is achieved. Transparent MIMO antenna achieves directional patterns for the operating band with the value of DG >9, ECC <; 0.1, TARC value less than -15dB, and the ratio of MEG within the agreed limit of ±3 dB confirming acceptable MIMO/diversity performance.","['MIMO communication', '5G mobile communication', 'Dipole antennas', 'Finite element analysis', 'Optical reflection', 'Reflector antennas']","['Transparent', 'MIMO', 'compact', '5G', 'mm-wave']"
"Autonomous vehicle technology aims to improve driving safety, driving comfort, and its economy, as well as reduce traffic accident rate. As the basic part of autonomous vehicle motion control module, path tracking aims to follow the reference path accurately, ensure vehicle stability and satisfy the robust performance of the control system. This article introduces the representative control strategies, robust control strategies and parameter observation-based control strategies on path tracking for autonomous vehicle. Furthermore, the implementations and disadvantages are summarized. Most importantly, the critical review in this article provides a list and discussion of the remaining challenges and unsolved problems on path tracking control.","['Autonomous vehicles', 'Control systems', 'Tracking', 'Roads', 'Robustness', 'Adaptation models', 'Robust control']","['Autonomous vehicle', 'path tracking', 'robust control', 'parameter observation']"
"We study the problem of user clustering and power assignment for a network comprised of cellular users and underlay device-to-device (D2D) users operating under a non-orthogonal multiple access (NOMA) scheme. Our goal is to maximize the sum-rate of the network by jointly optimizing the user clustering and power assignment. Moreover, we also aim to provide interference protection for the cellular users. The formulated optimization problem is a mixed-integer non-convex problem. Thus, the original problem is decomposed into two subproblems. The first subproblem of user clustering is formulated as a matching game with externalities, where this matching game is solved sequentially while the second subproblem pertaining to power assignment is solved using complementary Geometric programming. Finally, an efficient joint iterative algorithm is proposed that can achieve a suboptimal solution for the mix integer non-convex NP-hard problem. Simulation results show that the proposed algorithm can achieve up to 70% and 92% of performance gains in terms of the average sum-rate in comparison with the general NOMA and traditional orthogonal frequency-division multiple access (OFDMA) schemes, respectively. Moreover, our results show that the proposed scheme significantly enhances the network connectivity in terms of the number of admitted users compared with the traditional OFDMA, NOMA, and D2D schemes.","['Device-to-device communication', 'NOMA', 'Interference', 'Games', 'Resource management', 'Receivers', 'Cellular networks']","['Device-to-device (D2D) communication', 'non-orthogonal multiple access (NOMA)', 'matching theory', 'user clustering', 'power assignment', '5G']"
"One of the major challenges in cybersecurity is the provision of an automated and effective cyber-threats detection technique. In this paper, we present an AI technique for cyber-threats detection, based on artificial neural networks. The proposed technique converts multitude of collected security events to individual event profiles and use a deep learning-based detection method for enhanced cyber-threat detection. For this work, we developed an AI-SIEM system based on a combination of event profiling for data preprocessing and different artificial neural network methods, including FCNN, CNN, and LSTM. The system focuses on discriminating between true positive and false positive alerts, thus helping security analysts to rapidly respond to cyber threats. All experiments in this study are performed by authors using two benchmark datasets (NSLKDD and CICIDS2017) and two datasets collected in the real world. To evaluate the performance comparison with existing methods, we conducted experiments using the five conventional machine-learning methods (SVM, k-NN, RF, NB, and DT). Consequently, the experimental results of this study ensure that our proposed methods are capable of being employed as learning-based models for network intrusion-detection, and show that although it is employed in the real world, the performance outperforms the conventional machine-learning methods.","['IP networks', 'Machine learning', 'Benchmark testing', 'Network intrusion', 'Data models', 'Communication networks']","['Cyber security', 'intrusion detection', 'network security', 'artificial intelligence', 'deep neural networks']"
"Due to the high availability of large-scale annotated image datasets, paramount progress has been made in deep convolutional neural networks (CNNs) for image classification tasks. CNNs enable learning highly representative and hierarchical local image features directly from data. However, the availability of annotated data, especially in the medical imaging domain, remains the biggest challenge in the field. Transfer learning can provide a promising and effective solution by transferring knowledge from generic image recognition tasks to the medical image classification. However, due to irregularities in the dataset distribution, transfer learning usually fails to provide a robust solution. Class decomposition facilitates easier to learn class boundaries of a dataset, and consequently can deal with any irregularities in the data distribution. Motivated by this challenging problem, the paper presents Decompose, Transfer, and Compose (DeTraC) approach, a novel CNN architecture based on class decomposition to improve the performance of medical image classification using transfer learning and class decomposition approach. DeTraC enables learning at the subclass level that can be more separable with a prospect to faster convergence. We validated our proposed approach with three different cohorts of chest X-ray images, histological images of human colorectal cancer, and digital mammograms. We compared DeTraC with the state-of-the-art CNN models to demonstrate its high performance in terms of accuracy, sensitivity, and specificity.","['Biomedical imaging', 'Feature extraction', 'Lung', 'Task analysis', 'Machine learning', 'Computed tomography', 'Training']","['Convolution neural networks', 'class decomposition', 'data irregularity', 'medical image classification', 'transfer learning']"
"In algorithmic trading, feature extraction and trading strategy design are two prominent challenges to acquire long-term profits. However, the previously proposed methods rely heavily on domain knowledge to extract handcrafted features and lack an effective way to dynamically adjust the trading strategy. With the recent breakthroughs of deep reinforcement learning (DRL), sequential real-world problems can be modeled and solved with a more human-like approach. In this paper, we propose a novel trading agent, based on deep reinforcement learning, to autonomously make trading decisions and gain profits in the dynamic financial markets. We extend the value-based deep Q-network (DQN) and the asynchronous advantage actor-critic (A3C) for better adapting to the trading market. Specifically, in order to automatically extract robust market representations and resolve the financial time series dependence, we utilize the stacked denoising autoencoders (SDAEs) and the long short-term memory (LSTM) as parts of the function approximator, respectively. Furthermore, we design several elaborate mechanisms to make the trading agent more practical to the real trading environment, such as position-controlled action and n-step reward. The experimental results show that our trading agent outperforms the baselines and achieves stable risk-adjusted returns in both the stock and the futures markets.","['Reinforcement learning', 'Time series analysis', 'Autoregressive processes', 'Heuristic algorithms', 'Neural networks', 'Biological system modeling', 'Markov processes']","['Algorithmic trading', 'Markov decision process', 'deep neural network', 'reinforcement learning']"
"In this paper, an efficient optimization technique called Chaotic Harris Hawks optimization (CHHO) is proposed and applied for estimating the accurate operating parameters of proton exchange membrane fuel cell (PEMFC), which simulate and mimic its electrical performance. The conventional Harris Hawks optimization (HHO) is a recent optimization technique that is based on the hunting approach of Harris hawks. In this proposed optimization technique, ten chaotic functions are applied for tackling with the studied optimization problem. The CHHO is proposed to enhance the search capability of conventional HHO and avoid its trapping into local optima. The sum of squared errors (SSE) between the experimentally measured output voltage and the corresponding simulated ones is adopted as the objective function. The developed CHHO technique is tested on four various commercial PEMFC stacks to assess and validate its effectiveness compared with other well-known optimization techniques. A statistical study is performed to appreciate the stability and reliability of the proposed CHHO technique. However, the results show the effectiveness and superiority of proposed CHHO compared with the conventional HHO and other competitive metaheuristic optimization algorithms under the same study cases.","['Fuel cells', 'Optimization', 'Cathodes', 'Protons', 'Water', 'Hydrogen']","['Proton exchange membrane fuel cell', 'parameter estimation', 'Harris Hawks optimization', 'sum of squared errors']"
"Gesture recognition based on computer vision has gradually become a hot research direction in the field of human-computer interaction. The field of human-computer interaction is an important direction in the Internet of Things (IoTs) technology. Human-computer interaction through gestures is the direction of continuous research on IoTs technology. In recent years, the Kinect sensor-based gesture recognition method has been widely used in gesture recognition, because it can separate gestures from complex backgrounds and is less affected by illumination and can accurately track and locate gesture motions. At present, the Kinect sensor needs to be further improved on the recognition of complex gesture movements, especially the problem that the recognition rate of dynamic gestures is not high, which hinders the development of human-computer interaction under the IoTs technology. In this paper, based on the above problems, the Kinect-based gesture recognition is analyzed in detail, and a dynamic gesture recognition method based on HMM and D-S evidence theory is proposed. Based on the original HMM, the tangent angle and gesture change at different moments of the palm trajectory are used as the characteristics of the complex motion gesture, and the dimension of the trajectory tangent is reduced by the number of quantization codes. Then, the parameter model training of HMM is completed. Finally, combined with D-S evidence theory, combinatorial logic is judged, dynamic gesture recognition is carried out, and a better recognition effect is obtained, which lays a good foundation for human-computer interaction under the IoTs technology.",[],[]
"Since it was invented in 1986, elliptic curve cryptography (ECC) has been studied widely in industry and academy from different perspectives. Some of these aspects include mathematical foundations, protocol design, curve generation, security proofs, point representation, algorithms for inherent arithmetic in the underlying algebraic structures, implementation strategies in both software and hardware, and attack models, among others. The main advantage of ECC is that shorter keys (less-memory requirements and faster field arithmetic operations) can be used if compared with other cryptosystems, which has made it the ideal choice for implementing public key cryptography in resource constrained devices, as the ones found in the envisioned applications of the Internet of Things, e.g., wireless sensors. In this application domain, lightweight cryptography has emerged as the required one because of the scarce computing resources and limited energy in devices. In this paper, we present a survey of ECC in the context of lightweight cryptography. The aim of this paper is to identify the criteria that make an ECC-based system lightweight and a viable solution for using in practical constrained applications. Representative works are systematically revised to determine the key aspects considered in ECC designs for lightweight realizations. As a result, this paper defines, for the first time, the concept and requirements for elliptic curve lightweight cryptography.","['Elliptic curves', 'Elliptic curve cryptography', 'Wireless sensor networks', 'Internet of Things', 'Protocols']","['Cryptography', 'elliptic curve', 'lightweight', 'survey']"
"Automatic emotion recognition from the analysis of body movement has tremendous potential to revolutionize virtual reality, robotics, behavior modeling, and biometric identity recognition domains. A computer system capable of recognizing human emotion from the body can also significantly change the way we interact with the computers. One of the significant challenges is to identify emotion-specific features from a vast number of descriptors of human body movements. In this paper, we introduce a novel two-layer feature selection framework for emotion classification from a comprehensive list of body movement features. We used the feature selection framework to accurately recognize five basic emotions: happiness, sadness, fear, anger, and neutral. In the first layer, a unique combination of Analysis of Variance (ANOVA) and Multivariate Analysis of Variance (MANOVA) was utilized to eliminate irrelevant features. In the second layer, a binary chromosome-based genetic algorithm was proposed to select a feature subset from the relevant list of features that maximizes the emotion recognition rate. Score and rank-level fusion were applied to further improve the accuracy of the system. The proposed system was validated on proprietary and public datasets, containing 30 subjects. Different action scenarios, such as walking and sitting actions, as well as an action-independent case, were considered. Based on the experimental results, the proposed emotion recognition system achieved a very high emotion recognition rate outperforming all of the state-of-the-art methods. The proposed system achieved recognition accuracy of 90.0% during walking, 96.0% during sitting, and 86.66% in an action-independent scenario, demonstrating high accuracy and robustness of the developed method.","['Emotion recognition', 'Feature extraction', 'Analysis of variance', 'Biometrics (access control)', 'Computational modeling', 'Histograms', 'Genetic algorithms']","['Emotion recognition', 'feature selection', 'gait analysis', 'genetic algorithm', 'information fusion', 'human motion', 'kinect sensor', 'biometrics']"
"This paper focuses on energy efficiency aspects and related benefits of radio-access-network-as-a-service (RANaaS) implementation (using commodity hardware) as architectural evolution of LTE-advanced networks toward 5G infrastructure. RANaaS is a novel concept introduced recently, which enables the partial centralization of RAN functionalities depending on the actual needs as well as on network characteristics. In the view of future definition of 5G systems, this cloud-based design is an important solution in terms of efficient usage of network resources. The aim of this paper is to give a vision of the advantages of the RANaaS, to present its benefits in terms of energy efficiency and to propose a consistent system-level power model as a reference for assessing innovative functionalities toward 5G systems. The incremental benefits through the years are also discussed in perspective, by considering technological evolution of IT platforms and the increasing matching between their capabilities and the need for progressive virtualization of RAN functionalities. The description is complemented by an exemplary evaluation in terms of energy efficiency, analyzing the achievable gains associated with the RANaaS paradigm.","['Energy efficiency', 'Mobile communication', '5G mobile communication', 'Network architecture', 'Radio access network', 'Long Term Evolution', 'Virtualization', 'Cloud computing']","['Energy Efficiency', 'Wireless Communication', 'Radio Access Networks', 'RAN-as-a-Service', 'power model', 'Cloud-RAN', 'LTE-Advanced', 'SG']"
"Flying Ad-hoc Network (FANET) is a decentralized communication system solely formed by Unmanned Aerial Vehicles (UAVs). In FANET, the UAV clients are vulnerable to various malicious attacks such as the jamming attack. The aerial adversaries in the jamming attack disrupt the communication of the victim network through interference on the receiver side. Jamming attack detection in FANET poses new challenges for its key differences from other ad-hoc networks. First, because of the varying communication range and power consumption constraints, any centralized detection system becomes trivial in FANET. Second, the existing decentralized solutions, disregarding the unbalanced sensory data from new spatial environments, are unsuitable for the highly mobile and spatially heterogeneous UAVs in FANET. Third, given a huge number of UAV clients, the global model may need to choose a sub-group of UAV clients for providing a timely global update. Recently, federated learning has gained attention, as it addresses unbalanced data properties besides providing communication efficiency, thus making it a suitable choice for FANET. Therefore, we propose a federated learning-based on-device jamming attack detection security architecture for FANET. We enhance the proposed federated learning model with a client group prioritization technique leveraging the Dempster-Shafer theory. The proposed client group prioritization mechanism allows the aggregator node to identify better client groups for calculating the global update. We evaluated our mechanism with datasets from publicly available standardized jamming attack scenarios by CRAWDAD and the ns-3 simulated FANET architecture and showed that, in terms of accuracy, our proposed solution (82.01% for the CRAWDAD dataset and 89.73% for the ns-3 simulated FANET dataset) outperforms the traditional distributed solution (49.11% for the CRAWDAD dataset and 65.62% for the ns-3 simulated FANET dataset). Moreover, the Dempster-Shafer-based client group prioritization mechanism identifies the best client groups out of 56 client group combinations for efficient federated averaging.","['Jamming', 'Ad hoc networks', 'Unmanned aerial vehicles', 'Computer architecture', 'Training', 'Security', 'Computational modeling']","['Unmannad aerial vehicle', 'flying ad-hoc network', 'jamming attack', 'federated learning', 'on-device AI', 'Dempster–Shafer theory']"
"Due to the recent development of cyber-physical systems, big data, cloud computing, and industrial wireless networks, a new era of industrial big data is introduced. Deep learning, which brought a revolutionary change in computer vision, natural language processing, and a variety of other applications, has significant potential for solutions providing in sophisticated industrial applications. In this paper, a concept of device electrocardiogram (DECG) is presented, and an algorithm based on deep denoising autoencoder (DDA) and regression operation is proposed for the prediction of the remaining useful life of industrial equipment. First, the concept of electrocardiogram is explained. Then, a problem statement based on manufacturing scenario is presented. Subsequently, the architecture of the proposed algorithm called integrated DDA and the algorithm workflow are provided. Moreover, DECG is compared with traditional factory information system, and the feasibility and effectiveness of the proposed algorithm are validated experimentally. The proposed concept and algorithm combine typical industrial scenario and advance artificial intelligence, which has great potential to accelerate the implementation of industry 4.0.","['Machine learning', 'Production', 'Manufacturing', 'Maintenance engineering', 'Big Data', 'Hidden Markov models', 'Prediction algorithms']","['Cyber-physical systems', 'deep learning', 'device electrocardiogram', 'industrial big data', 'industry 40']"
"Although it is widely deemed impossible to overcome the information theoretic optimality of the one-time pad (OTP) cipher in pre-and post-quantum cryptography, this work shows that the optimality of information theoretic security (ITS) of OTP is paradoxical from the perspective of information conservational computing and cryptography. To prove this point, ITS of OTP is extended to information conservational security (ICS) of scalable OTP (S-OTP) with percentage-based key extension where total key length can be reduced to a condensed tiny minimum through “black hole” keypad compression coupled with “big bang” data recov-ery. The cost is a limited 25%+ increase in total data length and network traffic; the gain is to makes the transmission of long messages possible without weakening ITS/OTP. It is proven that if ITS/OTP were optimal, ICS/S-OTP would be impossible; on the other hand, if ICS/S-OTP were not information theoretically secure, ITS/OTP would not be secure either. Thus, we have a proof by contradiction on the paradoxical nature of OTP optimality. It is further proven that a summation with percentage distribution is a special case of equilibrium-based bipolar quantum cellular automata. This proof bridges a classical world with a quantum world and makes it possible to combine the advantages of both approaches for pre-and post-quantum cryptography. It is suggested that the findings of this work form an analytical paradigm of quantum intelligence machinery toward perfect information conservational security. Some mysteries in nature and science are identified. In particular, the question is posted: Could modern science have been like a well-founded building with a floor of observable beings and truths but missing its roof for equilibrium, harmony, information conservation, and logically definable causality?.",[],[]
"Accurately predicting future service traffic would be of great help for load balancing and resource allocation, which plays a key role in guaranteeing the quality of service (QoS) in cloud computing. With the rapid development of data center, the large-scale network traffic prediction requires more suitable methods to deal with the complex properties (e.g., high-dimension, long-range dependence, non-linearity, and so on). However, due to the limitations of traditional methods (e.g., strong theoretical assumptions and simple implementation), few research works could predict the large-scale network traffic efficiently and accurately. More importantly, most of the studies took only the temporal features but without the services’ communications into consideration, which may weaken the QoS of applications in the data center. To this end, we applied the gated recurrent unit (GRU) model and the interactive temporal recurrent convolution network (ITRCN) to single-service traffic prediction and interactive network traffic prediction, respectively. Especially, ITRCN takes the communications between services as a whole and directly predicts the interactive traffic in large-scale network. Within the ITRCN model, the convolution neural network (CNN) part learns network traffic as images to capture the network-wide services’ correlations, and the GRU part learns the temporal features to help the interactive network traffic prediction. We conducted comprehensive experiments based on the Yahoo! data sets, and the results show that the proposed novel method outperforms the conventional GRU and CNN method by an improvement of 14.3% and 13.0% in root mean square error, respectively.","['Predictive models', 'Data models', 'Correlation', 'Feature extraction', 'Convolution', 'Computational modeling']","['Network traffic prediction', 'interactive traffic representation', 'interactive temporal recurrent convolution network', 'gated recurrent unit', 'convolution neural network']"
"Newspapers are very important for a society as they inform citizens about the events around them and how they can impact their life. Their importance becomes more crucial and indispensable in the times of health crisis such as the current COVID-19 pandemic. Since the starting of this pandemic newspapers are providing rich information to the public about various issues such as the discovery of a new strain of coronavirus, lockdown and other restrictions, government policies, and information related to the vaccine development for the same. In this scenario, analysis of emergent and widely reported topics/themes/issues and associated sentiments from various countries can help us better understand the COVID-19 pandemic. In our research, the database of more than 100,000 COVID-19 news headlines and articles were analyzed using top2vec (for topic modeling) and RoBERTa (for sentiment classification and analysis). Our topic modeling results highlighted that education, economy, US, and sports are some of the most common and widely reported themes across UK, India, Japan, South Korea. Further, our sentiment classification model achieved 90% validation accuracy and the analysis showed that the worst affected country, i.e. the UK (in our dataset) also has the highest percentage of negative sentiment.","['COVID-19', 'Analytical models', 'Sentiment analysis', 'Pandemics', 'Vaccines', 'Data models', 'Social networking (online)']","['COVID-19', 'natural language processing', 'newspaper', 'machine learning', 'RoBERTa', 'sentiment analysis', 'topic modeling', 'Top2Vec']"
"Image registration is an important technique in many computer vision applications such as image fusion, image retrieval, object tracking, face recognition, change detection and so on. Local feature descriptors, i.e., how to detect features and how to describe them, play a fundamental and important role in image registration process, which directly influence the accuracy and robustness of image registration. This paper mainly focuses on the variety of local feature descriptors including some theoretical research, mathematical models, and methods or algorithms along with their applications in the context of image registration. The existing local feature descriptors are roughly classified into six categories to demonstrate and analyze comprehensively their own advantages. The current and future challenges of local feature descriptors are discussed. The major goal of the paper is to present a unique survey of the state-of-the-art image matching methods based on feature descriptor, from which future research may benefit.","['Feature extraction', 'Image matching', 'Image registration', 'Detectors', 'Computer vision', 'Histograms']","['Local feature descriptor', 'image matching', 'point pattern matching', 'pattern recognition']"
"A multiple-input multiple-output (MIMO) antenna system is proposed for fifth generation (5G) and fourth generation (4G) mobile communication. The design meets all of the requirements of both 5G and 4G antennas using only a single structure. Since 5G will work at millimeter-wave (mm-Wave), the proposed design serves triple bands at mm-Wave (28, 37 and 39 GHz) for 5G in addition to 2 GHz band (1.8-2.6) for 4G. Each MIMO element consists of a slot-based antenna, fed by two microstrip feeders for the 5G and 4G bands. The design works as a tapered slot antenna at mm-Wave offering end-fire radiation for 5G and works as an open-ended slot antenna for a 2 GHz band offering omni-direction radiation for 4G. The slot antenna type used in the proposed design produces wide bandwidths for the 5G and 4G. The overall volume of each MIMO antenna element is 0.21x0.10x0.003 λ 3 , where λ is the wavelength of the lowest operating frequency. As a proof of concept, a prototype is developed and tested. The measured results show a wide impedance bandwidth of |S 11 |<; -10 dB covering the band 27.5-40 GHz for 5G, and impedance bandwidth of |S 11 | <; -6 dB covering the band 1.8-2.6 GHz for 4G.","['5G mobile communication', 'MIMO communication', 'Slot antennas', 'Mobile antennas', 'Antenna feeds', 'Bandwidth']","['5G', '4G', 'MIMO antenna', 'mobile communication', 'slot antenna']"
"The permanency of highly-reliable power supply is a core trait of an electric power transmission network. A transmission line is the main part of this network through which power is transmitted to the utility. These lines are often damaged by accidental breakdowns owing to different random origins. Hence, researchers are trying to detect and identify these failures at the earliest to avoid financial losses. This paper offers a new real-time fast mathematical morphology-based fault feature extraction scheme for detection and classification of transmission line faults. The morphological median filter is exploited to wrest unique fault features which are then fed as an input to a decision tree classifier to classify the fault type. The acquired graphical and numerical results of the extracted features affirm the potency of the offered scheme. The proposed scheme is verified for different fault cases simulated on high-voltage transmission line modelled using ATP/EMTP with varying system constraints. The performance of the stated technique is also validated for fault detection and classification on real-field transmission lines. The results state that the proposed method is capable of detecting and classifying the faults with adequate precision and reduced computational intricacy, in less than a quarter of a cycle.","['Feature extraction', 'Power transmission lines', 'Circuit faults', 'Fault detection', 'Support vector machines', 'Real-time systems']","['Fault detection', 'fault classification', 'fault feature extraction', 'transmission line protection', 'decision tree', 'mathematical morphology']"
"The demand for spectrum resources has increased dramatically with the advent of modern wireless applications. Spectrum sharing, considered as a critical mechanism for 5G networks, is envisioned to address spectrum scarcity issue and achieve high data rate access, and guaranteed the quality of service (QoS). From the licensed network's perspective, the interference caused by all secondary users (SUs) should be minimized. From secondary networks point of view, there is a need to assign networks to SUs in such a way that overall interference is reduced, enabling the accommodation of a growing number of SUs. This paper presents a network selection and channel allocation mechanism in order to increase revenue by accommodating more SUs and catering to their preferences, while at the same time, respecting the primary network operator's policies. An optimization problem is formulated in order to minimize accumulated interference incurred to licensed users and the amount that SUs have to pay for using the primary network. The aim is to provide SUs with a specific QoS at a lower price, subject to the interference constraints of each available network with idle channels. Particle swarm optimization and a modified version of the genetic algorithm are used to solve the optimization problem. Finally, this paper is supported by extensive simulation results that illustrate the effectiveness of the proposed methods in finding a near-optimal solution.","['5G mobile communication', 'Interference', 'Heterogeneous networks', 'Genetic algorithms', 'Quality of service', 'Optimization', 'Resource management']","['Channel allocation', 'network selection', 'optimization']"
"By enabling very high bandwidth for radio communications, the millimeter-wave (mmWave), which can easily be integrated with massive-multiple-input-multiple-output (massive-MIMO) due to small antenna size, has been attracting growing attention as a candidate for the fifth-generation (5G) and 5G-beyond wireless communications networks. On the other hand, the communication over the orthogonal states/modes of orbital angular momentum (OAM) is a subset of the solutions offered by massive-MIMO communications. Traditional massive-MIMO-based mmWave communications did not concern the potential spectrum-efficiency-gain (SE-gain) offered by the orthogonal states of OAM. However, the highly expected maximum SE-gain for OAM and massive-MIMO communications is the product of SE-gains offered by OAM and multiplexing-MIMO. In this paper, we propose the OAM-embedded-MIMO (OEM) communication framework to obtain the multiplicative SE-gain for joint OAM and massive-MIMO-based mmWave wireless communications. We design the parabolic antenna for each uniform circular array antenna to converge OAM signals. Then, we develop the mode-decomposition and multiplexing-detection scheme to obtain the transmit signal on each OAM-mode of each transmit antenna. Also, we develop the OEM-water-filling power allocation policy to achieve the maximum multiplicative SE-gain for OEM communications. The extensive simulations obtained validate and evaluate our developed a parabolic antenna-based converging method, a mode-decomposition and multiplexing-detection scheme, and an OEM-water-filling policy, showing that our proposed OEM mmWave communications can significantly increase the SE as compared with the traditional massive-MIMO-based mmWave communications.","['Antenna arrays', 'MIMO communication', 'Multiplexing', 'Transmitting antennas', 'Wireless communication', 'Resource management']","['Millimeter-wave', 'massive multiple-input-multiple-output (MIMO)', 'orbital angular momentum (OAM)', 'OAM-embedded-MIMO (OEM)', 'multiplicative spectrum-efficiency', 'parabolic antenna', 'mode-decomposition', 'multiplexing-detection', 'OEM-water-filling power allocation']"
"In this paper, we investigate the outage probability (OP) performance of amplify-and-forward (AF) cognitive hybrid satellite-terrestrial overlay networks (CHSTONs) with the non-orthogonal multiple access (NOMA) scheme, in which half-duplexing terrestrial secondary networks cooperate with a primary satellite network for dynamic spectrum access. In order to improve the fairness of overlay paradigm, a NOMA-based power allocation profile is determined by instantaneous channel conditions. Considering the generalized shadowed-Rician fading for satellite links and Nakagami-mfading for terrestrial links, we derive the closed-form OP expressions for both the primary and secondary users. Then, the asymptotic OP expressions at the high signal-to-noise ratio (SNR) regime are also obtained to evaluate the achievable diversity order and coding gain. Finally, the numerical simulations are provided to validate the theoretical results as well as the superiority of the NOMA scheme in CHSTONs and proclaim the effect of key parameters on the performance of the NOMA users, such as fading configurations and the power split factor.","['NOMA', 'Relays', 'Signal to noise ratio', 'Satellite broadcasting', 'Interference', 'Fading channels', 'Overlay networks']","['Non-orthogonal multiple access (NOMA)', 'cognitive hybrid satellite-terrestrial overlay networks (CHSTONs)', 'outage probability']"
"Physical layer security has been recently recognized as a promising new design paradigm to provide security in wireless networks. In addition to the existing conventional cryptographic methods, physical layer security exploits the dynamics of fading channels to enhance secured wireless links. In this approach, jamming plays a key role by generating noise signals to confuse the potential eavesdroppers, and significantly improves quality and reliability of secure communications between legitimate terminals. This article presents theoretical limits and practical designs of jamming approaches for physical layer security. In particular, the theoretical limits explore the achievable secrecy rates of user cooperation-based jamming whilst the centralized and game theoretic-based precoding techniques are reviewed for practical implementations. In addition, the emerging wireless energy harvesting techniques are exploited to harvest the required energy to transmit jamming signals. Future directions of these approaches and the associated research challenges are also briefly outlined.","['Jamming', 'Noise measurement', 'Interference', 'Wireless communication', 'Receivers', 'Encoding', 'Physical layer']","['Physical layer security', 'cooperative jamming', 'full-duplex systems', 'game theory', 'wireless energy harvesting']"
"Precision Agriculture (PA) and Agriculture 4.0 (A4.0) have been widely discussed as a medium to address the challenges related to agricultural production. In this research, we present a Systematic Literature Review (SLR) supported by a Bibliometric Performance and Network Analysis (BPNA) of the use of A4.0 technologies and PA techniques in the coffee sector. To perform the SLR, 87 documents published since 2011 were extracted from the Scopus and Web of Science databases and processed through the Preferred Reporting Items for Systematic reviews and Meta-Analyzes (PRISMA) protocol. The BPNA was carried out to identify the strategic themes in the field of study. The results present 23 clusters with different levels of development and maturity. We also discovered and presented the thematic network structure of the most used A4.0 technologies in the coffee sector. Our findings shows that Internet of Things, Machine Learning and geostatistics are the most used technologies in the coffee sector, we also present the main challenges and trends related to technological adoption in coffee systems. We believe that the demonstrated results have the potential to be considered by researchers in future works and decision making related to the field of study.","['Agriculture', 'Market research', 'Productivity', 'Meteorology', 'Systematics', 'Bibliometrics']","['Agriculture 4.0', 'bibliometric', 'coffee', 'digital agriculture', 'digital transformation', 'industry 4.0', 'precision agriculture', 'strategic intelligence', 'sustainability']"
"Traditional approaches for job shop scheduling problems are ill-suited to deal with complex and changeable production environments due to their limited real-time responsiveness. Based on disjunctive graph dispatching, this work proposes a deep reinforcement learning (DRL) framework, that combines the advantages of real-time response and flexibility of a deep convolutional neural network (CNN) and reinforcement learning (RL), and learns behavior strategies directly according to the input manufacturing states, thus is more appropriate for practical order-oriented manufacturing problems. In this framework, a scheduling process using a disjunction graph is viewed as a multi-stage sequential decision-making problem and a deep CNN is used to approximate the state-action value. The manufacturing states are expressed as multi-channel images and input into the network. Various heuristic rules are used as available actions. By adopting the dueling double Deep Q-network with prioritized replay (DDDQNPR), the RL agent continually interacts with the scheduling environment through trial and error to obtain the best policy of combined actions for each decision step. Static computational experiments are performed on 85 JSSP instances from the well-known OR-Library. The results indicate that the proposed algorithm can obtain optimal solutions for small scale problems, and performs better than any single heuristic rule for large scale problems, with performances comparable to genetic algorithms. To prove the generalization and robustness of our algorithm, the instances with random initial states are used as validation sets during training to select the model with the best generalization ability, and then the performance of the trained policy on scheduling instances with different initial states is tested. The results show that the agent is able to get better solutions adaptively. Meanwhile, some studies on dynamic instances with random processing time are performed and experiment results indicate that out method can achieve comparable performances in dynamic environment in the short run.","['Job shop scheduling', 'Dynamic scheduling', 'Heuristic algorithms', 'Adaptive scheduling', 'Real-time systems']","['Adaptive scheduling', 'convolutional neural network', 'deep reinforcement learning', 'dueling double DQN', 'job shop scheduling problem (JSSP)']"
"The reliability of electrical components affects the stable operation of the power system. Electrical components inspection has long been important issues in the intelligent power system. The main problems of traditional recognition methods of electrical components are low detection accuracy and poor real-time performance, which are challenging to extract necessary features from the inspection images. This paper proposes a way to detect the electrical components in the Unmanned Aerial Vehicle (UAV) inspection image based on You Only Look Once (YOLO) V3 algorithm. Due to some of the inspection images are not clear, which result in the reduction of the available dataset. On this basis, we adopt Super-Resolution Convolutional Neural Network (SRCNN) to realize super-resolution reconstruction on the blurred image, which achieves the expansion of the dataset. We compare the performance of the proposed method with other popular recognition methods. The results of experiment verify the effectiveness of the proposed method, and the technique reaches high recognition accuracy, good robustness, and strong real-time performance for UAV power inspection system.","['Inspection', 'Feature extraction', 'Unmanned aerial vehicles', 'Image reconstruction', 'Image recognition', 'Image resolution', 'Insulators']","['Deep Learning', 'SRCNN', 'YOLO V3', 'electrical components', 'object detection']"
"Large-scale data centers enable the new era of cloud computing and provide the core infrastructure to meet the computing and storage requirements for both enterprise information technology needs and cloud-based services. To support the ever-growing cloud computing needs, the number of servers in today's data centers are increasing exponentially, which in turn leads to enormous challenges in designing an efficient and cost-effective data center network. With data availability and security at stake, the issues with data center networks are more critical than ever. Motivated by these challenges and critical issues, many novel and creative research works have been proposed in recent years. In this paper, we investigate in data center networks and provide a general overview and analysis of the literature covering various research areas, including data center network interconnection architectures, network protocols for data center networks, and network resource sharing in multitenant cloud data centers. We start with an overview on data center networks and together with its requirements navigate the data center network designs. We then present the research literature related to the aforementioned research topics in the subsequent sections. Finally, we draw the conclusions.","['Computer security', 'Resource management', 'Large-scale systems', 'Data centers', 'Cloud computing', 'Information technology', 'Servers', 'Computer architecture', 'Design methodology']","['Data Center Networks', 'Architecture', 'Resource Sharing']"
"Energy management system (EMS) is responsible for the optimal operation of microgrids. EMS adjusts its operational schedule for near future by using the available information. Market price signals are generally used for the operation of microgrids, which are obtained by using estimation/ forecasting methods. However, it is difficult to precisely predict the market prices due to the involvement of various complex factors like weather, policy, demand, errors in forecasting methods, and fuel cost. Therefore, in this paper, the uncertainties associated with the real-time market price signals (buying and selling) are realized via a robust optimization method. In addition to market price signals, uncertainties associated with renewable power sources and forecasted load values are also considered. Initially, a deterministic model is formulated for an ac/dc hybrid microgrid. Then a min-max robust counterpart is formulated by considering the worstcase uncertainties. Finally, an equivalent mixed integer problem is formulated by using linear duality and other optimality conditions. The developed model can provide feasible solutions for all the scenarios if the uncertainties fluctuate within the specified bounds. The effect of market price uncertainties on internal power transfer and external power trading, operation cost, the state-of-charge of energy storage elements, and unit commitment of dispatchable generators is analyzed. Taguchi's orthogonal array (OA) method is used to find the worst-case scenario within the specified uncertainty bounds. Then, Monte Carlo method is used to generate various scenarios within the uncertainty bounds to evaluate the robustness of the selected scenario via Taguchi's OA method. Finally, a violation index is formulated to evaluate the robustness of the proposed approach against the deterministic model. Simulations results have validated the robustness of the proposed optimization strategy.","['Microgrids', 'Uncertainty', 'Robustness', 'Optimization', 'Load modeling', 'Generators', 'Energy management']","['Forecasted price uncertainty', 'ac/dc hybrid microgrids', 'microgrid operation', 'optimal operation', 'robust optimization', 'uncertainty modeling']"
"In this paper, we investigate the secrecy performance of an energy harvesting relay system, where a legitimate source communicates with a legitimate destination via the assistance of multiple trusted relays. In the considered system, the source and relays deploy the time-switching-based radio frequency energy harvesting technique to harvest energy from a multi-antenna beacon. Different antenna selection and relay selection schemes are applied to enhance the security of the system. Specifically, two relay selection schemes based on the partial and full knowledge of channel state information, i.e., optimal relay selection and partial relay selection, and two antenna selection schemes for harvesting energy at source and relays, i.e., maximizing energy harvesting channel for the source and maximizing energy harvesting channel for the selected relay, are proposed. The exact and asymptotic expressions of secrecy outage probability in these schemes are derived. We demonstrate that applying relay selection approaches in the considered energy harvesting system can enhance the security performance. In particular, optimal relay selection scheme outperforms partial relay selection scheme and achieves full secrecy diversity order, regardless of energy harvesting scenarios.","['Energy harvesting', 'Performance evaluation', 'Relays', 'Network security', 'Antennas']","['Physical layer security', 'energy harvesting communications', 'relay networks', 'wireless power transfer', '5G']"
"The Shapley value has become popular in the Explainable AI (XAI) literature, thanks, to a large extent, to a solid theoretical foundation, including four “favourable and fair” axioms for attribution in transferable utility games. The Shapley value is probably the only solution concept satisfying these axioms. In this paper, we introduce the Shapley value and draw attention to its recent uses as a feature selection tool. We call into question this use of the Shapley value, using simple, abstract “toy” counterexamples to illustrate that the axioms may work against the goals of feature selection. From this, we develop a number of insights that are then investigated in concrete simulation settings, with a variety of Shapley value formulations, including SHapley Additive exPlanations (SHAP) and Shapley Additive Global importancE (SAGE). The aim is not to encourage any use of the Shapley value for feature selection, but we aim to clarify various limitations around their current use in the literature. In so doing, we hope to help demystify certain aspects of the Shapley value axioms that are viewed as “favourable”. In particular, we wish to highlight that the favourability of the axioms depends non-trivially on the way in which the Shapley value is appropriated in the XAI application.","['Feature extraction', 'Games', 'Computational modeling', 'Task analysis', 'Additives', 'Predictive models', 'Data models']","['Explainability', 'feature selection', 'interpretability', 'Shapley value', 'variable selection', 'XAI']"
"Accurate state-of-charge (SOC) and state-of-health (SOH) estimations of batteries are of great significance for electric vehicles. A combined SOC and SOH estimation method for lithium-ion batteries based on a dual extended Kalman filter (EKF) and fractional-order model (FOM) is proposed. A fractional second-order RC model is established and model parameters are identified offline by an adaptive genetic algorithm (AGA). One of the dual filters is used to jointly estimate the SOC and SOH (ohmic internal resistance and capacity), and another is employed to update the model parameters online. Compared with single filter with fixed parameters, the dual filters can obtain more accurate SOC estimation and model voltage prediction. The SOC root-mean square errors (RMSEs) decrease from 6.87%, 8.50% and 7.32% to 0.48%, 0.63% and 0.86% under the Federal Urban Driving Schedule (FUDS), the Dynamic Stress Test (DST) and the US06 Highway Driving Schedule tests, respectively, and the model voltage RMSEs decrease from 88.6 mV, 79.3 mV and 68.4 mV to 4.9 mV, 5.7 mV and 3.8 mV, respectively at room temperature. The accuracy of the SOH estimation is also verified under these three tests. The convergence and robustness of the proposed method are discussed and verified by using the wrong initial state value and noise analysis.","['Batteries', 'State of charge', 'Estimation', 'Resistance', 'Kalman filters', 'Mathematical model', 'Predictive models']","['State-of-charge', 'state-of-health', 'lithium-ion battery', 'fractional-order model', 'dual Kalman filter']"
"The newly released IEEE Std C95.1™-2019 defines exposure criteria and associated limits for the protection of persons against established adverse health effects from exposures to electric, magnetic, and electromagnetic fields, in the frequency range 0 Hz to 300 GHz. The exposure limits apply to persons permitted in restricted environments and to the general public in unrestricted environments. These limits are not intended to apply to the exposure of patients by or under the direction of physicians and care professionals, as well as to the exposure of informed volunteers in scientific research studies, or to the use of medical devices or implants. IEEE Std C95.1™-2019 can be obtained at no cost from the IEEE Get Program https://ieeexplore.ieee.org/document/8859679.",[],[]
"Frequency division duplex (FDD) systems dominate current cellular networks due to its advantages of low latency and strong anti-interference ability. However, the computation and the feedback overheads for predicting the downlink channel state information (DL-CSI) are the major bottlenecks to further improve the cellular FDD systems performance. To deal with these problems, in this paper, a convolutional long short-term memory network (ConvLSTM-net)-based deep learning method is proposed for predicting the DL-CSI from the uplink channel state information (UL-CSI) directly. In detail, our proposed ConvLSTM-net consists of two modules: one is the feature extraction module that learns spatial and temporal correlations between the DL-CSI and the UL-CSI, and the other one is the prediction module that maps the extracted features to the reconstructions of the DL-CSI. To evaluate the outperformance of the ConvLSTM-net, a long short-term memory network (LSTM-net) and a convolutional neural networks (CNN)-based schemes are simulated for comparisons. The simulation experiments consist of two parts. One part is that the hyper parameters of the proposed ConvLSTM-net are analyzed to explore their effects on the prediction performance. Another part is that experiments are conducted in the time domain and frequency domain, respectively, for selecting a more proper domain to predict the DL-CSI accurately. From the experiment results above, it can be verified that the proposed ConvLSTM-net with proper hyper parameters outperforms the compared schemes at predicting DL-CSI according to UL-CSI in the cellular FDD systems, especially in the time domain.","['Deep learning', 'Kernel', 'Computer architecture', 'Channel state information', 'Convolution', 'Correlation', 'Microprocessors']","['Channel prediction', 'channel state information', 'downlink', 'deep learning', 'FDD', 'uplink']"
"In this paper, we present a comprehensive channel modeling and characterization study for underwater visible light communications. Our study is based on the advanced ray tracing, which allows for an accurate description of the interaction of rays emitted from the lighting source within an underwater environment. Contrary to existing works, which are mainly limited to simplified underwater scenarios, i.e., empty sea, we take into account the presence of human and man-made objects to investigate the effects of shadowing and blockage. The reflection characteristics of the sea surface and sea bottom as well as the water characteristics, i.e., extinction coefficient and scattering phase function of particles, are precisely considered. As case studies, we consider various underwater scenarios with different transmitter/receiver specifications (i.e., viewing angle, aperture size) and different depths from the sea surface. For each environment, we obtain channel impulse responses and present a characterization study where channel parameters, such as channel DC gain, path loss, and delay spread, are obtained.","['Scattering', 'Solid modeling', 'Sea surface', 'Photonics', 'Absorption', 'Optical transmitters', 'Mathematical model']","['Underwater visible light communications', 'channel modeling', 'ray tracing']"
"A new differentially fed frequency reconfigurable antenna adopting proximity-coupling feeding for WLAN and sub-6-GHz 5G applications is proposed in this paper. It consists of two substrates that are separated by a 2.5-mm-thick air gap. By configuring the four p-i-n diode switches arranged on the two substrates, the excitation of the radiating patch and the length of the feed-lines can be controlled, and then, two different operating frequency bands can be obtained. The experiments indicate that the designed antenna can be switched between two states operating at 2.45- and 3.50-GHz band, respectively. Good agreement between the simulated and measured results is achieved, and the radiation patterns and gains are similar for the two states. The proposed antenna is a good candidate for WLAN (2.45 GHz) and sub-6-GHz 5G (3.50 GHz) applications.","['Antenna feeds', 'Antenna radiation patterns', 'Substrates', 'PIN photodiodes', 'Air gaps']","['Differentially-fed', 'frequency reconfigurable antenna', 'PIN diode switch']"
"There has been an increasing demand for connectivity of the clusters of microgrids to increase their flexibility and security. This paper presents a framework for implementation, simulation, and evaluation of a novel power routing algorithm for clusters of microgrids. The presumed cluster is composed of multiple direct current (dc) microgrids connected together through multi-terminal dc system in a meshed network. In this structure, the energy is redirected from the microgrid with excessive power generation capacity to the microgrid which has power shortage to supply its internal loads. The key contribution of this paper is that each microgrid in the cluster is unaware of the current state and other flows of the cluster. In this approach, the optimal power flow problem is solved for the system while managing congestion and mitigating power losses. The proposed methodology works for both radial and non-radial networks regardless of the network topology, scale, and number of microgrids involved in the cluster. Therefore, it is also well suited for large-scale optimal power routing problems that will emerge in the future clusters of microgrids. The effectiveness of the proposed algorithm is verified by MATLAB simulation. We also present a comprehensive cloud-based platform for further implementation of the proposed algorithm on the OPAL-RT real-time digital simulation system. The communication paths between the microgrids and the cloud environment can be emulated by OMNeT++.","['Microgrids', 'Routing', 'Uncertainty', 'Computational modeling', 'Power system stability', 'Cloud computing']","['Clusters of microgrids', 'cloud computing', 'congestion management', 'oblivious network design', 'optimal power routing', 'real-time simulation platform']"
"This paper proposes a multi-attractor period multi-scroll chaotic system and a second-generation current-controlled current conveyor (CCCII) with a wide tunable range of intrinsic resistance. The newly proposed multi-attractor period multi-scroll chaotic system is constructed by this CCCII. The proposed chaotic system can generate single-attractor period, double-attractor period, three-attractor period, and even more attractor period multi-scroll. The four-dimensional state equation of the chaotic system contains four nonlinear functions for generating multi-attractor period multi-scroll chaos. Since the intrinsic resistance of the CCCII can be adjusted by external voltages or currents, the multi-attractor period multi-scroll chaotic integrated circuit based on the proposed CCCII have a tunable characteristic. It is worth noting that a chaotic integrated circuit has been implemented completely using current signals instead of voltage signals, and more interestingly, it does not contain any passive resistor. The dynamic characteristics of the multi-attractor period multi-scroll chaotic system are given. The circuit designs of the CMOS CCCII and the corresponding chaotic circuit are made in detail. We conduct the numerical and circuit simulations of the proposed chaotic system and the integrated circuit implementation of the chaotic circuit based on the CMOS CCCII. The correctness of the CCCII circuit and the chaotic system are proved through hardware experiments. The comparison between the implementation scheme of the chaotic circuit in this paper and several reported chaotic circuits is conducted.","['Chaotic communication', 'Mathematical model', 'Resistors', 'Dynamic range', 'CMOS integrated circuits']","['Chaotic integrated circuit', 'CMOS CCCII', 'current mode', 'intrinsic resistance-tunable', 'multi-attractor period', 'multi-scroll', 'passive resistor']"
"In recent years, convolutional neural networks have achieved considerable success in different computer vision tasks, including image denoising. In this work, we present a residual dense neural network (RDUNet) for image denoising based on the densely connected hierarchical network. The encoding and decoding layers of the RDUNet consist of densely connected convolutional layers to reuse the feature maps and local residual learning to avoid the vanishing gradient problem and speed up the learning process. Moreover, global residual learning is adopted such that, instead of directly predicting the denoised image, the model predicts the residual noise of the corrupted image. The algorithm was trained for the case of additive white Gaussian noise and using a wide range of noise levels. Hence, one advantage of the proposal is that the denoising process does not require prior knowledge about the noise level. In order to evaluate the model, we conducted several experiments with natural image databases available online, achieving competitive results compared with state-of-the-art networks for image denoising. For comparison purpose, we use additive Gaussian noise with levels 10, 30, 50. In the case of grayscale images, we achieved PSNR of 34.39, 29.11, 26.99, and SSIM of 0.9297, 0.8193, 0.7491. For color images we obtained PSNR of 36.68, 31.43, 29.12, and SSIM of 0.9600, 0.8961, 0.8465.","['Image denoising', 'Noise reduction', 'Neural networks', 'Decoding', 'Convolutional codes', 'Kernel', 'Noise level']","['Additive white Gaussian noise', 'convolutional neural networks', 'image denoising', 'residual dense neural network']"
"The telecare medical information systems (TMISs) provide the convenience to the patients/users to be served at home. Along with such ease, it is essential to preserve the privacy and to provide the security to the patients/users in TMIS. Often, authentication protocols are adopted to guarantee privacy and secure interaction between the patients/users and remote server. Recently, Chaudhry et al. pointed out that Islam et al.'s scheme based on smart card is prone to user impersonation and server impersonation attacks. Chaudhry et al. later presented an enhanced scheme based on elliptic curve cryptography to remedy the weaknesses of Islam et al.'s scheme. Unfortunately, we find some important limitations in both schemes. We remark that their scheme is prone to off-line password guessing attack, user/server impersonation attack, and man-in-middle attack. To overcome these limitations, we present an improved authentication scheme keeping apart the threats encountered in the design of Chaudhry et al.'s scheme. Moreover, the presented scheme can also resist all known attacks. We prove the security of the proposed scheme with the help of widespread Burrows-Abadi-Needham logic. A brief comparison with the previous works provides that the presented protocol is more efficient and more secure than other related schemes.","['Authentication', 'Smart cards', 'Protocols', 'Servers', 'Elliptic curve cryptography']","['Telecare medicine information systems', 'elliptic curve cryptography', 'smart card', 'off-line password guessing attack', 'authentication', 'BAN-logic']"
"The rotating machinery plays a vital role in industrial systems, in which unexpected mechanical faults during operation can lead to severe consequences. For fault prevention, many fault diagnostic methods based on vibration signals are available in the literature. However, the vibration signals are obtained by using different types of sensors, which can cause sensor installation issues and damage the rotating machinery. In addition, this kind of data acquisition through vibration signal induces a large amount of signal noise during machine operation, which will challenge the later fault diagnosis. A recent fault detection method based on infrared thermography (IRT) for rotating machinery avoids these issues. However, the corresponding literature is limited by the fact that the characteristics of the manual design cannot characterize the fault completely so that the diagnostic accuracy cannot exceed the diagnostic method based on the vibration signals. This paper introduces a popular image feature extraction method into the fault diagnosis of rotating machinery based on IRT for the first time. First, capturing the IRT images of the rotating machinery in different states, and then two popular feature extraction methods for IRT images, bag-of-visual-word, and convolutional neural network, are tested in turn. Finally, the extracted features are classified to implement the automatic fault diagnosis. The developed method is applied to analyze the experimental IRT images collected from bearings, and the results demonstrate that the developed method is more effective than the traditional methods based on vibration signals.","['Feature extraction', 'Fault diagnosis', 'Machinery', 'Vibrations', 'Support vector machines', 'Visualization', 'Prognostics and health management']","['Fault diagnosis', 'infrared thermography', 'convolutional neural network', 'bag-of-visual-words', 'feature recognition']"
"Android malware has been in an increasing trend in recent years due to the pervasiveness of Android operating system. Android malware is installed and run on the smartphones without explicitly prompting the users or without the user’s permission, and it poses great threats to users such as the leakage of personal information and advanced fraud. To address these threats, various techniques are proposed by researchers and practitioners. Static analysis is one of these techniques, which is widely applied to Android malware detection and can detect malware quickly and prohibit malware before installation. To provide a clarified overview of the latest work in Android malware detection using static analysis, we perform a systematic literature review by identifying 98 studies from January 2014 to March 2020. Based on the features of applications, we first divide static analysis in Android malware detection into four categories, which include Android characteristic-based method, opcode-based method, program graph-based method, and symbolic execution-based method. Then we assess the malware detection capability of static analysis, and we compare the performance of different models in Android malware detection by analyzing the results of empirical evidence. Finally, it is concluded that static analysis is effective to detect Android malware. Moreover, there is a preliminary result that neural network model outperforms the non-neural network model in Android malware detection. However, static analysis still faces many challenges. Thus, it is necessary to derive some novel techniques for improving Android malware detection based on the current research community. Moreover, it is essential to establish a unified platform that is used to evaluate the performance of a series of techniques in Android malware detection fairly.","['Malware', 'Static analysis', 'Feature extraction', 'Analytical models', 'Bibliographies', 'Sensitivity', 'Systematics']","['Android malware detection', 'static analysis', 'systematic literature review']"
"Healthcare sector is probably the most benefited from the applications of nanotechnology. The nanotechnology, in the forms of nanomedicine, nanoimplants, nanobiosensors along with the internet of nano things (IoNT), has the potential to bring a revolutionizing advancement in the field of medicine and healthcare services. The primary aim of this paper is to explore the clinical and medical possibilities of these different implementations of nanotechnology. This paper provides a comprehensive overview of nanotechnology, biosensors, nanobiosensors, and IoNT. Furthermore, multilevel taxonomies of nanotechnology, nanoparticles, biosensors, nanobiosensors, and nanozymes are presented. The potential medical and clinical applications of these technologies are discussed in details with several examples. This paper specifically focuses on IoNT and its role in healthcare. In addition to describing a general architecture of IoNT for healthcare, the communication architecture of the IoNT is also explained. The challenges in the successful realization of IoNT are also discussed critically, along with a special discussion on internet of bio-nano things (IoBNT) and its potential in making IoNT more compatible to human body.","['Nanomaterials', 'Medical services', 'Nanoscale devices', 'Nanoparticles', 'Biosensors', 'Nanobioscience']","['Nanoparticle', 'nanobionics', 'nanomedicine', 'nanosensor', 'biosensor', 'IoNT', 'IoBNT', 'taxonomy', 'WBAN', 'medical implants', 'bio-nanochip', 'protocols', 'data management']"
"Transient impulse analysis is an effective way to detect the bearing fault at its early stage. However, it is hard to precisely extract these so-called transient impulses because these collected vibration signals usually are non-stationary, nonlinear, and drowned by heavy background noise. Variational mode decomposition (VMD) can play the role as an adaptive signal processing tool to reveal the weak transient impulses from complex vibration signals. However, its reasonable mode number is difficult to pre-set and this would make the loss of useful transient impulses. To solve this issue, an improved VMD strategy is presented in this paper . For this method, it can not only utilize the advantages of traditional VMD and empirical mode decomposition (EMD) but also adaptively select sensitive intrinsic mode function (IMF) components for fault component analysis by proposed indexed values. EMD is first used to process the collected vibration signal into a series of IMFs, and the so-called useful IMFs are then evaluated by a sensitive IMF evaluation index which is based on the conjoint analysis of relatedness and kurtosis. Afterward, VMD is further improved to effectively decompose the denoised signal reconstructed from these selected useful IMFs of traditional EMD. Finally, the improved VMD is used for incipient fault diagnosis by a defined transient impulse monitoring index and Hilbert envelope analysis. Experiments are performed to demonstrate the effectiveness of the proposed method. The experimental results confirm that the proposed method can accurately extract the features of an incipient fault of a bearing.","['Vibrations', 'Fault diagnosis', 'Feature extraction', 'Transient analysis', 'Indexes', 'Time-frequency analysis', 'Fault detection']","['Improved variational mode decomposition', 'incipient fault detection', 'empirical mode decomposition', 'rolling bearings']"
"The concept of physical layer security builds on the pivotal idea of turning the channel's imperfections, such as noise and fading, into a source of security. This is established through appropriately designed coding techniques and signal processing strategies. In this vein, it has been shown that fading channels can enhance the transmission of confidential information and that a secure communication can be achieved even when the channel to the eavesdropper is better than the main channel. However, to fully benefit from what fading has to offer, the knowledge of the channel state information at the transmitter (CSIT) is of primordial importance. In practical wireless communication systems, CSIT is usually obtained, prior to data transmission, through CSI feedback sent by the receivers. The channel links over which this feedback information is sent can be either noisy, rate-limited, or delayed, leading to CSIT uncertainty. In this paper, we present a comprehensive review of recent and ongoing research works on physical layer security with CSIT uncertainty. We focus on both information theoretic and signal processing approaches to the topic when the uncertainty concerns the channel to the wiretapper or the channel to the legitimate receiver. Moreover, we present a classification of the research works based on the considered channel uncertainty. Mainly, we distinguish between the cases when the uncertainty comes from an estimation error of the CSIT, from a CSI feedback link with limited capacity, or from an outdated CSI.","['Uncertainty', 'Fading channels', 'Network security', 'Physical layer', 'Receivers', 'Channel state information', 'Error analysis', 'Feedback']","['Physical layer security', 'fading channels', 'channel state information', 'estimation error', 'rate-limited feedback', 'outdated CSI']"
"With the explosive growth in the number of vehicles in use, automated license plate recognition (ALPR) systems are required for a wide range of tasks such as law enforcement, surveillance, and toll booth operations. The operational specifications of these systems are diverse due to the differences in the intended application. For instance, they may need to run on handheld devices or cloud servers, or operate in low light and adverse weather conditions. In order to meet these requirements, a variety of techniques have been developed for license plate recognition. Even though there has been a notable improvement in the current ALPR methods, there is a requirement to be filled in ALPR techniques for a complex environment. Thus, many approaches are sensitive to the changes in illumination and operate mostly in daylight. This study explores the methods and techniques used in ALPR in recent literature. We present a critical and constructive analysis of related studies in the field of ALPR and identify the open challenge faced by researchers and developers. Further, we provide future research directions and recommendations to optimize the current solutions to work under extreme conditions.","['License plate recognition', 'Feature extraction', 'Optical character recognition software', 'Task analysis', 'Computer vision', 'Character recognition', 'Deep learning']","['Automatic license plate recognition (ALPR)', 'character recognition', 'character segmentation', 'license plate detection', 'multi-stage plate recognition', 'single-stage plate recognition']"
"Nowadays, the development of robots and smart tractors for the automation of sowing, harvesting, weeding etc. is transforming agriculture. Farmers are moving from an agriculture where everything is applied uniformly to a much more targeted farming. This new kind of farming is commonly referred to as precision agriculture. However for autonomous guidance of these agricultural machines and even sometimes for weed detection an accurate detection of crop rows is required. In this paper we propose a new method called CRowNet which uses a convolutional neural network (CNN) and the Hough transform to detect crop rows in images taken by an unmanned aerial vehicle (UAV). The method consists of a model formed with SegNet (S-SegNet) and a CNN based Hough transform (HoughCNet). The performance of the proposed method was quantitatively compared to traditional approaches and it showed the best and most robust result. A good crop row detection rate of 93.58% was obtained with an IoU score per crop row above 70%. Moreover the model trained on a given crop field is able to detect rows in images of different types of crops.","['Agriculture', 'Transforms', 'Strips', 'Unmanned aerial vehicles', 'Image segmentation', 'Robots', 'Soil']","['Crop row detection', 'deep learning', 'weed detection', 'Hough transform', 'image processing']"
"Wind power prediction is the key technology to the safe dispatch and stable operation of power system with large-scale integration of wind power. In this work, based on the historical data of wind power, wind speed and temperature, the autoregressive moving average (ARMA) prediction model and the support vector machine (SVM) prediction model are established, particle swarm optimization (PSO) algorithm is involved for parameter optimization of SVM model. Furthermore, a hybrid PSO-SVM-ARMA prediction model based on ARMA and PSO-SVM model is illustrated for wind power prediction, and the covariance minimization method and PSO are employed to find the optimal weights. Moreover, with the basis of clustering theory, time series are clustered to examine the effective dataset for wind power prediction, and a clustered hybrid PSO-SVM-ARMA (C-PSO-SVM-ARMA) wind power prediction model is prospectively proposed. In case study, different prediction models are carried out and the prediction performance is examined based on different evaluation indices, the C-PSO-SVM-ARMA model shows better performance for wind power prediction with computational efficiency and satisfying precision.","['Predictive models', 'Wind power generation', 'Autoregressive processes', 'Support vector machines', 'Hybrid power systems', 'Data models', 'Time series analysis']","['Autoregressive moving average (ARMA) model', 'clustered hybrid wind power prediction model', 'clustering method', 'particle swarm optimization (PSO)', 'support vector machine (SVM)']"
"The blood vessels are the primary anatomical structure that can be visible in retinal images. The segmentation of retinal blood vessels has been accepted worldwide for the diagnosis of both cardiovascular (CVD) and retinal diseases. Thus, it requires an appropriate vessel segmentation method for automatic detection of retinal diseases such as diabetic retinopathy and cataract. The detection of retinal diseases using computer-aided diagnosis (CAD) can help people to avoid the risks of visual impairment and save medical resources. This survey presents a comparative analysis of various machine learning and deep learning-based methods for automated blood vessel segmentation in retinal images. This paper briefly describes fundus photography, publicly available retinal databases, pre-processing and post-processing techniques for retinal vessels segmentation. A comprehensive review of the state of the art supervised and unsupervised blood vessel segmentation methodologies are presented in this paper. The objective of this study is to establish a professional structure to familiarize an individual with up-to-date vessel segmentation techniques. Moreover, we compared these approaches to the dataset, evaluation metrics, pre-processing and post-processing steps, feature extraction, segmentation methods, and induced results.","['Retina', 'Cataracts', 'Image segmentation', 'Support vector machines', 'Biomedical imaging', 'Blood vessels', 'Feature extraction']","['Vessel segmentation', 'retinal diseases', 'image segmentation', 'retinal fundus images', 'medical imaging']"
"The increasing number of Internet of Thing (IoT) devices and services makes it convenient for people to sense the real world and makes optimal decisions or complete complex tasks with them. However, the latency brought by unstable wireless networks and computation failures caused by constrained resources limit the development of IoT. A popular approach to solve this problem is to establish an IoT service provision system based on a mobile edge computing (MEC) model. In the MEC model, plenty of edge servers are placed with access points via wireless networks. With the help of cached services on edge servers, the latency can be reduced, and the computation can be offloaded. The cache services must be carefully selected so that many requests can by satisfied without overloading resources in edge servers. This paper proposes an optimized service cache policy by taking advantage of the composability of services to improve the performance of service provision systems. We conduct a series of experiments to evaluate the performance of our approach. The result shows that our approach can improve the average response time of these IoT services.","['Servers', 'Skin', 'Wireless communication', 'Time factors', 'Humidity', 'Internet of Things', 'Task analysis']","['Mobile edge computing', 'Internet of Thing', 'service provisioning', 'service composition']"
"It is essential for Vehicular Ad-hoc networks (VANETs) to have reliable vehicles for communication with vehicles. VANET is dynamical network where the vehicles frequently alter their place. Safe routing is of great essence at the time of routing process to fit in shared trust/belief involving these nodes. Occasionally, the malicious node transmits the counterfeit data amid other nodes. To find out trust/belief is deemed to be a difficult task when the malicious nodes try to distort the discovery of route or transmission of data within the network. Researchers have worked extensively to ensure a safe routing process with trust-oriented applications. We develop the framework based on trust with a fresh mechanism to determine DDoS attacks in VANET. The major trust elements in the evaluation of trust are frequency value statistics, trust hypothesis statistics, residual energy, trust policy, and data factor. Based on the trust elements, the generation of trust evaluation matrix takes place. We develop the suggested trust mechanism in an innovative manner to offer the security in a better manner by avoiding the trespassers in the network. The deterrence design by trust evaluation mechanism in combination with a clustering method is proficiently made use for the identification of the attacker and reduction of the price concerning detection method. The suggested system optimizes the utilization of a bandwidth without compromising the security of the nodes in the network.","['Denial-of-service attack', 'Computer crime', 'Routing', 'Road side unit', 'Roads']","['DDoS', 'trust evaluation', 'secure routing', 'cluster', 'intrusion prevention']"
"This paper investigates the interplay of cloud computing, fog computing, and Internet of Things (IoT) in control applications targeting the automation industry. In this context, a prototype is developed to explore the use of IoT devices that communicate with a cloud-based controller, i.e., the controller is offloaded to cloud or fog. Several experiments are performed to investigate the consequences of having a cloud server between the end device and the controller. The experiments are performed while considering arbitrary jitter and delays, i.e., they can be smaller than, equal to, or greater than the sampling period. This paper also applies mitigation mechanisms to deal with the delays and jitter that are caused by the networks when the controller is offloaded to the fog or cloud.","['Cloud computing', 'Automation', 'Delays', 'Edge computing', 'Process control', 'Computer architecture', 'Time factors']","['Industrial IoT', 'fog computing', 'cloud computing', 'industrial automation systems']"
"In this paper, novel computing paradigm by exploiting the strength of feed-forward artificial neural networks (ANNs) with Levenberg-Marquardt Method (LMM), and Bayesian Regularization Method (BRM) based backpropagation is presented to find the solutions of initial value problems (IVBs) of linear/nonlinear pantograph delay differential equations (LP/NP-DDEs). The dataset for training, testing and validation is created with reference to known standard solutions of LP/NP-DDEs. ANNs are implemented using the said dataset for approximate modeling of the system on mean squared error based merit functions, while learning of the adjustable parameters is conducted with efficacy of LMM (ANN-LMM) and BRMs (ANN-BRM). The performance of the designed algorithms ANN-LMM and ANN-BRM on IVPs of first, second and third order NP-FDEs are verified by attaining a good agreement with the available solutions having accuracy in the range from 10 -5 to 10 -8 and are further endorsed through error histograms and regression measures.","['Mathematical model', 'Differential equations', 'Integrated circuit modeling', 'Solid modeling', 'Analytical models', 'Delays', 'Backpropagation']","['Artificial neural networks', 'Levenberg-Marquardt method', 'Bayesian regularization method', 'nonlinear pantograph equation', 'regression analysis', 'intelligent computing', 'numerical computing']"
"False data injection (FDI) attacks, as a new class of cyberattacks, bring a severe threat to the security and reliable operation of the smart grid by damaging the state estimation of the power system. To address this issue, an extreme learning machine (ELM)-based one-class-one-network (OCON) framework is proposed for detecting the FDI attacks in this paper. Under this framework, to effectively detect bus-based FDI attacks and identify the bus node being attacked, the subnets of state identification layer in OCON adopt the ELM algorithm to accurately divide the false data and the normal data. After that, a global layer is employed to analyze whether the bus node associated with its corresponding subnet is attacked by false data utilizing the results from the state identification layer. Finally, in order to improve the resilience of the power system, a prediction recovery strategy is proposed to remedy the detected false data by exploiting the spatial correlation of power data. The proposed framework is tested on the IEEE 14 bus system using real load data from New York independent system operator. The simulation results demonstrate that the proposed framework not only accurately recognizes the multiple bus nodes under the FDI attacks but also efficiently recovers the data injected by false data.","['State estimation', 'Smart grids', 'Transmission line measurements', 'Meters', 'Computer crime', 'Resilience']","['Smart grid', 'false data injection (FDI) attacks', 'extreme learning machine (ELM)', 'one-class-one-network (OCON)']"
"Automatic human fall detection is one important research topic in caring for vulnerable people, such as elders at home and patients in medical places. Over the past decade, numerous methods aiming at solving the problem were proposed. However, the existing methods only focus on detecting human themselves and cannot work effectively in complicated environments, especially for the falls on furniture. To alleviate this problem, a new method for human fall detection on furniture using scene analysis based on deep learning and activity characteristics is presented in this paper. The proposed method first performs scene analysis using a deep learning method faster R-CNN to detect human and furniture. Meanwhile, the space relation between human and furniture is detected. The activity characteristics of the detected people, such as human shape aspect ratio, centroid, motion speed are detected and tracked. Through measuring the changes of these characteristics and judging the relations between the people and furniture nearby, the falls on furniture can be effectively detected. Experiment results demonstrated that our approach not only accurately and effectively detected falls on furniture, such as sofa and chairs but also distinguished them from other fall-like activities, such as sitting or lying down, while the existing methods have difficulties to handle these. In our experiments, our algorithm achieved 94.44% precision, 94.95% recall, and 95.50% accuracy. The proposed method can be potentially used and integrated as a medical assistance in health care and medical places and appliances.","['Image analysis', 'Sensors', 'Proposals', 'Machine learning', 'Shape', 'Feature extraction', 'Hidden Markov models']","['Activity characteristics', 'deep learning', 'faster R-CNN', 'human fall detection', 'medical assistance', 'scene analysis']"
"Emotion recognition has a key role in affective computing. Recently, fine-grained emotion analysis, such as compound facial expression of emotions, has attracted high interest of researchers working on affective computing. A compound facial emotion includes dominant and complementary emotions (e.g., happily-disgusted and sadly-fearful), which is more detailed than the seven classical facial emotions (e.g., happy, disgust, and so on). Current studies on compound emotions are limited to use data sets with limited number of categories and unbalanced data distributions, with labels obtained automatically by machine learning-based algorithms which could lead to inaccuracies. To address these problems, we released the iCV-MEFED data set, which includes 50 classes of compound emotions and labels assessed by psychologists. The task is challenging due to high similarities of compound facial emotions from different categories. In addition, we have organized a challenge based on the proposed iCV-MEFED data set, held at FG workshop 2017. In this paper, we analyze the top three winner methods and perform further detailed experiments on the proposed data set. Experiments indicate that pairs of compound emotion (e.g., surprisingly-happy vs happily-surprised) are more difficult to be recognized if compared with the seven basic emotions. However, we hope the proposed data set can help to pave the way for further research on compound facial emotion recognition.","['Compounds', 'Emotion recognition', 'Face recognition', 'Gold', 'Task analysis', 'Databases', 'Feature extraction']","['Dominant and complementary emotion recognition', 'compound emotions', 'fine-grained face emotion dataset']"
"Energy management in distribution systems has gained attention in recent years. Coordination of electricity generation and consumption is crucial to save energy, reduce energy prices and achieve global emission targets. Due to the importance of the subject, this paper provides a literature review on recent research on energy management systems and classifies the works based on several factors including energy management goals, the approaches taken for performing energy management and solution algorithms. Furthermore, the paper reviews some of the most proficient techniques and methodologies adopted or developed to address energy management problem and provides a table to compare such techniques. The current challenges and limitations of energy management systems are explained and some future research directions have been provided at the end of the paper.","['Energy management', 'Power distribution', 'Load modeling', 'Optimization', 'Generators', 'Bibliographies', 'Energy storage']","['Energy management', 'load management', 'power distribution', 'data analysis', 'smart grids', 'energy storage', 'wind energy', 'solar energy', 'energy storage', 'electric vehicles']"
"The Internet of Things (IoT) provides a new paradigm for the development of heterogeneous and distributed systems, and it has increasingly become a ubiquitous computing service platform. However, due to the lack of sufficient computing and storage resources dedicated to the processing and storage of huge volumes of the IoT data, it tends to adopt a cloud-based architecture to address the issues of resource constraints. Hence, a series of challenging security and trust concerns have arisen in the cloud-based IoT context. To this end, a novel trust assessment framework for the security and reputation of cloud services is proposed. This framework enables the trust evaluation of cloud services in order to ensure the security of the cloud-based IoT context via integrating security- and reputation-based trust assessment methods. The security-based trust assessment method employs the cloud-specific security metrics to evaluate the security of a cloud service. Furthermore, the feedback ratings on the quality of cloud service are exploited in the reputation-based trust assessment method in order to evaluate the reputation of a cloud service. The experiments conducted using a synthesized dataset of security metrics and a real-world web service dataset show that our proposed trust assessment framework can efficiently and effectively assess the trustworthiness of a cloud service while outperforming other trust assessment methods.","['Security', 'Cloud computing', 'Quality of service', 'Internet of Things', 'Measurement', 'Computer architecture', 'Big Data']","['Cloud-based IoT', 'cloud service trust assessment', 'security and reputation assessment', 'trustworthy cloud service selection']"
"Blockchain technology is among the most significant developments and revolutionary innovations of the Information Technology industry. It corners a crucial space in the present digital era and has already made significant differences in human life. Moreover, it is anticipated that the Blockchain technology will improvise the existing IT facilities in the next several years in many domains. Recent technological developments are allowing for a major advancement in Healthcare sectors. Information security and accessibility are critical considerations for the integration and communication with Electronic Healthcare Record (EHR) systems when sharing private medical information. In this context, selecting the most effective blockchain model for secure and trustworthy EHRs in the healthcare sector requires an accurate mechanism for evaluating the impact of different available blockchain models for its features. The present study uses a scientifically proven approach for evaluating the impact of blockchain technology and provides a novel idea and path to the future researchers. This research analysis garnered the feedback of 56 domain experts in the healthcare management for assessing the impact of different blockchain models. To eliminate the ambiguities that arose due to multiple opinions of these experts and for the externalization and organization of information about the selection context of the blockchain model, the study used a decision model. Fuzzy Analytic Analytical Network Process (F-ANP) method was used to calculate the weights of the criteria as well as the Fuzzy-Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) technique was used to evaluate the effect of alternative solutions. Further, the results obtained through this empirical investigation will be an instrumental reference for choosing the most appropriate Blockchain model for maintaining breach-free EHRs.","['Decision making', 'Electronic healthcare', 'Context modeling', 'Technological innovation', 'Industries']","['Blockchain', 'decision making', 'fuzzy logic', 'healthcare blockchain', 'health and safety']"
"Telemedicine offers a medical-on-demand (MoD) service from a distance. This technology is designed to overcome distance barriers and improve the process of accessing medical services in distant rural communities. With the development of cloud computing, the MoD services in the telemedicine system are provided by the Cloud Service Provider (CSP). This CSP connects the patient and the medical staff in different places with both convenience and fidelity. Meanwhile, the outsourcing healthcare data on public cloud platforms bring some new challenges on the security. Although attribute-based encryption (ABE) algorithm realizes flexible and fine-grained access control, a large number of patients subscribe or unsubscribe the different medical services frequently in the cloud, which takes a huge cost for membership management. In this paper, an ABE scheme is presented to achieve the dynamic authentication and authorization with higher flexibility and efficiency for the MoD services in telemedicine system. On the one hand, when the patient alters his ordered service, it requires no updating on the parameters for those whose statuses remain unchanged. We construct an independent-update key policy ABE scheme in the distributed telemedicine system that aims to updates patient's keys separately, and there are multiple authorities to manage this system altogether which is more similar to the real situation. On the other hand, by using blockchain and distributed database technologies, the private healthcare data stored in public cloud is protected in integrity, which avoids the misdiagnosis accident from the inaccurate electronic health records distorted by a malicious user or authority from the inner cloud. Finally, we analyze the collusion attack in multiple authorities and formally prove the security of this protocol in a standard model. After comparing and simulating, the results of this work show a better performance.","['Cloud computing', 'Medical services', 'Telemedicine', 'Blockchain', 'Cryptography', 'Medical diagnostic imaging']","['Attribute-based encryption', 'blockchain', 'independent-update', 'multi-authority', 'medical on demand']"
"Brain cancer is one of the most dominant causes of cancer death; the best way to diagnose and treat brain tumors is to screen early. Magnetic Resonance Imaging (MRI) is commonly used for brain tumor diagnosis; however, it is a challenging problem to achieve higher accuracy and performance, which is a vital problem in most of the previously presented automated medical diagnosis. In this paper, we propose a Hybrid Two-Track U-Net(HTTU-Net) architecture for brain tumor segmentation. This architecture leverages the use of Leaky Relu activation and batch normalization. It includes two tracks; each one has a different number of layers and utilizes a different kernel size. Then, we merge these two tracks to generate the final segmentation. We use the focal loss, and generalized Dice (GDL), loss functions to address the problem of class imbalance. The proposed segmentation method was evaluated on the BraTS'2018 datasets and obtained a mean Dice similarity coefficient of 0.865 for the whole tumor region, 0.808 for the core region and 0.745 for the enhancement region and a median Dice similarity coefficient of 0.883, 0.895, and 0.815 for the whole tumor, core and enhancing region, respectively. The proposed HTTU-Net architecture is sufficient for the segmentation of brain tumors and achieves highly accurate results. Other quantitative and qualitative evaluations are discussed, along with the paper. It confirms that our results are very comparable expert human-level performance and could help experts to decrease the time of diagnostic.","['Tumors', 'Magnetic resonance imaging', 'Kernel', 'Image segmentation', 'Computer architecture', 'Convolution', 'Cancer']","['Brain tumor segmentation', 'deep neural networks', 'U-net', 'fully convolutional network', 'BraTS’2018 challenge']"
"A wearable fabric CPW antenna is presented for medical body area network (MBAN) applications at 2.4 GHz based on an electromagnetic bandgap design and frequency selective surface (EBG-FSS). Without EBG-FSS, the basic antenna has an omnidirectional radiation pattern, and when operated close to human tissue, the performance and efficiency degrade, and there is a high specific absorption rate. To overcome this problem, the antenna incorporates EBG-FSS, which reduces the backward radiation, with SAR reduced by 95%. The gain is improved to 6.55 dBi and the front-to-back ratio is enhanced by 13 dB compared to the basic antenna. The overall dimensions of the integrated design are 60 × 60 × 2.4 mm 3 . Simulation and experimental studies reveal that the antenna integrated with EBG-FSS can tolerate loading by human tissue as well as bending. Thus, the design is a good candidate for MBAN applications.","['Antennas', 'Periodic structures', 'Metamaterials', 'Coplanar waveguides', 'Inductance', 'Substrates', 'Mathematical model']","['AMC', 'EBG', 'SAR', 'wearable fabric antennas']"
